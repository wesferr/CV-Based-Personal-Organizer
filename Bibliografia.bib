@inproceedings{NoAuthor2013,
abstract = {his paper presents a low-cost and natural Kinect-based Human-Computer Interaction system using 3D pointing gesture that assists visually impaired persons to navigate in indoor environments. Kinect is a state-of-art stereo-camera that plugs into the USB port of a standard computer, and comes with Microsoft developed SDK to facilitate application development. The proposed system will provide necessary information on the object that the user is pointing at, such as its distance from the user's hand and the locations of nearby objects, from a database that is manually updated beforehand. The system is designed to help visually impaired persons to get used to a new indoor environment and explores the potential for applying Kinect to assistive technology in a broader way.},
annote = {cited By 2},
booktitle = {ISSNIP Biosignals and Biorobotics Conference, BRC},
doi = {10.1109/BRC.2013.6487535},
isbn = {9781467330244},
issn = {23267771},
keywords = {Assistive Technology,Human-Computer Interaction,Kinect,Object Navigation,Pointing Gesture},
month = {feb},
pages = {1--6},
publisher = {IEEE},
title = {{Real-time 3D pointing gesture with Kinect for object-based navigation by the visually impaired}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876767680{\&}doi=10.1109{\%}2FBRC.2013.6487535{\&}partnerID=40{\&}md5=0d0de2caa4d008bf0a45e1076014735f http://ieeexplore.ieee.org/document/6487535/},
year = {2013}
}
@inproceedings{Abdalla2007810,
abstract = {This paper presents the concept of extracting information from a moving object using a fixed camera in an enclosed environment in order to extract some of the image attributes. The work relies on tracking a single object in an indoor environments and the knowledge extraction of a particular object is based on three preset measurement tools. The first tool is pixel location retrieval by calculating the center of mass for the object of interest. Second attribute extraction is based on the time spend by object of interest in each frame and in each predefined zones. Finally the third measurement approach is achieved by calculating the pixel frequency distribution of the object. This work form a precursor to identifying intruder (or any interested moving object) based on pixel activity using fixed angle view video images. {\textcopyright}2007 IEEE.},
annote = {cited By 1},
author = {Abdalla, A A and Asirvadam, V S and Sebastian, P},
booktitle = {2007 International Conference on Intelligent and Advanced Systems, ICIAS 2007},
doi = {10.1109/ICIAS.2007.4658499},
keywords = {Attribute extractions; Center of masses; Extracti,Cameras; Image segmentation; Pixels,Image processing},
pages = {810--814},
title = {{Mining moving object attributes based on pixel location for fixed camera}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-58049116090{\&}doi=10.1109{\%}2FICIAS.2007.4658499{\&}partnerID=40{\&}md5=91671240b9771f38dca12cf0d73f5e7b},
year = {2007}
}
@inproceedings{Abdallah20062429,
abstract = {The indoor tracking and tracing system is a new method that allows indoor tracking and tracing. The system is able to follow up the movement of the tracked object and determines the exact location. It can be widely used in prisons, secured companies and monitored closed areas. The Indoor Tracking and Tracing System is composed of a small mobile system that can be traced using fixed stations, the object being traced is plotted on a map on the screen of a computer using intelligent software. {\textcopyright} 2006 IEEE.},
annote = {cited By 0},
author = {Abdallah, A},
booktitle = {Proceedings - 2006 International Conference on Information and Communication Technologies: From Theory to Applications, ICTTA 2006},
doi = {10.1109/ICTTA.2006.1684787},
keywords = {Follow up; Indoor tracking; Intelligent software;},
pages = {2429--2433},
title = {{A new method for indoor tracking and tracing system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961872425{\&}doi=10.1109{\%}2FICTTA.2006.1684787{\&}partnerID=40{\&}md5=89227810dda2e0a3dab35f9ccf32614c},
volume = {2},
year = {2006}
}
@inproceedings{7141254,
abstract = {Radio Frequency Identification (RFID) system has shown remarkable progress, especially in identifying, locating, or tracking objects. Some of the existing challenges include improving position estimation beyond RFID coverage. Following a brief introduction, an analysis of the new requirements of the indoor location system-based RFID and a system prototype is presented. To this end, this research proposed a combination of ZigBee-based RFID; the system consists of multi-hop tags that can communicate with many wireless devices not limited to readers and long-range reader based on an active RFID technology integration with wireless transceivers in a self-healing mesh network using the IEEE 802.15.4-protocol. The system design focuses on many aspects such as: standard compliance with the IEEE 802.15.4 protocol, recognition of multiple tags faster than the collision resolution, and achievement of a long communication range to communicate with tags.},
author = {Abdulla, R},
booktitle = {International Conference on Frontiers of Communications, Networks and Applications (ICFCNA 2014 - Malaysia)},
doi = {10.1049/cp.2014.1428},
keywords = {data communication;protocols;radio transceivers;ra},
month = {nov},
pages = {1--6},
title = {{A conceptual study of long range active RFID system for reliable data communication}},
year = {2014}
}
@article{Abdullah2019499,
abstract = {Radio Frequency Identification (RFID) is an automatic identification technology that can track and identify people, animals, and objects. It uses the radio frequency signal to send data from RFID reader to RFID tags. A common RFID system will involve RFID tag, RFID reader, and antenna as its components. Nowadays, RFID technology has been widely used for indoor positioning especially for the smart shelf in locating and tracking the object on the shelf. But, the existing smart shelf needs more than four antenna and more than two readers to increase the accuracy of locating the location and position of the misplaced item at the certain covered area. This research paper will compare a few algorithms which are Fingerprinting (Block Distance), Trilateration (Least Square Estimate) and Trilateration (Two-Border) to show the different accuracy among them and to increase the accuracy in locating the exact position of missing object by using Real Time Locating System (RTLS) by proposing a new algorithm. Besides, Received Signal Strength Indication (RSSI) is the chosen method of getting data from different points of the shelf to find the location of the missing object on the shelf. This indoor positioning use reference tag technique to get the RSSI data from the shelf. Thus, we can identify the missing object and detect if there is misplaced object occur or track the real-time location of the object. {\textcopyright} Springer Nature Switzerland AG 2019.},
annote = {cited By 0},
author = {Abdullah, W.N.F.W. and {Mohd. Arshad}, M R and Karkonasasi, K and Mousavi, S A and Mohamed, H},
doi = {10.1007/978-3-319-99007-1_47},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Algorithms; Antennas; Automation; Indoor positioni,Indoor positioning; Reference tags; RSSI; RTLS; S,Radio frequency identification (RFID)},
pages = {499--509},
title = {{RFID smart shelf based on reference tag technique}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053874048{\&}doi=10.1007{\%}2F978-3-319-99007-1{\_}47{\&}partnerID=40{\&}md5=d666fedf91cc8e6120312044f2edebb0},
volume = {843},
year = {2019}
}
@inproceedings{Abrahamson1999128,
abstract = {Metal and nonmetal objects, buried to a selected depth in dry sand in an indoor sandbox, are illuminated by an impulse radar system playing the role of a ground penetrating radar (GPR). The recorded time-series data of backscattered echoes from these targets are analyzed in the joint time-frequency domain using a pseudo-Wigner distribution (PWD). These distributions with their extracted features in the two-dimensional time-frequency domain are viewed as the target signatures. We have previously demonstrated the usefulness of the PWD for target identification purposes, in particular the merits of the PWD relative to various competing time-frequency distributions for targets buried at different depths. We have also used a classification method developed from the fuzzy C-means (FCM) clustering technique to reduce the number and kind of features in the PWD signature templates. This is accomplished by converting the PWD signature into a representation by a cluster of points associated with a weight and then reducing the cluster to a number of (weightless) cluster centers. We investigate here how the selected number of cluster centers and the choice of a governing parameter in the FCM algorithm influence the target recognition capability of the resulting signature representations. The classification algorithm is tested against validation data taken from an additional set of returned echoes. The same targets are used but they are buried at a different location in the sand. Class membership of a target is then decided using a simple metric. The results of our investigation serve to assess the possibility of identifying subsurface targets using a GPR, by means of the present technique.},
annote = {cited By 10},
author = {Abrahamson, S and Ericsson, A and Gustafsson, A and Strifors, H C and Gaunaurd, G C},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
keywords = {Algorithms; Feature extraction; Frequency domain a,Fuzzy C-means (FCM) clustering methods; Ground pe,Object recognition},
pages = {128--139},
title = {{Comparison of fuzzy-cluster based time-frequency signatures for automatic classification of underground mine-like targets}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032671663{\&}partnerID=40{\&}md5=9a1d22dd73eafa7f45562e6822c1ce42},
volume = {3718},
year = {1999}
}
@inproceedings{Acampora201581,
abstract = {Ambient Assisted Living (AAL) is considered as the main technological solution that will enable the aged and people in recovery to maintain their independence and a consequent high quality of life for a longer period of time than would otherwise be the case. This goal is achieved by monitoring human's activities and deploying the appropriate collection of services to set environmental features and satisfy user preferences in a given context. However, both human monitoring and services deployment are particularly hard to accomplish due to the uncertainty and ambiguity characterising human actions, and heterogeneity of hardware devices composed in an AAL system. This research addresses both the aforementioned challenges by introducing 1) an innovative system, based on Self Organising Feature Map (SOFM), for automatically classifying the resting location of a moving object in an indoor environment and 2) a strategy able to generate context-aware based Fuzzy Markup Language (FML) services in order to maximize the users' comfort and hardware interoperability level. The overall system runs on a distributed embedded platform with a specialised ceiling-mounted video sensor for intelligent activity monitoring. The system has the ability to learn resting locations, to measure overall activity levels, to detect specific events such as potential falls and to deploy the right sequence of fuzzy services modelled through FML for supporting people in that particular context. Experimental results show less than 20{\%} classification error in monitoring human activities and providing the right set of services, showing the robustness of our approach over others in literature with minimal power consumption. {\textcopyright} 2014 IEEE.},
annote = {cited By 2},
author = {Acampora, G and Appiah, K and Hunter, A and Vitiello, A},
booktitle = {IEEE SSCI 2014 - 2014 IEEE Symposium Series on Computational Intelligence - IA 2014: 2014 IEEE Symposium on Intelligent Agents, Proceedings},
doi = {10.1109/IA.2014.7009462},
keywords = {Ambient assisted living; Ambient assisted living,Conformal mapping; Hardware; Intelligent agents; I,Location based services},
pages = {81--88},
title = {{Interoperable services based on activity monitoring in Ambient Assisted Living environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925336636{\&}doi=10.1109{\%}2FIA.2014.7009462{\&}partnerID=40{\&}md5=9d8a7733c3ee732889ed7f8850ac30e6},
year = {2015}
}
@inproceedings{Adan2011343,
abstract = {Laser scanners are increasingly used to create semantically rich 3D models of buildings for civil engineering applications such as planning renovations, space usage planning, and building maintenance. Currently these models are created manually - a time-consuming and error-prone process. This paper presents a method to automatically convert the raw 3D point data from a laser scanner positioned at multiple locations throughout a building into a compact, semantically rich model. Our algorithm is capable of identifying and modeling the main structural components of an indoor environment (walls, floors, ceilings, windows, and doorways) despite the presence of significant clutter and occlusion, which occur frequently in natural indoor environments. Our method begins by extracting planar patches from a voxelized version of the input point cloud. We use a conditional random field model to learn contextual relationships between patches and use this knowledge to automatically label patches as walls, ceilings, or floors. Then, we perform a detailed analysis of the recognized surfaces to locate windows and doorways. This process uses visibility reasoning to fuse measurements from different scan locations and to identify occluded regions and holes in the surface. Next, we use a learning algorithm to intelligently estimate the shape of window and doorway openings even when partially occluded. Finally, occluded regions on the surfaces are filled in using a 3D inpainting algorithm. We evaluated the method on a large, highly cluttered data set of a building with forty separate rooms yielding promising results.},
annote = {cited By 27},
author = {Adan, A and Xiong, X and Akinci, B and Huber, D},
booktitle = {Proceedings of the 28th International Symposium on Automation and Robotics in Construction, ISARC 2011},
keywords = {3-d modeling; 3-D point data; 3D models; Automatic,Architectural design; Buildings; Civil engineerin,Three dimensional},
pages = {343--348},
title = {{Automatic creation of semantically rich 3D building models from laser scanner data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861543196{\&}partnerID=40{\&}md5=6cd80af29d02578f0736af4f04fd057f},
year = {2011}
}
@inproceedings{Afghantoloee2018,
abstract = {Mobility of people with disabilities is one of the most important challenges for their social integration. There have been significant effort to develop assistive technologies to guide the PWD during their mobility in recent years. However, these technologies have limitations when it comes to the navigation and guidance of these people through accessible routes. This is specifically problematic in indoor environments where detection, location and tracking of people, and other dynamic objects that may limit the mobility of these people, are very challenging. Thus, many researches have leveraged the use of sensors to track users and dynamic objects in indoor environments. However, in most of the described methods, the sensors are manually deployed. Due to the complexity of indoor environments, the diversity of sensors and their sensing models, as well as the diversity of the profiles of people with disabilities and their needs during their mobility, the optimal deployment of a sensor network is a challenging task. There exist several optimization methods to maximize coverage and minimize the number of sensors while maintaining the minimum connectivity between the sensor nodes in a network. Most of the current sensor network optimization methods oversimplify the environment and do not consider the complexity of 3D indoor environments. In this paper, we propose a novel 3D local optimization algorithm based on a geometric spatial data structure that takes into account some of these complexities for the purpose of helping PWD in their mobility in 3D indoor environments such as shopping centers, museums and other public buildings. {\textcopyright} Ali Afghantoloee and Mir Abolfazl Mostafavi.},
annote = {cited By 0},
author = {Afghantoloee, A and Mostafavi, M A},
booktitle = {Leibniz International Proceedings in Informatics, LIPIcs},
doi = {10.4230/LIPIcs.GIScience.2018.19},
keywords = {Assistive technology; Local optimization algorith,Complex networks,Geographic information systems; Sensor networks; S},
title = {{Towards optimal deployment of a sensor network in a 3D indoor environment for the mobility of people with disabilities}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051358329{\&}doi=10.4230{\%}2FLIPIcs.GIScience.2018.19{\&}partnerID=40{\&}md5=9328d54d0bd97d0e640faa0de91da609},
volume = {114},
year = {2018}
}
@inproceedings{Agrawal2013137,
abstract = {Indoor Positioning Systems (IPSs) are emerging computing systems that can locate objects or people inside indoor environment. This technology shows assurance for future mobile apps that can be used in malls, museums, hospitals, airports and college campuses for self localization. Despite advances in Global Positioning System (GPS) technology, indoor spaces are still out of reach of satellites. GPS signals are not designed to penetrate most construction materials. An IPS relies on nearby anchors or landmarks, and uses various sensing schemes including artificial vision, Wi-Fi, Bluetooth, Camera images etc. In this paper, we present a system that leverages the camera and Wi-Fi present in the smart phones carried by users, to track them as they traverse in indoor environments. It makes use of a radio map of an indoor environment. A significant challenge that our system surmounts is to estimate user's position without any prior user-specific knowledge, such as the user's initial location. The results obtained after conducting simulations demonstrate the validity and suitability of the proposed algorithm to provide a high performance level in terms of positional accuracy and scalability. {\textcopyright} 2013 IEEE.},
annote = {cited By 2},
author = {Agrawal, L and Toshniwal, D},
booktitle = {Proceedings of the 2013 13th International Conference on Computational Science and Its Applications, ICCSA 2013},
doi = {10.1109/ICCSA.2013.28},
keywords = {Cameras; Global system for mobile communications;,Computing system; Indoor environment; Indoor posi,Global positioning system},
pages = {137--143},
title = {{Smart phone based indoor pedestrian localization system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893214987{\&}doi=10.1109{\%}2FICCSA.2013.28{\&}partnerID=40{\&}md5=7841b5dcac315c54be6a9d2f56d9c460},
year = {2013}
}
@article{Agustin2011244,
abstract = {The proposed system estimates the number of people in indoor or outdoor location. A background model of the scene is constructed to detect moving objects (people) in a video stream. Detected foreground objects are preprocessed to eliminate pixel noise and small artifacts by performing opening morphology operation in the foreground image. Counting persons in the occluded foreground object is estimated by counting the human blobs by estimating the grid size. The accurately normalized and calibrated reference grid model is necessary for the grid estimation. {\textcopyright} 2011 Springer-Verlag.},
annote = {cited By 1},
author = {Agustin, O C and Oh, B.-J.},
doi = {10.1007/978-3-642-27192-2_29},
journal = {Communications in Computer and Information Science},
keywords = {Background model; Foreground images; Foreground ob,Communication; Detector circuits; Information tec,Estimation},
number = {PART 1},
pages = {244--253},
title = {{People counting using object detection and grid size estimation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-83755185989{\&}doi=10.1007{\%}2F978-3-642-27192-2{\_}29{\&}partnerID=40{\&}md5=c327c26c5f0506db1c52eb919a0eca71},
volume = {265 CCIS},
year = {2011}
}
@phdthesis{Ahmed:2010:RMF:2338077,
address = {Atlanta, GA, USA},
annote = {AAI3464035},
author = {Ahmed, Nova},
isbn = {978-1-124-75885-5},
publisher = {Georgia Institute of Technology},
title = {{Reliable Middleware Framework for Rfid System}},
year = {2010}
}
@inproceedings{Ahmed20151435,
abstract = {While in the near future everything will be tagged with Radio Frequency Identification (RFID) tags, the localization of these tags in their environment is becoming an important feature for many RFID-based ubiquitous computing applications. The problem being tackled here relates to the problem of object location in wireless sensor networks, it is a specific problem in localization. Localization primarily refers to the detection coordinates of a node or an object. This work presents an approach named multidimensional scaling for estimating the location of unknown RFID tags, within the area to facilitate locating all tags in a RFID network and reduce the localization cost and environment complexity. It measures the distances between the reader and tags using the log normal distance path loss propagation model for indoor environment based on Received Signal Strength (RSS) measurement. The main advantage of this technique is reduction the number of expensive RFID readers and it can better tolerate noises. However, signals in indoor environments are generally harshly impaired because of multipath propagation and the variable factors in the surrounding environment, resulting in the tags have very limited capabilities which pose many challenges for positioning them. This work presents also the effect of propagation parameters on the localization accuracy by varying these parameters to observe the probability distribution of estimated distance, where the propagation parameters in indoor environments make working with signal strength measurements challenging. {\textcopyright} 2015 IEEE.},
annote = {cited By 2},
author = {Ahmed, R and Avaritsiotis, J N},
booktitle = {Proceedings of the 2015 Science and Information Conference, SAI 2015},
doi = {10.1109/SAI.2015.7237336},
keywords = {Communication channels (information theory); Compl,Computing applications; Environment complexity; M,Radio frequency identification (RFID)},
pages = {1435--1439},
title = {{The propagation parameters on RFID-localization accuracy}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957831430{\&}doi=10.1109{\%}2FSAI.2015.7237336{\&}partnerID=40{\&}md5=3db978fd4c28932548f0870d0831618f},
year = {2015}
}
@article{Ahmed:2017:RDP:3151123.3151126,
address = {New York, NY, USA},
author = {Ahmed, Tanvir and Calders, Toon and Lu, Hua and Pedersen, Torben Bach},
doi = {10.1145/3151123.3151126},
issn = {1946-7729},
journal = {SIGSPATIAL Special},
number = {2},
pages = {11--18},
publisher = {ACM},
title = {{Risk Detection and Prediction from Indoor Tracking Data}},
url = {http://doi.acm.org/10.1145/3151123.3151126},
volume = {9},
year = {2017}
}
@inproceedings{Ahn2018317,
abstract = {Currently, geospatial datasets are produced in various models and formats in accordance with the spatial scale of the real world such as ground/ surface/underground or indoor/outdoor. The location-based services application also uses the optimal data model and format for each purpose. Therefore, there are various geospatial dataset for representing features of the same space. Various geospatial data on same object cause problems with the financial problems and the suitability of the data. In the paper, we reviewed how to integrate existing geospatial data to utilize geospatial data constructed in different models and formats. There are four main ways to fuse existing geospatial information. The existing geospatial data fusion methods consist of a method through geometry data conversion, a method through the aspect of visualization, a method based on attribute data, and a method using topological relationships. Based on this review, we defined a geospatial data fusion method on topological relationships, which is a method considering topological relationship between geospatial objects. In this method, the topological relationship of objects uses the basic concept of IndoorGML. {\textcopyright} Authors 2018. CC BY 4.0 License.},
annote = {cited By 0},
author = {Ahn, D S and Park, J H and Lee, J Y},
booktitle = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
doi = {10.5194/isprs-archives-XLII-4-W9-317-2018},
keywords = {Anchor nodes; Financial problems; Geo-spatial inf,Data fusion; Data handling; Data visualization; Lo,Topology},
number = {4/W9},
pages = {317--319},
title = {{Defining geospatial data fusion methods based on topological relationships}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057603898{\&}doi=10.5194{\%}2Fisprs-archives-XLII-4-W9-317-2018{\&}partnerID=40{\&}md5=4905d020f8b06ab4050c548be03dd383},
volume = {42},
year = {2018}
}
@inproceedings{Ahn200865,
abstract = {This paper presents wireless localization networks for locating stationary object in an indoor office environment. Actual experimental test results based on UWB (IEEE 802.15.4a), WLAN (IEEE 802.11), and ZigBee (IEEE 802.15.4) are briefly presented and advantages and disadvantages of each method are also addressed. A new method based on received-signal strength index (RSSI) of radio signals emitted from fixed reference nodes is outlined. In the new method, mobile reference tags are used to detect signal strength accurately so that reliable signal propagation model can be produced. {\textcopyright} 2008 IEEE.},
annote = {cited By 10},
author = {Ahn, H.-S. and Wonpil, Y},
booktitle = {2008 IEEE/ASME International Conference on Mechatronics and Embedded Systems and Applications, MESA 2008},
doi = {10.1109/MESA.2008.4735721},
keywords = {Embedded systems; Encoding (symbols); Integrated c,Experimental tests; Ieee 802.11; Ieee 802.15.4a;,Wireless sensor networks},
pages = {65--70},
title = {{Wireless localization networks for indoor service robots}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-60749099754{\&}doi=10.1109{\%}2FMESA.2008.4735721{\&}partnerID=40{\&}md5=40680520f0f21fdf9515944fc010d16c},
year = {2008}
}
@article{Ahn201197,
abstract = {In this paper an inexpensive, low-power and scalable location system for mobile objects under indoor environments, ScaleLoc, is proposed and its performance is evaluated by simulation. IEEE 802.15.4a (Chirp spread spectrum) protocol is adopted and the location of a target is determined with trilateration. As the number of mobile objects increases, the performance may deteriorate due to communication collisions. For graceful degradation and system scalability, an arbitration scheme is adopted. Sufficient information for localization such as the node-ids and locations of reference nodes is supplied by arbitration nodes. {\textcopyright} 2011 Springer-Verlag.},
annote = {cited By 1},
author = {Ahn, S.-Y. and Kim, J.-H. and Park, J.-S. and Oh, H.-R. and Seong, Y R},
doi = {10.1007/978-3-642-24106-2_13},
journal = {Communications in Computer and Information Science},
keywords = {Chirp spread spectrum; Graceful degradation; IEEE,Discrete event simulation; Spectroscopy; Standard,Information technology},
pages = {97--103},
title = {{ScaleLoc: A scalable real-time locating system for moving targets}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053438989{\&}doi=10.1007{\%}2F978-3-642-24106-2{\_}13{\&}partnerID=40{\&}md5=638da0c0f7a14e34c2f822c302940817},
volume = {206 CCIS},
year = {2011}
}
@inproceedings{Aida2014207,
abstract = {As schemes for indoor positioning of persons and objects using near field communication and/or visible light communication come closer to reality, expectations are centering on the spread of indoor location-based services. A problem with these schemes is that they are costly because special equipment is often required for transmission and reception. As relative positioning schemes by controlling illuminance and color temperature of existing indoor lighting, this study proposes those using luminance and color temperature. Relative positioning schemes using luminance and color temperature rapidly estimate a relative position by switching multiple lighting patterns of a ceiling lighting system. By gradually adjusting luminance and color temperature for different locations, positioning is possible on the basis of the degree of change in sensed values. We implemented this relative positioning scheme using luminance and color temperature and evaluated the relation between the Euclidean distance and the real distance between sensors in a real space simulating an office. As a result, it was clarified that there was a correlation between the Euclidean distance and the real distances between sensors in 5 stages. {\textcopyright} 2014 IEEE.},
annote = {cited By 1},
author = {Aida, H and Ichikawa, H and Okada, M and Miki, M},
booktitle = {Proceedings - 2014 10th International Conference on Mobile Ad-Hoc and Sensor Networks, MSN 2014},
doi = {10.1109/MSN.2014.35},
keywords = {Color temperatures; Euclidean distance; Indoor po,Color; Indoor positioning systems; Lighting; Locat,Luminance},
pages = {207--212},
title = {{Indoor relative positioning scheme using illuminance and color temperature}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946531519{\&}doi=10.1109{\%}2FMSN.2014.35{\&}partnerID=40{\&}md5=eaccbb77118f8e62509e1901a4e22be5},
year = {2014}
}
@inproceedings{Aider2002460,
abstract = {An efficient and simple method for matching image features to a model is presented. It is designed to indoor mobile robot self-location. It is a two stage method based on interpretation tree search approach and using straight line correspondences. In the first stage a set of matching hypothesis is generated. Exploiting the specificity of the mobile robotics context, the global interpretation tree is divided into two sub-trees and then two geometric constraints are defined directly on 2D-3D correspondences in order to improve pruning and search efficiency. In the second stage, the pose is calculated for each matching hypothesis and the best one is selected according to a defined error function. Test results illustrate the performances of the approach.},
annote = {cited By 9},
author = {Aider, O A and Hoppenot, P and Colle, E},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
keywords = {Algorithms; Cameras; Mobile robots; Object recogni,Feature matching; Model-based localisation; Visio,Pattern matching},
pages = {460--465},
title = {{A model to image straight line matching method for vision-based indoor mobile robot self-location}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036448782{\&}partnerID=40{\&}md5=1b7275544f0f5e280fa20cbab40e1424},
volume = {1},
year = {2002}
}
@inproceedings{Ajmat2011195,
abstract = {Worldwide museums have in common the intention of "telling a story", this intention is beyond value and size of the displayed pieces, its geographical location or the quantity of people that visit them. In this perspective, light fulfils a highly regarded double role: to reveal the object itself (physiological function) and "to generate ambience" (significance function) where the statement is produced and, therefore, it takes part of the statement in an implicit form. However, lighting together with other environmental conditions (like temperature and humidity), can modify objects' properties significantly throughout their exhibition time, leading to deterioration. Therefore there is always a dilemma to solve: Exhibition versus Preservation. High standards of preservation may lead to poor conditions of exhibition. On the other hand, a stimulating ambience for exhibition may expose valuable objects to lower preservation standards. This paper explores the relationship between the exhibition of artwork or historical pieces in museums and the role of lighting and other environmental conditions as generator of an ambience where a story is told. It presents surveys carried out in museums in Argentina and Spain under diverse indoor conditions. An evaluation is presented of the influence of daylighting and lighting design in museums and its relationship with other environmental conditions in the quality of exhibitions. Conclusions include recommendations for museum administrators about lighting in the exhibition of vulnerable pieces in museums. {\textcopyright} 2011 WIT Press.},
annote = {cited By 3},
author = {Ajmat, R and Sandoval, J and {Arana Sema}, F and O'Donell, B and Gor, S and Alonso, H},
booktitle = {WIT Transactions on the Built Environment},
doi = {10.2495/STR110171},
keywords = {Argentina; Environmental conditions; Geographical,Argentina; Spain,Conservation; Daylighting; Lighting; Maintenance;,Exhibitions,design; environmental conditions; geographical re},
pages = {195--206},
title = {{Lighting design in museums: Exhibition vs. preservation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855760196{\&}doi=10.2495{\%}2FSTR110171{\&}partnerID=40{\&}md5=179362c1e8ffc8bb786d116ef3933c6f},
volume = {118},
year = {2011}
}
@article{Akram201838251,
abstract = {Indoor localization has garnered the attention of researchers over the past two decades due to diverse and numerous applications. The existing works either provide room-level or latitude-longitude prediction instead of a hybrid solution, catering only to specific application needs. This paper proposes a new infrastructure-less, indoor localization system named HybLoc using Wi-Fi fingerprints. The system employs Gaussian Mixture Model (GMM)-based soft clustering and Random Decision Forest (RDF) ensembles for hybrid indoor localization i.e., both room-level and latitude-longitude prediction. GMM-based soft clustering allows finding natural data subsets helping cascaded classifiers better learn underlying data dynamics. The RDF ensembles enhance the capabilities of decision trees providing better generalization. A publically available Wi-Fi fingerprints data set UJIIndoorLoc (multi-floor and multi-building) has been used for experimental evaluation. The results describe the potential of HybLoc to provide the hybrid location of user viz a viz the reported literature for both levels of prediction. For room estimation, HybLoc has demonstrated mean 85{\%} accuracy, 89{\%} precision as compared with frequently used k Nearest Neighbors (kNN) and Artificial Neural Network (ANN)-based approaches with 56{\%} accuracy, 60{\%} precision and 42{\%} accuracy, 48{\%} precision, respectively, averaged over all buildings. We also compared HybLoc performance with baseline Random Forest providing 79{\%} accuracy and 82{\%} precision which clearly demonstrates the enhanced performance by HybLoc. In terms of latitude-longitude prediction, HybLoc, kNN, ANN, and baseline Random Forest had 6.29 m, 8.1 m, 180.7 m, and 10.2 m mean error over complete data set. We also present useful results on how number of samples and missing data replacement value affect the performance of the system. {\textcopyright} 2013 IEEE.},
annote = {cited By 2},
author = {Akram, B A and Akbar, A H and Shafiq, O},
doi = {10.1109/ACCESS.2018.2852658},
journal = {IEEE Access},
keywords = {Big data applications; Decision forest; Ensemble,Big data; Classification (of information); Decisio,Indoor positioning systems},
pages = {38251--38272},
title = {{HybLoc: Hybrid indoor wi-fi localization using soft clustering-based random decision forest ensembles}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049472175{\&}doi=10.1109{\%}2FACCESS.2018.2852658{\&}partnerID=40{\&}md5=8b8223591126fe59bc129cfaa4cbc202},
volume = {6},
year = {2018}
}
@inproceedings{Aksu:2008:RLE:1410012.1410036,
address = {New York, NY, USA},
author = {Aksu, Aylin and Kabara, Joseph and Spring, Michael B},
booktitle = {Proceedings of the First ACM International Workshop on Mobile Entity Localization and Tracking in GPS-less Environments},
doi = {10.1145/1410012.1410036},
isbn = {978-1-60558-189-7},
keywords = {indoor location estimation,neural networks},
pages = {103--108},
publisher = {ACM},
series = {MELT '08},
title = {{Reduction of Location Estimation Error Using Neural Networks}},
url = {http://doi.acm.org/10.1145/1410012.1410036},
year = {2008}
}
@inproceedings{Al-Ammar2014245,
abstract = {The user location information represents a core dimension as understanding user context is a prerequisite for providing human-centered services that generally improve quality of life. In comparison with outdoor environments, sensing location information in indoor environments requires a higher precision and is a more challenging task due in part to the expected various objects (such as walls and people) that reflect and disperse signals. In this paper, we survey the related work in the field of indoor positioning by providing a comparative analysis of the state-of-the-art technologies, techniques, and algorithms. Unlike previous studies and surveys, our survey present new taxonomies, review some major recent advances, and argue on the area open problems and future potential. We believe this paper would spur further exploration by the research community of this challenging problem space. {\textcopyright} 2014 IEEE.},
annote = {cited By 46},
author = {Al-Ammar, M A and Alhadhrami, S and Al-Salman, A and Alarifi, A and Al-Khalifa, H S and Alnafessah, A and Alsaleh, M},
booktitle = {Proceedings - 2014 International Conference on Cyberworlds, CW 2014},
doi = {10.1109/CW.2014.41},
keywords = {Algorithms; Surveying; Technology,Comparative analysis; Indoor positioning; localiz,Surveys},
pages = {245--252},
title = {{Comparative survey of indoor positioning technologies, techniques, and algorithms}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920932666{\&}doi=10.1109{\%}2FCW.2014.41{\&}partnerID=40{\&}md5=24d0212b9a4b97acbb49c5d1b470c5f4},
year = {2014}
}
@inproceedings{Alahi:2008:ODM:1463542.1463545,
address = {New York, NY, USA},
author = {Alahi, Alexandre and Vandergheynst, Pierre and Bierlaire, Michel and Kunt, Murat},
booktitle = {Proceedings of the 1st ACM Workshop on Analysis and Retrieval of Events/Actions and Workflows in Video Streams},
doi = {10.1145/1463542.1463545},
isbn = {978-1-60558-318-1},
keywords = {object detection,object matching,region descriptor},
pages = {9--16},
publisher = {ACM},
series = {AREA '08},
title = {{Object Detection and Matching in a Mixed Network of Fixed and Mobile Cameras}},
url = {http://doi.acm.org/10.1145/1463542.1463545},
year = {2008}
}
@article{Alahmadi2018106,
abstract = {Augmented reality allows users to visualize annotations, videos, and images overlaid on physical objects through the use of a camera. However, the high computational processing cost of matching an image seen through a camera with that in an enormous database of images makes it daunting to use the concept of augmented reality on a smartphone. As matching an image with another takes time, some researchers leverage Global Positioning System (GPS) for localizing outdoor objects. Tagging images with GPS location reduces the number of images that are required to find a match which improves the overall efficiency. Unfortunately, this approach is not suitable for indoor environment as GPS does not work in indoor environments. To address this problem, we propose a system for mobile augmented reality (MAR) in indoor environments. By leveraging the already available Wi-Fi infrastructure, we estimate the location of the users inside a building to narrow down the search space. Furthermore, we utilize the smartphone motion sensors such as accelerometers and magnetometers to detect the phone's direction towards an object, and also to capture the inclination degree of the smartphone to further reduce the search domain for an object. We deployed the system in a building at Florida State University. We tested our proposal and found that using the system we decreased the matching time significantly. Due to refining the search domain of the annotated image database, MAR uses the object recognition algorithm more efficiently and decreases the matching time from 2.8 s to just 17 ms with a total of 200 annotated images. {\textcopyright} Springer International Publishing AG, part of Springer Nature 2018.},
annote = {cited By 0},
author = {Alahmadi, M and Yang, J},
doi = {10.1007/978-3-319-94361-9_9},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Accelerometers; Artificial intelligence; Augmented,Computational processing; Florida State Universit,Image enhancement},
pages = {106--122},
title = {{Towards efficient mobile augmented reality in indoor environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049368684{\&}doi=10.1007{\%}2F978-3-319-94361-9{\_}9{\&}partnerID=40{\&}md5=78845b85b2c83e9926ace2150ec8130e},
volume = {10970 LNCS},
year = {2018}
}
@inproceedings{Alakhras:2013:MFI:2497623.2498297,
address = {Washington, DC, USA},
author = {Alakhras, Marwan and Hussein, Mousa and Oussalah, Mourad},
booktitle = {Proceedings of the 2013 UKSim 15th International Conference on Computer Modelling and Simulation},
doi = {10.1109/UKSim.2013.51},
isbn = {978-0-7695-4994-1},
keywords = {Fuzzy Logic,RSS,WLAN indoor localization,fingerprint},
pages = {656--662},
publisher = {IEEE Computer Society},
series = {UKSIM '13},
title = {{Multivariable Fuzzy Inference with Multi Nearest Neighbour for Indoor WLAN Localization Based on RSS Fingerprint}},
url = {https://doi.org/10.1109/UKSim.2013.51},
year = {2013}
}
@inproceedings{Alamri2013318,
abstract = {Spatial database indexes are basically designed to speed up retrievals where it is usually assumed that the objects of interest are constant unless conspicuously updated. Therefore, capturing continuously moving objects in traditional spatial indexes will require frequent updates of the locations of these objects. This paper outlines a PhD thesis that addresses the challenges of indexing the moving objects in indoor spaces. The main goal of this thesis is to develop new indoor index structures for moving objects focusing on the following four challenges: (1) introducing a queries taxonomy for moving objects to illustrate the query types for the databases of moving objects; (2) introducing an adjacency index structure for moving objects in indoor spaces; (3) capturing both spatial and temporal properties in an indoor data structure; (4) introducing an index structure for moving objects in indoor spaces that is based on a specific type of movement pattern. {\textcopyright} 2013 IEEE.},
annote = {cited By 4},
author = {Alamri, S},
booktitle = {Proceedings - International Conference on Data Engineering},
doi = {10.1109/ICDEW.2013.6547473},
keywords = {Index structure; Indoor space; Movement pattern; M,Indexing (of information),Technical presentations},
pages = {318--321},
title = {{Indexing and querying moving objects in indoor spaces}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881470919{\&}doi=10.1109{\%}2FICDEW.2013.6547473{\&}partnerID=40{\&}md5=5db5c913078b8b8d2cb81781f0a932c2},
year = {2013}
}
@article{Alamri2018402,
abstract = {Purpose: With the rapid development of the indoor spaces positioning technologies such as the radio-frequency identification (RFID), Bluetooth and WI-FI, the locations of indoor spatial objects (static or moving) constitute an important foundation for a variety of applications. However, there are many challenges and limitations associated with the structuring and querying of spatial objects in indoor spaces. The purpose of this study is to address the current trends, limitations and future challenges associated with the structuring and querying of spatial objects in indoor spaces. Also it addresses the related features of indoor spaces such as indoor structures, positioning technologies and others. Design/methodology/approach: In this paper, the author focuses on understanding the aspects and challenges of spatial database managements in indoor spaces. The author explains the differences between indoor spaces and outdoor spaces. Also examines the issues pertaining to indoor spaces positioning and the impact of different shapes and structures within these spaces. In addition, the author considers the varieties of spatial queries that relate specifically to indoor spaces. Findings: Most of the research on data management in indoor spaces does not consider the issues and the challenges associated with indoor positioning such as the overlapping of Wi-Fi. The future trend of the indoor spaces includes included different shapes of indoors beside the current 2D indoor spaces on which the majority of the data structures and query processing for spatial objects have focused on. The diversities of the indoor environments features such as directed floors, multi-floors cases should be considered and studied. Furthermore, indoor environments include many special queries besides the common ones queries that used in outdoor spaces such as KNN, range and temporal queries. These special queries need to be considered in data management and querying of indoor environments. Originality/value: To the best of the author's knowledge, this paper successfully addresses the current trends, limitations and future challenges associated with the structuring and querying of spatial objects in indoor spaces. {\textcopyright} 2018, Emerald Publishing Limited.},
annote = {cited By 0},
author = {Alamri, S},
doi = {10.1108/IJWIS-05-2018-0039},
journal = {International Journal of Web Information Systems},
keywords = {Design/methodology/approach; Graph connectivity;,Environmental management,Floors; Information management; Query processing;},
number = {4},
pages = {402--422},
title = {{Spatial data managements in indoor environments: Current trends, limitations and future challenges}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056660402{\&}doi=10.1108{\%}2FIJWIS-05-2018-0039{\&}partnerID=40{\&}md5=fc61dd995fae1adeb4a0ab137900d5e7},
volume = {14},
year = {2018}
}
@article{Alamri2018,
abstract = {The indexing and tracking of objects moving in indoor spaces has increasingly become an important area of research, which presents a fundamentally different challenge. There are two main reasons for why indoor should be treated as cellular space. Firstly, an indoor space has entities, such as rooms and walls, that constrain the movement of the moving objects. Secondly, the relevant notion of locations of an object is cell based rather than an exact Euclidean coordinate. As a solution, in our earlier works, we proposed a cell-based indexing structure, called the C-tree, for indexing objects moving in indoor space. In this paper, we extend the C-tree to solve another interesting problem. It can be observed that many indoor spaces (such as shopping centers) contain wings/sections. For such a space, there are queries for which the wing/section location of an object, rather than the cellular location, is the relevant answer (e.g., "the object is in the east wing"). In this paper, we propose a new index structure, called the GMI-tree ("GMI" stands for "Graph-based Multidimensional Index"). The GMI-tree is based on two notions of distance, or equivalently, two notions of adjacency: one represents horizontal adjacency and the other represents vertical adjacency. {\textcopyright} 2018 Sultan Alamri et al.},
annote = {cited By 2},
author = {Alamri, S and Taniar, D and Nguyen, K},
doi = {10.1155/2018/4175298},
journal = {Mobile Information Systems},
keywords = {C (programming language),Cellular space; Euclidean coordinates; Graph-base,Forestry; Graphic methods; Indexing (of informatio},
title = {{Vertical Indexing for Moving Objects in Multifloor Environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042154182{\&}doi=10.1155{\%}2F2018{\%}2F4175298{\&}partnerID=40{\&}md5=11f929f01c3e1e82bf0b542eb253012a},
volume = {2018},
year = {2018}
}
@article{Alamri201370,
abstract = {To facilitate a variety of indoor applications, positioning technologies have been developed in indoor spaces (such as WI-FI and RFID). Thus, the requirement for the tracking and monitoring of moving objects in indoor spaces has increased considerably. The indexing of moving objects in indoor spaces is of essential importance, as these are different from outdoor spaces in many respects, such as the measurements and the positioning technologies. Therefore, in this paper, we propose a new adjacency-index structure for objects moving in indoor space which includes both spatial and temporal properties. The spatial index is based on the connectivity (adjacency) between the indoor environment cells. Moreover, we propose two temporal indexes with different methods to store the temporal data, which can support and enable efficient query processing and efficient updates for objects moving in indoor space. The proposed indexes can efficiently serve different types of spatial queries, such as KNN and indoor range, and a variety of temporal queries which are essential in an indoor environment. An empirical performance study suggests that the proposed data structures are effective, efficient, and robust. {\textcopyright} 2013 Elsevier B.V.},
annote = {cited By 18},
author = {Alamri, S and Taniar, D and Safar, M and Al-Khalidi, H},
doi = {10.1016/j.neucom.2013.03.035},
journal = {Neurocomputing},
keywords = {Indexing (of information),Indoor; Mobile database; Moving objects; Spatial d,Query languages; Tracking (position),article; data base; information processing; infor},
pages = {70--78},
title = {{Spatiotemporal indexing for moving objects in an indoor cellular space}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884210144{\&}doi=10.1016{\%}2Fj.neucom.2013.03.035{\&}partnerID=40{\&}md5=aff7ff32a1d1d103903cd3d111a5acfa},
volume = {122},
year = {2013}
}
@inproceedings{AlconadaVerzini:2015:ATL:2804565.2804570,
address = {New York, NY, USA},
author = {{Alconada Verzini}, Federico Mart$\backslash$'$\backslash$in and Tonelli, Juan Ignacio and Challiol, Cecilia and Lliteras, Alejandra Beatriz and Gordillo, Silvia Ethel},
booktitle = {Proceedings of the 2015 Workshop on Narrative {\&}{\#}38; Hypertext},
doi = {10.1145/2804565.2804570},
isbn = {978-1-4503-3797-7},
keywords = {in-situ authoring tool,indoor-outdoor space,location-aware experiences,mobile applications,separation of concern},
pages = {21--25},
publisher = {ACM},
series = {NHT '15},
title = {{Authoring Tool for Location-Aware Experiences}},
url = {http://doi.acm.org/10.1145/2804565.2804570},
year = {2015}
}
@inproceedings{Alhadhrami201554,
abstract = {Tracking is a process that captures knowledge of the path of an object's movement and its current location. This paper proposes an ultra-wideband (UWB) indoor tracking system for blind people in a high interference environment suchfiastr facilities with communication equipment. To the best of our knowledge, our proposed system is thefirst that ofiers two features (1) server-based tracking, in which the administra-tor can get the current position and the path of the blind person in question; and (2) situation awareness, in which the blind person can get voice information about existing and surrounding places. The system has shown satisfactory results when it was used and evaluated by some blind par-ticipants. {\textcopyright} 2015 ACM.},
annote = {cited By 1},
author = {Alhadhrami, S and Alnafessah, A and Al-Ammar, M and Alarifi, A and Al-Khalifa, H and Alsaleh, M},
booktitle = {13th International Conference on Advances in Mobile Computing and Multimedia, MoMM 2015 - Proceedings},
doi = {10.1145/2837126.2837141},
keywords = {Communication equipments; indoor; Interference en,Mobile computing; Sensors; Surface discharges; Tar,Ultra-wideband (UWB)},
pages = {54--62},
title = {{UWB Indoor Tracking System for Visually Impaired People}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84968732879{\&}doi=10.1145{\%}2F2837126.2837141{\&}partnerID=40{\&}md5=b9e88c4be30862f0fffe0afab9605ad4},
year = {2015}
}
@article{Ali2012156,
abstract = {Real Time Locating System (RTLS) is a system that allows tracking and determining the locations of objects in real time. This system is based on local positioning system. Wireless signals are sent to readers from simple inexpensive tags to determine their locations. There are many researchers who have carried out Landmarc algorithm in different areas. In order to further enlarge the application domain and localization, Landmarc algorithm was the first attempt active RFID tag for indoor location sensing. However, this algorithm has many limitations; some of these limitations were taken into consideration in this paper, such as, improving the localization accuracy, the need for more reference tags that are considered costly and lack of a proper and efficient way to avoid the RF interference phenomenon. In addition, the calculation the Euclidian distance between the tracking tag and all reference tags in the area will select unnecessary reference tags to be nearest reference tags to tracking tags. This paper proposed a new Virtual Landmarc (VL) algorithm and Inclusive and Exclusive constant, to solve the limitation of the Landmarc. The Inclusive and Exclusive being used to estimate the position of the target by the range of the readers used. The results, shows that the accuracy of the Virtual Landmarc is 99.9{\%} with error distance e=0.626157 and the accuracy of the Landmarc is 90{\%} with error distance e=0.788345.},
annote = {cited By 0},
author = {Ali, S A M and Mohd, M R H and Alomari, S A},
doi = {10.4156/ijact.vol4.issue20.19},
journal = {International Journal of Advancements in Computing Technology},
keywords = {Active rfid tags; Error distance; Euclidian distan,Algorithms,Radio frequency identification (RFID)},
number = {20},
pages = {156--164},
title = {{An efficient virtual landmarc algorithm to enhance the indoor Real Time Location System}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869211636{\&}doi=10.4156{\%}2Fijact.vol4.issue20.19{\&}partnerID=40{\&}md5=5c3cd31079c8e2df37c9a980e6d4ff43},
volume = {4},
year = {2012}
}
@inproceedings{8292752,
abstract = {The Smart City vision is to improve quality of life and efficiency of urban operations and services while meeting economic, social, and environmental needs of its dwellers. Realizing this vision requires cities to make significant investments in all kinds of smart objects. Recently, the concept of smart vehicle has also emerged as a viable solution for various pressing problems such as traffic management, drivers' comfort, road safety and on-demand provisioning services. With the availability of onboard vehicular services, these vehicles will be a constructive key enabler of smart cities. Smart vehicles are capable of sharing and storing digital content, sensing and monitoring its surroundings, and mobilizing on-demand services. However, the provisioning of these services is challenging due to different ownerships, costs, demand levels, and rewards. In this paper, we present the concept of Smart Vehicle as a Service (SVaaS) to provide continuous vehicular services in smart cities. The solution relies on a location prediction mechanism to determine a vehicle's future location. Once a vehicle's predicted location is determined, a Quality of Experience (QoE) based service selection mechanism is used to select services that are needed before the vehicle's arrival. We provide simulation results to show that our approach can adequately establish vehicular services in a timely and efficient manner. It also shows that the number of utilized services have been doubled when prediction and service discovery is applied.},
author = {Aloqaily, M and Ridhawi, I A and Kantraci, B and Mouftah, H T},
booktitle = {2017 IEEE 28th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)},
doi = {10.1109/PIMRC.2017.8292752},
issn = {2166-9589},
keywords = {cloud computing;intelligent transportation systems},
pages = {1--6},
title = {{Vehicle as a resource for continuous service availability in smart cities}},
year = {2017}
}
@article{Alsinglawi201781,
abstract = {The Internet of Things (IoT) enables numerous business opportunities in fields as diverse as e-health, smart cities, smart homes, among many others. The IoT incorporates multiple long-range, short-range, and personal area wireless networks and technologies into the designs of IoT applications. Localisation in indoor positioning systems plays an important role in the IoT. Location Based IoT applications range from tracking objects and people in real-time, assets management, agriculture, assisted monitoring technologies for healthcare, and smart homes, to name a few. Radio Frequency based systems for indoor positioning such as Radio Frequency Identification (RFID) is a key enabler technology for the IoT due to its costeffective, high readability rates, automatic identification and, importantly, its energy efficiency characteristic. This paper reviews the state-of-the-art RFID technologies in IoT Smart Homes applications. It presents several comparable studies of RFID based projects in smart homes and discusses the applications, techniques, algorithms, and challenges of adopting RFID technologies in IoT smart home systems.},
annote = {cited By 7},
author = {Alsinglawi, B and Elkhodr, M and Nguyen, Q V and Gunawardana, U and Maeder, A and Simoff, S},
doi = {10.5121/ijcnc.2017.9107},
journal = {International Journal of Computer Networks and Communications},
number = {1},
pages = {81--99},
title = {{RFID localisation for internet of things smart homes: A survey}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027879831{\&}doi=10.5121{\%}2Fijcnc.2017.9107{\&}partnerID=40{\&}md5=f66b9a02c605eab97a226d2ec213a8e6},
volume = {9},
year = {2017}
}
@inproceedings{Alsobhi:2008:IIC:1722902.1722910,
address = {Anaheim, CA, USA},
author = {Alsobhi, Khalil and Sharif, Bayan and Ntagkounakis, Konstantinos and Carrasco, Rolando},
booktitle = {Proceedings of the Eighth IASTED International Conference on Wireless and Optical Communications},
isbn = {978-0-88986-744-4},
keywords = {SINR,WiMAX deployment,cellular environment,fixed relay system,system level simulation},
pages = {37--41},
publisher = {ACTA Press},
series = {WOC '08},
title = {{Improving Indoor Capacity for WiMAX Networks Using Multi-hop Relays}},
url = {http://dl.acm.org/citation.cfm?id=1722902.1722910},
year = {2008}
}
@inproceedings{5759268,
abstract = {A Received Signal Strength (RSS)-based Indoor Location Method (ILS) is presented in this contribution. The motivation is the location/tracking of person/assets in indoor scenarios. The proposed network infrastructure consists on a set of receivers that measures the RSS value from a transmitter node which is attached to the asset to be located. Theoretical bases of the method are the integral equations relating the electromagnetic (EM) fields with their sources, establishing a cost function relating the measured field at the receivers and the unknown position of the transmitter. The location method is evaluated in several indoor scenarios using portable measurement equipment. Once the method is successfully tested, next step is the network hardware implementation: for this purpose, ZigBee nodes have been selected. Finally, an application example using the proposed ZigBee-based sensor network is presented.},
author = {Alvarez, Y and d. Cos, M E and Lorenzo, J and Las-Heras, F},
booktitle = {European Workshop on Smart Objects: Systems, Technologies and Applications},
keywords = {Maximum likelihood estimation;Frequency control;Ac},
pages = {1--8},
title = {{Indoor Location System using a Wireless Sensor Network}},
year = {2010}
}
@article{Alvarez:2010:NRS:1928785.1928789,
address = {New York, NY, United States},
author = {{\'{A}}lvarez, Yuri and de Cos, Mar$\backslash$'$\backslash$ia Elena and Lorenzo, Jos{\'{e}} and Las-Heras, Fernando},
doi = {10.1155/2010/254345},
issn = {1687-1472},
journal = {EURASIP J. Wirel. Commun. Netw.},
pages = {4:1----4:11},
publisher = {Hindawi Publishing Corp.},
title = {{Novel Received Signal Strength-based Indoor Location System: Development and Testing}},
url = {http://dx.doi.org/10.1155/2010/254345},
volume = {2010},
year = {2010}
}
@inproceedings{7343661,
abstract = {Many location-based services target users in indoor environments. Similar to the case of dense urban areas where many obstacles exist, indoor localization techniques suffer from outlying measurements caused by severe multipath propagation and non-line-of-sight (NLOS) reception. Obstructions in the signal path caused by static or mobile objects downgrade localization accuracy. We use robust multipath mitigation techniques to detect and filter out outlying measurements in indoor environments. We validate our approach using a power-based localization system with GSM. We conducted experiments without any prior knowledge of the tracked device's radio settings or the indoor radio environment. We obtained localization errors in the range of 3m even if the sensors had NLOS links to the target device.},
author = {Alyafawi, I and Braun, T and Dimitrova, D C},
booktitle = {2015 IEEE 26th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)},
doi = {10.1109/PIMRC.2015.7343661},
keywords = {cellular radio;indoor radio;radionavigation;signal},
pages = {2193--2198},
title = {{Robust indoor localization of narrowband signals}},
year = {2015}
}
@inproceedings{Aman2016,
abstract = {Bluetooth Low Energy (BLE) enabled iBeacon is a low-power device and is suitable for many proximity and location-based applications. Micro-localization refers to the phenomena of tracking a target with high accuracy, which is an integral part of location-aware applications, both indoor and outdoor. Although many approaches towards localization have already been proposed in many research works, Received Signal Strength Identification (RSSI) based localization using the latest BLE technology is comparatively a new concept and it reduces the energy requirements of such applications. But RSSI based distance calculation provide only a rough estimation of the proximity and does not give an accurate result for micro-localization. This paper presents and evaluates a computationally simple method for micro-localization of an object from the RSSI values from a collection of iBeacons so the method can be used in devices with very low processing power. Among the different scenarios the experiments were conducted, most of them resulted in localization error of less than 1m. {\textcopyright} 2016 IEEE.},
annote = {cited By 8},
author = {Aman, M S and Jiang, H and Quint, C and Yelamarthi, K and Abdelgawad, A},
booktitle = {2016 IEEE 7th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2016},
doi = {10.1109/UEMCON.2016.7777904},
keywords = {Bluetooth low energies (BLE); iBeacon; Location-a,Mobile telecommunication systems; Target tracking,Ubiquitous computing},
title = {{Reliability evaluation of iBeacon for micro-localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010468155{\&}doi=10.1109{\%}2FUEMCON.2016.7777904{\&}partnerID=40{\&}md5=8ae17796c952962fab1e76c9b702e81b},
year = {2016}
}
@inproceedings{7894055,
abstract = {Tour guide system, as referred by the name, is a system used for assisting visitors during a tour of a certain place. Increasing tour efficiency while minimizing resources required has been studied by many researchers. The traditional multilingual human tour guides limit in the fact that, they cannot provide personalized information to every visitor because of time constraint. Also, having persons to assist tourists as a guide is expensive. Some tour guide robots and devices were presented in previous works to overcome certain limitations, but some challenges still exist. In this work, an indoor location-aware portable device is presented aiming at improving the user's experience during a tour of an indoor facility. The proposed system can provide personalized audio-visual information based on the location of the visitor, making the visitors independent of following a guide. The core of the module is a Raspberry Pi 3 with Bluetooth Low Energy (BLE) and Wi-Fi transceivers. Localization is performed using iBeacons, and RFID technology is used to identify certain objects. The Thingworx platform has been used as the application cloud server while YouTube has been used to present visual feedback to the user.},
author = {Aman, M S and Quint, C D and Abdelgawad, A and Yelamarthi, K},
booktitle = {2017 IEEE Sensors Applications Symposium (SAS)},
doi = {10.1109/SAS.2017.7894055},
keywords = {audio-visual systems;Bluetooth;cloud computing;ind},
pages = {1--6},
title = {{Sensing and classifying indoor environments: An Iot based portable tour guide system}},
year = {2017}
}
@article{Amato2013391,
abstract = {Exploring new applications and services for mobile environments has generated considerable excitement among both industries and academics. In this paper we propose a context-aware recommender system that accommodates user's needs with location-dependent multimedia information available in a mobile environment related to an indoor scenario. Specifically, we propose a recommender system for the planning of browsing activities that are based on objects features, users' behaviours and on the current context the state of which is captured by apposite sensor networks. We present the features of such a system and we discuss the proposed approach. {\textcopyright} Springer-Verlag Berlin Heidelberg 2013.},
annote = {cited By 2},
author = {Amato, F and Mazzeo, A and Moscato, V and Picariello, A},
doi = {10.1007/978-3-642-34952-2_16},
journal = {Studies in Computational Intelligence},
pages = {391--411},
title = {{A recommendation system for browsing of multimedia collections in the Internet of Things}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893102397{\&}doi=10.1007{\%}2F978-3-642-34952-2{\_}16{\&}partnerID=40{\&}md5=2737a584600a23859dfbbcd23610a778},
volume = {460},
year = {2013}
}
@inproceedings{1258375,
abstract = {This paper presents a novel 802.11-based positioning system called the maximal cluster centered positioning system (MCCPS) developed and demonstrated at National Central University. The MCCPS system locates mobile objects via collecting the sensed power strengths of the mobile objects to multiple wireless access points. To overcome the serious multipath fading problem in the indoor environment, several positions called reference points were selected and a database is introduced to maintenance the power signature of each reference point. The experimental results show that the location information provided by MCCPS assures high correctness of region classification and low distance error.},
author = {And},
booktitle = {GLOBECOM '03. IEEE Global Telecommunications Conference (IEEE Cat. No.03CH37489)},
doi = {10.1109/GLOCOM.2003.1258375},
keywords = {wireless LAN;indoor radio;cellular radio;mobility},
pages = {929--933 Vol.2},
title = {802.11-based positioning system for context aware applications},
volume = {2},
year = {2003}
}
@inproceedings{4601829,
abstract = {This paper presents an integrated on-line operation system that enables a human user to operate humanoid robots by using natural language instructions. This paper has two major contributions. First, we present an integrated behavior system that is able to trigger behaviors according to speech commands, by recognizing objects, triggering actions and generating whole body motions on-line. Second, we present a situated natural language instruction system that is able not only to act according to speech commands, but also response to the direction of the sound source. A system that is able to understand natural language instructions and act accordingly will need the integration of knowledge representation, perception, decision making and on-line motion generation technologies. This paper tackles this integration problem by addressing the issues of representing knowledge of objects and actions which facilitates natural language instructions for tasks in indoor human environments. We propose a taxonomy of objects in indoor human environments and a lexicon of actions in this preliminary attempt to construct a reliable and flexible natural language instruction system. We report on the implementation of the proposed system on humanoid robot HRP-2, which is able to locate auditory sources and receive natural language instructions from a user within 2 meters using a 8-channel microphone array connected to a speech recognition embedded system on-board the robot.},
author = {And},
booktitle = {2008 IEEE/ASME International Conference on Advanced Intelligent Mechatronics},
doi = {10.1109/AIM.2008.4601829},
issn = {2159-6247},
keywords = {humanoid robots;knowledge representation;microphon},
pages = {1176--1182},
title = {{A natural language instruction system for humanoid robots integrating situated speech recognition, visual recognition and on-line whole-body motion generation}},
year = {2008}
}
@article{Antonakaki20091723,
abstract = {In this paper a bottom-up approach for human behaviour understanding is presented, using a multi-camera system. The proposed methodology, given a training set of normal data only, classifies behaviour as normal or abnormal, using two different criteria of human behaviour abnormality (short-term behaviour and trajectory of a person). Within this system an one-class support vector machine decides short-term behaviour abnormality, while we propose a methodology that lets a continuous Hidden Markov Model function as an one-class classifier for trajectories. Furthermore, an approximation algorithm, referring to the Forward Backward procedure of the continuous Hidden Markov Model, is proposed to overcome numerical stability problems in the calculation of probability of emission for very long observations. It is also shown that multiple cameras through homography estimation provide more precise position of the person, leading to more robust system performance. Experiments in an indoor environment without uniform background demonstrate the good performance of the system. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
annote = {cited By 53},
author = {Antonakaki, P and Kosmopoulos, D and Perantonis, S J},
doi = {10.1016/j.sigpro.2009.03.016},
journal = {Signal Processing},
keywords = {Approximation algorithms; Cameras; Convergence of,Behaviour understanding; Bottom-up approaches; Con,Trajectories},
number = {9},
pages = {1723--1738},
title = {{Detecting abnormal human behaviour using multiple cameras}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-67349116864{\&}doi=10.1016{\%}2Fj.sigpro.2009.03.016{\&}partnerID=40{\&}md5=6c3405726ee60272ebcbbaf52392967f},
volume = {89},
year = {2009}
}
@inproceedings{Anup20171027,
abstract = {This paper proposes a proof-of-concept for a novel automated indoor/outdoor navigation system. Our proposed method shall enable an object/user equipped to be able to navigate through closed environments using an automatically generated Spatial Map Graph (SMG) with the aid of pre-placed visual markers. The system is robust to dynamically changing complex environments, through adaptive reconfigurations in the SMG during execution. We show that it is possible to find optimal routes among several interconnected paths without relying on an external positioning system. Points of interest in a passive environment are detected from real time first-person-view input, which is then processed to pinpoint the current location, and extended further for navigation. Through this paper we explore the advantages and the challenges faced in implementing such a navigation system in a practical scenario. The way forward and future work has also been discussed. {\textcopyright} 2017 IEEE.},
annote = {cited By 2},
author = {Anup, S and Goel, A and Padmanabhan, S},
booktitle = {IEEE Region 10 Annual International Conference, Proceedings/TENCON},
doi = {10.1109/TENCON.2017.8228008},
keywords = {Automatically generated; Closed environment; Comp,Computer vision; Navigation systems,Indoor positioning systems},
pages = {1027--1031},
title = {{Visual positioning system for automated indoor/outdoor navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044218938{\&}doi=10.1109{\%}2FTENCON.2017.8228008{\&}partnerID=40{\&}md5=8a97f3c06ff4f0975501fa78f8500387},
volume = {2017-Decem},
year = {2017}
}
@inproceedings{Aparicio2008487,
abstract = {This paper proposes a method for merging Bluetooth and WLAN technologies to face the problem of indoor positioning. Firstly, using Bluetooth measurements the zone where the target object is located is enclosed. Afterwards, processing WiFi measurements the RSS readings are compared only against the fingerprints of the points within the previously determined zone for the precise determination of the object position. In a recent work, we approached this problem by constructing simulated Bluetooth and WLAN maps and assuming that Bluetooth measurements determine precisely the zone where the object is located. Here we present a new algorithm to cope with erroneous identification of the preselected region. The performance of this method has been tested experimentally and the comparison between the localization results obtained using both technologies and using only WiFi is presented. {\textcopyright}2008 IEEE.},
annote = {cited By 46},
author = {Aparicio, S and P{\'{e}}rez, J and Bernardos, A M and Casar, J R},
booktitle = {IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems},
doi = {10.1109/MFI.2008.4648042},
keywords = {Bluetooth,Cellular telephone systems; Intelligent systems;,Fusion methods; Indoor positioning; Object positio},
pages = {487--491},
title = {{A fusion method based on bluetooth and WLAN technologies for indoor location}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650518251{\&}doi=10.1109{\%}2FMFI.2008.4648042{\&}partnerID=40{\&}md5=48240984680d9a5dfdb136e63b2a86f2},
year = {2008}
}
@inproceedings{Appiah20142430,
abstract = {This paper presents a system for automatically classifying the resting location of a moving object in an indoor environment. The system uses an unsupervised neural network (Self Organising Feature Map) fully implemented on a low-cost, low-power automated home-based surveillance system, capable of monitoring activity level of elders living alone independently. The proposed system runs on an embedded platform with a specialised ceiling-mounted video sensor for intelligent activity monitoring. The system has the ability to learn resting locations, to measure overall activity levels and to detect specific events such as potential falls. First order motion information, including first order moving average smoothing, is generated from the 2D image coordinates (trajectories). A novel edge-based object detection algorithm capable of running at a reasonable speed on the embedded platform has been developed. The classification is dynamic and achieved in real-time. The dynamic classifier is achieved using a SOFM and a probabilistic model. Experimental results show less than 20{\%} classification error, showing the robustness of our approach over others in literature with minimal power consumption. The head location of the subject is also estimated by a novel approach capable of running on any resource limited platform with power constraints. {\textcopyright} 2014 IEEE.},
annote = {cited By 11},
author = {Appiah, K and Hunter, A and Lotfi, A and Waltham, C and Dickinson, P},
booktitle = {IEEE International Conference on Fuzzy Systems},
doi = {10.1109/FUZZ-IEEE.2014.6891833},
keywords = {Ambient assisted living; Classification errors; M,Behavioral research; Conformal mapping; Low power,Monitoring},
pages = {2430--2437},
title = {{Human behavioural analysis with self-organizing map for ambient assisted living}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912571919{\&}doi=10.1109{\%}2FFUZZ-IEEE.2014.6891833{\&}partnerID=40{\&}md5=acb9e79fa31d7e801b766283b9726b75},
year = {2014}
}
@inproceedings{Arman:2016:IVC:3005422.3005430,
address = {New York, NY, USA},
author = {Arman, Arif and Abdullah, Kaysar and Rabban, Ishat E and Ali, Mohammed Eunus},
booktitle = {Proceedings of the Eighth ACM SIGSPATIAL International Workshop on Indoor Spatial Awareness},
doi = {10.1145/3005422.3005430},
isbn = {978-1-4503-4585-9},
keywords = {color map,indoor 3D space,text data,visibility query},
pages = {47--50},
publisher = {ACM},
series = {ISA '16},
title = {{IndVizCMap: Visibility Color Map in an Indoor 3D Space}},
url = {http://doi.acm.org/10.1145/3005422.3005430},
year = {2016}
}
@inproceedings{Arslan2019,
abstract = {Construction is one of the most hazardous industries because it involves dynamic interactions between workers and machinery on sites. The recent technological developments in indoor positioning technologies provide a huge volume of spatio-temporal data for studying dynamic interactions of moving objects. The results from such studies can be used for enhancing safety management strategies on sites by recognizing the mobility related workers` behaviors. For understanding workers` mobility behaviors to improve site safety, a system is proposed based on semantic trajectories and the Hidden Markov Models (HMMs). Firstly, the system captures raw spatio-temporal trajectories of workers using an Indoor Positioning System (IPS) and preprocess them for determining the important stay locations where the workers are spending the majority of their time. Then, these processed trajectories are transformed into semantic trajectories to establish an understanding of the meanings behind workers` mobility behaviors in terms of the building environment. Lastly, HMMs along with the Viterbi algorithm are used for categorizing different workers` mobility behaviors within the identified stay locations. The proposed system is tested using an indoor building environment and the results show that it holds a potential to identify high-risk workers` behaviors to improve site safety. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Arslan, M and Cruz, C and Ginhac, D},
booktitle = {2018 14th International Conference on Emerging Technologies, ICET 2018},
doi = {10.1109/ICET.2018.8603666},
keywords = {Building environment; Dynamic interaction; Hidden,Carrier mobility; Global positioning system; Hidde,Occupational risks},
title = {{Understanding worker mobility within the stay locations using HMMs on semantic trajectories}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061731093{\&}doi=10.1109{\%}2FICET.2018.8603666{\&}partnerID=40{\&}md5=3e4d5a80e4eb63c9f9531020ec7f3adc},
year = {2019}
}
@article{Asmus197419,
abstract = {Cleaning is usually the first step involved in the various processes employed to restore a work of art. It is also one of the most delicate and difficult operations undertaken to preserve a deteriorating art object. Generally, the criteria governing the cleaning of a work of art in stone or metal are concerned with a maximum respect and care for the original materials, the eventual irreversible alterations undergone through centuries (formation of patinas, changes of color, etc.) as well as the removal or isolation of parts that may, during later periods, have been added. Difficulties involved in cleaning works of art in marble and stone change according to the different materials involved, and their varying exposures to exterior elements. Particularly complicated are the problems arising from outdoor exposure where destructive elements such as air pollution, biological attacks, etc., are superimposed on natural weathering effects. Natural or artificial degradation almost always reveals itself as a bulk degradation that begins on the surface of these materials. The presence of varying extraneous substances on the surface often encourage the introduction and propagation of exceedingly harmful forms of degradation to the interior. Consequently, surface cleaning not only improves appearance, but preserves materials as well. Many bibliographical examples exist of statues and monuments in which superficial modifications. have strongly encouraged the advance of a degradation process towards the interior. The cleaning of works of art protected by an indoor location, though as important in every way, tends to be a generally easier affair. {\textcopyright} 1974 SPIE.},
annote = {cited By 40},
author = {Asmus, J F and Murphy, C G and Munk, W H},
doi = {10.1117/12.953831},
journal = {Proceedings of SPIE - The International Society for Optical Engineering},
pages = {19--30},
title = {{Studies on the interaction of laser radiation with art artifacts}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957502439{\&}doi=10.1117{\%}2F12.953831{\&}partnerID=40{\&}md5=96b17d5f7f49bef1369184e4f580dd80},
volume = {41},
year = {1974}
}
@inproceedings{Avery:2008:UES:1605298.1605348,
address = {Washington, DC, USA},
author = {Avery, Benjamin and Thomas, Bruce H and Piekarski, Wayne},
booktitle = {Proceedings of the 7th IEEE/ACM International Symposium on Mixed and Augmented Reality},
doi = {10.1109/ISMAR.2008.4637327},
isbn = {978-1-4244-2840-3},
pages = {69--72},
publisher = {IEEE Computer Society},
series = {ISMAR '08},
title = {{User Evaluation of See-through Vision for Mobile Outdoor Augmented Reality}},
url = {https://doi.org/10.1109/ISMAR.2008.4637327},
year = {2008}
}
@inproceedings{Ayyalasomayajula:2018:BCA:3281411.3281428,
address = {New York, NY, USA},
author = {Ayyalasomayajula, Roshan and Vasisht, Deepak and Bharadia, Dinesh},
booktitle = {Proceedings of the 14th International Conference on Emerging Networking EXperiments and Technologies},
doi = {10.1145/3281411.3281428},
isbn = {978-1-4503-6080-7},
keywords = {RF-based indoor positioning,bluetooth low energy,indoor localization},
pages = {126--138},
publisher = {ACM},
series = {CoNEXT '18},
title = {{BLoc: CSI-based Accurate Localization for BLE Tags}},
url = {http://doi.acm.org/10.1145/3281411.3281428},
year = {2018}
}
@article{NoAuthor2011,
abstract = {Path analysis becomes a powerful tool when dealing with behavior analysis, i. e., detecting abnormal movements. In a multiple target scenario it is complicated to obtain each object path because of collision events, such as grouping and splitting targets, and occlusions, both total or partial. In this work, a method to obtain the similarity between different trajectories is presented, based in register techniques. In addition, an hierarchical architecture is used to obtain the corresponding paths of the objects in a scene, to cope with collision events. Experimental results show promising results in path analysis, enabling it to establish thresholds to abnormal path detection. {\textcopyright} 2011 Springer-Verlag.},
annote = {cited By 0},
archivePrefix = {arXiv},
arxivId = {1512.01215},
author = {B, Michael Gadermayr and Wimmer, Georg and Uhl, Andreas and Kogler, Hubert and Andreas, V},
doi = {10.1007/978-3-642-24085-0},
eprint = {1512.01215},
isbn = {978-3-642-24084-3},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 1},
pages = {467--478},
title = {{Image Analysis and Processing  ICIAP 2011}},
url = {http://link.springer.com/10.1007/978-3-642-24085-0},
volume = {6978},
year = {2011}
}
@article{Baba:2017:CIR:3124104.3124108,
address = {New York, NY, USA},
author = {Baba, Asif Iqbal and Lu, Hua and Pedersen, Torben Bach and Jaeger, Manfred},
doi = {10.1145/3124104.3124108},
issn = {1946-7729},
journal = {SIGSPATIAL Special},
number = {1},
pages = {11--18},
publisher = {ACM},
title = {{Cleansing Indoor RFID Tracking Data}},
url = {http://doi.acm.org/10.1145/3124104.3124108},
volume = {9},
year = {2017}
}
@inproceedings{Bagci:2009:OLN:1661393.1661395,
abstract = {The indoor localisation problem is more complex than just finding whereabouts of users. Finding positions of users relative to the devices of a smart space is even more important. Unfortunately, configuring such systems manually is a tedious process, requires expert knowledge, and is sensitive to changes in the environment. Moreover, many existing solutions do not take user privacy into account. We propose a new system, called Simultaneous Localisation and Configuration (SLAC), to address the problem of locating devices and users relative to those devices, and combine this problem into a single estimation problem. The SLAC algorithm, based on FastSLAM, is able to locate devices using the received signal strength indicator (RSSI) of devices and motion data from users. Simulations have been used to show the performance in a controlled environment and the effect of the amount of RSSI updates on the localisation error. Live tests in non-trivial environments showed that we can achieve room level accuracy and that the localisation can be performed in real time. This is all done locally, i.e. running on a user's device, with respect for privacy and without using any prior information of the environment or device locations. Although promising, more work is required to increase accuracy in larger environments and to make the algorithm more robust for environment noise caused by walls and other objects. Existing techniques, e.g. map fusing, can alleviate these problems. {\textcopyright} 2016 IEEE.},
address = {Inderscience Publishers, Geneva, SWITZERLAND},
annote = {From Duplicate 1 (Analysis and design of an object tracking service for intelligent environments - Recio, I; Moya, J M; Araujo, {\'{A}}; Vallejo, J C; Malag{\'{o}}n, P)
And Duplicate 40 (A statistical approach for shadow detection using spatio-temporal contexts - Liu, Y; Adjeroh, D)
And Duplicate 45 (Indoor positioning using particle filters with optimal importance function - Pishdad, L; Labeau, F)
And Duplicate 55 (Find my stuff: A search engine for everyday objects - Knierim, P; Nickels, J; Musiol, S; K{\"{o}}nings, B; Schaub, F; Wiedersheim, B; Weber, M)
And Duplicate 65 (A hybrid RFID and CV system for item-level localization of stationary objects - Berz, E L; Tesch, D A; Hessel, F P)
And Duplicate 108 (Investigation and demonstration of local positioning system using ultrasonic sensors for wide indoor areas - Hada, T; Sunaga, H; Akiyama, M; Ioroi, S; Tanaka, H)
And Duplicate 123 (Effect of collision on movement tracking using active RFID power measurement - Kim, T; Lee, S; Park, S.-C.)
And Duplicate 127 (Region of Interest detection using indoor structure and saliency map - Kataoka, K; Sudo, K; Morimoto, M)
And Duplicate 130 (A universal mobile robot for assistive tasks - Takagi, M; Takahashi, Y; Komeda, T)
And Duplicate 169 (Improvement of pedestrian dead reckoning by heading correction based on optimal access points selection method - Tateno, S; Cho, Y; Li, D; Tian, H; Hsiao, P)
And Duplicate 192 (A computer vision-based perception system for visually impaired - Tapu, R; Mocanu, B; Zaharia, T)
And Duplicate 198 (Moving edge matching for moving object tacking - Murshed, M; Morshed, M; Chae, O)
And Duplicate 205 (Position estimation for goods tracking system using mobile detectors - Mineno, H; Hida, K; Mizutani, M; Miyauchi, N; Kusunoki, K; Fukuda, A; Mizuno, T)
And Duplicate 221 (Location based reconfigurable cell site diversity techniques for LED-ID system - Uddin, M S; Jang, Y M)
And Duplicate 230 (Development of bluetooth based indoor positioning application - Satan, A; Toth, Z)
And Duplicate 236 (LOVINA: Location-aware virtual navigation system based on active RFID - Wang, C.-S.)
And Duplicate 259 (Autonomous feature-based exploration using multi-sensors - Huwedi, A; Steinhaus, P; Dillmann, R)
And Duplicate 264 (Sliding-Typed Communication Range Recognition method for indoor position estimation in passive RFID systems - Inada, A; Oda, Y; Nakamori, E; Fujimoto, M; Wada, T; Mutsuura, K; Okada, H)
And Duplicate 267 (Scene structure inference through scene map estimation - Hueting, M; Ptrucean, V; Ovsjanikov, M; Mitra, N J)
And Duplicate 276 (An active low cost mesh networking indoor tracking system - Carlin, S; Curran, K)
And Duplicate 294 (Improved particle filtering by exploring nomadic movements - Zhang, S; Raulefs, R)
And Duplicate 319 (LumiSpace: A VR architectural daylighting design system - Hong, Y; Michalatos, P)
And Duplicate 320 (Reliable indoor location prediction using conformal prediction - Nguyen, K A; Luo, Z)
And Duplicate 337 (Generating holistic 3D scene abstractions for text-based image retrieval - Li, A; Sun, J; Ng, J.Y.-H.; Yu, R; Morariu, V I; Davis, L S)
And Duplicate 342 (Indoor localization system for assisting visually impaired people - Alam, M M; Arefin, S E; Alim, M A; Adib, S I; Rahman, M A)
And Duplicate 349 (Singe image-based data-driven indoor scenes modeling - Zhang, Y; Liu, Z; Miao, Z; Wu, W; Liu, K; Sun, Z)
And Duplicate 353 (Web mining driven semantic scene understanding and object localization - Zhou, K; Varadarajan, K M; Zillich, M; Vincze, M)
And Duplicate 356 (Finding dense locations in symbolic indoor tracking data: modeling, indexing, and processing - Ahmed, T; Pedersen, T B; Lu, H)

cited By 2

From Duplicate 2 (Turning Corners into Cameras: Principles and Methods - Bouman, K L; Ye, V; Yedidia, A B; Durand, F; Wornell, G W; Torralba, A; Freeman, W T)
And Duplicate 87 (CROWD-PAN-360: Crowdsourcing Based Context-Aware Panoramic Map Generation for Smartphone Users - Raychoudhury, V; Shrivastav, S; Sandha, S S; Cao, J)
And Duplicate 99 (Cicada: A highly-precise easy-embedded and omni-directional indoor location sensing system - Gu, H; Shi, Y; Chen, Y; Wang, B; Jiang, W)
And Duplicate 102 (Design and implementation of library books search and management system using RFID technology - Cheng, H; Huang, L; Xu, H; Hu, Y; Wang, X A)
And Duplicate 126 (ICam: Precise at-a-distance interaction in the physical environment - Patel, S N; Rekimoto, J; Abowd, G D)
And Duplicate 174 (Perception of an indoor robot workspace by using CTFM sonar imaging - Politis, Zafiris; Probert, Penny)
And Duplicate 195 (IMAF: In situ indoor modeling and annotation framework on mobile phones - Kim, H; Reitmayr, G; Woo, W)
And Duplicate 268 (BatMapper: Acoustic sensing based indoor floor plan construction using smartphones - Zhou, B; Elbadry, M; Gao, R; Ye, F)
And Duplicate 300 (Spatial-geometric approach to physical mobile interaction based on accelerometer and IR sensory data fusion - Rahman, A.S.M.M.; Hossain, M A; Saddik, A E)

cited By 9

From Duplicate 3 (EnLighting: An indoor visible light communication system based on networked light bulbs - Schmid, S; Richner, T; Mangold, S; Gross, T R)
And Duplicate 77 (Active visual planning for mobile robot teams using hierarchical pomdps - Zhang, S; Sridharan, M; Washington, C)
And Duplicate 93 (Passive location estimation using TOA measurements - Shen, J; Molisch, A F)
And Duplicate 139 (A Web 2.0 platform to enable context-a ware mobile mash-ups - L{\'{o}}pez-de-Ipi{\~{n}}a, D; Vazquez, J I; Abaitua, J)
And Duplicate 148 (Robust system for indoor localisation and identification for the health care environment - Ropponen, A; Rimminen, H; Sepponen, R)
And Duplicate 217 (Video based 3D reconstruction using spatio-temporal attention analysis - Xiao, X; Xu, C; Rui, Y)
And Duplicate 243 (Automatic objects removal for scene completion - Yang, J; Hua, K; Wang, Y; Wang, W; Wang, H; Shen, J)
And Duplicate 246 (Orientation-aware indoor localization path loss prediction model for wireless sensor networks - Lihan, M; Tsuchiya, T; Koyanagi, K)

cited By 11

From Duplicate 4 (Context-aware activity recognition through a combination of ontological and statistical reasoning - Riboni, D; Bettini, C)
And Duplicate 64 (A smartphone-based obstacle detection and classification system for assisting visually impaired people - Tapu, R; Mocanu, B; Bursuc, A; Zaharia, T)

cited By 57

From Duplicate 5 (Logo recognition for image-based indoor positioning systems on mobile devices - Wang, S.-S.; Tsai, P.-H.; Li, W.-S.)
And Duplicate 17 (Simple decentralised market-oriented management of OFDMA femto-cells - Rodriguez, V; Mathar, R)
And Duplicate 18 (Characterising indoor positioning estimation using experimental data from an active RFID-based real-time location system - Lam, L D M; Tang, A; Grundy, J)
And Duplicate 22 (TagFree: Passive object differentiation via physical layer radiometric signatures - Zou, Y; Wang, Y; Ye, S; Wu, K; Ni, L M)
And Duplicate 38 (Fusion of WiFi and vision based on smart devices for indoor localization - Guo, J; Zhang, S; Zhao, W; Peng, J)
And Duplicate 43 (Robot localization method using multi-PTS cameras and Wi-Fi receiver - Lee, Y.-C.)
And Duplicate 46 (An event-driven architecture for spatio-temporal surveillance of business activities - Pestana, G; Metter, J; Heuchler, S; Reis, P)
And Duplicate 56 (Removing object bouncing from indoor tracking data - Baba, A)
And Duplicate 57 (Wireless Positioning Sensor Network Integrated with Cloud for Industrial Automation - Kamruzzaman, S M; Jaseemuddin, M; Fernando, X; Moeini, P)
And Duplicate 60 (In Search of Indoor Dense Regions: An Approach Using Indoor Positioning Data - Li, H; Lu, H; Shou, L; Chen, G; Chen, K)
And Duplicate 61 (3D scene segmentation with a shape repository - Wan, L; Miao, Z; Chang, D; Cen, Y)
And Duplicate 63 (A fast learning neural network for oriented visual place map based robot navigation - Datta, A; Yow, K.-C.)
And Duplicate 68 (Towards indoor location estimation and tracking with wireless sensors - Bagci, F; Kluge, F; Satzger, B; Ungerer, T)
And Duplicate 73 (Demo: CELLI - Indoor positioning using polarized sweeping light beams - Wei, Y.-L.; Huang, C.-J.; Tsai, H.-M.; Lin, K.C.-J.)
And Duplicate 75 (Detection and tracking faces in unconstrained color video streams - Passarinho, C J P; Salles, E O T; Sarcinelli-Filho, M)
And Duplicate 76 (Where Am I? Comparing CNN and LSTM for Location Classification in Egocentric Videos - Kapidis, G; Poppe, R W; Van Dam, E A; Veltkamp, R C; Noldus, L.P.J.J.)
And Duplicate 80 (Interactive room capture on 3D-aware mobile devices - Sankar, A; Seitz, S M)
And Duplicate 84 (Magnetic field indoor positioning system based on automatic spatial-segmentation strategy - Du, Y; Arslan, T)
And Duplicate 89 (Object-based Indoor Localization using Region-based Convolutional Neural Networks - Chenning, L; Ting, Y; Qian, Z; Haowei, X)
And Duplicate 90 (RETRACTED ARTICLE: The research of RFID-based indoor signal block positioning system optimum interval of placing tags - Wu, J; Zhou, L; Xiang, Z)
And Duplicate 98 (A wide area surveillance video system by combination of omni-directional and network controlled cameras - Sato, Y; Hashimoto, K; Shibata, Y)
And Duplicate 100 (A micro-location based dynamic device-oriented control system for iOT applications - Cheng, R.-S.; Lin, K W; Hong, W.-J.; Pan, Y.-J.; Yang, C.-W.)
And Duplicate 101 (Management of Subdivided Dynamic Indoor Environments by Autonomous Scanning System - Lee, J; Seo, M; Kim, J; Hwang, S; Kim, T; Kim, K.-S.)
And Duplicate 105 (Human tracking with multiple 3D cameras for perceptual sensor network - Choi, J; Kim, C; Park, S.-K.)
And Duplicate 111 (Ground view-based SLAM using a commercial web camera in unstructured indoor environments - An, S.-Y.; Lee, L.-K.; Oh, S.-Y.; Kang, J.-G.)
And Duplicate 112 (Topological estimation using ultrasonic and radio - Nakamura, Y; Kobayashi, R; Minami, M; Nishimura, T)
And Duplicate 115 (DMCHS: An energy-accuracy tradeoff scheme for HetNet-based indoor localization framework - Xia, J; Xu, C; Liu, Z; Yu, H)
And Duplicate 121 (Spatial and temporal sampling control for visual surveillance application - Emmanuel, S; Zhang, P; Sugama, A)
And Duplicate 129 (Building/environment Data/information System for Fine-Scale Indoor Location Specific Services - Li, C C; Wu, P; Wang, H; Chu, E T H; Liu, J W S)
And Duplicate 131 (Smart monitoring via participatory BLE relaying - Radhakrishnan, M; Sen, S; Misra, A; Lee, Y; Balan, R K)
And Duplicate 132 (Fast frontier detection in indoor environment for monocular SLAM - Upadhyay, S; Krishna, K M; Kumar, S)
And Duplicate 133 (Carrier tracking loop improvement in a new indoor positioning system - Lu, X; Zhang, Y; Zheng, Z)
And Duplicate 134 (IoT Metadata Creation System for Mobile Images and Its Applications - Tseng, H.-Y.; Lee, C.-T.; Lin, C.-A.; Chou, P H)
And Duplicate 143 (Color distribution tracking for facial analysis - Gracia-Roche, J J; Orrite, C; Bernu{\'{e}}s, E; Herrero, J E)
And Duplicate 153 (Multi-target indoor tracking and recognition system with infrared markers for virtual reality - Xu, W; Wang, B; Jiang, Y)
And Duplicate 158 (3D photography using shadows - Bouguet, J.-Y.; Perona, P)
And Duplicate 179 (Viewpoint based mobile robotic exploration aiding object search in indoor environment - Desingh, K; Nagariya, A; Krishna, K M)
And Duplicate 186 (The Study on Indoor Localization for Manufacturing Execution System - Huang, S; Mohanty, S; Ashfahani, A; Pratama, M)
And Duplicate 193 (Detection of acoustic events by using MFCC and spectro-temporal gabor filterbank features - Khan, U Z; Shaukat, A; Akram, M U; Basit, M K; Hassan, A; Wahid, A)
And Duplicate 194 (Applying ATAM to evaluate indoor location systems for smartphones - Vieira, E B; Leal, A G)
And Duplicate 199 (Location of Persons Using Binary Sensors and BLE Beacons for Ambient Assitive Living - Jim{\'{e}}nez, A R; Seco, F; Peltola, P; Espinilla, M)
And Duplicate 200 (Real time multi target capturing using partitioning in robot vision - Barfeh, D P Y; Bustamante, R V; Jose, E C; Lansigan, F P; Mendoza, E R; Mariano, V Y)
And Duplicate 201 (A deep learning approach for indoor user localization in smart environments - De Vita, F; Bruneo, D)
And Duplicate 203 (Location estimation using auditory signal emitted and received by all objects - Nishimura, T; Nakamura, Y; Tomobe, H; Kurata, T; Okuma, T; Matsuo, Y)
And Duplicate 220 (Demo: Real-time object tagging and retrieval - Jain, P; Roy Choudhury, R)
And Duplicate 224 (Na{\"{i}}ve bayes classifier for indoor positioning using bluetooth low energy - Farahiyah, D; Romadhoni, R M; Pratomo, S W)
And Duplicate 228 (Leveraging human computations to improve schematization of spatial relations from imagery - Rao, H; Huang, S.-W.; Fu, W.-T.)
And Duplicate 233 (Poster: An infrastructureless and self-deployable indoor navigation approach using semantic signatures - Im, T; De, P)
And Duplicate 235 (Image-Based 3D Model Retrieval for Indoor Scenes by Simulating Scene Context - Liu, M; Zhang, Y; He, J; Guo, J; Guo, Y)
And Duplicate 244 (Directional Grid Maps: Modeling Multimodal Angular Uncertainty in Dynamic Environments - Senanayake, R; Ramos, F)
And Duplicate 253 (The invariant features-based target tracking across multiple cameras - Xiao, J; Liu, Z; Yang, H; Hu, X)
And Duplicate 273 (SeeThrough: Finding objects in heavily occluded indoor scene images - Mitra, N; Kim, V; Yumer, E; Hueting, M; Carr, N; Reddy, P)
And Duplicate 274 (Applying software product line technology to prototyping of real-time object tracking - Chiang, C.-C.; Marshall, B)
And Duplicate 275 (Effectiveness of online RF fingerprinting for indoor localization - Othman, H; At, N; Topal, C)
And Duplicate 285 (A new method for shifted anchor coordinates retrieval in UWB positioning system - Djaja-Josko, V; Kolakowski, J)
And Duplicate 291 (Real-time patient localization in urgent care: System design and hardware perspective - Konecny, J; Prauzek, M; Martinek, R; Michalek, L; Tomis, M)
And Duplicate 297 (An RFID-based dynamic positioning scheme with MATLAB GUI - Xie, M; Wang, M; Liu, Z)
And Duplicate 301 (Self-localization using fixations as landmarks - Tiberio, L M; Canosa, R L)
And Duplicate 302 (Complete 3D Scene Parsing from an RGBD Image - Zou, C; Guo, R; Li, Z; Hoiem, D)
And Duplicate 303 (Survey on Algorithms and Techniques for Indoor Navigation Systems. - Alqahtani, E J; Alshamrani, F H; Syed, H F; Alhaidari, F A)
And Duplicate 304 (PETLON: Planning efficiently for task-level-optimal navigation - Lo, S.-Y.; Zhang, S; Stone, P)
And Duplicate 306 (Harmonium: Ultra wideband pulse generation with bandstitched recovery for fast, accurate, and robust indoor localization - Pannuto, P; Kempke, B; Chuo, L.-X.; Blaauw, D; Dutta, P)
And Duplicate 324 (A Real-Time UWB Multi-Channel Indoor Positioning System for Industrial Scenarios - Schroeer, G)
And Duplicate 345 (Poster abstract: A stolen object detection and tracing system for mobile valuables - Su, Y.-W.; Chuang, C.-C.; Lee, Y.-F.; Shen, C.-C.)
And Duplicate 346 (Vision-based entrance detection in outdoor scenes - Talebi, M; Vafaei, A; Monadjemi, A)
And Duplicate 347 (A smart home 3D modeling approach for spatiotemporal analysis - Chamberland-Tremblay, D; Giroux, S; Caron, C)
And Duplicate 354 (A time scheduling scheme used for multi-cells indoor localization - Lee, J X; Chin, F; Lin, Z W)
And Duplicate 355 (Management of mobile objects location for video content filtering - Panta, F J; Qodseya, M; S{\`{e}}des, F; P{\'{e}}ninou, A)
And Duplicate 359 (A case-based approach for indoor location - Bento, C; Peixoto, J; Veloso, M)

cited By 0

From Duplicate 6 (Ubiquitous tagless object locating with ambient harmonic tags - Ma, Y; Kan, E C)
And Duplicate 15 (Low complexity Wireless Indoor Positioning approaches based on fingerprinting techniques - Maneerat, K; Prommak, C)
And Duplicate 16 (Real-time shape retrieval for robotics using skip Tri-Grams - Li, Y; Bitsakos, K; Fermuller, C; Aloimonos, Y)
And Duplicate 23 (Integrating heterogeneous locating services for efficient development of location-based services - Takatsuka, H; Tokunaga, S; Saiki, S; Matsumoto, S; Nakamura, M)
And Duplicate 26 (Rapid mesh network setup for indoor RF tracking - Hedley, M; Sathyan, T)
And Duplicate 29 (Indoor location-assisted device switching system for VoIP application - Syed Ariffin, S H; Abdul Wahab, N H; Fisal, N; Latiff, L A; Choong, K.-N.; Raj, M A; Mohamed, R; Abbas, M)
And Duplicate 52 (A position correction method for RSSI based indoor-localization - Yoshida, T; Wang, J; Cheng, Z)
And Duplicate 53 (Stereo Object Proposals - Huang, S; Wang, W; He, S; Lau, R W H)
And Duplicate 71 (An efficient grid index for moving objects in indoor environments - Kim, Y; Jung, H; Jang, J; Kim, U.-M.)
And Duplicate 78 (Position finding based on multiple doppler sensors - Schelkshorn, S; Detlefsen, J)
And Duplicate 88 (Grammar-based map parsing for view invariant map descriptor - Enfu, L; Kanji, T; Xiaoxiao, F)
And Duplicate 91 (Location identification for visitor behavior log in museum - Aizawa, K; Yamasaki, T; Kawaji, H; Kawamura, S)
And Duplicate 97 (Main mobile object detection and localization in video sequences - Tsechpenakis, G; Xirouhakis, Y; Delopoulos, A)
And Duplicate 103 (Zone-based indoor localization using neural networks: A view from a real testbed - Anzum, N; Afroze, S F; Rahman, A)
And Duplicate 118 (Part-based SLAM for partially changing environments - Yuuto, C; Kanji, T; Masatoshi, A)
And Duplicate 119 (Guiding robots through wireless location positioning - Curran, K; Condell, J; Knox, J)
And Duplicate 120 (Mobile objects in indoor environment: Trajectories reconstruction - Panta, F J; S{\`{e}}des, F)
And Duplicate 137 (Closing the gaps in inertial motion tracking - Shen, S; Gowda, M; Choudhury, R R)
And Duplicate 140 (The research of RFID localization technology based on bi-directional RSSI - Men, C; Mao, L; Wu, L)
And Duplicate 150 (User independent, multi-modal spotting of subtle arm actions with minimal training data - Bauer, G; Blanke, U; Lukowicz, P; Schiele, B)
And Duplicate 156 (Proposed novel schema design for map generation to assist vision impaired in an indoor navigation environment - Jayakody, J.A.D.C.A.; Murray, I)
And Duplicate 164 (Synthesis of environment maps for mixed reality - Walton, D R; Thomas, D; Steed, A; Sugimoto, A)
And Duplicate 177 (A Framework for creating and using maps of privately owned spaces - Shafer, S)
And Duplicate 206 (Object detection in indoor scenes using log-polar mapping - Bishay, M; Peters II, R A; Kawamura, K)
And Duplicate 213 (Mobile pointme based pervasive gaming interaction with learning objects annotated physical atlas - Md Mahfujur Rahman, A S; El Saddik, A)
And Duplicate 237 (Automated human mobility mode detection based on GPS tracking data - Tian, J; Jiang, Y; Chen, Y; Li, W; Mu, N)
And Duplicate 250 (Computer vision geo-location, awareness {\&} detail - Zelek, J; Fazl, E; Asmar, D; Fakih, A)
And Duplicate 252 (Discrimination of multiple objects and expanding positioning area for indoor positioning systems using ultrasonic sensors - Sunaga, H; Hada, T; Akiyama, M; Ioroi, S; Tanaka, H)
And Duplicate 254 (Rapid three-dimensional scene modeling by sketch retrieval and auto-arrangement - Ren, P; Fan, Y; Zhou, M; Wang, Z; Du, G; Qian, L)
And Duplicate 261 (Three-dimensional mapping for data collected using variable stereo baseline - Kowalczuk, Z; Merta, T)
And Duplicate 263 (Use of active RFID and environment-embedded sensors for indoor object location estimation - Li, M; Mori, T; Noguchi, H; Shimosaka, M; Sato, T)
And Duplicate 269 (An RF-based wearable sensor system for indoor tracking to facilitate efficient healthcare management - Ouyang, Y; Shan, K; Bui, F M)
And Duplicate 272 (Low cost vision-based 3D localization system for indoor unmanned aerial vehicles - Andrean, S Y; Joelianto, E; Widyotriatmo, A; Adiprawita, W)
And Duplicate 284 (VLC-based location data transferal for smart devices - Kim, J.-H.; Kang, S.-Y.; Lee, S.-T.)
And Duplicate 290 (},
author = {Bagci, Faruk and Kluge, F and Ungerer, T and Bagherzadeh, N and Liu, C.-L. and Ge, Y and Xiong, H and Xiao, K and Geng, W and Perkins, M and Wang, J Z and Zha, H and Cipolla, R and Bento, C and Peixoto, J and Veloso, M and Krishna, M T G and Ravishankar, M and Babu, R and Khoury, H M and Kamat, V R and Ahmed, T and Pedersen, T B and Lu, H.-C. and Panta, F J and Qodseya, M and S{\`{e}}des, F and P{\'{e}}ninou, A and Lee, J X and Chin, F and Lin, Z W and Zhou, K and Varadarajan, K M and Zillich, M and Vincze, M and Pratkanis, A and Leeper, A E and Salisbury, K and Bulten, W and {Van Rossum}, A C and Haselager, W F G and Zhu, X and Huang, P.-C. and Meng, J and Han, S and Mok, A K and Chen, D and Nixon, M and Zhang, Y and Liu, Z and Miao, Z and Wu, W and Liu, K and Sun, Z and Potgantwar, A D and Wadhai, V M and Chamberland-Tremblay, D and Giroux, S and Caron, C and Talebi, M and Vafaei, A and Monadjemi, A and Su, Y.-W. and Chuang, C.-C. and Lee, Y.-F. Y.-C. and Shen, C.-C. and Zhuang, Y and Li, Y and Wang, W.-H. and Bagci, Faruk and Kluge, F and Ungerer, T and Bagherzadeh, N and Alam, M M and Arefin, S E and Alim, M A and Adib, S I and Rahman, M A and Yim, J and Joo, J and Park, C and Ren, Z and Sudderth, E B and Yu, J and Ku, W.-S. and Sun, M.-T. and Lu, H.-C. and Zhong, X and Wang, W.-H. and Wang, Q and Li, A and Sun, J and Ng, J.Y.-H. and Yu, R and Morariu, V I and Davis, L S and Mainetti, L and Mighali, V and Patrono, L and Zhao, J and Ishwar, P and Konrad, J and Gorlatova, M and Kinget, P and Kymissis, I and Rubenstein, D and Wang, X A and Zussman, G and Yang, B and Lu, H.-C. and Jensen, C S and Jeevarathnam, N G and Uysal, I and Bu, Y and Seo, K and Huh, J.-H. and Cai, L and He, L and Xu, Y and Zhao, Y and Yang, X and Xia, Y and Zhang, L and Xu, W and Shan, Z and Liu, Y and Kunze, L and Beetz, M and Saito, M and Azuma, H and Okada, K and Inaba, M and Wirz, M and Roggen, D and Tr{\"{o}}ster, G and Bekkali, A and Matsumoto, M and Blankenbach, J and Norrdine, A and Schroeer, G and Ding, H.-L. and Ng, W W Y and Chan, P P K and Wu, D.-L. and Chen, X.-L. and Yeung, D S and Bouet, M and {Dos Santos}, A L and Lu, H.-C. and Yang, B and Jensen, C S and Nguyen, K A and Luo, Z and Hong, Y and Michalatos, P and Shen, J and Molisch, A F and Salmi, J and Dubey, A and Kulkarni, A and Paras, A and Deole, A and Gandhi, A S and Bhurchandi, K M and Zhou, C and Yuan, J and Liu, H and Qiu, J and Liu, J W S and Wark, T and Martin, S and Corke, P and D'Souza, M and J{\"{a}}ms{\"{a}}, J and Luimula, M and Piesk{\"{a}}, S and Brax, V and Saukko, O and Verronen, P and Hatthasin, U and Thainimit, S and Vibhatavanij, K and Premasathian, N and Worasawate, D and Marias, G F and Papazafeiropoulos, G and Priggouris, N and Hadjiefthymiades, S and Merakos, L and Hara, K and Nishino, K and Ikeuchi, K and Alamri, S and Taniar, D and Safar, M and Al-Khalidi, H and Stringa, E and Soldatini, F and Regazzoni, C S and Lee, H.-J. and Park, J C and Han, S and Shin, K G and Pannuto, P and Kempke, B and Chuo, L.-X. and Blaauw, D and Dutta, P and Wang, J Z and Li, J and Wiederholdy, G and Lo, S.-Y. and Zhang, S and Stone, P and Alqahtani, E J and Alshamrani, F H and Syed, H F and Alhaidari, F A and Zou, C and Guo, R and Li, Z and Hoiem, D and Tiberio, L M and Canosa, R L and Rahman, A.S.M.M. and Hossain, M A and Saddik, A E and Chianese, A and Marulli, F and Moscato, V and Piccialli, F and Wagner, S and Handte, M and Zuniga, M and Marr{\'{o}}n, P J and Xie, M and Wang, M and Liu, Z and Kulkarni, S and Junghare, S and Mujibiya, A and Torii, J and Zhang, S and Raulefs, R and Mata, F and Claramunt, C and Juarez, A and Alamri, S and Taniar, D and Safar, M and Konecny, J and Prauzek, M and Martinek, R and Michalek, L and Tomis, M and G{\'{o}}mez, D and Bernardos, A M and Casar, J R and Sasagawa, M and Ikematsu, K and Siio, I and Kanezaki, A and Suzuki, T and Harada, T and Kuniyoshi, Y and Afyouni, I and Ray, C and Ilarri, S and Claramunt, C and Niu, X and Li, M and Cui, X and Liu, J W S and Liu, S and Chowdhury, K R and Djaja-Josko, V and Kolakowski, J and Kim, J.-O. J.-H. and Kang, S.-Y. and Lee, S.-T. J and Fernandes, H and Costa, P and Paredes, H and Filipe, V and Barroso, J and Powell, M W and Sarkar, S and Goldgof, D B and Ivanov, K and Papapostolou, A and Chaouchi, H and Schwartz, S and Wong, A and Clausi, D A and Ma, S and Liu, Q and Sheu, P.C.-Y. and Paucher, R and Turk, M and Liu, T and Chi, T and Li, H and Rui, X and Lin, H and Carlin, S and Curran, K and Othman, H and At, N and Topal, C and Chiang, C.-C. and Marshall, B and Mitra, N J and Kim, V and Yumer, E and Hueting, M and Carr, N and Reddy, P and Andrean, S Y and Joelianto, E and Widyotriatmo, A and Adiprawita, W and Soltani, M M and Motamedi, A and Hammad, A and Petrushin, V A and Wei, G and Gershman, A V and Ouyang, Y and Shan, K and Bui, F M and Zhou, B and Elbadry, M and Gao, R and Ye, F and Hueting, M and Ptrucean, V and Ovsjanikov, M and Mitra, N J and Brida, P and Benikovsky, J and MacHaj, J and Cadena, C and Ko{\v{s}}eck{\'{a}}, J and Inada, A and Oda, Y and Nakamori, E and Fujimoto, M and Wada, T and Mutsuura, K and Okada, H and Li, M and Mori, T and Noguchi, H and Shimosaka, M and Sato, T and Yang, P and Wu, W and Moniri, M and Chibelushi, C C and Kowalczuk, Z and Merta, T and Kumar, C P and Poovaiah, R and Sen, A and Ganadas, P and Huwedi, A and Steinhaus, P and Dillmann, R and Rivera-Rubio, J and Idrees, S and Alexiou, I and Hadjilucas, L and Bharath, A A and Baba, A I and Jaeger, M and Lu, H.-C. and Pedersen, T B and Ku, W.-S. and Xie, X and Maesen, S and Goorts, P and Bekaert, P and Hara, K and Nishino, K and Ikeuchi, K and Ren, P and Fan, Y and Zhou, M and Wang, Z and Du, G and Qian, L and Xiao, J and Liu, Z and Yang, H and Hu, X and Sunaga, H and Hada, T and Akiyama, M and Ioroi, S and Tanaka, H and Chen, L.-C. and Sheu, R.-K. and Lu, H.-C. and Lo, W.-T. and Chu, Y.-P. and Zelek, J and Fazl, E and Asmar, D and Fakih, A and Li, H and Lu, H.-C. and Shou, L and Chen, G and Chen, K and Arias-De-reyna, E and Dai, F and Zhu, Z and Lihan, M and Tsuchiya, T and Koyanagi, K and Zhang, C and Chen, X.-L. and Zhou, L and Chen, W.-B. W.-T. and Senanayake, R and Ramos, F and Yang, J and Hua, K and Wang, Y and Wang, W.-H. and Wang, H and Shen, J and Liao, L and Fox, D and Hightower, J and Kautz, H and Schulz, D and Ochmann, S and Vock, R and Wessel, R and Klein, R and Liu, W and Gong, S and Zhou, Y and Wang, P and Molyneaux, D and Izadi, S and Kim, D and Hilliges, O and Hodges, S and Cao, X and Butler, A and Gellersen, H and Ahmed, T and Pedersen, T B and Lu, H.-C. and Tian, J and Jiang, Y and Chen, Y and Li, W.-S. and Mu, N and Wang, C.-S. and Liu, M and Zhang, Y and He, J and Guo, J and Guo, Y and Murillo, A C and Ko{\v{s}}eck{\'{a}}, J and Guerrero, J J and Sag{\"{u}}{\'{e}}s, C and Im, T and De, P and Li, B and Gallagher, T and Dempster, A G and Rizos, C and Baha aldin, N and Er{\c{c}}elebi, E and Ayka{\c{c}}, M and Satan, A and Toth, Z and Zhang, Y and Partridge, K and Reich, J and Rao, H and Huang, S.-W. W and Fu, W.-T. and Chriki, A and Touati, H and Snoussi, H and Christensen, K F and Christiansen, L L and Pedersen, T B and Pihl, J and Ng, W W Y and Ding, H.-L. and Chan, P P K and Yeung, D S and Farahiyah, D and Romadhoni, R M and Pratomo, S W and Yang, X and Tian, Y and Yi, C and Arditi, A and Biocca, F and Tang, A and Owen, C and Xiao, F and Uddin, M S and Jang, Y M and Jain, P and {Roy Choudhury}, R and Vuckovic, M and Petrovi{\'{c}}, I and Vidovic, D and Kostovic, Z and Pletl, S and Kukolj, D and Xu, B and Yu, R and Sun, G and Yang, Z and Xiao, X and Xu, C and Rui, Y and Jin, P and Cui, T and Wang, Q and Jensen, C S and Focken, D and Stiefelhagen, R and Chandrasekaran, V and Narayan, K and Vasani, R K and Balasubramanian, V and {Md Mahfujur Rahman}, A S and {El Saddik}, A and Cherntanomwong, P and Chantharasena, W and Hern{\'{a}}ndez, J L and Moreno, M V and Jara, A J and Skarmeta, A F and Qiu, C and Mutka, M W and Xu, J and G{\"{u}}ting, R H and Bento, C and Soares, T and Veloso, M and Baptista, B and Bouguet, J.-Y. and Perona, P and Bishay, M and {Peters II}, R A and Kawamura, K and Mineno, H and Hida, K and Mizutani, M and Miyauchi, N and Kusunoki, K and Fukuda, A and Mizuno, T and Chen, C.-H. and Chiu, C.-C. and Liu, C.-L. and Nishimura, T and Nakamura, Y and Tomobe, H and Kurata, T and Okuma, T and Matsuo, Y and Luoh, L and {De Vita}, F and Bruneo, D and Barfeh, D P Y and Bustamante, R V and Jose, E C and Lansigan, F P and Mendoza, E R and Mariano, V Y and Jim{\'{e}}nez, A R and Seco, F and Peltola, P and Espinilla, M and Murshed, M and Morshed, M and Chae, O and Song, B and Vaswani, N and Roy-Chowdhury, A K and Headley, W C and {Da Silva}, C.R.C.M. and Buehrer, R M and Kim, H and Reitmayr, G and Woo, W and Vieira, E B and Leal, A G and Khan, U Z and Shaukat, A and Akram, M U and Basit, M K and Hassan, A and Wahid, A and Tapu, R and Mocanu, B and Zaharia, T and M{\'{e}}ndez-Polanco, J A and Mu{\~{n}}oz-Mel{\'{e}}ndez, A and Morales, E F and Zhang, B and Trajcevski, G and Liu, L and Funk, M and Boldt, R and Pfleging, B and Pfeiffer, M and Henze, N and Schmidt, A and Tsai, C.-Y. and Chou, S.-Y. and Lin, S.-W. and Wang, W.-H. and Deng, Z and Todorovic, S and {Jan Latecki}, L and Huang, S.-W. W and Mohanty, S and Ashfahani, A and Pratama, M and Liu, M and Zhang, K and Zhu, J and Wang, J Z and Guo, J and Guo, Y and Swadzba, A and Wachsmuth, S and Zhou, Y and Yan, S and Huang, T S and Lee, W.-Y. W.-T. and Hur, K and Kim, T and Eom, D.-S. and Kim, J.-O. J.-H. and Afyouni, I and Ray, C and Ilarri, S and Claramunt, C and Gardner, M.-A. and Sunkavalli, K and Yumer, E and Shen, X and Gambaretto, E and Gagn{\'{e}}, C and Lalonde, J.-F. and Desingh, K and Nagariya, A and Krishna, K M and Vaucelle, C and Paradiso, J A and Ishii, H and Shafer, S and Liu, Q and Li, R and Hu, H and Gu, D and Bobek, S and Grodzki, O and Nalepa, G J and Politis, Zafiris and Probert, Penny and Zeng, Y and Pathak, P H and Mohapatra, P and Wu, P and Kong, L and Gao, S and Frintrop, S and Rome, E and N{\"{u}}chter, A and Surmann, H and Dwiyasa, F and Lim, M.-H. and Ong, Y.-S. and Panigrahi, B and Tateno, S and Cho, Y and Li, D and Tian, H and Hsiao, P and Marques, N and Meneses, F and Moreira, A and Reza, A W and Geok, T K and Papapostolou, A and Chaouchi, H and Mori, T and Siridanupath, C and Noguchi, H and Sato, T and Walton, D R and Thomas, D and Steed, A and Sugimoto, A and Lin, L and Gong, H and Li, L and Wang, L and Zhang, D and Jiang, X and Ni, L M and Gao, R and Zhao, M and Ye, T and Ye, F and Wang, Y and Bian, K and Wang, T and Li, X and Pittarello, F and {De Faveri}, A and Ye, T and Walsh, M and Haigh, P and Barton, J and Mathewson, A and O'Flynn, B and O'Mathuna, C and Bouguet, J.-Y. and Perona, P and Chen, K and Lai, Y.-K. and Wu, Y.-X. and Martin, R and Hu, S.-M. and Jayakody, J.A.D.C.A. and Murray, I and Sato, Y and Hashimoto, K and Shibata, Y and Wang, H and Jin, P and Zhao, L and Zhang, L and Yue, L and Xu, W and Wang, B and Jiang, Y and Bahadori, S and Iocchi, L and Leone, G R and Nardi, D and Scozzafava, L and Rivadeneyra, C and Campbell, M and Bauer, G and Blanke, U and Lukowicz, P and Schiele, B and Marchesotti, L and Piva, S and Regazzoni, C S and Ropponen, A and Rimminen, H and Sepponen, R and Tesch, D A and Berz, E L and Hessel, F P and Cupec, R and Nyarko, E K and Filko, D and Kitanov, A and Petrovi, I and Kim, Y M and Mitra, N J and Yan, D.-M. and Guibas, L and Zhu, Z and Oskiper, T and Samarasekera, S and Kumar, R and Sawhney, H S and Gracia-Roche, J J and Orrite, C and Bernu{\'{e}}s, E and Herrero, J E and Chen, Z and Xia, F and Huang, T S and Bu, F and Wang, H and Mainetti, L and Mighali, V and Patrono, L and Men, C and Mao, L and Wu, L and L{\'{o}}pez-de-Ipi{\~{n}}a, D and Vazquez, J I and Abaitua, J and Al-Nuaimi, A and Piccolrovazzi, M and Gedikli, S and Steinbach, E and Schroth, G and Shen, S and Gowda, M and Choudhury, R R and Meng, X and Gao, Y and Kwok, K.-H. and Zhao, H and Ishiguro, H and Yamamoto, M and Tsuji, S and Tseng, H.-Y. and Lee, C.-T. and Lin, C.-A. C.-H. C.-Y. C.-T. and Chou, P H and Lu, X and Zhang, Y and Zheng, Z and Upadhyay, S and Krishna, K M and Kumar, S and Radhakrishnan, M and Sen, S and Misra, A and Lee, Y.-F. Y.-C. and Balan, R K and Takagi, M and Takahashi, Y and Komeda, T and Li, C C and Wu, P and Wang, H and Chu, E T H and Liu, J W S and Sharhan, S M H and Zickau, S and Kataoka, K and Sudo, K and Morimoto, M and Patel, S N and Rekimoto, J and Abowd, G D and Wu, C.-C. C.-J. and Tsai, W.-H. and Yuan, M L and Ong, S K and Nee, A Y C and Kim, T and Lee, S.-T. J and Park, S.-K. S.-C. and Chen, R C and Huang, S.-W. W and Lin, Y C and Zhao, Q F and Emmanuel, S and Zhang, P and Sugama, A and Panta, F J and S{\`{e}}des, F and Curran, K and Condell, J and Knox, J and Yuuto, C and Kanji, T and Masatoshi, A and Kawsar, F and Fujinami, K and Nakajima, T and Liu, Z and Zhang, Y and Wu, W and Liu, K and Sun, Z and Xia, J and Xu, C and Liu, Z and Yu, H and Nur, K and Morenza-Cinos, M and Carreras, A and Pous, R and Guo, B and Satake, S and Imai, M and Nakamura, Y and Kobayashi, R and Minami, M and Nishimura, T and An, S.-Y. and Lee, L.-K. and Oh, S.-Y. and Kang, J.-G. and Lee, S.-T. J and Lim, J and Tewolde, G and Kwon, J and Daniyal, F and Taj, M and Cavallaro, A and Hada, T and Sunaga, H and Akiyama, M and Ioroi, S and Tanaka, H and Zhou, B and Gao, R and Elbadry, M and Ye, F and Weng, D and Huang, Y and Liu, Y and Wang, Y and Choi, J and Kim, C and Park, S.-K. S.-C. and Wan, E A and Paul, A S and Anzum, N and Afroze, S F and Rahman, A.S.M.M. and Cheng, H and Huang, L and Xu, H and Hu, Y and Wang, X A and Lee, J X and Seo, M and Kim, J.-O. J.-H. and Hwang, S and Kim, T and Kim, K.-S. and Cheng, R.-S. and Lin, K.C.-J. W and Hong, W.-J. and Pan, Y.-J. and Yang, C.-W. and Gu, H and Shi, Y and Chen, Y and Wang, B and Jiang, W and Sato, Y and Hashimoto, K and Shibata, Y and Tsechpenakis, G and Xirouhakis, Y and Delopoulos, A and Wang, J Z and Zhang, L and Wang, X A and Xiong, J and Chen, X.-L. and Fang, D and Hauschildt, D and Kemper, J and Kirchhof, N and Juretko, B and Linde, H and Shou, Y.-W. and Lin, C.-A. C.-H. C.-Y. C.-T. and Siana, L and Shen, T.-K. and Shen, J and Molisch, A F and Feng, Y and Du, W and Guan, X and Gao, F and Chen, Y and Aizawa, K and Yamasaki, T and Kawaji, H and Kawamura, S and Wu, J and Zhou, L and Xiang, Z and Chenning, L and Ting, Y and Qian, Z and Haowei, X and Enfu, L and Kanji, T and Xiaoxiao, F and Raychoudhury, V and Shrivastav, S and Sandha, S S and Cao, J and Zou, H and Xie, L and Jia, Q.-S. and Wang, H and Pongthawornkamol, T and Ahmed, S and Nahrstedt, K and Uchiyama, A and Du, Y and Arslan, T and Gentile, C and Braga, A J and Kik, A and Lin, C.-A. C.-H. C.-Y. C.-T. and Chen, P.-Y. and Chen, W.-B. W.-T. and Kuo, S.-P. and Tseng, Y.-C. and Sankar, A and Seitz, S M and Wu, T.-Y. and Liaw, G.-H. and Huang, S.-W. W and Lee, W.-Y. W.-T. and Wu, C.-C. C.-J. and Schelkshorn, S and Detlefsen, J and Zhang, S and Sridharan, M and Washington, C and Kapidis, G and Poppe, R W and {Van Dam}, E A and Veltkamp, R C and Noldus, L.P.J.J. and Passarinho, C J P and Salles, E O T and Sarcinelli-Filho, M and Durucan, E and Ebrahimi, T and Wei, Y.-L. and Huang, C.-J. and Tsai, H.-M. and Lin, K.C.-J. W and Delmerico, J A and Corso, J J and Baran, D and David, P and Ryde, J and Kim, Y M and Jung, H and Jang, J and Kim, U.-M. and Hepeng, D and Donglin, S and Chrysikos, T and Papadakos, C and Kotsopoulos, S and Bagci, Faruk and Kluge, F and Satzger, B and Ungerer, T and Yi, C and Suh, I H and Lim, G H and Jeong, S and Choi, B.-U. and Hedau, V and Hoiem, D and Forsyth, D and Berz, E L and Tesch, D A and Hessel, F P and Tapu, R and Mocanu, B and Bursuc, A and Zaharia, T and Datta, A and Yow, K.-C. and Conci, N and Lizzi, L and Wan, L and Miao, Z and Chang, D and Cen, Y and Li, H and Lu, H.-C. and Shou, L and Chen, G and Chen, K and Piyathilaka, L and Kodagoda, S and Xu, K and Ma, R and Zhang, H and Zhu, C and Shamir, A and Cohen-Or, D and Huang, H and Kamruzzaman, S M and Jaseemuddin, M and Fernando, X and Moeini, P and Baba, A I and Knierim, P and Nickels, J and Musiol, S and K{\"{o}}nings, B and Schaub, F and Wiedersheim, B and Weber, M and Chen, Y and Ni, D and Zhang, L and Deng, C and Huang, S.-W. W and Wang, W.-H. and He, S and Lau, R W H and Yoshida, T and Wang, J Z and Cheng, Z and Chawla, K and McFarland, C and Robins, G and Shope, C and Pirkl, G and Lukowicz, P and Blumrosen, G and Hod, B and Anker, T and Dolev, D and Rubinsky, B and Sun, Y and Bo, L and Fox, D and Guan, L and Franco, J.-S. and Pollefeys, M and Pestana, G and Metter, J and Heuchler, S and Reis, P and Pishdad, L and Labeau, F and Samadi, M and Kollar, T and Veloso, M and Lee, Y.-F. Y.-C. and Bonani, M and Magnenat, S and R{\'{e}}tornaz, P and Mondada, F and Zhao, Y and Lamarca, A and Smith, J R and Liu, Y and Adjeroh, D and Chianese, A and Piccialli, F and Valente, I and Guo, J and Zhang, S and Zhao, W and Peng, J and Khan, S H and Bennamoun, M and Sohel, F and Togneri, R and Naseem, I and Schulz, D and Fox, D and Hightower, J and Dey, A and Sandor, C and Sankar, A and Seitz, S M and Tabibiazar, A and Basir, O and Ahmad, J and Mehmood, I and Rho, S and Chilamkurti, N and Baik, S W and Zhou, Y and Benois-Pineau, J and Nicolas, H and Zhou, S K and Chellappa, R and Moghaddam, B and {Syed Ariffin}, S H and {Abdul Wahab}, N H and Fisal, N and Latiff, L A and Choong, K.-N. and Raj, M A and Mohamed, R and Abbas, M and Yu, S.-I. and Yang, Y and Hauptmann, A and Yan, D.-M. and Zhao, Z and Ng, W W Y and Hedley, M and Sathyan, T and Lee, K.-M. and Li, M and Lin, C.-A. C.-H. C.-Y. C.-T. and Viswanathan, P and Southey, T and Little, J and Mackworth, A and Takatsuka, H and Tokunaga, S and Saiki, S and Matsumoto, S and Nakamura, M and Zou, Y and Wang, Y and Ye, S and Wu, K and Ni, L M and Malekpour, A and Ling, T C and Lim, W C and Kawaji, H and Hatada, K and Yamasaki, T and Aizawa, K and Duan, C and Rao, X and Yang, L and Liu, Y and Lam, L D M and Tang, A and Grundy, J and Rodriguez, V and Mathar, R and Li, Y and Bitsakos, K and Fermuller, C and Aloimonos, Y and Maneerat, K and Prommak, C and Patil, S and Talele, K and Amer, A and Dubois, E and Mitiche, A and Abdat, M and Wan, T.-C. and Supramaniam, S and Ghadiok, V and Goldin, J and Ren, W and Antic, B and Ommer, B and Ogawa, Y and Wang, Z and Wada, T and Hirata, Y and Kosuge, K and Cankaya, I A and Koyun, A and Yigit, T and Yuksel, A S and Xu, J and G{\"{u}}ting, R H and Ma, Y and Kan, E C and Wang, S.-S. and Tsai, P.-H. and Li, W.-S. and Riboni, D and Bettini, C and Schmid, S and Richner, T and Mangold, S and Gross, T R and Bouman, K L and Ye, V and Yedidia, A B and Durand, F and Wornell, G W and Torralba, A and Freeman, W T and Recio, I and Moya, J M and Araujo, {\'{A}} and Vallejo, J C and Malag{\'{o}}n, P},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1504/IJSNET.2009.029392},
issn = {1748-1279},
keywords = {2D images,3 d model retrievals,3-D mapping,3-D shape,3-D space,3-d modeling,3D Laser scanning,3D Structure,3D acquisition,3D content,3D directions,3D indoor scenes,3D laser scanners,3D localization,3D meshes,3D model retrieval,3D model retrieval methods,3D modeling,3D models,3D object,3D object retrieval,3D parsing,3D photography,3D reconstruction,3D scenes,3D spatial analysis,3D-position,3d representations,3d sensors,802.15.4a,A-thermal,ADL,AP selection,ATAM,Abstracting,Acceleration sensors,Accelerometers,Access control,Access control mechanism,Access points,Accident prevention,Accumulative errors,Accuracy Improvement,Accuracy and precision,Accurate estimation,Accurate location,Acoustic event detections,Acoustic imaging,Acoustic sensing,Acoustics,Acquisition,Active RFID,Active radio frequency identifications,Active rfid tags,Activity recognition,Activity sensing,Actual distance,Actual measurements,Ad hoc mode,Ad hoc systems,Adaptive background model,Adaptive particle filters,Adaptive systems,Adaptive transformations,Additional costs,Additional knowledge,Adverse effect,Agent-based approach,Agent-based architecture,Agglomerative clustering,Aggregate queries,Air navigation,Airport passenger,Airport security,Airport surveillance,Airports,Alarm systems,Algebraic approaches,Algorithm design and analysis,Algorithm performance,Algorithmic procedure,Algorithms,Algorithms and data structures,Aliasing,Aliasing problems,Allocentric representations,Alpha channels,Alternate method,Alternative technologies,Amazon mechanical tu,Ambient Intelligence,Ambient assisted living,Ambient intelligence,Ambient signals,Anchor nodes,Anchor point,Anchors,Android applications,Angle estimations,Angle of arrival,Angle-of-arrival,Angular distribution,Angular resolutions,Angular uncertainty,Animals,Anomalous events,Anomaly detections,Antenna arrays,Antennas,Antialiasing,Appearance adaptive model,Appliance controls,Application area,Application programs,Application services,Applications,Approximate geometries,Arbitrary number,Arbitrary objects,Architectural decision,Architectural design,Architecture,Area of interest,Artificial Intelligence,Artificial intelligence,Artificial intelligence techniques,Assisted living,Assistive,Assistive devices,Assistive technology,Asynchronous system,Attention funnel,Attenuation factors,Attenuator,Attitude estimation,Attitude stabilization,Attractive solutions,Attribute graph grammar,Attribute graphs,Au,Auction,Audio acoustics,Audio signals,Audio systems,Augmented Reality(AR) attention,Augmented reality,Augmented reality applicati,Augmented reality systems,Automated,Automated discovery,Automated video surveillance,Automatic identificati,Automatic identification,Automatic layout,Automatic method,Automatic segmentations,Automatically generated,Automatically track,Automation,Autonomous Mobile Robot,Autonomous agents,Autonomous driving,Autonomous exploration,Autonomous feature-based exploration,Autonomous land vehicle,Autonomous navigation,Autonomous robotic systems,Autonomous stair climbing,Autonomous surveillance,Average errors,Background image,Background knowledge,Background segmentation,Background subtraction,Backscattering,Backward projection,Band pass filtering,Bandpass filters,Bandstitching,Bandwidth,Bandwidth savings,Bar codes,Base stations,Basic systems,Battery powered devices,Bayes Classifier,Bayesian,Bayesian frameworks,Bayesian inference,Bayesian methods,Bayesian model,Bayesian networks,Beacon,Beacon nodes,Beads,Beam plasma interactions,Bearing c,Bearings (structural),Behavioral patterns,Behavioral research,Beijing [Beijing (ADS)],Beijing [China],Benchmarking,Best paths,Beverages,Bi-directional communicatio,Big data,Binary images,Binary phase shift keying,Binocular Stereo,Biological,Biological information,Biomedical Technology,Biomimetics,Bit error rate,Ble beacons,Blind people,Blind person,Blind source separation,Bluetooth,Bluetooth low energ,Bluetooth low energies (BLE),Bluetooth low energies (BTL,Bluetooth low energies (BTLE,Bluetooth low energies (BTLE),Bluetooth networks,Bluetooth technology,Bluetooth-based,Body-worn sensors,Boolean algebra,Boolean functions,Bounding box,Bounding polygons,Broadband n,Broadband networks,Budget control,Building automatio,Building blockes,Building footprint,Building materials,Building property,Building signal systems,Buildings,Bullseye,Burn scars,Burning buildings,Burns,Business Process,Business processing,C-v models,CRLB,Calibrated cameras,Calibration,Camera calibration,Camera direction,Camera model,Camera network,Camera placement,Camera selec,Camera sensor,Camera tracking,Cameras,Canny edge detectors,Capability,Capacitive reactance,Capacitive sensor,Capture images,Car parks,Carrie,Carrier phase error,Carrier tracking loop,Ceilings,Cell phone,Cells,Cellular neural networks,Cellular radio systems,Cellular space,Cellular telephones,Centralized processing,Challe,Challenging tasks,Change detection,Changing environment,Channel distortions,Channel state information,Charge ac,Chemical sensors,China,Chirp modulation,Chirp spread spectrum,Chromaticity,Chronic d,Circular-shaped landmark,Cl,Classification (of,Classification (of information),Classification methods,Classification rates,Classification sch,Classification system,Closed contours,Closed-form formulae,Cloud computin,Cluster Anal,Cluster computing,Clustering,Clustering algorithms,Clutter (information theory),Cluttered backgrounds,Cluttered environments,Co-occurrence statistics,Co-ordinate system,Coarse-to-fine localization,Code sequences,Codes (symbols),Coffee shops,Cognitive systems,Coherent frameworks,Collaborative TOA/RSSI localization,Collective robotics,Color,Color and textures,Color calibration,Color correction,Color image processing,Color images,Color information,Color segmentation,Color variations,Color video,Com,Combinatorial optimization,Combinatorial optimization prob,Commercial applications,Commercial off-the-shelf,Commercial-off-the-shelf,Commun,Communi,Communication,Communication area,Communication channels (information th,Communication cost,Communication equipments,Communication interface,Communication layers,Communication rang,Communication technologies,Competing technologies,Compl,Complex dynamics,Complex networks,Complex scenes,Complicated b,Component,Compressed sensing,Compressive sensing,Compu,Computation,Computation complexity,Computation theory,Computational,Computational complexity,Computational costs,Computational efficiency,Computational geometry,Computational limitations,Computational methods,Computational model,Computational performance,Compute,Computer,Computer Vision,Computer aided desi,Computer aided design,Computer applications,Computer architecture,Computer graphics,Computer hardware,Computer networks,Computer operating systems,Computer privacy,Computer programming,Computer science,Computer simulation,Computer simulation technology,Computer software,Computer software portability,Computer supported cooperativ,Computer supported cooperative work,Computer systems,Computer terminals,Computer vision,Computer vision algo,Computer vision applications,Computer vision system,Computer vision tech,Computer vision technolog,Computer-Assisted,Computers,Computing applications,Computing paradigm,Concentration (proc,Conceptual knowledge,Concrete service,Concurrent engin,Conditi,Conditional random field,Conductive materials,Conformal mapping,Connected component analysis,Connectivity indices,Consistency checks,Consistent performance,Constraine,Constrained space,Construction engineering,Construction sites,Construction works,Content based retrieval,Content creation,Content-b,Context Awareness,Context annotation,Context aware applications,Context awareness,Context free languages,Context independent,Context sensitive grammars,Context-Aware,Context-aware,Context-aware applications,Context-aware systems,Contextual cue,Contextual information,Contextual navigation,Contextual re,Contextual rela,Continuous monitoring,Continuous processing,Continuous query processing,Continuous tracking,Control services,Control systems,Control theory,Controlled environment,Controllers,Conventional approach,Conventional methods,Conventional systems,Convolution,Convolution neural network,Convolutional neural,Convolutional neural net,Convolutional neural networ,Convolutional neural network,Cooperative localiza,Cooperative localization,Coordinate measuring machines,Cosine similarity,Cost benefit analysis,Cost effect,Cost effectiveness,Costs,Counter propagation networks,Coupled hidden Markov models,Coverage gaps,Covering algori,Cramer-Rao bounds,Cramer-rao lower bound,Critical equipment,Critical infrastructures,Crowd evacuation,Crowd managements,Crowd sou,Crowdsourcing,Cryptography,Crystal orientation,Cult,Cultural environment,Cultural heritages,Current data,Current generation,Curve fitting,Cybernetics,Cytology,D,D dimensions,D-function,Daily live,Daily lives,Daily use,Data,Data Processing,Data acquisition,Data and information,Data anoma,Data driven,Data fusion,Data handling,Data integration,Data management,Data measurements,Data mining,Data privacy,Data processing,Data reduction,Data representations,Data sample,Data sets,Data size,Data structures,Data type,Data-communication,Data-dr,Database systems,Daylighting,Daylighting design,De,Dead reckoning,Decision support systems,Decision supports,Decision theoretic approach,Decision trees,Decision-tree algorith,Deep learning,Deep neural networks,Degeneracy problems,Delivery task,Deployment costs,Dept,Depth,Depth Estimation,Depth percep,Descriptors,Design,Design a,Design and implementations,Design challenges,Design paradigm,Design recommendations,Design tool,Detection algorithm,Detection and collection syst,Detection and tracking,Detection experiments,Detection range,Detectors,Device switching,Device system,Device-free localizations,Diesel engines,Different frequency,Differentiation schemes,Digital compass,Digital devices,Digital filters,Digital information,Digital museums,Digital representations,Digital storag,Digital storage,Dijkstra's algorithms,Direc,Direct paths,Directi,Direction of motion,Directional patterns (antenna),Directive antenna,Disabled persons,Discrete time contr,Distance estimation,Distance information,Distributed,Distributed c,Distributed compute,Distributed computer systems,Distributed objects,Distributed particle filter,Diversity reception,Domestic appliances,Door de,Door detection,Doors,Doppler effect,Doppler frequency,Doppler measurements,Dual-space geometry,Duration query,Dynamic approaches,Dynamic environmen,Dynamic objec,Dynamic positioning,Dynamic time warping,Dynamical feedback systems,Dynamical systems,E,E-learning,EMO node,Earth magnetic fields,Economic and social effec,Economic and social effects,Economics,Edge,Edge Segme,Edge detection,Education,Effectiv,Effective measures,Effectiveness and efficiencies,Efficiency,Efficient detection,Efficient managements,Efficient systems,Elderly people,Electric batteries,Electric power utiliz,Electric rectifiers,Electrical engineerin,Electromagneti,Electromagnetic,Electromagnetic pulse,Electronic circui,Electronic circuit tracking,Electronic component,Electronic data interchange,Electronic device,Electronic document identification systems,Elevators,Em,Embedded sensors,Embedded systems,Emergency,Emergency evacuation,Emergency response,Emergency services,Emerging applications,Emotional speech,Empirical pe,Empirical studies,Encoding (symbols),Energy accuracy tradeoff,Energy assessment,Energy efficiency,Energy efficient,Energy harvesting,Energy utilization,Engi,Engine,Engineering challenges,Engineering education,Enhanced performance,Enhanced resolutions,Entropy,Envir,Environme,Environment awareness,Environment cognition,Environment maps,Environmental dynamics,Environmental fa,Environmental factors,Environmental interference,Environmental technology,Environmental testing,Equipment,Equipment Desi,Equipment t,Err,Error analysis,Error detection,Error sources,Error statistics,Error variance,Errors,Estimated errors,Estimation,Estimation errors,Estimation performa,Estimation problem,Event model,Event-driven architectures,Exhibitions,Expe,Exper,Experiential,Experime,Experimen,Experimental evaluation,Experimentation,Experiments,Extended Kalman filtering,Extended Kalman filters,Extensive simulations,External-,Extraction,Extraction techniques,Extreme learning machine,Eye trackers,FOV,Face recognition,Face tracking,Fading (radio),Fast learn,Fe,Fea,Feasibility studies,Feature dimensions,Feature extract,Feature extraction,Feature map,Feature pa,Feature poin,Feature pool,Feature projection,Feedback,Feedback operations,Field of view,Field programmable gate,Field programmable gate arrays (FPGA),Fingerpri,Fingerprint,Fingerprint Recognition,Fingerprint algorithm,Fingerprint matching,Fingerprint method,Fingerprinting,Fingerprinting-like algorithm,Finite distance illumination,Floor surface,Floorplans,Floors,Flow visualization,Focal points,Forecasting,Forensic,Forensic applications,Forestry,Formal languages,Frames per seconds,Free Localization,Free sol,Free spaces,Frequ,Freque,Frequenc,Frequency estimation,Frequency i,Frequency re-us,Frequency separation,Frequent pattern,Fu,Future trends,Fuzzy pr,G,GIS,GPS,GPS signals,Gabor filters,Gateway WLAN Location Center (GWLC),Gateways (computer net,Gateways (computer networks),Gaussian filtering,Ge,Gene,General st,Generative models,Generic data,Generic frameworks,Genetic algorithms,Geograph,Geographic,Geographic information systems,Geom,Geomag,Geomagnetism,Geometric reaso,Geometric reasoning,Geometry,Gestural,Gesture recognition,Gl,Globa,Global illumination change,Global informa,Global positioning sy,Global positioning syste,Global positioning system,Global reference,Global s,Global system for mobile commu,Global system for mobile communications,Google,Graph theory,Graph-ba,Graph-based mo,Graphic methods,GraphicaL model,Graphical user interfaces,Gravity forces,Grid cells,Grid index,Ground pe,Ground planes,Gyroscopes,H,H -infinity controls,Ha,Hand held computers,Hand held device,Hand-held,Handhel,Handicapped persons,Hardware,Hardware acceleration,Harmonic,Harmonic analysis,Harsh environm,Harvesting,Head mounted displays,Health care,Heat radiation,Helmet mounted displays,Heterogeneo,Heterogeneous sourc,Hidden,Hidden M,Hidden Markov models,Hier-archica,Hier-archical clus,Hierarchic,Hierarchica,Hierarchical Clustering,Hierarchical architectures,Hierarchical decompositions,Hierarchical location model,High Speed,High d,High dynamic,High level knowledge,High quality,High quality images,High tra,High-level go,High-quality,High-quality imaging,Higher-l,Historical databases,Holography,Home robot,Home service ro,Hot research topics,Human bodies,Human computer,Human computer interaction,Human context,Human movements,Human rehabilitation equipment,Human robot interactio,Human robots,Human to environment inter,Human-centric,Humidity control,Hybrid systems,I,I.3.5 [computer graphics]: c,Identification (co,Identification data,Illumination changes,Illumination conditions,Im,Imag,Image,Image Enhanc,Image Enhancement,Image Interpretati,Image a,Image analysis,Image coding,Image completion,Image datasets,Image enhancement,Image ex,Image matching,Image processing,Image r,Image recognition,Image recon,Image reconstruc,Image reconstruction,Image regions,Image representations,Image resolution,Image retrieval,Image retrieval syste,Image segme,Image segmentatio,Image segmentation,Image sensors,Image texture,Image-based,Image-based localizations,Imaging,Imaging systems,Implicit,Importa,In,In-buildings,In-door naviga,In-door navigations,Incremental development,Ind,Independent component analysis,Index structure,Indexing,Indexing (materials working),Indexing (of information),Indexing moving o,Indexing scale-invar,Indo,Indoo,Indoor,Indoor Positioning,Indoor and outdoor locations,Indoor applicat,Indoor applications,Indoor en,Indoor envi,Indoor enviro,Indoor environ,Indoor environme,Indoor environment,Indoor environments,Indoor flows,Indoor l,Indoor loc,Indoor loca,Indoor localiz,Indoor localization,Indoor locating,Indoor location services,Indoor location systems,Indoor locations,Indoor mixe,Indoor mobile robots,Indoor mobility,Indoor n,Indoor navigation,Indoor object,Indoor posit,Indoor positi,Indoor position,Indoor positionin,Indoor positioning,Indoor positioning s,Indoor positioning sy,Indoor positioning sys,Indoor positioning syst,Indoor positioning syste,Indoor positioning system,Indoor positioning systems,Indoor propagation,Indoor sp,Indoor space,Indoor surv,Indoor testing,Indoor tracking,Indoor/outdoor,Indus,Indust,Industrial automation,Industrial facilities,Industry,Inf,Inference eng,Inference engines,Info,Informa,Information,Information Retrieval,Information Storage and Retrie,Information analysis,Information management,Information retrieva,Information retrieval,Information science,Information services,Information systems,Infrar,Infrared devices,Infrared imag,Infrared radiation,Initial,Innovation,Int,Integral part,Intel,Intell,Intellectual systems,Intelligent b,Intelligent build,Intelligent buildings,Intelligent e,Intelligent networks,Intelligent robots,Intelligent system,Intelligent systems,Intens,Intera,Interaction,Interactive compute,Interactive computer gr,Interactive computer graphics,Interactive computer systems,Interactive devices,Interactive modeling,Interactive s,Interference environments,Interference suppression,Intern,International,International conferences,Internet,Internet of thing (I,Internet of things,Internet protocols,Interoperability,Interpolat,Intuitive,Invariant featu,Invariant features,Iot devic,Iter,Iterative methods,Javascript,K neare,Kalman filters,Key fr,Kinect sens,Knowle,Knowled,Knowledge acq,Knowledge acquisition,Knowledge eng,Knowledge management,Known en,L,LED-ID system,LTE,Lambertian diffuse component,Landing,Landmark,Large virtual environments,Large-scale fading,Laser applications,Laser range,Laser range measurements,Laser range-finders,Laser-assisted interaction,Lasers,Layout,Learnin,Learning algorithms,Learning appr,Learning objects,Learning systems,Least squares a,Level of detail,Li,Lib,Light,Light emitting,Light emitting diodes,Light source positi,Light sources,Lighti,Lighting,Line of s,Line segment,Line-of-sight paths,Linear regression methods,Linear systems,Lo,Loc,Loca,Locali,Localisation,Locality sen,Localization,Localization a,Localization and tracking,Localization errors,Localization hardware costs,Localization met,Localization performance,Localization services,Localizing tags,Locat,Locati,Locating system,Locatio,Location,Location Tr,Location assisted sys,Location based,Location based services,Location detections,Location e,Location estimation,Location in,Location information,Location-Based,Location-awar,Location-aware,Log,Log polar mapping,Log-norma,Long sh,Low costs,Low power electronics,Low-level features,M,MAP estimation,MATLAB GUI,MRC,Ma,Machine design,Machinery,Magnetic couplings,Magnetic field effects,Magnetic fields,Mana,Manhat,Manifold structures,Manipula,Manipulators,Map,Map vi,Mapping,Maps,Markov processes,Mat,Mathematical,Mathematical m,Mathematical models,Mathematical techniq,Mathematical techniques,Mathematical transformations,Matrix algebr,Maximal ratio combining (MRC),Me,Measurement data,Media management,Mergers and acquisitions,Met,Metadata,Metallurgy,Microeconomics,Middleware,Millimeter wave system,Mob,Mobil,Mobile,Mobile applications,Mobile camera,Mobile computers,Mobile computing,Mobile crowdsensing,Mobile de,Mobile detectors,Mobile devi,Mobile devices,Mobile envi,Mobile inte,Mobile interaction,Mobile m,Mobile nodes,Mobile objects,Mobile phones,Mobile robo,Mobile robots,Mobile telecommunication systems,Mobiles,Model matching problem,Models,Monito,Monitoring,Monocular cameras,Monte Carlo,Monte Carlo methods,Moti,Motio,Motion,Motion Picture,Motion analysis,Motion detection,Motion pl,Movement,Moving ob,Moving obje,Moving object lo,Mu,Mult,Multi,Multi-senso,Multi-views,Multilayer occlusion,Multimedia ob,Multimodality,Multiple ob,Museums,N,Natural feature tracking,Natural resources explorati,Nav,Navig,Navigat,Navigati,Navigatio,Navigation,Navigation systems,Nearest neighbor search,Net,Networ,Network layers,Network protocols,Network-control,Neur,Neural ne,Neural networks,Nonlinear filtering,Numerical Analysis,O,Objec,Object,Object detection,Object finding system,Object location,Object r,Object recog,Object recognitio,Object recognition,Object region,Object removal,Object tracking,Obst,Obstacle dete,Obstacle detectors,Occlusion,Office buildings,Omni-directional working,One dimensional,Online,Online Photos,Ontology,Optical,Optical character,Optical projectors,Optical radar,Optim,Optimization,Orienta,Orientation sensors,Outdoor e,P,PHP,Panoramic views,Parks,Particle fi,Particle filter,Particle filters,Patents and inventions,Patient moni,Patient rehabilitation,Patt,Pattern Recognition,Pattern recognit,Pattern recognition,Performance metrics,Person identification,Ph,Phased,Phot,Photography,Pipelines,Pixe,Place recognition,Planar surface,Play and learn,Pos,Position estimation,Positioni,Positioning,Positioning system,Power cont,Power contr,Power pricing,Probability,Probes,Problem solving,Processing f,Product information,Proje,Projective matrix,QR codes,Quality control,Query languages,Query p,Query proce,Query processing,R,RF-ID tags,RSS,Radar,Radial,Radiation pattern,Radio,Radio Frequency signatures,Radio communication,Radio f,Radio fr,Radio fre,Radio freq,Radio frequency,Radio frequency identifi,Radio frequency identification (,Radio frequency identification (RFID,Radio frequency identification (RFID),Radio navigation,Radio receivers,Radio transceivers,Radio w,Radio waves,Radiometry,Random processe,Re,Rea,Real,Real time systems,Rece,Recei,Received,Recovery,Redundancy,Reflecti,Region of in,Relati,Reliability,Rendering (computer,Rendering (computer graphics),Reproducibility of Results,Retail stores,Ro,Robot applica,Robot applicati,Robot n,Robot programming,Robotics,Robots,Rope,S,Sales,Satellite communication systems,Scanning,Scene representation,Scene struc,Scheduling,Se,Search engines,Security sy,Security sys,Security syst,Security systems,Sem,Sema,Seman,Semantic 3D environ,Semantic Web,Semantics,Sens,Sensitivit,Sensor networks,Sensor nodes,Sensors,Shadow dete,Signal,Signal Processing,Signal detection,Signal encodi,Signal encoding,Signal filter,Signal proc,Signal proce,Signal processing,Signal receivers,Site dive,Situ,Skin,Slide W,Smartphones,Social sciences,Software prototyping,Sonar,Sonar imaging,Source separation,Spatial con,Speech,Statistical,Stere,Stereo image pro,Stereo image processing,Stereo vision,Structu,Subch,Subtraction Technique,Supervised learning,Surface plasmon resonance,Surface reflectance,Surveying,Synchronization,Syntactics,Tags,Target tracking,Technical p,Technology,Tel,Telecommun,Telecommunication networks,Telecommunication se,Telecommunication systems,Telephone sets,Textures,Thre,Three dimensional,Three dimensional computer grap,Three dimensional computer graphics,Three-Dimensional,Time differ,Time serie,Timing,Topolog,Topology,Tracki,Tracking (positi,Tracking (position),Tracking algorithms,Tracking s,Trajectories,Transducers,Transm,Transmitters,U,Ubiqui,Ubiquitous,Ubiquitous c,Ubiquitous computing,Ult,Ultra-wid,Ultra-wideband (U,Ultra-wideband (UWB),Ultrasonic,Ultrasonic sensors,Ultrasonic testing,Ultrasonics,Unce,Uncertainty analysis,User interfaces,User-Co,Vehicles,Video cameras,Video datas,Video shots,Video-based surveillance systems,Virtual realit,Virtual reality,Vis,Visible light communication,Visual Tra,Visual odometry,Visualization,WSNs,Wearable co,Wearable computers,Web services,Wi-Fi,Wire,Wirel,Wireless local area n,Wireless local area networks (WLAN),Wireless sensor networks,Wireless telecommunication syst,Wireless telecommunication systems,World Wide Web,Zigbee,algorithm,article,artificial intelligence,auto,blind,blind/visually impaire,compressive sensing,computer assisted diagnosis,data processing,data set,database,devices,equation,equipment design,evaluation s,fingerprinting,geometry,graphical method,heterogeneity,iBeacons,iOS (operating system),index method,indoor,indoor location estimation,indoor location tracking,indoor physical map,k-NN,mapping,matrix,modeling,moving objects,numeric,pervasive computing,positioning,precisio,spatial anal,ubiquitous computing,wireless networks,wireless sensor networks},
number = {2},
pages = {1--8},
publisher = {Inderscience Publishers},
title = {{Optimisations for LocSens {\&}Ndash; an Indoor Location Tracking System Using Wireless Sensors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952566504{\&}doi=10.1007{\%}2F978-3-642-02481-8{\_}139{\&}partnerID=40{\&}md5=d8a7a3686625f812f2c7674217960960 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041916662{\&}doi=10.1109{\%}2FICCV.2017.249{\&}partnerID=40{\&}},
volume = {18},
year = {2017}
}
@article{BahaAldin20173811,
abstract = {Radio frequency identification technologies are popular since their cost is very low and its data transmission based upon radio-wave communications. Where, the objects that are attached to tags are located using the reference tags. However, RSSI information suffers from the multipath propagation and anisotropic interference. So, the localization accuracy will be affected severely. Also, the multipath-propagation increases whenever the reference-tags increase, and so does for the cost, and signal interference. This paper presents a boundary virtual reference label algorithm for improving the indoor-efficiency by inserting some virtual reference tags on the boundary with establishing a linear regression model that eliminates unwanted tag information from the estimation procedure. The Results show that the localisation precision of the proposed approach has significantly increased, at least 78{\%} without adding extra reference tags or radio frequency interference which represents a significant improvement over other algorithms. {\textcopyright} 2017, Springer Science+Business Media, LLC.},
annote = {cited By 2},
author = {{Baha Aldin}, N and Er{\c{c}}elebi, E and Ayka{\c{c}}, M},
doi = {10.1007/s11277-017-4700-7},
journal = {Wireless Personal Communications},
keywords = {Indoor locations; Linear regression models; Local,Indoor positioning systems; Linear regression; Mul,Radio frequency identification (RFID)},
number = {3},
pages = {3811--3829},
title = {{An Accurate Indoor RSSI Localization Algorithm Based on Active RFID System with Reference Tags}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027157037{\&}doi=10.1007{\%}2Fs11277-017-4700-7{\&}partnerID=40{\&}md5=e4e90f1fe45500e3c8abd8f9d00cc508},
volume = {97},
year = {2017}
}
@article{Bahaaldin20182943,
abstract = {Traditional indoor location technologies such as infrared technology and ultrasonic technology are complex, expensive, or having unsatisfactory location accuracy. Radio frequency identification (RFID) technologies are very popular in many areas since their costs are very low. The tag in such technologies acts as the transmitter, and the radio signal strength indicator (RSSI) information is measured at the reader. However, RSSI information suffers strictly from the multipath circumstance and circumferential elements. Therefore, the localization accuracy of the boundary will be affected severely. In order to solve this problem, we introduce the boundary virtual reference label (BVIRE) algorithm to well utilize RFID techniques for locating the tracking object, which inserts some virtual reference tags on the boundary by establishing a linear regression model that eliminates unwanted tag information from the estimation procedure. The positioning accuracy of the boundary tags and stability have been improved significantly, at least 78{\%}, without adding extra reference tags or radio frequency interference. Also, the estimation errors of our improved BVIRE are much smaller compared to the virtual reference label, location identification based on the dynamic active RFID calibration (LANDMARC), ultrawide band, RADAR, and PinPoint algorithms. {\textcopyright} T{\"{U}}BTAK.},
annote = {cited By 0},
author = {Bahaaldin, N and Ercelebi, E},
doi = {10.3906/elk-1505-52},
journal = {Turkish Journal of Electrical Engineering and Computer Sciences},
keywords = {Indoor locations; Linear regression models; Locat,Indoor positioning systems; Infrared radiation; Li,Radio frequency identification (RFID)},
number = {6},
pages = {2943--2957},
title = {{BVIRE improved algorithm for indoor localization based on RFID and a linear regression model}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062959458{\&}doi=10.3906{\%}2Felk-1505-52{\&}partnerID=40{\&}md5=f841a8ae129dce99fff011390c71c4c7},
volume = {26},
year = {2018}
}
@article{Bai2017,
abstract = {Objects in scenes are thought to be important for scene recognition. In this paper, we propose to utilize scene-specific objects represented by deep features for scene categorization. Our approach combines benefits of deep learning and Latent Support Vector Machine (LSVM) to train a set of scene-specific object models for each scene category. Specifically, we first use deep Convolutional Neural Networks (CNNs) pre-Trained on the large-scale object-centric image database ImageNet to learn rich object features and a large number of general object concepts. Then, the pre-Trained CNNs is adopted to extract features from images in the target dataset, and initialize the learning of scene-specific object models for each scene category. After initialization, the scene-specific object models are obtained by alternating between searching over the most representative and discriminative regions of images in the target dataset and training linear SVM classifiers based on obtained region features. As a result, for each scene category a set of object models that are representative and discriminative can be acquired. We use them to perform scene categorization. In addition, to utilize global structure information of scenes, we use another CNNs pre-Trained on the large-scale scene-centric database Places to capture structure information of scene images. By combining objects and structure information for scene categorization, we show superior performances to state-of-The-Art approaches on three public datasets, i.e. MIT-indoor, UIUC-sports and SUN. Experiment results demonstrated the effectiveness of the proposed method. {\textcopyright} 2017 World Scientific Publishing Company.},
annote = {cited By 3},
author = {Bai, S},
doi = {10.1142/S0218001417550138},
journal = {International Journal of Pattern Recognition and Artificial Intelligence},
keywords = {Classification (of information),Convolution; Image retrieval; Neural networks; Sup,Convolutional neural network; Large-scale objects},
number = {9},
title = {{Scene Categorization Through Using Objects Represented by Deep Features}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016948782{\&}doi=10.1142{\%}2FS0218001417550138{\&}partnerID=40{\&}md5=9d50ba7901244439e3f6a571ed23b12b},
volume = {31},
year = {2017}
}
@inproceedings{1651796,
abstract = {The paper discusses various techniques that have emerged for estimation of location and tracking of stationary and mobile objects both in the open terrain as well as inside a building. For outdoor applications, Global Positioning System (GPS) has proven reliable and accurate. For urban and indoor applications various RF based ranging/positioning techniques have been investigated. Recently modifications to GPS for indoor applications have been proposed. For example, network assisted - GPS (A-GPS) provides via a cellular data link, additional ephemeris to stand alone GPS for aiding. Increase in the indoor GPS receiver sensitivity has been proposed by providing a large number of correlators. A number of other sensors such as inertial measurement unit (IMU), enhanced dead reckoning devices, miniature or micro electromechanical systems (MEMS) could come to aid for durations following the loss of GPS. In addition path constraints based on the indoor environment may assist in determining accurately the position. The objective of our research has been to provide a seamless, sensor fused tracking system in which data from various sensors may be processed using Kalman filters or more general particle filtering algorithms. Interest is in the applicability of these techniques to develop a military soldier wearable system for use in combat training systems for military operations in urban terrain (MOUT)},
author = {Bakhru, K},
booktitle = {2005 IEEE 16th International Symposium on Personal, Indoor and Mobile Radio Communications},
doi = {10.1109/PIMRC.2005.1651796},
issn = {2166-9570},
keywords = {cellular radio;indoor radio;Kalman filters;militar},
pages = {2029--2033 Vol. 3},
title = {{A seamless tracking solution for indoor and outdoor position location}},
volume = {3},
year = {2005}
}
@article{Barreira:2012:CLM:2367580.2367585,
address = {New York, NY, USA},
author = {Barreira, Alexandre and Sommer, Philipp and Kusy, Brano and Jurdak, Raja},
doi = {10.1145/2367580.2367585},
issn = {1551-3688},
journal = {SIGBED Rev.},
keywords = {Bluetooth,collaboration,localization},
number = {3},
pages = {29--31},
publisher = {ACM},
title = {{Collaborative Localization of Mobile Users with Bluetooth: Caching and Synchronisation}},
url = {http://doi.acm.org/10.1145/2367580.2367585},
volume = {9},
year = {2012}
}
@article{8538014,
abstract = {The order-of-arrival (OOA) of a stream of objects moving along a direction is important for decision making in logistic and industrial applications. As an example, the dispatch of luggage in airports requires to determine their OOA at checkpoints; as another example, the automatic steering of items in supply chains requires to sort and identify them while moving on a conveyor belt. This paper establishes a general framework for determining the OOA of objects that are moving along a monitored direction via radio-frequency identification (RFID) systems. Three techniques for OOA tracking are proposed and developed for objects equipped with RFID tags possessing ranging capabilities. The benefits of the proposed techniques are validated experimentally based on measurements gathered with an RFID system operating in an indoor environment.},
author = {Bartoletti, S and Decarli, N and Dardari, D and Chiani, M and Conti, A},
doi = {10.1109/JRFID.2018.2881708},
issn = {2469-7281},
journal = {IEEE Journal of Radio Frequency Identification},
keywords = {airports;conveyors;decision making;radiofrequency},
number = {4},
pages = {185--196},
title = {{Order-of-Arrival of Tagged Objects}},
volume = {2},
year = {2018}
}
@inproceedings{Basu2012465,
abstract = {Wireless sensors are constrained by a limited supply of energy when powered by batteries. They also have limited memory and limited computational power. The challenge of a network based on such constrained infrastructure is twofold; maintaining data reliability and energy efficiency. Availability of the instantaneous channel side or state information (CSI) at the transmitter can help it to set transmission parameters, such as power, data rate and encoding technique, to achieve optimum results. However in an indoor environment, when the movement of objects between a transmitter and a receiver is random, the estimated CSI may not be sufficient to obtain desired results. This paper evaluates the impact of channel fading on data reliability due to multipath transmission. Simulation results q the number of retransmissions required for an indoor fading channel and its impact on battery life. Although adaptive transmission techniques have been proposed and implemented to maximize throughput in several technologies including WIMAX, the primary focus of this paper is on research related to improve energy efficiency of sensor nodes rather than throughput. This is because sensors used for surveillance and monitoring are not designed for high data rates, but are meant to send data to the central station with a certain threshold bit error rate and acceptable latency. This paper proposes a transmission strategy to increase energy efficiency of fading radio channels for improved data reliability. It also emphasizes the need to introduce an opportunistic transmission strategy to meet these goals. {\textcopyright} 2012 IEEE.},
annote = {cited By 0},
author = {Basu, D and Sengupta, G and Moretti, G},
booktitle = {IEEE International Conference on Networks, ICON},
doi = {10.1109/ICON.2012.6506602},
keywords = {Adaptive transmission; Adaptive transmission techn,Channel state information; Energy efficiency; Fad,Information retrieval},
pages = {465--470},
title = {{Issues of data reliability in indoor channel: Impact on the energy efficiency of battery powered wireless sensor nodes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877853143{\&}doi=10.1109{\%}2FICON.2012.6506602{\&}partnerID=40{\&}md5=3faad48216a064af319df703383ad24f},
year = {2012}
}
@inproceedings{BayroKaiser:2010:ISL:1851600.1851719,
address = {New York, NY, USA},
author = {{Bayro Kaiser}, Esteban Tobias},
booktitle = {Proceedings of the 12th International Conference on Human Computer Interaction with Mobile Devices and Services},
doi = {10.1145/1851600.1851719},
isbn = {978-1-60558-835-3},
keywords = {pedestrian,slam,wearable computing},
pages = {487--488},
publisher = {ACM},
series = {MobileHCI '10},
title = {{Indoor Simultaneous Localization and Mapping for Pedestrian with Wearable Computing}},
url = {http://doi.acm.org/10.1145/1851600.1851719},
year = {2010}
}
@inproceedings{7275470,
abstract = {High-quality positioning is of fundamental importance for an increasing variety of advanced driver assistance systems. GNSS-based systems are predominant outdoors but usually fail in enclosed areas where a direct line-of-sight to satellites is unavailable. For those scenarios, external infrastructure-based positioning systems are a promising alternative. However, external position detections have no identity information as they may belong to any object, i.e. they are anonymous. Moreover, the area covered by external sensors may contain gaps where objects cannot be observed leading to a correspondence problem between multiple detections and actual objects. We present a global tracking-by-identification approach as extension to existing local trackers that uses odometry sensor data of vehicles to find the corresponding subset of external detections. Thus, our approach enables the assignment of anonymous external detections to a specific vehicular endpoint and the estimation of its current position without requiring an initial location. The problem is decomposed resulting in a two step approach. The first algorithm determines possible track segment combinations which are used as track hypotheses. The track hypothesis generation algorithm considers spatio-temporal relationships between track segments, thus avoiding exponentially growing complexity inherent to data association problems. The second algorithm compares track hypotheses to the relative vehicle trajectory using pseudo-distance correlation metrics. In a detailed evaluation, we demonstrate that the proposed approach is able to reliably perform global tracking and identification of camera-observed vehicles in real-time, despite relatively large coverage gaps of the external sensors.},
author = {Becker, D and Binder, A and Einsiedler, J and Radusch, I},
booktitle = {2014 International Conference on Indoor Positioning and Indoor Navigation (IPIN)},
doi = {10.1109/IPIN.2014.7275470},
keywords = {driver information systems;indoor radio;radio trac},
pages = {77--86},
title = {{Multi-modal identification and tracking of vehicles in partially observed environments}},
year = {2014}
}
@inproceedings{Becker:2018:VOT:3204949.3208117,
address = {New York, NY, USA},
author = {Becker, Daniel and Schmidt, Matthias and da Silva, Fernando Bombardelli and G{\"{u}}l, Serhan and Hellge, Cornelius and Sawade, Oliver and Radusch, Ilja},
booktitle = {Proceedings of the 9th ACM Multimedia Systems Conference},
doi = {10.1145/3204949.3208117},
isbn = {978-1-4503-5192-8},
keywords = {automatic driving,compressed-domain analysis,driver-assistance systems,indoor localization,infrastructure-based localization,visual object tracking},
pages = {513--516},
publisher = {ACM},
series = {MMSys '18},
title = {{Visual Object Tracking in a Parking Garage Using Compressed Domain Analysis}},
url = {http://doi.acm.org/10.1145/3204949.3208117},
year = {2018}
}
@inproceedings{Behzadan20051914,
abstract = {This paper describes research that investigates the application of Augmented Reality (AR) in 3D animation of simulated construction operations. The objective is an AR-based platform that can be used together with corresponding equipment (HMD, GPS receiver, and a portable computer) to generate a mixed view of the real world and superimposed virtual simulation objects in an outdoor environment. The characteristic that distinguishes the presented work from indoor AR applications is the capability to produce real time updated output as the user moves around while applying minimum constraints over the user's position and orientation. The ability to operate independently of environmental factors (e.g. lighting conditions and terrain variations) makes the described framework a powerful tool for outdoor AR applications. This paper presents initial results and an AR platform prototype (UM-AR-GPS-ROVER) that is able to place 3D graphical objects at any desired location in outdoor augmented space.},
annote = {cited By 43},
author = {Behzadan, A H and Kamat, V R},
booktitle = {Proceedings - Winter Simulation Conference},
doi = {10.1109/WSC.2005.1574469},
keywords = {Augmented space; Construction graphics; Environme,Computer simulation; Computer vision; Environmenta,Virtual reality},
pages = {1914--1920},
title = {{Visualization of construction graphics in outdoor augmented reality}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846651998{\&}doi=10.1109{\%}2FWSC.2005.1574469{\&}partnerID=40{\&}md5=b2e001aae66aefdfcfa18f2c91850809},
volume = {2005},
year = {2005}
}
@article{Bekiarski2012173,
abstract = {Visual perception methods are developed first mainly for human perception description and understanding. The results of these researches are now very popular for robots visual perception modeling. In this chapter is present first a brief review of the basic visual perception methods suitable for intelligent mobile robots applications. The analysis of these methods is directed to the mobile robot motion control, where the visual perception is used for objects or human body localization like: Bayesian visual perception methods for localization; log-polar visual perception; area of robot observation mapping using visual perception; landmark-based finding and localization with visual perception etc. The development of an algorithm for mobile robot visual perception is proposed based on the features of log-polar transformation to represent some of the objects and scene fragments in area of mobile robot area of observation in a more simple form for the image processing. The features and advantages of the proposed algorithm are demonstrated with the popular for the mobile robots visual perception situation of motion control in a road or corridor with outdoor road edges, painted lane separation lines or indoor two side existing room or corridor lines. The proposed algorithm is tested with suitable simulations and the experiments with real mobile robots like Pioneer 3-DX (Mobil Robots INC), WiFiBot and Lego Robot Mindstorms NXT. The results are summarized and presented as graphics, test images and comparative tables in the conclusion. {\textcopyright} Springer-Verlag Berlin Heidelberg 2012.},
annote = {cited By 2},
author = {Bekiarski, A},
doi = {10.1007/978-3-642-24693-7_7},
journal = {Intelligent Systems Reference Library},
pages = {173--209},
title = {{Visual mobile robots perception for motion control}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885584496{\&}doi=10.1007{\%}2F978-3-642-24693-7{\_}7{\&}partnerID=40{\&}md5=fe3bf0c24710cf4248ca30f82ff5afb8},
volume = {29},
year = {2012}
}
@inproceedings{Bekkali2007,
abstract = {Radio Frequency Identification (RFID) is a rapidly developing technology which uses wireless communication for automatic identification of objects. The localization of RFID tagged objects in their environment is becoming an important feature for the ubiquitous computing applications. In This paper we introduce a new positioning algorithm for RFID tags using two mobile RFID readers and landmarks which are passive or active tags with known location and distributed randomly. We present an analytical method for estimating the location of the unknown tag by using the multilateration with the landmarks and a probabilistic RFID map-based technique with Kalman Filtering to enhance the location estimation of the tag. This algorithm is independent from the readers coordinates, and hence it can be more practical due to its mobility and its low cost to achieve a high deployment of this emerging technology. Results obtained after conducting extensive simulations demonstrate the validity and suitability of the proposed algorithm to provide high performance level in terms of accuracy and scalability. {\textcopyright} 2007 IEEE.},
annote = {cited By 150},
author = {Bekkali, A and Sanson, H and Matsumoto, M},
booktitle = {3rd IEEE International Conference on Wireless and Mobile Computing, Networking and Communications, WiMob 2007},
doi = {10.1109/WIMOB.2007.4390815},
keywords = {Analytical methods; Automatic identification; Com,Automation; Boolean functions; Control theory; Ele,Ubiquitous computing},
title = {{RFID indoor positioning based on probabilistic RFID map and Kalman Filtering}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-47049114032{\&}doi=10.1109{\%}2FWIMOB.2007.4390815{\&}partnerID=40{\&}md5=6fe3f5d50dccc096139b0dc9ccb85591},
year = {2007}
}
@article{Ben2014,
abstract = {The increasing availability of indoor positioning, driven by techniques like RFID, Bluetooth, and smart phones, enables a variety of indoor location-based services (LBSs). Efficient queries based on semantic-constraint in indoor spaces play an important role in supporting and boosting LBSs. However, the existing indoor index techniques cannot support these semantic constraints-based queries. To solve this problem, this paper addresses the challenge of indexing moving objects in indoor spaces, in which both the moving objects and the indoor environments include semantic meanings. We present an indoor semantic-based model, which gives the formal description of semantics of indoor cells and moving objects. Then, a new semantic-based index is proposed for indoor environment, which can support queries under semantic constraint. In addition, we develop efficient algorithms for two new queries, which are the nearest neighbor query based on semantic constraints for static indoor cells and moving objects, respectively. The conducted experiment demonstrates that the proposed index structure is effective, robust, and efficient. {\textcopyright} 2014 Tingting Ben et al.},
annote = {cited By 5},
author = {Ben, T and Qin, X and Wang, N},
doi = {10.1155/2014/424736},
journal = {International Journal of Distributed Sensor Networks},
keywords = {Algorithms; Indexing (of information); Location ba,Formal Description; Index structure; Indexing mov,Semantics},
title = {{A semantic-based indexing for indoor moving objects}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904105263{\&}doi=10.1155{\%}2F2014{\%}2F424736{\&}partnerID=40{\&}md5=c61e78805e1f259bfb26f221bd602976},
volume = {2014},
year = {2014}
}
@article{Ben20152002,
abstract = {Moving object index is widely used in location-based services. Since people spend large parts of their lives in indoor spaces (e.g. hospitals, shopping malls, subway systems, etc.), effective management of indoor mobile data becomes very important. Existing indoor moving object indices focus on historical data queries, and only one type of queries is supported. In this paper, we propose a novel index, called MQII (multiple queries indoor index), which supports not only history queries and present queries, but also object queries and range queries. MQII is based on graph-based model, and can index two aspects with the object list and bucket list structure, such as the object and spatial-temporal scales. In order to improve the query performance, we present a RFID (radio frequency identification) data preprocessing method to reduce the size of the input data sets for MQII. Furthermore, effective update and query algorithms are developed. Experimental results show that compared with existing indoor moving object indices, the data preprocessing can reduce the amount of data. In addition, the index we proposed not only supports history queries and present queries, but also provides efficient object location queries, trajectory queries and range queries. This method can be used in various indoor spaces such as office buildings, hospitals and hotels. {\textcopyright}, 2015, Science Press. All right reserved.},
annote = {cited By 0},
author = {Ben, T and Qin, X and Xu, J},
doi = {10.7544/issn1000-1239.2015.20131230},
journal = {Jisuanji Yanjiu yu Fazhan/Computer Research and Development},
keywords = {Data preprocessing; Effective management; Graph-b,Graphic methods; Hospitals; Information management,Location based services},
number = {9},
pages = {2002--2013},
title = {{Index of indoor moving objects for multiple queries}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946409961{\&}doi=10.7544{\%}2Fissn1000-1239.2015.20131230{\&}partnerID=40{\&}md5=c8f782955bd00b8631331c1f305e561e},
volume = {52},
year = {2015}
}
@article{Benedek2008608,
abstract = {In in this paper, we propose a new model regarding foreground and shadow detection in video sequences. The model works without detailed a priori object-shape information, and it is also appropriate for low and unstable frame rate video sources. Contribution is presented in three key issues: 1) we propose a novel adaptive shadow model, and show the improvements versus previous approaches in scenes with difficult lighting and coloring effects; 2) we give a novel description for the foreground based on spatial statistics of the neighboring pixel values, which enhances the detection of background or shadow-colored object parts; 3) we show how microstructure analysis can be used in the proposed framework as additional feature components improving the results. Finally, a Markov random field model is used to enhance the accuracy of the separation. We validate our method on outdoor and indoor sequences including real surveillance videos and well-known benchmark test sets. {\textcopyright} 2008 IEEE.},
annote = {cited By 88},
author = {Benedek, C and Szir{\'{a}}nyi, T},
doi = {10.1109/TIP.2008.916989},
journal = {IEEE Transactions on Image Processing},
keywords = {Adaptive shadow model; Shadow detection; Surveill,Algorithms; Artificial Intelligence; Bayes Theore,Automated; Reproducibility of Results; Security M,Bayesian networks; Feature extraction; Markov proc,Computer-Assisted; Information Storage and Retrie,Image analysis,algorithm; article; artificial intelligence; auto},
number = {4},
pages = {608--621},
title = {{Bayesian foreground and shadow detection in uncertain frame rate surveillance videos}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-41849102422{\&}doi=10.1109{\%}2FTIP.2008.916989{\&}partnerID=40{\&}md5=016b4d61f33de90024b6ed44247c4a55},
volume = {17},
year = {2008}
}
@article{Benezeth:2011:ADU:1922692.1923007,
address = {New York, NY, USA},
author = {Benezeth, Yannick and Jodoin, Pierre-Marc and Saligrama, Venkatesh},
doi = {10.1016/j.patrec.2010.10.008},
issn = {0167-8655},
journal = {Pattern Recogn. Lett.},
keywords = {Abnormality detection,Motion detection,Video surveillance},
number = {3},
pages = {423--431},
publisher = {Elsevier Science Inc.},
title = {{Abnormality Detection Using Low-level Co-occurring Events}},
url = {http://dx.doi.org/10.1016/j.patrec.2010.10.008},
volume = {32},
year = {2011}
}
@inproceedings{1211016,
abstract = {The knowledge of the spatial coordinates of an object is an inestimable information required for many applications in many fields. This information is highly needed in the telecommunication field and particularly, in the emerging context of connected objects. In this area, the environment awareness enhanced by the location based adaptability is the key to success to ensure energy efficient pervasive communication. High data rate wireless communication may also benefit from the location information by using modulation in the spatial domain, in addition to modulation in frequency, time or code domain. To access the spatial domain, a microwave interferometric location system (MILS), leading to a-two dimensional (2D) location, has been developed. The combination of this phase sensitive device with a stereoscopic measurement allows a precise 3 dimensional (3D) indoor location. Tested, indoor and outdoor, at a frequency compatible with Bluetooth applications, this system point out the feasibility of such approach.},
author = {Benlarbi-Dela, A and Cousin, J C},
booktitle = {IEEE MTT-S International Microwave Symposium Digest, 2003},
doi = {10.1109/MWSYM.2003.1211016},
issn = {0149-645X},
keywords = {indoor radio;radio direction-finding;radiowave int},
pages = {623--626 vol.1},
title = {{3D indoor micro location using a stereoscopic microwave phase sensitive device}},
volume = {1},
year = {2003}
}
@inproceedings{Bergeron20181,
abstract = {In this paper, we address the issue of indoor activities of daily living recognition with a novel Activity Recognition System (ARS). This system only uses interactions between objects. Their locations is provided by a tracking system based on passive RFID tags to compute activity probabilities. Classification within the tracking system is done through a random forest that gives over 97{\%} in accuracy. Activities are represented by the use of a custom behaviour tree, which makes it possible to compose interactions to form activities of any complexity. Interactions and activities are defined in a human readable form to allow everyone to expand them with minimal prior knowledge. {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Bergeron, Frederic and Giroux, Sylvain and Bouchard, Kevin and Gaboury, Sebastien},
booktitle = {2017 IEEE SmartWorld, Ubiquitous Intelligence {\&} Computing, Advanced {\&} Trusted Computed, Scalable Computing {\&} Communications, Cloud {\&} Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)},
doi = {10.1109/UIC-ATC.2017.8397548},
isbn = {978-1-5386-0435-9},
keywords = {Activities of Daily Living,Activity recognition,Big data,Decision trees,Radio frequency identifi,Ubiquitous computing},
month = {aug},
pages = {1--5},
publisher = {IEEE},
title = {{RFID based activities of daily living recognition}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050216551{\&}doi=10.1109{\%}2FUIC-ATC.2017.8397548{\&}partnerID=40{\&}md5=2437d8ce8e73ef538f1e9ce65ff7869e https://ieeexplore.ieee.org/document/8397548/},
year = {2017}
}
@article{Bergmann2016377,
abstract = {Working memory (WM) tasks may involve brain activation actually implicated in long-term memory (LTM). In order to disentangle these two memory systems, we employed a combined WM/LTM task, using a spatial relational (object-location) memory paradigm and analyzed which brain areas were associated with successful performance for either task using fMRI. Critically, we corrected for the performance on the respective memory task when analyzing subsequent memory effects. The WM task consisted of a delayed-match-to-sample task assessed in an MRI scanner. Each trial consisted of an indoor or outdoor scene in which the exact configuration of four objects had to be remembered. After a short delay (713s), the scene was presented from a different angle and spatial recognition for two objects was tested. After scanning, participants received an unexpected subsequent recognition memory (LTM) task, where the two previously unprobed objects were tested. Brain activity during encoding, delay phase and probe phase was analyzed based on WM and LTM performance. Results showed that successful WM performance, when corrected for LTM performance, was associated with greater activation in the inferior frontal gyrus and left fusiform gyrus during the early stage of the maintenance phase. A correct decision during the WM probe was accompanied by greater activation in a wide network, including bilateral hippocampus, right superior parietal gyrus and bilateral insula. No voxels exhibited supra-threshold activity during the encoding phase, and we did not find any differential activity for correct versus incorrect trials in the WM task when comparing LTM correct versus LTM incorrect trials. {\textcopyright} 2016, The Author(s).},
annote = {cited By 4},
author = {Bergmann, H C and Daselaar, S M and Fern{\'{a}}ndez, G and Kessels, R P C},
doi = {10.1007/s10339-016-0772-7},
journal = {Cognitive Processing},
keywords = {Adolescent; Adult; Brain; Brain Mapping; Female;,Computer-Assisted; Magnetic Resonance Imaging; Ma,Long-Term; Memory,Short-Term; Oxygen; Photic Stimulation; Serial Le,adult; Article; brain region; comparative study; f,oxygen},
number = {4},
pages = {377--387},
title = {{Neural substrates of successful working memory and long-term memory formation in a relational spatial memory task}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976274592{\&}doi=10.1007{\%}2Fs10339-016-0772-7{\&}partnerID=40{\&}md5=52f1ea474e5e5525284fa1f220b117b9},
volume = {17},
year = {2016}
}
@inproceedings{7281681,
abstract = {Systems need to know the physical locations of objects and people to optimize user experience and solve logistical and security issues. Also, there is a growing demand for applications that need to locate individual assets for industrial automation. This work proposes an indoor positioning system (IPS) able to estimate the item-level location of stationary objects using off-the-shelf equipment. By using RFID technology, a machine learning model based on support vector regression (SVR) is proposed. A multi-frequency technique is developed in order to overcome off-the-shelf equipment constraints. A k-means approach is also applied to improve accuracy. We have implemented our system and evaluated it using real experiments. The localization error is between 17 and 31 cm in 2.25m2area coverage.},
author = {Berz, E L and Tesch, D A and Hessel, F P},
booktitle = {2015 IEEE 24th International Symposium on Industrial Electronics (ISIE)},
doi = {10.1109/ISIE.2015.7281681},
issn = {2163-5145},
keywords = {indoor navigation;indoor radio;learning (artificia},
pages = {1418--1423},
title = {{RFID indoor localization based on support vector regression and k-means}},
year = {2015}
}
@article{8401981,
abstract = {Localisation of objects and people in indoor environments has been widely studied due to security issues and because of the benefits that a localisation system can provide. Indoor positioning systems (IPSs) based on more than one technology can improve localisation performance by leveraging the advantages of distinct technologies. This study proposes a multi-sensor IPS able to estimate the three-dimensional (3D) location of stationary objects using off-the-shelf equipment. By using radio-frequency identification (RFID) technology, machine-learning models based on support vector regression (SVR) and artificial neural networks (ANNs) are proposed. A{\textless}i{\textgreater}k{\textless}/i{\textgreater}-means technique is also applied to improve accuracy. A computer vision (CV) subsystem detects visual markers in the scenario to enhance RFID localisation. To combine the RFID and CV subsystems, a fusion method based on the region of interest is proposed. We have implemented the authors' system and evaluated it using real experiments. On bi-dimensional scenarios, localisation error is between 9 and 29 cm in the range of 1 and 2.2 m. In a machine-learning approach comparison, ANN performed 31{\%} better than SVR approach. Regarding 3D scenarios, localisation errors in dense environments are 80.7 and 73.7 cm for ANN and SVR models, respectively.},
author = {Berz, E L and Tesch, D A and Hessel, F P},
doi = {10.1049/iet-cps.2017.0067},
issn = {2398-3396},
journal = {IET Cyber-Physical Systems: Theory Applications},
keywords = {computer vision;image fusion;indoor navigation;lea},
number = {2},
pages = {81--88},
title = {{Machine-learning-based system for multi-sensor 3D localisation of stationary objects}},
volume = {3},
year = {2018}
}
@inproceedings{Bhattacharjee20151200,
abstract = {We consider the problem of enabling a robot to efficiently obtain a dense haptic map of its visible surroundings using the complementary properties of vision and tactile sensing. Our approach assumes that visible surfaces that look similar to one another are likely to have similar haptic properties. We present an iterative algorithm that enables a robot to infer dense haptic labels across visible surfaces when given a color-plus-depth (RGB-D) image along with a sequence of sparse haptic labels representative of what could be obtained via tactile sensing. Our method uses a color-based similarity measure and connected components on color and depth data. We evaluated our method using several publicly available RGBD image datasets with indoor cluttered scenes pertinent to robot manipulation. We analyzed the effects of algorithm parameters and environment variation, specifically the level of clutter and the type of setting, like a shelf, table top, or sink area. In these trials, the visible surface for each object consisted of an average of 8602 pixels, and we provided the algorithm with a sequence of haptically-labeled pixels up to a maximum of 40 times the number of objects in the image. On average, our algorithm correctly assigned haptic labels to 76.02{\%} of all of the object pixels in the image given this full sequence of labels. We also performed experiments with the humanoid robot DARCI reaching in a cluttered foliage environment while using our algorithm to create a haptic map. Doing so enabled the robot to reach goal locations using a single plan after a single greedy reach, while our previous tactile-only mapping method required 5 or more plans to reach each goal. {\textcopyright} 2015 IEEE.},
annote = {cited By 9},
author = {Bhattacharjee, T and Shenoi, A A and Park, D and Rehg, J M and Kemp, C C},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2015.7353522},
keywords = {Algorithm parameters; Cluttered scenes; Complemen,Algorithms; Anthropomorphic robots; Color; Iterati,Intelligent robots},
pages = {1200--1207},
title = {{Combining tactile sensing and vision for rapid haptic mapping}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958152988{\&}doi=10.1109{\%}2FIROS.2015.7353522{\&}partnerID=40{\&}md5=a5f55cfb27d270f65b16e83e3d39c4a4},
volume = {2015-Decem},
year = {2015}
}
@article{Bhowmick2014172,
abstract = {This paper presents a wearable navigation assistive system for the blind and the visually impaired built with off-the-shelf technology. Microsoft Kinect's on board depth sensor is used to extract Red, Green, Blue and Depth (RGB-D) data of the indoor environment. Speeded-Up Robust Features (SURF) and Bag-of-Visual-Words (BOVW) model is used to extract features and reduce generic indoor object detection into a machine learning problem. A Support Vector Machine classifier is used to classify scene objects and obstacles to issue critical real-time information to the user through an external aid (earphone) for safe navigation. We performed a user-study with blind-fold users to measure the efficiency of the overall framework. {\textcopyright}Springer International Publishing Switzerland 2014.},
annote = {cited By 7},
author = {Bhowmick, A and Prakash, S and Bhagat, R and Prasad, V and Hazarika, S M},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Artificial intelligence; Classification (of inform,Bag-of-visual-words; Blind; Kinect; Machine learn,Learning systems},
pages = {172--183},
title = {{IntelliNavi : Navigation for blind based on kinect and machine learning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911942280{\&}partnerID=40{\&}md5=53544c9bcf9c90610a339f10210e730b},
volume = {8875},
year = {2014}
}
@article{Bianchini20051040,
abstract = {In this paper, we introduce a new recursive neural network model able to process directed acyclic graphs with labelled edges. The model uses a state transition function which considers the edge labels and is independent both from the number and the order of the children of each node. The computational capabilities of the new recursive architecture are assessed. Moreover, in order to test the proposed architecture on a practical challenging application, the problem of object detection in images is also addressed. In fact, the localization of target objects is a preliminary step in any recognition system. The proposed technique is general and can be applied in different detection systems, since it does not exploit any a priori knowledge on the particular problem. Some experiments on face detection, carried out on scenes acquired by an indoor camera, are reported, showing very promising results. {\textcopyright} 2005 Elsevier Ltd. All rights reserved.},
annote = {cited By 35},
author = {Bianchini, M and Maggini, M and Sarti, L and Scarselli, F},
doi = {10.1016/j.neunet.2005.07.003},
journal = {Neural Networks},
keywords = {Acyclic graphs; Edge labels; Neural network model,Automated; Phantoms,Cameras; Graph theory; Image analysis; Knowledge a,Computer Simulation; Face; Humans; Image Interpre,Computer-Assisted; Information Storage and Retrie,Imaging,Neural networks,analytic method; article; artificial neural netwo},
number = {8},
pages = {1040--1050},
title = {{Recursive neural networks for processing graphs with labelled edges: Theory and applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-26944454812{\&}doi=10.1016{\%}2Fj.neunet.2005.07.003{\&}partnerID=40{\&}md5=8d8b79d20d5cb8d61892d44ae3ea7d07},
volume = {18},
year = {2005}
}
@inproceedings{Biswas2015525,
abstract = {Robot localization and mapping algorithms commonly represent the world as a static map. In reality, human environments consist of many movable objects like doors, chairs and tables. Recognizing that such environment often have a large number of instances of a small number of types of objects, we propose an alternative approach, Model-Instance Object Mapping that reasons about the models of objects distinctly from their different instances. Observations classified as short-term features by Episodic non-Markov Localization are clustered to detect object instances. For each object instance, an occupancy grid is constructed, and compared to every other object instance to build a directed similarity graph. Common object models are discovered as strongly connected components of the graph, and their models as well as distribution of instances saved as the final Model-Instance Object Map. By keeping track of the poses of observed instances of object models, Model-Instance Object Maps learn the most probable locations for commonly observed object models. We present results of Model-Instance Object Mapping over the course of a month in our indoor office environment, and highlight the common object models thus learnt in an unsupervised manner. {\textcopyright} Springer International Publishing Switzerland 2015.},
annote = {cited By 0},
author = {Biswas, J and Veloso, M},
booktitle = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
doi = {10.1007/978-3-319-18615-3_43},
pages = {525--536},
title = {{Model-instance object mapping}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958534370{\&}doi=10.1007{\%}2F978-3-319-18615-3{\_}43{\&}partnerID=40{\&}md5=07793760805851895c0978d44544478b},
volume = {8992},
year = {2015}
}
@inproceedings{Blache:2014:VMM:2854124.2854137,
address = {Goslar Germany, Germany},
author = {Blache, L and Loscos, C and Nocent, O and Lucas, L},
booktitle = {Proceedings of the 7th Eurographics Workshop on 3D Object Retrieval},
doi = {10.2312/3dor.20141052},
isbn = {978-3-905674-58-3},
pages = {69--76},
publisher = {Eurographics Association},
series = {3DOR '14},
title = {{3D Volume Matching for Mesh Animation of Moving Actors}},
url = {https://doi.org/10.2312/3dor.20141052},
year = {2014}
}
@article{Bok2011310,
abstract = {In this paper, we propose a new location acquisition method that reduces the computation cost of location acquisition and keeps the accuracy of the location. The proposed method performs the event filtering to selects the necessary reference tags and then computes the accurate locations of objects. If the locations of objects are changed then update the locations of objects. To show the superiority of our proposed method, we compare it with LANDMARC, which is the most popular localization method. It shows that the proposed system reduces the computation cost of location estimation 500 times more than LANDMARC. {\textcopyright} 2011 Springer-Verlag.},
annote = {cited By 3},
author = {Bok, K S and Park, Y H and Pee, J I and Yoo, J S},
doi = {10.1007/978-3-642-27186-1_42},
journal = {Communications in Computer and Information Science},
keywords = {Accurate location; Computation costs; Event filter,Computer graphics; Cost reduction; Information te,Mergers and acquisitions},
number = {PART 2},
pages = {310--318},
title = {{Location acquisition method based on RFID in indoor environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84055190824{\&}doi=10.1007{\%}2F978-3-642-27186-1{\_}42{\&}partnerID=40{\&}md5=c2f679388d563080857fc3185a163e1b},
volume = {263 CCIS},
year = {2011}
}
@inproceedings{4699497,
abstract = {RFID is an automatic identification technique that stores and remotely retrieves data on small devices called tags. This technology enables tracking of people and objects and could support the conception of pervasive networks if identities are linked in real-time to their locations. We propose a scalable and robust 3-D localization method for RFID tags based only on connectivity information. Virtual landmarks are used to define inclusive and exclusive constraints, localize tags and estimate the accuracy of the calculations. Simulation results show that our algorithm provides fine-grained localization accuracy.},
author = {Bouet, M and Pujolle, G},
booktitle = {2008 IEEE 19th International Symposium on Personal, Indoor and Mobile Radio Communications},
doi = {10.1109/PIMRC.2008.4699497},
issn = {2166-9570},
keywords = {radiofrequency identification;range-free 3D locali},
pages = {1--5},
title = {{A range-free 3-D localization method for RFID tags based on virtual landmarks}},
year = {2008}
}
@inproceedings{Bradley2018147,
abstract = {In today's world, the rapid advancement of technology allows us to find new solutions to old problems in critical areas, namely patient and staff tracking in healthcare facilities. The medical staff within these facilities are in an environment where they depend on immediately knowing the location of a patient or other medical staff. McAllister et al. [1] proposed a solution named LoCATE (Localization of Health Center Assets Through an IoT Environment) which uses existing technology to track all patients and medical staff in near real time. LoCATE makes use of the current wireless networks (e.g., WiFi) within a healthcare facility by using edge node technology as its tracking solution. It can locate an object within three to five feet of its calculated position. The ubiquity of WiFi infrastructure in healthcare facilities makes it an attractive option to use, as the backbone for a patient and staff tracking system. However, Internet of Things (IoT) devices and edge nodes create security holes in networks and leak data to the open world. This paper aims to analyze what security holes and data leaks LoCATE creates in a healthcare facility. In this paper, we show the dangers of using simple and default passwords, the need to physically secure edge nodes, and the importance of securing data before transmission. We exploit the system's weak security measures by forging edge node data, gaining unauthorized access, performing denial of service attack, and launching other attacks. We analyze the successfulness of these attacks to offer mitigation techniques for future devices located in other critical areas similar to the healthcare facilities. {\textcopyright} 2018 IEEE.},
annote = {cited By 2},
author = {Bradley, C and El-Tawab, S and Heydari, M H},
booktitle = {2018 Systems and Information Engineering Design Symposium, SIEDS 2018},
doi = {10.1109/SIEDS.2018.8374726},
keywords = {Denial-of-service attack; Facilities; Health care;,Healthcare facility; Indoor localization; Interne,Mobile security},
pages = {147--152},
title = {{Security analysis of an IoT system used for indoor localization in healthcare facilities}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049318042{\&}doi=10.1109{\%}2FSIEDS.2018.8374726{\&}partnerID=40{\&}md5=8b335a9325d76888f8a36230b87e8eda},
year = {2018}
}
@phdthesis{Cai:1997:THM:926830,
annote = {AAI9824879},
author = {Cai, Qin},
isbn = {0-591-77417-8},
publisher = {The University of Texas at Austin},
title = {{Tracking Human Motion in Indoor Environments Using a Distributed-camera System}},
year = {1997}
}
@inproceedings{Camden2015,
abstract = {The Robotics Collaborative Technology Alliance administered by the U.S. Army Research Laboratory has focus areas in Intelligence, Human/Robot Interaction, Perception/Sensing, and Dexterous Manipulation and Unique Mobility. Research assessments are conducted to evaluate technologies integrated on a robotic platform. In this study, a Clearpath Husky is equipped with a robotic arm, monocular and stereo camera pair, and a Hokuyo scanning laser rangefinder. The purpose of this investigation, drawing upon intelligence, perception, and dexterous manipulation, is to assess the ability of the system to autonomously search a room for an object, identify the object, and position the robot so the object can be grabbed and lifted by the arm/end effector. The system capability requires integration of several component capabilities related to room mapping, semantic labeling, precise movement, robot and arm planning, and obstacle detection and avoidance. The Husky used previously developed mapping algorithms to map the room until it identified the search object, at which time its focus was directed to positioning for the grasp-object task and executing the grasp via the robot arm/end effector. Two indoor areas at Fort Indiantown Gap, Pennsylvania were used for the experiment. Experimental conditions varied the orientation of a single target object, the location of the object, and the presence of obstacles acting to obscure the object during the search and challenged the planning to enable the arm to make the grasp.},
annote = {cited By 2},
author = {Camden, R and Bodt, B and Childers, M},
booktitle = {AUVSI Unmanned Systems 2015},
keywords = {Collaborative technologies; Dexterous manipulatio,Conformal mapping; Human robot interaction; Intell,Robot programming},
title = {{An assessment of an autonomous indoor search and grasp capability}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010843540{\&}partnerID=40{\&}md5=b38da9ab15b30d0e94069a5c5203b23b},
year = {2015}
}
@inproceedings{Can2016,
abstract = {Human detection from depth images is gaining substan- tial attention since depth information facilitates object extraction from the background. In this paper, we propose a human detec- tion method where search for humans is performed over regions obtained from a pre-segmentation of the depth image. Our seg- mentation scheme is based on K-means clustering of location, depth values and surface normals of pixels. Once homogeneous regions are determined, the top portion of the boundary of each region in the segmentation map is extracted and matched with re- alistic head-shoulder template curves. We evaluate our method both on a publicly available dataset, and on our new human de- tection dataset, which is composed of 500 depth images of humans in diverse poses acquired in varying indoor environments. {\textcopyright} 2016 Society for Imaging Science and Technology.},
annote = {cited By 1},
author = {Can, G N and Dutagaci, H},
booktitle = {IS and T International Symposium on Electronic Imaging Science and Technology},
doi = {10.2352/ISSN.2470-1173.2016.21.3DIPM-046},
keywords = {Depth information; Homogeneous regions; Human det,Feature extraction; Image segmentation,Image processing},
title = {{Human detection from still depth images}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030172279{\&}doi=10.2352{\%}2FISSN.2470-1173.2016.21.3DIPM-046{\&}partnerID=40{\&}md5=98799cfe835878c9a4e9627c0602056c},
year = {2016}
}
@inproceedings{Cardei:2013:PCN:2725669.2725673,
address = {USA},
author = {Cardei, Mihaela and Jones, Brandon and Raviv, Daniel},
booktitle = {Proceedings of the 20th Conference on Pattern Languages of Programs},
isbn = {978-1-941652-00-8},
keywords = {architecture,contextual navigation,pattern,policy},
pages = {3:1----3:10},
publisher = {The Hillside Group},
series = {PLoP '13},
title = {{A Pattern for Context-aware Navigation}},
url = {http://dl.acm.org/citation.cfm?id=2725669.2725673},
year = {2013}
}
@article{Caron2015791,
abstract = {The development of mobile robots for domestic assistance requires solving problems integrating ideas from different fields of research like computer vision, robotic manipulation, localization and mapping. Semantic mapping, that is, the enrichment a map with highlevel information like room and object identities, is an example of such a complex robotic task. Solving this task requires taking into account hard software and hardware constraints brought by the context of autonomous mobile robots, where short processing times and low energy consumption are mandatory. We present a light-weight scene segmentation and object instance recognition algorithm using an RGB-D camera and demonstrate it in a semantic mapping experiment. Our method uses a feed-forward neural network to fuse texture, color and depth information. Running at 3Hz on a single laptop computer, our algorithm achieves a recognition rate of 97{\%} in a controlled environment, and 87{\%} in the adversarial conditions of a real robotic task. Our results demonstrate that state of the art recognition rates on a database does not guarantee performance in a real world experiment. We also show the benefit in these conditions of fusing several recognition decisions and data from different sources. The database we compiled for the purpose of this study is publicly available. {\textcopyright} Springer International Publishing Switzerland 2015.},
annote = {cited By 7},
author = {Caron, L.-C. and Filliat, D and Gepperth, A},
doi = {10.1007/978-3-319-16199-0_55},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Cameras; Complex networks; Energy utilization; Lap,Computer vision,Instance recognition; Mobile robotic; Rgb-d camer},
pages = {791--805},
title = {{Neural network fusion of color, depth and location for object instance recognition on a mobile robot}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958536473{\&}doi=10.1007{\%}2F978-3-319-16199-0{\_}55{\&}partnerID=40{\&}md5=ca79b0a8a3f729d959fea83e2ad149de},
volume = {8927},
year = {2015}
}
@inproceedings{Celso20192060,
abstract = {In this paper, we present an implementation of indoor localization, where the location of an object is determined without using the outdoor infrastructure of GPS. Various work involving different technologies exist, but the field remains open to a solution which can attain widespread use, in consideration of cost and infrastructure needed for deployment. For our implementation, we localized a common smartphone in an area with many WiFi signals. The main method was through RSS fingerprinting which was able to achieve a mean error of 2.5 m, aside from outliers that drove the error to 16 m. To improve this, Pedestrian Dead Reckoning (PDR) techniques were leveraged in addition to the WiFi system. Realtime testing showed that the WiFi+PDR system was able to achieve a 2.28 m mean localization error, while it reached 2.62 m for the WiFi-only approach. Finally, a peer-to-peer approach was explored, in which neighboring smartphone peers were treated as pseudo access points to help eliminate the outlier errors that resulted from very similar RSS fingerprints. To measure distance between peers, an acoustic method was employed using 1 KHz sine waves. The Time Difference of Arrival (TDoA) was computed between peers, and the readings allowed for coarse estimates in 5-m bins. However, for very noisy environments, this frequency range may cause the acoustic system to be erroneous, possibly driving the error to as high as 18.01 m. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Celso, A and Dantes, J D and {Armand Ravelo}, L and Limjoco, W J and {Michael Tiglao}, N},
booktitle = {IEEE Region 10 Annual International Conference, Proceedings/TENCON},
doi = {10.1109/TENCON.2018.8650510},
keywords = {Acoustic fields; Acoustics; Distributed computer s,Indoor positioning systems,fingerprinting; Indoor localization; localization},
pages = {2060--2065},
title = {{Improving WiFi Indoor Localization Through a Peer-to-Peer Architecture}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063225791{\&}doi=10.1109{\%}2FTENCON.2018.8650510{\&}partnerID=40{\&}md5=40ab3fcea40d9703b3253557fab3862c},
volume = {2018-Octob},
year = {2019}
}
@article{Chadalavada:2018:IIS:3279953.3264907,
address = {New York, NY, USA},
author = {Chadalavada, Perumal Varun and Palaniappan, Goutham and Chandran, Vimal Kumar and Truong, Khai and Wigdor, Daniel},
doi = {10.1145/3264907},
issn = {2474-9567},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
keywords = {Indoor Localization,Inductive Sensing,Object Identification,Object Tagging,Smart Surfaces},
number = {3},
pages = {97:1----97:28},
publisher = {ACM},
title = {{ID'Em: Inductive Sensing for Embedding and Extracting Information in Robust Materials}},
url = {http://doi.acm.org/10.1145/3264907},
volume = {2},
year = {2018}
}
@article{NoAuthor2019,
abstract = {The proceedings contain 40 papers. The special focus in this conference is on Ethical Hacking. The topics include: Image encryption using pseudorandom permutation; Authentication of diffie-hellman protocol against man-in-the-middle attack using cryptographically secure CRC; Multiple RGB image steganography using arnold and discrete cosine transformation; braincomputer interface-based fear detection: A self-defense mechanism; modelling and simulation of proton exchange membrane fuel cell for stand-alone system; hardware realization of power adaptation technique for cognitive radio sensor node; Driven by the need for a reliable and cost-effective LED driver; SGSQoT: A community-based trust management scheme in internet of things; A novel trust evaluation model based on data freshness in WBAN; Social engineering attack detection and data protection model (SEADDPM); CREnS: A convolutional coder-based encryption algorithm for tiny embedded cognitive radio sensor node; bilingual machine translation: English to bengali; comparison of different classification techniques using different datasets; an algorithmic approach for generating quantum ternary superposition operators and related performance measures; a survey on collaborative filtering: Tasks, approaches and applications; feature subset selection of semi-supervised data: An intuitionistic fuzzy-rough set-based concept; an efficient indoor occupancy detection system using artificial neural network; real-time facial recognition using deep learning and local binary patterns; hepatocellular carcinoma survival prediction using deep neural network; detection and retrieval of colored object from a live video stream with mutual information; OnlineKALI: Online vulnerability scanner; a machine learning framework for recognizing handwritten digits using convexity-based feature vector encoding; a secure framework for IoT-based healthcare system; Smart irrigation: IOT-based irrigation monitoring system.},
annote = {cited By 0},
author = {Chakraborty, Mohuya and Emilia, Valentina and Mandal, Balas J K},
isbn = {9789811315435},
journal = {Advances in Intelligent Systems and Computing},
title = {{International Ethical Hacking Conference 2018}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055112161{\&}partnerID=40{\&}md5=02b5b803c77e7ab6a5a1e0952418cb09},
volume = {811},
year = {2018}
}
@phdthesis{Chan:2013:PIL:2520694,
address = {New York, NY, USA},
annote = {AAI3561578},
author = {Chan, Matthew},
isbn = {978-1-303-08777-6},
publisher = {City University of New York},
title = {{Passive Indoor Leveled Rfid Localization Algorithms}},
year = {2013}
}
@inproceedings{Chan:2014:ELR:2634435.2635246,
address = {Washington, DC, USA},
author = {Chan, Matthew and Zhang, Xiaowen},
booktitle = {Proceedings of the 2014 11th International Conference on Information Technology: New Generations},
doi = {10.1109/ITNG.2014.92},
isbn = {978-1-4799-3188-0},
keywords = {Bayesian inference,RFID localization,experiment,multilateration,nearest-neighbor},
pages = {163--169},
publisher = {IEEE Computer Society},
series = {ITNG '14},
title = {{Experiments for Leveled RFID Localization for Indoor Stationary Objects}},
url = {https://doi.org/10.1109/ITNG.2014.92},
year = {2014}
}
@inproceedings{Chanel:2016:DOO:2897843.2915199,
address = {New York, NY, USA},
author = {Chanel, David-Alexandre and Constant, Romain},
booktitle = {ACM SIGGRAPH 2016 Art Gallery},
doi = {10.1145/2897843.2915199},
isbn = {978-1-4503-4280-3},
pages = {370--371},
publisher = {ACM},
series = {SIGGRAPH '16},
title = {{Doors 2015}},
url = {http://doi.acm.org/10.1145/2897843.2915199},
year = {2016}
}
@inproceedings{4395720,
abstract = {New techniques are being devised to use RFID technology to enable Indoor Position tracking of tagged objects. RFID holds immense promise in this area as tags are cheaply available and robust to various kinds of RF interference. In this paper, passive UHF (868MHz) tags placed at uniformly spaced points in a grid in different sets of orientations are used to find out the contour patterns of reader antenna in a given area under static environment. This information is used to estimate the position of unknown tags from the readings obtained by the reader antennas. The computed results are presented and discussed.},
author = {Chattopadhyay, A and Harish, A R},
booktitle = {2007 IEEE Antennas and Propagation Society International Symposium},
doi = {10.1109/APS.2007.4395720},
issn = {1522-3965},
keywords = {indoor radio;radiofrequency identification;radiofr},
pages = {1217--1220},
title = {{Analysis of UHF passive RFID tag behavior and study of their applications in low range indoor location tracking}},
year = {2007}
}
@inproceedings{Chau2011569,
abstract = {This paper presents a new algorithm to track mobile objects in different scene conditions. The main idea of the proposed tracker includes estimation, multi-features similarity measures and trajectory filtering. A feature set (distance, area, shape ratio, color histogram) is defined for each tracked object to search for the best matching object. Its best matching object and its state estimated by the Kalman filter are combined to update position and size of the tracked object. However, the mobile object trajectories are usually fragmented because of occlusions and misdetections. Therefore, we also propose a trajectory filtering, named global tracker, aims at removing the noisy trajectories and fusing the fragmented trajectories belonging to a same mobile object. The method has been tested with five videos of different scene conditions. Three of them are provided by the ETISEO benchmarking project (http://www-sop.inria.fr/orion/ETISEO) in which the proposed tracker performance has been compared with other seven tracking algorithms. The advantages of our approach over the existing state of the art ones are: (i) no prior knowledge information is required (e.g. no calibration and no contextual models are needed), (ii) the tracker is more reliable by combining multiple feature similarities, (iii) the tracker can perform in different scene conditions: single/several mobile objects, weak/strong illumination, indoor/outdoor scenes, (iv) a trajectory filtering is defined and applied to improve the tracker performance, (v) the tracker performance outperforms many algorithms of the state of the art.},
annote = {cited By 7},
author = {Chau, D P and Bremond, F and Thonnat, M and Corvee, E},
booktitle = {VISAPP 2011 - Proceedings of the International Conference on Computer Vision Theory and Application},
keywords = {Algorithms; Color matching; Computer vision; Imag,Color histogram; Feature sets; Global tracker; Ind,Trajectories},
pages = {569--574},
title = {{Robust mobile object tracking based on multiple feature similarity and trajectory filtering}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960153655{\&}partnerID=40{\&}md5=1e33eb829470ed3af1d193b3fc68053c},
year = {2011}
}
@inproceedings{Chawathe2008980,
abstract = {We describe a method for determining the location of a mobile device, such as a handheld computer or mobile phone, in an indoor environment using Bluetooth beacons. Since it uses inexpensive commodity devices, this method is inexpensive to deploy. The limited range of Bluetooth reception is used to advantage. Another important advantage of this method is that it allows the mobile device to determine its location while remaining anonymous, unidentified to the beacons or other nearby devices. In such a deployment, an important design task is the placement of beacons. Signal propagation in indoor environments is complex, affected by factors such as floor-plans and duct-work, varying transmission and reflection properties of building materials and furniture, and interference from other devices. Therefore, the area from which a beacon is visible is very irregular and not well approximated by simple models such as ellipsoids. Our solution permits complex reception characteristics to be accurately modeled and provides a simple method for choosing beacon locations. {\textcopyright} 2008 IEEE.},
annote = {cited By 61},
author = {Chawathe, S S},
booktitle = {IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC},
doi = {10.1109/ITSC.2008.4732690},
keywords = {Architectural design; Bluetooth; Building materia,Beacon placements; Design tasks; Indoor environmen,Location},
pages = {980--985},
title = {{Beacon placement for indoor localization using Bluetooth}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-60749084227{\&}doi=10.1109{\%}2FITSC.2008.4732690{\&}partnerID=40{\&}md5=b4030e535f841abecd315f5bc6032cf8},
year = {2008}
}
@inproceedings{Chen2017444,
abstract = {A vision based method was introduced to detect human patterns. The purpose of the research is to assist the decision maker while considering the installation of automated external defibrillators (AEDs). We first recorded the video of people in the objective building. During the process of detection, we adopt the histogram of oriented gradient (HOG) to detect the locations of people at each time interval. HOG is the descriptor which could describe the shape of objects in the image, based on the orientation or gradient of each pixel. After the extraction of the human volume data, we further analyze the patterns of the human and the distribution of human in the building. The analysis would help to plan and evaluate locations of AEDs based on the real potential demand distribution and could optimized the performance of AED during an emergency. {\textcopyright} 2017 American Society of Civil Engineers.},
annote = {cited By 0},
author = {Chen, C.-C. and Chen, A Y},
booktitle = {Congress on Computing in Civil Engineering, Proceedings},
keywords = {Automated external defibrillator; Decision makers,Behavioral research; Decision making; Location,Defibrillators},
pages = {444--449},
title = {{Video-based indoor human detection for decision-making of the installation locations for automated external defibrillators}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021724445{\&}partnerID=40{\&}md5=b140b005894bd4edf9379f496abddce2},
year = {2017}
}
@inproceedings{Chen2012317,
abstract = {This paper presents an indoor positioning technique using a modified probabilistic neural network (MPNN) scheme. It measures the received signal strength (RSS) between an object and stations, and then transforms the RSS into distances. A MPNN engine determines coordinate of the object with the input distances. The experiments are conducted in a realistic ZigBee sensor network. The proposed approach performs significantly better than triangulation technique when the RSS data are unstable. It can be efficiently applied to applications of location based service (LBS). {\textcopyright} 2012 IEEE.},
annote = {cited By 6},
author = {Chen, C.-Y. and Yin, L.-P. and Chen, Y.-J. and Hwang, R.-C.},
booktitle = {Proceedings - 3rd International Conference on Information Security and Intelligent Control, ISIC 2012},
doi = {10.1109/ISIC.2012.6449770},
keywords = {Indoor positioning; Modified probabilistic neural,Intelligent control; Location based services; Neu,Tracking (position)},
pages = {317--320},
title = {{A modified probability neural network indoor positioning technique}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874482562{\&}doi=10.1109{\%}2FISIC.2012.6449770{\&}partnerID=40{\&}md5=19198fc37c4c3b563aa29c930fd16d08},
year = {2012}
}
@inproceedings{4531427,
abstract = {We have developed a monocular SLAM method which uses the scale-invariant feature transform (SIFT) algorithm to detect salient features within the scene. Only feature points with large scales are considered as worth-tracking features to reduce the computation load and enhance the robustness. These feature information are input to an extended Kalman filter with the spatial coordinates of the feature points and that of the observing camera as its state variables. The angular and translational velocity and acceleration of the camera are also included as the state variables. Compared to previous approaches, we use the reciprocal of the depth, instead of the depth itself, as the state variable, together with other state variables, in the extended Kalman filter to represent the relative distance between the camera and the feature points. The extended Kalman filter can accurately estimate the spatial location of the feature points and that of the camera with only one camera after a very short period for those feature points experiencing significant change in parallax. We have tested the proposed method with a hand-held camera walking in both indoor and outdoor environment. The outdoor environment for the experiment is populated with both close and distant objects. The results show very accurate estimates on the spatial locations of the camera and feature points within seconds.},
author = {Chen, Chwan Hsen and Chan, Yung Pyng},
booktitle = {Proceedings of IEEE Workshop on Advanced Robotics and its Social Impacts, ARSO},
doi = {10.1109/ARSO.2007.4531427},
isbn = {9781424419531},
issn = {21627568},
keywords = {image sensors;Kalman filters;mobile robots;robot v},
pages = {1--6},
title = {{SIFT-based monocluar SLAM with inverse depth parameterization for robot localization}},
year = {2007}
}
@article{Chen200890,
abstract = {This paper presents a novel object tracking method based on SIFT (scale invariant feature transform) feature matching. First an object SIFT feature database is built offline. Then we detect and locate the object online by exactly matching SIFT feature between test image and the database using a K-tree based nearest neighbor algorithm. According to the location, an active camera is controlled to make the object always lie in the center of view. The validity is proved by the experiments accomplished in real indoor environment. The true positive of our method is up to 94{\%}, while that of HSV based method is less than 80{\%} in our experimental conditions. Experimental results shows that the method is offictive.},
annote = {cited By 1},
author = {Chen, F and Hong, B and Cai, Z and Yang, J},
journal = {Huazhong Keji Daxue Xuebao (Ziran Kexue Ban)/Journal of Huazhong University of Science and Technology (Natural Science Edition)},
keywords = {Active vision; Feature matching; K-tree; Object l,Database systems; Experiments; Tracking (position),Trees (mathematics)},
number = {SUPPL. 1},
pages = {90--93},
title = {{Moving object tracking method based on active vision system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-56549108022{\&}partnerID=40{\&}md5=df8b469cf2ceca2823f06dc1a0043628},
volume = {36},
year = {2008}
}
@article{Chen20132029,
abstract = {This paper presents a novel indoor positioning technique based on neural network. Each sensor was modeled by an independent neural network in order to catch the mapping between the object's position coordinate and the received signal strengths from different directions and distances. Unlike the traditional neural network application in this field, the position coordinate of the object was used as the input and the received signal strength was used as the output in the neural model. We assume that if the distance between sensor and object is fixed, then the sensed signal strengths from different directions should be the same. A new least-squares location estimation method was developed to calculate the object's position in accordance with the received signal strengths sensed by different sensors and the estimated coordinates given by all neural networks. From the simulation results shown, it is clearly found that the new indoor position technique developed is more accurate and more stable than the traditional neural network approaches. {\textcopyright} 2013 American Scientific Publishers All rights reserved.},
annote = {cited By 2},
author = {Chen, H.-C. and Chen, Y.-J. and Chen, C.-Y. and Wang, S T and Yang, J.-P. and Hwang, R.-C.},
doi = {10.1166/asl.2013.4622},
journal = {Advanced Science Letters},
number = {7},
pages = {2029--2033},
title = {{A new indoor positioning technique based on neural network}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876823059{\&}doi=10.1166{\%}2Fasl.2013.4622{\&}partnerID=40{\&}md5=36225b23049f41b294a0ce0637c7bdfd},
volume = {19},
year = {2013}
}
@inproceedings{6776063,
abstract = {This paper presents a helpful application with a real-time detection system that can automatically capture the last scene where the user-defined important objects appear. The introduced method uses RGB-D information as input and has high detection rate in messy indoor environments. Additionally, we build an user-friendly using flow on object online learning and detection which may be suitable for future technologies of wearable devices.},
author = {Chen, I and Chi, C and Hsu, S and Chen, L},
booktitle = {2014 IEEE International Conference on Consumer Electronics (ICCE)},
doi = {10.1109/ICCE.2014.6776063},
issn = {2158-3994},
keywords = {image colour analysis;object detection;real-time s},
month = {jan},
pages = {412--413},
title = {{A real-time system for object detection and location reminding with RGB-D camera}},
year = {2014}
}
@inproceedings{Chen:2015:BCD:2753476.2753478,
address = {New York, NY, USA},
author = {Chen, Kaifei and He, Siyuan and Chen, Beidi and Kolb, John and Katz, Randy H and Culler, David E},
booktitle = {Proceedings of the 2015 Workshop on IoT Challenges in Mobile and Industrial Systems},
doi = {10.1145/2753476.2753478},
isbn = {978-1-4503-3502-7},
keywords = {composability,framework,localization},
pages = {7--12},
publisher = {ACM},
series = {IoT-Sys '15},
title = {{BearLoc: A Composable Distributed Framework for Indoor Localization Systems}},
url = {http://doi.acm.org/10.1145/2753476.2753478},
year = {2015}
}
@inproceedings{Chen2011105,
abstract = {Guiding navigation is an important application in wireless sensor networks to make moving objects leave dangerous areas safely and quickly. However, guiding policy without considering congestion problem will postpone the escape time. In this paper, we propose a distributed flow-based guiding protocol for indoor environments to evacuate mobile objects from dangerous area to exit. Our goal is to construct less congested paths to minimize the escape time and the congestion time. Each sensor in the network holds an artificial potential value determined by the moving speed of object on a path monitored by it, the distances to exits, and the capacity of exits that have the maximum potential values, and objects are directed to paths with higher potential values. Nevertheless, our approach also solves the local maximum problem that objects are trapped at a non-exit location holding a local maximum potential value. In addition, we adopt a traffic flow model for transforming object density of a road into object's velocity to reduce the computational cost and the communication overhead. Simulation results show our proposed protocol can efficiently decrease the escape time and congestion time. {\textcopyright} 2011 IEEE.},
annote = {cited By 18},
author = {Chen, P.-Y. and Kao, Z.-F. and Chen, W.-T. and Lin, C.-H.},
booktitle = {Proceedings of the International Conference on Parallel Processing},
doi = {10.1109/ICPP.2011.55},
keywords = {Artificial potentials; Communication overheads; Co,Sensors; Traffic congestion; Value engineering,Wireless sensor networks},
pages = {105--114},
title = {{A distributed flow-based guiding protocol in wireless sensor networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80155183493{\&}doi=10.1109{\%}2FICPP.2011.55{\&}partnerID=40{\&}md5=9a32a124522bbe4d483f4eeeb6389d4a},
year = {2011}
}
@inproceedings{Chen2009210,
abstract = {Navigation applications and location-based services are now becoming standard features in smart phones. However, locating a mobile user anytime anywhere is still a challenging task, especially in GNSS degraded and denied environments such as urban canyons and indoor environments. To approach a seamless indoor/outdoor positioning solution, self-contained sensors, such as accelerometers, digital compasses, gyros, and pressure sensors are being adapted as augmentation technologies to a GNSS receiver. However, the GNSS obstructed areas are typically contaminated such that significant error sources disturb the measurements of the augmenting sensors as well, e.g. a digital compass can be disturbed significantly by any object bearing magnetic perturbance, for example, an elevator; not to mention the problems of signal-degraded areas e.g. indoors. This paper presents a DSP-based positioning platform based on multiple sensors and multiple networks. The positioning sensors include a GNSS receiver and low-cost self-contained sensors (accelerometer and digital compass), while the networks include WLAN/Bluetooth. Algorithms applying GNSS, sensor measurements, and network measurements for data validation, outlier rejection, and positioning are discussed in this paper. Test results in both indoor and outdoor environments are presented and the positioning performance is demonstrated.},
annote = {cited By 20},
author = {Chen, R and Chen, Y and Pei, L and Chen, W and Liu, J and Kuusniemi, H and Lepp{\"{a}}koski, H and Takala, J},
booktitle = {22nd International Technical Meeting of the Satellite Division of the Institute of Navigation 2009, ION GNSS 2009},
keywords = {Accelerometers; Compasses (magnetic); Digital sig,Data validation; Digital compass; DSP-based; Error,Sensors},
pages = {210--216},
title = {{A DSP-based multi-sensor multi-network positioning platform}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952218840{\&}partnerID=40{\&}md5=481beffe4a2c3ba53727bc53a160a7fb},
volume = {1},
year = {2009}
}
@inproceedings{Chen20112295,
abstract = {In the recent year, the position location system with ubiquitous computing has become very important, and the use of technology in the position location system has increasingly become the object of study and enterprise applications. One of the rapidly advancing technologies of position location system research is the global positioning system (GPS) but in indoor environments, the receiver may not receive the signal because the signal is subject to the building's impact. This congenital limitation renders the GPS unusable for the indoor position location system. In this paper, we will use cascade correlation network for an indoor position location system, and provide location service for user. In the first part, we will collect the RSS information of reference point to train the hybrid neural network models, and input the RSS information of track object to the model, and the model will provide the location of track object according to the RSS information. In the second part, we will calculate the performance of each neural network models and their weights were modified according to performance of each neural network. We will test the accuracy of location system again, and will use this system for patient care, smart home, and smart space. {\textcopyright} 2011 IEEE.},
annote = {cited By 2},
author = {Chen, R.-C. and Lin, Y.-C. and Lin, Y.-S.},
booktitle = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
doi = {10.1109/ICSMC.2011.6084020},
keywords = {Automation; Cybernetics; Intelligent buildings; N,Cascade correlation network; Enterprise applicatio,Global positioning system},
pages = {2295--2300},
title = {{Indoor position location based on cascade correlation networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-83755206334{\&}doi=10.1109{\%}2FICSMC.2011.6084020{\&}partnerID=40{\&}md5=b77b2b6cbb1e323e08b56f5800fea32c},
year = {2011}
}
@inproceedings{5304900,
abstract = {RFID-based localization has received considerable attention within the healthcare industry and has made a major impact on the healthcare system in hospitals. In this paper, we propose a new location tracking algorithm that aims to improve the accuracy of indoor localization for healthcare applications. In our approach, a cost function associated with a shape constraint factor is used to find the optimal reference tag positions that enclose the tracking tag. The cost function consists of the similarity and disparity of signal strength between the tracking and reference tags, as well as geometrical correlation properties. The experimental results indicate that the proposed shape constraint algorithm provides considerable improvement in average estimation error as compared with existing methods. We believe that this new algorithm is of potential value in dynamic location tracking of objects for healthcare applications.},
author = {Chen, W and Chang, H H and Lin, T H and Chen, P C and Chen, L K and Hwang, S J and Yen, D H J and Yuan, H S and Chu, W C},
booktitle = {2009 2nd International Conference on Biomedical Engineering and Informatics},
doi = {10.1109/BMEI.2009.5304900},
issn = {1948-2914},
keywords = {health care;indoor radio;object recognition;radiof},
pages = {1--5},
title = {{Dynamic Indoor Localization Based on Active RFID for Healthcare Applications: A Shape Constraint Approach}},
year = {2009}
}
@inproceedings{Chen2018719,
abstract = {We present a 3D positioning system called Pokeball, which uses a single-source magnetic sphere. The system comprises three mutually orthogonal coils and an Arbitrary Waveform Generator (AWG) to generate the designated signals. By applying Frequency Division Multiplexing (FDM), Pokeball generates two rotating magnetic fields with different frequencies of phase-quadrature current signals. The positioning object is equipped with a three-axis magnetoresistive sensor that measures the strength of the magnetic field and extracts the results into two signals with different frequencies. The phases of the two signals are used to determine the elevation and azimuth angles, while the amplitudes of the signals are used to calculate the distance between the source and the object. Then, based on the calculations, the location of the object is determined. The results of a comprehensive set of experiments demonstrate that Pokeball can achieve an accuracy of less than 40 cm for positioning errors in its effective positioning range. Moreover, Pokeball does not require site surveys, and it is robust against radio interference and environmental obstructions. Our approach has a great deal of potential for use in a wide range of applications, such as mobile systems, wearable computing devices, and location-based applications, where an instantaneous and accurate indoor 3D positioning system is essential. {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Chen, W.-T. and Chen, L.-J.},
booktitle = {Proceedings - 2017 IEEE International Conference on Internet of Things, IEEE Green Computing and Communications, IEEE Cyber, Physical and Social Computing, IEEE Smart Data, iThings-GreenCom-CPSCom-SmartData 2017},
doi = {10.1109/iThings-GreenCom-CPSCom-SmartData.2017.111},
keywords = {3-D positioning systems; Arbitrary waveform gener,Green computing,Internet of things; Magnetic fields; Radio interfe},
pages = {719--726},
title = {{Pokeball: A 3D positioning system using magnetism}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047405110{\&}doi=10.1109{\%}2FiThings-GreenCom-CPSCom-SmartData.2017.111{\&}partnerID=40{\&}md5=bb8f4c899c42fd5ee975599b517b29f2},
volume = {2018-Janua},
year = {2018}
}
@inproceedings{Chen2008625,
abstract = {This paper proposes a framework for retrieving semantic video events from indoor surveillance video databases. The goal is to locate video sequences containing events of interest to the user. This framework starts by tracking objects and segmenting videos into Common Appearance Intervals (CAIs). The spatiotemporal trajectories are obtained, based on which features are extracted for the construction of semantic event models. In the retrieval, the database user interacts with the machine and provides "feedbacks" to the retrieval result. The learning component learns from the spatiotemporal data, the semantic event model as well as the "feedback" and returns the refined result to the user. Specifically, the learning algorithm is developed based on a Coupled Hidden Markov Model (CHMM), which models the interactions of objects in CAIs and recognizes hidden patterns among them. This iterative learning and retrieval process contributes to the bridging of the "semantic gap", and the experimental results show the effectiveness of the proposed framework. {\textcopyright} 2008 IEEE.},
annote = {cited By 3},
author = {Chen, X and Zhang, C},
booktitle = {Proceedings - 10th IEEE International Symposium on Multimedia, ISM 2008},
doi = {10.1109/ISM.2008.82},
keywords = {Coupled hidden Markov models; Feedbacks]; Hidden p,Feedback; Hidden Markov models; Information theor,Security systems},
pages = {625--630},
title = {{Semantic event retrieval from surveillance video databases}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-62949151325{\&}doi=10.1109{\%}2FISM.2008.82{\&}partnerID=40{\&}md5=8985f83f9ab888ea81293bdccec0ee3c},
year = {2008}
}
@inproceedings{Chen20124747,
abstract = {Using quadrotor as an indoor robot asks for accurate locating and control methods. To solve this problem, a composite algorithm combining MIMU(Micro Inertial Measurement Unit) and monocular vision is used. The algorithm uses the measurement of MIMU as the source of position updating, while monocular vision algorithm provides the detection result of the feature of reference lines on the ground. The location of the reference lines detected is then compared with the result of MIMU, and the combination of these two results brings more accurate locating result for quadrotor. Compared to using MIMU, the error can decrease from 50cm to 10cm when the height of quadrotor is 1m. An object following platform is used for validating the composite algorithm, and system identification method is used for modeling the AR.Drone. Trajectory following algorithm and object following method are also developed. The scene of an AR.Drone searching at the navigation area and following the UGV is presented at last. {\textcopyright} 2012 IEEE.},
annote = {cited By 2},
author = {Chen, X.-L. and Tang, Q and Che, J},
booktitle = {Proceedings of the World Congress on Intelligent Control and Automation (WCICA)},
doi = {10.1109/WCICA.2012.6359378},
keywords = {Algorithms,GPS-denied environment; Indoor navigation; object,Intelligent control; Intelligent vehicle highway},
pages = {4747--4753},
title = {{An indoor quadrotor locating and object-following algorithm using monocular vision}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872343640{\&}doi=10.1109{\%}2FWCICA.2012.6359378{\&}partnerID=40{\&}md5=96c389cd77d2f24ace93a8f810e28914},
year = {2012}
}
@phdthesis{Chen:2008:HSR:1559307,
address = {Birmingham, AL, USA},
annote = {AAI3316460},
author = {Chen, Xin},
isbn = {978-0-549-69859-3},
publisher = {University of Alabama at Birmingham},
title = {{Human-centered Semantic Retrieval in Multimedia Databases}},
year = {2008}
}
@inproceedings{Chen2007,
abstract = {This paper presents the design and implementation of a WLAN based system for locating and tracking receivers inside buildings. It utilizes the WiFi access points existing in most modern office buildings, and is able to track multiple objects simultaneously. Experimental result shows that it provides a locating accuracy of about 5 m under indoor environment. {\textcopyright} 2007 IEEE.},
annote = {cited By 14},
author = {Chen, Y and Luo, R},
booktitle = {2007 IEEE International Conference on Portable Information Devices, PIDs 2007},
doi = {10.1109/PORTABLE.2007.49},
keywords = {Design and implementations; Indoor environment; M,Location,Office buildings},
title = {{Design and Implementation of a WiFi-Based Local Locating System}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934312470{\&}doi=10.1109{\%}2FPORTABLE.2007.49{\&}partnerID=40{\&}md5=f10112480dc25a82d73a7ca1e7815df2},
year = {2007}
}
@inproceedings{Chen200970,
abstract = {For the various applications in home automation, the service system requires to precisely estimate user's locations by certain sensors. It is considered as a challenge to automatically serve a mobile user in the house. However, indoor localization cannot be carried out effectively by the well-know Global Positioning System (GPS). In recent years, Wireless Sensor Networks (WSNs) are thus popularly used to locate a mobile object in an indoor environment. Some physical features are widely discussed to solve indoor localization in WSN. In this paper, we inquired about the RSSI solutions on indoor localization, and proposed a Closer Tracking Algorithm (CTA) to locate a mobile user in the house. The proposed CTA was implemented by using ZigBee CC2431 modules. The experimental results show that the proposed CTA can accurately determine the position with error distance less than 1 meter. At the same time, the proposed CTA has at least 85{\%} precision when the distance is less than one meter. {\textcopyright} 2009 by Knowledge Systems Institute Graduate School.},
annote = {cited By 19},
author = {Chen, Y.-T. and Yang, C.-L. and Chang, Y.-K. and Chu, C.-P.},
booktitle = {Proceedings: DMS 2009 - 15th International Conference on Distributed Multimedia Systems},
keywords = {Algorithms; Global positioning system; Indoor posi,Home automation; Indoor environment; Indoor local,Wireless sensor networks},
pages = {70--75},
title = {{A RSSI-based algorithm for indoor localization using ZigBee in wireless sensor network}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923879781{\&}partnerID=40{\&}md5=79fbb569d39529579417432733ad044b},
year = {2009}
}
@phdthesis{Chen:2012:TSE:2518866,
address = {Baltimore, MD, USA},
annote = {AAI3536526},
author = {Chen, Yin},
isbn = {978-1-267-94858-8},
publisher = {Johns Hopkins University},
title = {{Towards Scalable and Efficient Embedded Sensing Networks}},
year = {2012}
}
@inproceedings{5162266,
abstract = {RFID-tracking of indoor objects has been a subject of continuous interest in health and safety monitoring. In this paper, we propose a new location tracking algorithm that aims to improve localization accuracy of existing methods. The proposed method divides a sensing area into several communities, each of which consists of a number of neighboring reference tags, e.g. four. Rather than trying to track objects based on each individual reference tag, our approach estimates the coordinates of tracking objects by looking for the community that the object has the highest probability to be enclosed within. The experimental results indicate that our location tracking algorithm provides much improved tracking accuracy while retaining fast computation speed for real-time tracking. Moreover, the proposed tracking system, which provides fast installation with simple manipulation, is promising in healthcare and medical monitoring applications.},
author = {Cheng, C and Chang, H H and Chen, Y and Lin, T H and Chen, P C and Huang, C M and Yuan, H S and Chu, W C},
booktitle = {2009 3rd International Conference on Bioinformatics and Biomedical Engineering},
doi = {10.1109/ICBBE.2009.5162266},
issn = {2151-7614},
keywords = {biomedical communication;health and safety;medical},
pages = {1--4},
title = {{Accurate Location Tracking Based on Active RFID for Health and Safety Monitoring}},
year = {2009}
}
@inproceedings{Cheng2017,
abstract = {Passive millimeter-wave (PMMW) imaging has been widely adopted in earth remote sensing and security screening applications. To obtain more information about the interested objects, polarimetric measurement is an important approach. In this paper, the polarization characteristics of several common structures (i.e., sphere, cone, cylinder and human) have been analyzed theoretically and the corresponding physical meanings have been revealed. The analyzed polarization feature parameters include Stokes vector, angle of polarization, degree of linear polarization, and linear polarization ratio. Additionally, the indoor and outdoor simulations have been conducted to display the influence of ambient radiation on the polarization characteristics. The simulation results can provide some intrinsic mechanisms to acquire objects information, such as 3D structure feature and material composition. {\textcopyright} 2017 SPIE.},
annote = {cited By 1},
author = {Cheng, Y and Hu, F and Gui, L and Hu, Y and Han, Z},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.2270947},
keywords = {Brightness temperatures; Common structures; Degre,Millimeter waves; Polarimeters; Remote sensing,Polarization},
title = {{Passive millimeter-wave polarization characteristics of several common structures}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039045673{\&}doi=10.1117{\%}2F12.2270947{\&}partnerID=40{\&}md5=26446a52e88946163e5f377b9b1cff53},
volume = {10407},
year = {2017}
}
@inproceedings{Cheng201163,
abstract = {Augmented Reality (AR) that can be considered as a form of location-based services is a technique utilizing position and orientation information and a location database of POIs to enrich video or photographs by adding on graphics or text objects. The AR technique can be used to develop Pedestrian Navigation Systems (PNSs), but high-precision positioning is needed for displaying AR objects at proper places. However, the required level of accuracy is far beyond current commercial positioning solutions, e.g., outdoor GPS and indoor RF systems. In this paper, we propose an AR-based positioning technique for AR users to position their locations. First, by utilizing a coarse positioning system, AR objects can be roughly displayed on the touch screen of a AR device. Then, AR objects can be matched with their images on the display via drag-and-drop operations by users. Thus, both the coordinates of the AR objects in the image and in the real world can be known. Based on the coordinates along with the knowledge of the camera focal length, the location at which the photograph was taken can be known. The location of the camera can be treated as the location of the user. The proposed positioning technique is very helpful in developing high-precision PNSs. {\textcopyright} 2011 IEEE.},
annote = {cited By 9},
author = {Cheng, Y.-C. and Lin, J.-Y. and Yi, C.-W. and Tseng, Y.-C. and Kuo, L.-C. and Yeh, Y.-J. and Lin, C.-W.},
booktitle = {Proceedings of the International Conference on Parallel Processing Workshops},
doi = {10.1109/ICPPW.2011.48},
keywords = {Augmented reality; Cameras; Human computer intera,Camera focal length; Coarse positioning; Drag-and-,Tracking (position)},
pages = {63--70},
title = {{AR-based positioning for mobile devices}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80155194924{\&}doi=10.1109{\%}2FICPPW.2011.48{\&}partnerID=40{\&}md5=cb2d9f719e008297de05d8f6ed575377},
year = {2011}
}
@inproceedings{Chiang:2006:VAV:1193214.1193959,
address = {Washington, DC, USA},
author = {Chiang, Kai-Li and Tsai, Wen-Hsiang},
booktitle = {Proceedings of the 2006 International Conference on Intelligent Information Hiding and Multimedia},
doi = {10.1109/IIH-MSP.2006.170},
isbn = {0-7695-2745-0},
keywords = {Vehicle,danger condition,location,painting.,patrolling,security surveillance},
pages = {415--418},
publisher = {IEEE Computer Society},
series = {IIH-MSP '06},
title = {{Vision-Based Autonomous Vehicle Guidance in Indoor Environments Using Odometer and House Corner Location Information}},
url = {http://dx.doi.org/10.1109/IIH-MSP.2006.170},
year = {2006}
}
@article{Chippendale2015375,
abstract = {In this paper, a personal assistant and navigator system for visually impaired people will be described. The showcase presented intends to demonstrate how partially sighted people could be aided by the technology in performing an ordinary activity, like going to a mall and moving inside it to find a specific product. We propose an Android application that integrates Pedestrian Dead Reckoning and Computer Vision algorithms, using an off-the-shelf Smartphone connected to a Smartwatch. The detection, recognition and pose estimation of specific objects or features in the scene derive an estimate of user location with sub-meter accuracy when combined with a hardware-sensor pedometer. The proposed prototype interfaces with a user by means of Augmented Reality, exploring a variety of sensorial modalities other than just visual overlay, namely audio and haptic modalities, to create a seamless immersive user experience. The interface and interaction of the preliminary platform have been studied through specific evaluation methods. The feedback gathered will be taken into consideration to further improve the proposed system. {\textcopyright} Springer International Publishing Switzerland 2015.},
annote = {cited By 1},
author = {Chippendale, P and Tomaselli, V and D'Alto, V and Urlini, G and Modena, C M and Messelodi, S and Strano, S M and Alce, G and Hermodsson, K and Razafimahazo, M and Michel, T and Farinella, G M},
doi = {10.1007/978-3-319-16199-0_27},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Assistive technology; In-door navigations; Qualit,Augmented reality; Haptic interfaces; Mobile devic,Computer vision},
pages = {375--390},
title = {{Personal shopping assistance and navigator system for visually impaired people}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928791516{\&}doi=10.1007{\%}2F978-3-319-16199-0{\_}27{\&}partnerID=40{\&}md5=b2766f1a6d9917b7dfa0bd749a87096c},
volume = {8927},
year = {2015}
}
@article{Chmielewska2015119,
abstract = {In this paper we present an algorithm for precise estimation of moving objects density (typically people and vehicles) in indoor and outdoor scenes. Automatic generation of the so-called density maps is based on video sequences acquired by surveillance systems. Our approach offers two types of solutions. The first one increments the accumulation table when a moving object is detected in a location of interest, delivering a density map of the presence of moving objects. The second algorithm increments the accumulation table only in cases of detecting a new moving object, resulting in a density map of the count of moving objects. The proposed algorithms were tested with the use of PETS 2009 database and with our own database of long-term video recordings. Finally, results of the density maps visualization and determination of the "busy hours" are presented. {\textcopyright} 2015 Agata Chmielewska et al.},
annote = {cited By 2},
author = {Chmielewska, A and Parzych, M and Marciniak, T and Dabrowski, A},
doi = {10.1515/fcds-2015-0008},
journal = {Foundations of Computing and Decision Sciences},
keywords = {Algorithms; Security systems; Video recording,Behaviour analysis; Density estimation; Density m,Object detection},
number = {2},
pages = {119--132},
title = {{New approach to traffic density estimation based on indoor and outdoor scenes from CCTV}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930030371{\&}doi=10.1515{\%}2Ffcds-2015-0008{\&}partnerID=40{\&}md5=f8014d9f2a212ea8fb105ecb2529f93c},
volume = {40},
year = {2015}
}
@inproceedings{Cho2016,
abstract = {Nowadays, user localization in indoor environments is more necessary to build many location-based services. This paper presents a robust audio identification method for enhancing a real-time indoor localization system on a mobile device using the audio signals emitted by nearby loudspeakers. The proposed audio identification method deals with various noise distortions due to different noisy indoor locations by using foreground/background audio separation, prominent spectral pitch-based binary audio fingerprinting, and spectral peak-triplet-based audio fingerprinting. Experimental results confirm that the proposed audio identification method is quite robust in different noise conditions and achieves preliminary promising results for discriminating the location and orientation of a user in large indoor locations. {\textcopyright} 2016 IEEE.},
annote = {cited By 1},
author = {Cho, H.-S. and Ko, S.-S. and Kim, H.-G.},
booktitle = {2016 IEEE International Conference on Multimedia and Expo Workshop, ICMEW 2016},
doi = {10.1109/ICMEW.2016.7574701},
keywords = {Acoustic noise,Audio acoustics; Indoor positioning systems; Locat,Audio fingerprinting; Audio identification; Audio},
title = {{A robust audio identification for enhancing audio-based indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992027336{\&}doi=10.1109{\%}2FICMEW.2016.7574701{\&}partnerID=40{\&}md5=9eb2babb52df10681b44e3e759d05022},
year = {2016}
}
@article{Cho2017132,
abstract = {The Internet of Things interconnects a mass of billions devices, from smartphones to cars, to provide convenient services to people. This gives immediate access to various data about the objects and the environmental context-leading to smart services and increased efficiency. A number of retail stores have started to adopt IoT enabled services to attract customers. In particular, thanks to indoor proximity technologies, it is possible to introduce location-based smart services to customers, for example, transmitting identifiable signals that represent the locations of stores. In this article, we investigate a potential security risk involved in such technologies: physical signals used as identifiers can be captured and forged easily with today's widely available IoT software for implementing location spoofing attacks. We highlight this security risk by providing a case study: an in-depth security analysis of the recently launched Starbucks service called Siren Order. {\textcopyright} 2017 IEEE.},
annote = {cited By 1},
author = {Cho, J and Yu, J and Oh, S and Ryoo, J and Song, J and Kim, H},
doi = {10.1109/MCOM.2017.1600595CM},
journal = {IEEE Communications Magazine},
keywords = {Environmental contexts; Location based; Physical,Indoor positioning systems; Internet of things; Lo,Location based services},
number = {3},
pages = {132--137},
title = {{Wrong Siren! A Location Spoofing Attack on Indoor Positioning Systems: The Starbucks Case Study}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017660676{\&}doi=10.1109{\%}2FMCOM.2017.1600595CM{\&}partnerID=40{\&}md5=b490ce56bbe1cbb6ffbbe4163cebdbb0},
volume = {55},
year = {2017}
}
@inproceedings{8560479,
abstract = {Recently, impulse radio-ultra wideband is widely used for highly accurate location estimation of robots and objects in indoor space for building automation. For their accurate positioning, calibration must be performed after the positioning system is installed, and a compensation technique of the multipath signals should be performed in real-time. In this paper, a real-time calibration and error compensation method is proposed. A filter that estimates channel common error and channel-specific error sequentially is designed based on cubature Kalman filter and the fast and accurate estimation performance of this filter is verified experimentally.},
author = {Cho, S Y},
booktitle = {2018 IEEE 14th International Conference on Automation Science and Engineering (CASE)},
doi = {10.1109/COASE.2018.8560479},
issn = {2161-8089},
keywords = {calibration;error compensation;Global Positioning},
pages = {668--670},
title = {{CKF-based Fast Error Compensation Filter Design for IR-UWB Indoor Positioning System for Building Automation}},
year = {2018}
}
@inproceedings{Choi20157,
abstract = {Recently, interests in 3D indoor modeling and positioning have been growing. Data fusion by using different sensors data is one of the 3D model producing methods. For a data fusion between two kinds of sensors, precise system calibration is essential. If relative geometric location of each sensor can be accurately measured with a system-calibration, it is possible to locate a pixel that corresponds to the same object in two different images, and thus, produce a more precise data-fusion. Purpose of this study is finding more efficient method of system calibration between optical and range sensor. For this urpose, experiment was designed by considering following variables, i) system calibration method, ii) testbed type, iii) and distance data(whether use it or not). So, In this study, test-bed for system calibration was designed by considering the characteristics of sensors. Also, precise simulation was done to find efficient method of system calibration, and its results were reflected in real experiment. Results of simulation show that the bundle adjustment method is more efficient than single photo resection in system calibration between range and optical sensors. And the most efficient case was when using i) the bundle adjustment with ii) the simulated data set which were obtained between 2m to 4m away from the test-bed. These results of simulation were reflected in real system calibration. Finally, real system calibration were performed and its results were compared to results of simulation. And accuracy of system calibration was evaluated by producing fusion data between range and optical sensors.},
annote = {cited By 0},
author = {Choi, W and Kim, C and Kim, Y},
booktitle = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
doi = {10.5194/isprsarchives-XL-7-W4-7-2015},
keywords = {3D data fusion; Bundle adjustments; Distance datu,Birefringence; Data fusion; Equipment testing; Ima,Calibration},
number = {7W4},
pages = {7--12},
title = {{A study for efficient methods of system calibration between optical and range sensors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975041812{\&}doi=10.5194{\%}2Fisprsarchives-XL-7-W4-7-2015{\&}partnerID=40{\&}md5=e5840be0b7434460efc8fc8c47667b2c},
volume = {40},
year = {2015}
}
@inproceedings{Choosaksakunwiboon:2018:PTB:3281667.3281718,
address = {Kaki Bukit TechPark II,, Singapore},
author = {Choosaksakunwiboon, Shanatip and Terawong, Chawin and Suttisirikul, Suppakorn and Anantavrasilp, Isara and Thiemjarus, Surapa and Wisadsud, Sodsai and Kaemarungsi, Kamol},
booktitle = {Proceedings of the 12th International Convention on Rehabilitation Engineering and Assistive Technology},
keywords = {BLE,RSSI,channel separation,indoor positioning system,localization,log-distance path loss model},
pages = {241--244},
publisher = {Singapore Therapeutic, Assistive {\&} Rehabilitative Technologies (START) Centre},
series = {i-CREATe 2018},
title = {{A Pre-processing Technique for BLE-based Indoor Localization}},
url = {http://dl.acm.org/citation.cfm?id=3281667.3281718},
year = {2018}
}
@article{ChristyJebaMalar2019289,
abstract = {The position of a movable object is required in an indoor environment for providing various business interest services and for emergency services. The techniques implemented on WLAN (802.11b Wireless LANs) endow with more ubiquitous (Feng et al. in IEEE Trans Mob Comput 12(12), 2012, [1]) within the environment and the requirement for additional hardware is not necessary, thereby reducing infrastructure cost and enhancing the value of wireless data network. The received signal strength (RSS) from various reference points (RP) were recorded by a tool and fingerprint radio map is constructed. The signal property of a fingerprint will differ in each point. The location can be found by comparing the current signal strength with already collected radio maps. Almost all indoor environments are equipped with Wi-Fi devices. No additional hardware is required for the setup. In this paper, we introduce SVM classifier (Roos et al. in IEEE Trans Mob Comput 1(1), 5969, 2002 [2]) as a methodology with minimum cost and without scarifying accuracy. The obtained results show minimal location error and accurate location of the object. {\textcopyright} Springer Nature Singapore Pte Ltd 2019.},
annote = {cited By 0},
author = {{Christy Jeba Malar}, A and Kousalya, G},
doi = {10.1007/978-981-10-8971-8_26},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Accurate location; Indoor environment; Indoor pos,Emergency services; Hardware; Indoor positioning s,Support vector machines},
pages = {289--298},
title = {{Fingerprint-Based Support Vector Machine for Indoor Positioning System}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050390102{\&}doi=10.1007{\%}2F978-981-10-8971-8{\_}26{\&}partnerID=40{\&}md5=61f839f80ec860b9920f6b5d39fbbe98},
volume = {670},
year = {2019}
}
@article{Chruszczyk201671,
abstract = {This paper presents comparison of prototype location system built with standard components of 2.4 and 5 GHz WLAN network infrastructure. The system can be used for personal or other objects' positioning, both for indoor and outdoor environments. The system is local, i.e. its operational area is limited to WLAN network operating range. The system is based on standard and widely available WLAN components (access points, network adapters). The goal is to avoid any hardware and software modifications. Also position calculation should not be power hungry operation. Method of location is based in Received Signal Strength Indication (RSSI) returned by most of RF ICs (including WLAN). The main focus is research of how much accuracy (and usefulness) can be expected from standard WLAN hardware. Both static and dynamic scenarios have been tested and compared. {\textcopyright} by {\L}ukasz Chruszczyk 2016.},
annote = {cited By 8},
author = {Chruszczyk, {\L} and Zajac, A and Grzechca, D},
doi = {10.1515/eletel-2016-0010},
journal = {International Journal of Electronics and Telecommunications},
keywords = {Dynamic scenarios; Hardware and software; Indoor,Hardware; Location; Reconfigurable hardware; Wirel,Local area networks},
number = {1},
pages = {71--79},
title = {{Comparison of 2.4 and 5 GHz WLAN Network for Purpose of Indoor and Outdoor Location}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966539161{\&}doi=10.1515{\%}2Feletel-2016-0010{\&}partnerID=40{\&}md5=a18619cf898ea1f406265ec905b173a4},
volume = {62},
year = {2016}
}
@inproceedings{Chu2013239,
abstract = {In recent years, there has been considerable research interest in social computing and radio frequency identification (RFID) technology. In this paper, we present a Smart Shopping System to provide customers with a smart shopping experience with the help of social vectors and RFID technology. Social vectors provide a systematic and mathematical way to define and quantify social relationships between any entities, while RFID technology allows any object to be easily tracked and identified in an indoor environment. The Smart Shopping System identifies the location of customers using RFID technology and finds similar customers using social vectors with the purpose of providing product recommendations and sending customized marketing messages such as mobile advertisements or e-coupons to customers; smart phones as soon as the customers come into a shop or are near to the shop. Other innovative functionalities include receiving real-time product reviews from similar customers who have just visited the same shops, and exchanging e-coupons or product information using NFC technology.},
annote = {cited By 2},
author = {Chu, T H S and Hui, F C P and Chan, H C B},
booktitle = {Lecture Notes in Engineering and Computer Science},
keywords = {Cellular telephone systems,Computer science; Mobile telecommunication systems,Indoor environment; Mobile advertisement; Product},
pages = {239--244},
title = {{Smart shopping system using social vectors and RFID}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880048659{\&}partnerID=40{\&}md5=ad088d08bdcfd85548e72eb6c2f237f5},
volume = {2202},
year = {2013}
}
@inproceedings{Chung2006527,
abstract = {One of the central issues in sensor networks for context-awareness is location tracking, whose goal is to monitor the tracking path of a moving object. This paper describes our indoor location-tracking system for in-building, mobile, location-dependent healthcare applications. Ceiling-mounted beacons are spread through the building which publish location information on RF and ultrasonic signals and allows applications running on mobile and static nodes to learn their physical location. The target to be tracked carries listener node, this node listens the beacons information as they arrived and forwards these beacons to the base station .At the base station the multilateration was used to determine the location of the listener. This information at the base station was further processed to check the activity of the person. In the location-tracking system we also could calculate the user's activity, that is, how much the user moves in span of time. The monitored activity data of the patient can support doctor or caregiver to see the status of the patient.},
annote = {cited By 1},
author = {Chung, W.-Y. and Singh, V K and Jeong, D.-U. and Mylylae, R and Lim, H},
booktitle = {6th IASTED International Multi-Conference on Wireless and Optical Communications: Wireless Sensor Networks, WSN 2006},
keywords = {Base stations; Health care; Optical communication,Beacons; Health care application; Indoor location,Tracking (position)},
pages = {527--530},
title = {{Passive and cost effective people indoor location tracking system for ubiquitous healthcare}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887239271{\&}partnerID=40{\&}md5=a82493f5013cbe596fabe04fcfa73db1},
year = {2006}
}
@inproceedings{Chuo:2017:RNI:3117811.3117840,
address = {New York, NY, USA},
author = {Chuo, Li-Xuan and Luo, Zhihong and Sylvester, Dennis and Blaauw, David and Kim, Hun-Seok},
booktitle = {Proceedings of the 23rd Annual International Conference on Mobile Computing and Networking},
doi = {10.1145/3117811.3117840},
isbn = {978-1-4503-4916-1},
keywords = {ASIC,RF reflection,indoor localization,multipath,neural network classification,non line-of-sight,time-of-arrival},
pages = {222--234},
publisher = {ACM},
series = {MobiCom '17},
title = {{RF-Echo: A Non-Line-of-Sight Indoor Localization System Using a Low-Power Active RF Reflector ASIC Tag}},
url = {http://doi.acm.org/10.1145/3117811.3117840},
year = {2017}
}
@inproceedings{5653750,
abstract = {Radio signals based indoor location systems is a hot topic. Even many papers deals with this subject, and some solutions were tested, currently we have no mature commercial implementations. Based on WLAN, RFID, WSN, ZigBee or proprietary solutions, location systems working principles implies the measurement of radio signals. Due to propagation issues in real working conditions, the practical demonstrated performances are far enough from theoretical simulation results. In indoor environments, the presence of different objects in rooms may cause multiple propagation paths, dynamic position changing objects or human presence affect the measurement precision. In this paper, we evaluate a 2.4 GHz WSN based location system both in an isolated environment setup - in a shielded room, and in real conditions in a laboratory room and compare the results. We measure the electromagnetic field generated by the system, in order to estimate the potential risks to humans if these systems are massively deployed.},
author = {Coca, E and Popa, V and Buta, G},
booktitle = {2010 IEEE 16th International Symposium for Design and Technology in Electronic Packaging (SIITME)},
doi = {10.1109/SIITME.2010.5653750},
keywords = {personal area networks;radiofrequency identificati},
pages = {69--72},
title = {{An indoor location system performance evaluation and electromagnetic measurements}},
year = {2010}
}
@article{Cocias2014199,
abstract = {In this paper, a markerless approach for estimating the pose of a robot using only 3Dvisual information is presented. As opposite to traditional methods, our approach makes use of 3D features solely for determining a relative position between the imaged scene (e.g. landmarks present on site) and the robot. Such a landmark is calculated from stored 3D map of the environment. The recognition of the landmark is performed via a 3D Object Retrieval (3DOR) search engine. The presented pose estimation technique produces a reliable and accurate pose information which can be further used for complex scene understanding and/or navigation. The performance of the proposed approach has been evaluated against a traditional marker-based position estimation library. {\textcopyright} Springer International Publishing Switzerland 2014.},
annote = {cited By 0},
author = {Cocias, T T and Grigorescu, S M and Moldoveanu, F},
doi = {10.1007/978-3-319-03206-1_15},
journal = {Studies in Computational Intelligence},
pages = {199--211},
title = {{Indoor pose estimation using 3D scene landmarks for service robotics}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893096767{\&}doi=10.1007{\%}2F978-3-319-03206-1{\_}15{\&}partnerID=40{\&}md5=b9499df76f4e9b6397dd8ef085e30aae},
volume = {530},
year = {2014}
}
@inproceedings{5944053,
abstract = {Indoor position tracking systems are essential to support new types of applications for domotics and elderly care services. Unfortunately, while locating moving objects (e.g., people in a room) typically requires accuracy in the order of a few tens of cm, the intrinsically crowded nature of indoor environments (e.g., due to the presence of obstacles and/or multiple targets) as well as manifold sources of uncertainty may considerably degrade measurement results. In this paper, we present a local positioning system (LPS) provided with wireless connectivity. The proposed solution relies on two cascaded extended Kalman filters. The first one estimates the attitude of the platform within a global reference frame. The second one relies on the estimated attitude to return the planar position of the moving object in a room. The proposed approach is much more scalable than centralized location tracking techniques (e.g. based on external cameras only) because it does not require collecting and processing large data sets in real-time. Also, just low-rate position corrections are needed to keep uncertainty within given boundaries. Such position calibration values, measured with any type of external positioning infrastructure, can be sent to the LPS through a low-cost radio link like in a Wireless Sensor Network (WSN), at no risk of saturating the communication channel even when multiple objects are present in the room.},
author = {Colombo, A and Fontanelli, D and Macii, D and Palopoli, L},
booktitle = {2011 IEEE International Instrumentation and Measurement Technology Conference},
doi = {10.1109/IMTC.2011.5944053},
issn = {1091-5281},
keywords = {calibration;Global Positioning System;indoor radio},
pages = {1--6},
title = {{A wearable embedded inertial platform with wireless connectivity for indoor position tracking}},
year = {2011}
}
@inproceedings{Colonnier:2015:VOL:2977527.2977543,
address = {New York, NY, USA},
author = {Colonnier, Fabien and Manecy, Augustin and Juston, Rapha{\"{e}}l and Viollet, St{\'{e}}phane},
booktitle = {Proceedings of the 4th International Conference on Biomimetic and Biohybrid Systems - Volume 9222},
doi = {10.1007/978-3-319-22979-9_16},
isbn = {978-3-319-22978-2},
keywords = {Eye micro-movements,Hyperacuity,Insect vision,Robotics},
pages = {153--163},
publisher = {Springer-Verlag New York, Inc.},
series = {Living Machines 2015},
title = {{Visual Odometry and Low Optic Flow Measurement by Means of a Vibrating Artificial Compound Eye}},
url = {http://dx.doi.org/10.1007/978-3-319-22979-9{\_}16},
year = {2015}
}
@inproceedings{Combier201817,
abstract = {An Augmented Reality prototype is presented. Its hardware architecture is composed of a Head Mounted Display, a wide Field of View (FOV) stereo-vision passive system, a gaze tracker and a laptop. An associated software architecture is proposed to immerse the user in augmented environments where he/she can move freely. The system maps the unknown real-world (indoor or outdoor) environment and is localized into this map by means of binocular state-of-the-art Simultaneous Localization and Mapping techniques. It overcomes the FOV limitations of conventional augmented reality devices by using wide-angle cameras and associated algorithms. It also solves the parallax issue induced by the distinct locations of the two cameras and of the user's eyes by using Depth Image Based Rendering. An embedded gaze tracker, together with environment modeling techniques, enable gaze controlled interaction. A simple application is presented, in which a virtual object is inserted into the user's FOV and follows his/her gaze. While the targeted real time performance has not yet been achieved, the paper discusses ways to improve both frame rate and latency. Other future works are also overviewed. Copyright {\textcopyright} 2018 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
annote = {cited By 0},
author = {Combier, J and Vandeportaele, B and Dan{\`{e}}s, P},
booktitle = {VISIGRAPP 2018 - Proceedings of the 13th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
keywords = {Augmented environments; Depth image based renderi,Augmented reality; Cameras; Computer vision; Eye t,Stereo image processing},
pages = {17--27},
title = {{Towards an augmented reality head mounted display system providing stereoscopic wide field of view for indoor and outdoor environments with interaction through the gaze direction}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047873086{\&}partnerID=40{\&}md5=fbff4a6c8e4163847b027a245ad0edc0},
volume = {4},
year = {2018}
}
@article{Correll:2010:IRG:1873118.1873130,
address = {Secaucus, NJ, USA},
author = {Correll, Nikolaus and Arechiga, Nikos and Bolger, Adrienne and Bollini, Mario and Charrow, Ben and Clayton, Adam and Dominguez, Felipe and Donahue, Kenneth and Dyar, Samuel and Johnson, Luke and Liu, Huan and Patrikalakis, Alexander and Robertson, Timothy and Smith, Jeremy and Soltero, Daniel and Tanner, Melissa and White, Lauren and Rus, Daniela},
doi = {10.1007/s11370-010-0076-1},
issn = {1861-2776},
journal = {Intell. Serv. Robot.},
keywords = {Indoor gardening,Robotic agriculture,Tomato detection},
number = {4},
pages = {219--232},
publisher = {Springer-Verlag New York, Inc.},
title = {{Indoor Robot Gardening: Design and Implementation}},
url = {http://dx.doi.org/10.1007/s11370-010-0076-1},
volume = {3},
year = {2010}
}
@inproceedings{5767934,
abstract = {In this demonstration paper, we present a powerful distributed framework for finding similar trajectories in a smartphone network, without disclosing the traces of participating users. Our framework, exploits opportunistic and participatory sensing in order to quickly answer queries of the form: Report objects (i.e., trajectories) that follow a similar spatio-temporal motion to Q, where Q is some query trajectory. SmartTrace, relies on an in-situ data storage model, where geo-location data is recorded locally on smartphones for both performance and privacy reasons. SmartTrace then deploys an efficient top-K query processing algorithm that exploits distributed trajectory similarity measures, resilient to spatial and temporal noise, in order to derive the most relevant answers to Q quickly and efficiently. Our demonstration shows how the SmartTrace algorithmics are ported on a network of Android-based smartphone devices with impressive query response times. To demonstrate the capabilities of SmartTrace during the conference, we will allow the attendees to query local smartphone networks in the following two modes: (i) Interactive Mode, where devices will be handed out to participants aiming to identify who is moving similar to the querying node; and (ii) Trace-driven Mode, where a large-scale deployment can be launched in order to show how the K most similar trajectories can be identified quickly and efficiently. The conference attendees will be able to appreciate how interesting spatio-temporal search applications can be implemented efficiently (for performance reasons) and without disclosing the complete user traces to the query processor (for privacy reasons)1. For instance, an attendee might be able to determine other attendees that have participated in common sessions, in order to initiate new discussions and collaborations, without knowing their trajectory or revealing his/her own trajectory either.},
author = {Costa, C and Laoudias, C and Zeinalipour-Yazti, D and Gunopulos, D},
booktitle = {2011 IEEE 27th International Conference on Data Engineering},
doi = {10.1109/ICDE.2011.5767934},
issn = {2375-026X},
keywords = {query processing;smartphone network;spatio-tempora},
pages = {1288--1291},
title = {{SmartTrace: Finding similar trajectories in smartphone networks without disclosing the traces}},
year = {2011}
}
@inproceedings{Costea2018,
abstract = {An indoor localization and monitoring system for equipment and people is an important issue in production area monitoring and offices, lab research, etc. Although several monitoring systems are currently under development by previous investigators, these issues remain significant difficulties. For instance, the pyroelectric IR (PIR) system provides less accurate information of human location and is restricted when there are multiple targets. Also, the RFID localization system is constrained by its limited accuracy. In this study, we propose an indoor localization and monitoring system based on a network of PIR sensors and RFID sensors - a sensory fusion system. A sensor-network based localization method called the PIR-RFID inference algorithm is under development. This algorithm determines the fused position from both the PIR localization system and RFID signal localization system, which utilize the received signal strength propagation model. We have developed and experimentally demonstrated a networked sensory fusion system, which can be successfully applied in localize multiple targets - equipment and people. With an accurate localization mechanism for the indoor environment, the provision of appropriate tasks / services can be built for each modeled situation. What is new in this system, as an evolved sensory fusion system, is that the entire system has been designed and built according with specific requests of a real life situation, as standalone system, on its own, that is, regardless of the other systems a production area / shop floor / equipment a building can have. This system can interact with practically any systems at any level and can be adapted to virtually any existing building system. {\textcopyright} 2018 SPIE.},
annote = {cited By 0},
author = {Costea, A and chiopu, P and Vldescu, M},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.2325470},
keywords = {Abnormal activity detection; Behavior analysis; L,Data fusion; Indoor positioning systems; Inference,Monitoring},
title = {{Design and implementation of redundant integrated human and equipment indoor tracking system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061112114{\&}doi=10.1117{\%}2F12.2325470{\&}partnerID=40{\&}md5=cbc5aeff06355b8415b09b89904d79f2},
volume = {10977},
year = {2018}
}
@article{Coughlan:2007:CTF:1317075.1317085,
address = {New York, NY, United States},
author = {Coughlan, James and Manduchi, Roberto},
doi = {10.1155/2007/96357},
issn = {1687-5176},
journal = {J. Image Video Process.},
number = {2},
pages = {10},
publisher = {Hindawi Publishing Corp.},
title = {{Color Targets: Fiducials to Help Visually Impaired People Find Their Way by Camera Phone}},
url = {http://dx.doi.org/10.1155/2007/96357},
volume = {2007},
year = {2007}
}
@inproceedings{6700031,
abstract = {This article presents a system for tracking the position of objects within a smart home to support a robot assistant in pick-and-place tasks. The current system is capable of estimating the position of an object using the signal strength received by a mobile device in a ZigBee sensor network. Received strength signal indication measurements were done in laboratory for applying a estimation method. Two models were utilized (a) log-distance path loss - model in which signal lost has a random influence with log-normal distribution, and (b) free space decay law - based on the decay law for a signal on a open space. Experiments with satisfactory results were done with a public dataset to benchmark our data.},
author = {da Fonseca, V P and Rosa, P F F},
booktitle = {IECON 2013 - 39th Annual Conference of the IEEE Industrial Electronics Society},
doi = {10.1109/IECON.2013.6700031},
issn = {1553-572X},
keywords = {home automation;log normal distribution;mobile com},
month = {nov},
pages = {5492--5497},
title = {{Indoors object location protocol in a smart home}},
year = {2013}
}
@inproceedings{Dai20172432,
abstract = {A key requirement for leveraging supervised deep learning methods is the availability of large, labeled datasets. Unfortunately, in the context of RGB-D scene understanding, very little data is available - current datasets cover a small range of scene views and have limited semantic annotations. To address this issue, we introduce ScanNet, an RGB-D video dataset containing 2.5M views in 1513 scenes annotated with 3D camera poses, surface reconstructions, and semantic segmentations. To collect this data, we designed an easy-to-use and scalable RGB-D capture system that includes automated surface reconstruction and crowd-sourced semantic annotation. We show that using this data helps achieve state-of-the-art performance on several 3D scene understanding tasks, including 3D object classification, semantic voxel labeling, and CAD model retrieval. {\textcopyright} 2017 IEEE.},
annote = {cited By 61},
author = {Dai, A and Chang, A X and Savva, M and Halber, M and Funkhouser, T and Nie{\ss}ner, M},
booktitle = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
doi = {10.1109/CVPR.2017.261},
keywords = {3d object classifications; 3D reconstruction; Aut,Cameras; Computer aided design; Computer vision; D,Three dimensional computer graphics},
pages = {2432--2443},
title = {{ScanNet: Richly-annotated 3D reconstructions of indoor scenes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041928024{\&}doi=10.1109{\%}2FCVPR.2017.261{\&}partnerID=40{\&}md5=42a29ca9e1074ea0b45d1adbc6b71819},
volume = {2017-Janua},
year = {2017}
}
@inproceedings{Daim201979,
abstract = {Impulse Radio Ultra-Wideband (IR-UWB) radar is a type of radar functioning based on UWB transmission technology that uses an exceedingly wide bandwidth low power impulse signal to continuously transmitting and receiving the impulse signal for object detection within a range. IR-UWB radar has shown promising utilization in realizing indoor environment device-free wireless positioning which is an emerging positioning technique that can approximate the presence and location of a person or object in passive manner without the obligation of any attached tracking devices. With this motivation, in this paper a study on indoor environment device-free wireless positioning using IR-UWB radar is presented. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Daim, T J and Lee, R M A},
booktitle = {Proceedings - 2018 IEEE International Conference on Artificial Intelligence in Engineering and Technology, IICAIET 2018},
doi = {10.1109/IICAIET.2018.8638458},
keywords = {Artificial intelligence; Object detection; Radar;,Impulse radio ultra wideband (IR-UWB); Indoor env,Ultra-wideband (UWB)},
pages = {79--82},
title = {{Indoor environment device-free wireless positioning using IR-UWB radar}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063139162{\&}doi=10.1109{\%}2FIICAIET.2018.8638458{\&}partnerID=40{\&}md5=130c07dfc7d5e6c0b5cb0afb1ee1fbce},
year = {2019}
}
@article{Danafar2006222,
abstract = {A set of transforms (SVD transforms) were introduced in (Shahshahani and Tavakoli Targhi) for understanding images. These transforms have been applied to some problems in computer vision including segmentation, detection of objects in a texture environment, classification of textures, detection of cracks or other imperfections, etc. This technique is shown to be applicable to determination of the location of eyes in a facial image. This method makes no use of color cues, prior geometric knowledge or other assumptions and does not require training. It is also insensitive to local perturbations in lighting, change of orientation and pose, scaling, and complexity of the background including indoor and outdoor environments. The method can be used for eye tracking and has applications to face recognition. It has also been used in animal eye detection and differ-entiation. {\textcopyright} 2007 Wiley Periodicals, Inc.},
annote = {cited By 1},
author = {Danafar, S and Sheikh, L T and Targhi, A T},
doi = {10.1002/ima.20084},
journal = {International Journal of Imaging Systems and Technology},
keywords = {Computer vision; Face recognition; Image analysis;,Eye tracking; Facial images; Fourth order neighbo,Singular value decomposition},
number = {5},
pages = {222--229},
title = {{A method for eye detection based on SVD transforms}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247126890{\&}doi=10.1002{\%}2Fima.20084{\&}partnerID=40{\&}md5=28be4598a0b93a2b9c59dc8b01ba6806},
volume = {16},
year = {2006}
}
@inproceedings{Dao2015405,
abstract = {This paper presents a study on the indoor localization system using the passive UHF RFID technology. Positions of multi-antennas are designed according to the Triangular model to narrow the location area of object tags. Major parts as Path Loss models, calibration method, localization algorithm and proposed methodology will be discussed in detail. The orientation between antennas and calibrated Path Loss models are used in improving the localization quality. Besides, the accuracy is increased by combining indoor Path Loss models with Triangular technique. {\textcopyright} 2014 IEEE.},
annote = {cited By 4},
author = {Dao, T.-H. and Le, M.-T. and Nguyen, Q.-C.},
booktitle = {International Conference on Advanced Technologies for Communications},
doi = {10.1109/ATC.2014.7043421},
keywords = {Antennas; Calibration; Mobile antennas; Signal rec,Indoor localization; Indoor path loss; Passive ta,Indoor positioning systems},
pages = {405--410},
title = {{Indoor localization system using passive UHF RFID tag and multi-antennas}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940514132{\&}doi=10.1109{\%}2FATC.2014.7043421{\&}partnerID=40{\&}md5=137556dbcf8dd6b346fdd4e4581a1f81},
volume = {2015-Febru},
year = {2015}
}
@article{Dasgupta2015,
abstract = {We consider the problem of autonomous landmine detection using a team of mobile robots. Previous research on robotic landmine detection mostly employs a single robot equipped with a landmine detection sensor to detect landmines. We envisage that the quality of landmine detection can be significantly improved if multiple robots are coordinated to detect landmines in a cooperative manner by incrementally fusing the landmine-related sensor information they collect and then use that information to visit locations of potential landmines. Towards this objective, we describe a multirobot system called COMRADES to address different aspects of the autonomous landmine detection problem including distributed area coverage to detect and locate landmines, information aggregation to fuse the sensor information obtained by different robots, and multirobot task allocation (MRTA) to enable different robots to determine a suitable sequence to visit locations of potential landmines while reducing the time required and battery expended. We have used commercially available all-terrain robots called Coroware Explorer that are customized with a metal detector to detect metallic objects including landmines, as well as indoor Corobot robots, both in simulation and in physical experiments, to test the different techniques in COMRADES. {\textcopyright} 2015 Prithviraj Dasgupta et al.},
annote = {cited By 2},
author = {Dasgupta, P and Baca, J and Guruprasad, K R and Mun{\~{o}}z-Mel{\'{e}}ndez, A and Jumadinova, J},
doi = {10.1155/2015/921370},
journal = {Journal of Robotics},
keywords = {Area coverages; Information aggregation; Landmine,Bombs (ordnance); Explosives; Industrial robots; I,Landmine detection},
title = {{The COMRADE system for multirobot autonomous landmine detection in postconflict regions}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947650236{\&}doi=10.1155{\%}2F2015{\%}2F921370{\&}partnerID=40{\&}md5=04439cfffe722dc5654be980d0411a10},
volume = {2015},
year = {2015}
}
@book{Dayioglu:2013:DIO:2566872,
address = {USA},
author = {Dayioglu, Emrah},
isbn = {3656318301, 9783656318309},
publisher = {GRIN Verlag},
title = {{Design and Implementation of Object Oriented Location Aware Application for Android Mobile Devices and Web Service Integration}},
year = {2013}
}
@article{PaivadeCarvalho2018268,
abstract = {Biodeterioration is a topic of ever-growing concern and is particularly relevant in the context of cultural heritage conservation, since artworks and monuments provide diversified ecological niches for microorganism colonization. Despite all the gathered knowledge in recent years, current established norms and accepted contamination thresholds have a prominent focus on human health and air quality preservation. Nonetheless they still are not enough or are not adequately applied for cultural heritage preservation. In the light of this study within a very important Museum from Coimbra (Portugal), the current knowledge and accepted norms are discussed. Despite the meticulous control of environmental parameters inside this art repository, the presence of fungal colonies was unexpectedly detected on wooden sculptures and paintings that were deposited inside a custom-built room. Contaminated art objects were sampled for fungal isolation and identification, along with seasonal indoor air sampling, for a one-year period. Molecular biology methods complemented with morphological observation were used for the identification of fungal organisms. Direct sampling of 8 contaminated paintings allowed the retrieval of 10 fungal isolates (3 different genera and 4 different species). In addition, 19 fungal isolates (5 different genera and 9 different species) were retrieved from 7 contaminated wooden sculptures. The air sampling process provided a total of 150 isolates (24 different genera and 43 different species), from which the most common genera were Aspergillus, Cladosporium and Penicillium, and the most frequent species were Aspergillus versicolor, Cladosporium cladosporioides, Penicillium copticola and P. corylophilum. Although the number of airborne CFU was considerably low in all seasons, some fungal species with known biodeterioration capability and adverse human health effects were found. The relevance of air contamination monitoring as a single tool for biodeterioration risk assessment is discussed, as are the currently available norms and recommendations. Preventive measures are advised and considerations are made regarding potentially more effective approaches. {\textcopyright} 2018 Elsevier Masson SAS},
annote = {cited By 0},
author = {de Carvalho, H and Mesquita, N and Trov{\~{a}}o, J and {Fern{\'{a}}ndez Rodr{\'{i}}guez}, S and Pinheiro, A C and Gomes, V and Alcoforado, A and Gil, F and Portugal, A},
doi = {10.1016/j.culher.2018.05.001},
journal = {Journal of Cultural Heritage},
pages = {268--276},
title = {{Fungal contamination of paintings and wooden sculptures inside the storage room of a museum: Are current norms and reference values adequate?}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047094066{\&}doi=10.1016{\%}2Fj.culher.2018.05.001{\&}partnerID=40{\&}md5=13819ba6439ea8df63d2ee8f2257af39},
volume = {34},
year = {2018}
}
@article{DeIpia2002206,
abstract = {Sentient Computing provides computers with perception so that they can react and provide assistance to user activities. Physical spaces are made sentient when they are wired with networks of sensors capturing context data, which is communicated to computing devices spread through the environment. These devices interpret the information provided and react by performing the actions expected by the user. Among the types of context information provided by sensors, location has proven to be especially useful. Since location is an important context that changes whenever the user moves, a reliable location-tracking system is critical to many sentient applications. However, the sensor technologies used in indoor location tracking are expensive and complex to deploy, configure and maintain. These factors have prevented a wider adoption of Sentient Computing in our living and working spaces. This paper presents TRIP, a low-cost and easily deployable vision-based sensor technology addressing these issues. TRIP employs off-the-shelf hardware (lowcost CCD cameras and PCs) and printable 2-D circular markers for entity identification and location. The usability of TRIP is illustrated through the implementation of several sentient applications. {\textcopyright} 2002 Springer-Verlag London Ltd.},
annote = {cited By 140},
author = {{De Ipi{\~{n}}a}, D L and Mendon{\c{c}}a, P R S and Hopper, A},
doi = {10.1007/s007790200020},
journal = {Personal and Ubiquitous Computing},
keywords = {Common object request broker architecture (CORBA);,Context-aware computing; Entity identification; I,Sensors},
number = {3},
pages = {206--219},
title = {{TRIP: A low-cost vision-based location system for ubiquitous computing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0344842369{\&}doi=10.1007{\%}2Fs007790200020{\&}partnerID=40{\&}md5=8933a76be9ea859070d2c8273df312d0},
volume = {6},
year = {2002}
}
@inproceedings{DeMeloNeto2016551,
abstract = {In general people often spend 80-90{\%} of their time in indoor environments, which include shopping malls, libraries, airports, universities, schools, offices, factories, hospitals, among others. In these environments, GPS does not work properly, causing inaccurate positioning. Currently, when performing the location of people or objects in indoor environments, no single technology can reproduce the same results achieved by the GPS for outdoor environments. One of the main reasons for this is the high complexity of indoor environments where, unlike outdoor spaces, there is a series of obstacles such as walls, equipment and even people. Due to this, it is necessary to consider the use of information from multiple sources using different technologies. Thus, this work proposes an adaptable approach for indoor location, which allows the use and combination of different technologies, techniques and methods in this context.},
annote = {cited By 0},
author = {{De Melo Neto}, M A V and {De Aquino J{\'{u}}nior}, G S},
booktitle = {Proceedings of the International Conference on Software Engineering and Knowledge Engineering, SEKE},
doi = {10.18293/SEKE2016-130},
keywords = {High complexity; Indoor environment; Indoor locat,Information use; Knowledge engineering; Location,Software engineering},
pages = {551--554},
title = {{An adaptable approach for indoor location}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988429379{\&}doi=10.18293{\%}2FSEKE2016-130{\&}partnerID=40{\&}md5=e78f6ddd9c79592fc43531f18288a58c},
volume = {2016-Janua},
year = {2016}
}
@article{DePaz2014111,
abstract = {Indoor locating systems (RTLS), have notably advanced during recent years, becoming one of the main challenges for several research teams. The main objective of indoor locating systems is to obtain functional systems able to locate different elements in those environment where GPS (Global Positioning System) is limited. The growing use of mobile devices in the information society provides a powerful mechanism to obtain geographical data and has led to new algorithms aimed at facilitating object positioning with easonable power consumption. In this paper we propose an innovative indoor location architecture that makes use of the data provided by mobile devices to locate objects. The architecture is applied to a case study in a real environment focused on obtaining the location of security staff in the subway network in a city in the north of Spain. {\textcopyright} Springer International Publishing Switzerland 2014.},
annote = {cited By 0},
author = {{De Paz}, J F and Villarrubia, G and Bajo, J and Sirvent, G and Li, T},
doi = {10.1007/978-3-319-07476-4_14},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Functional systems; Geographical data; Gps (globa,Global positioning system; Indoor positioning syst,Multi agent systems},
pages = {111--119},
title = {{Indoor location system for security guards in subway stations}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927743319{\&}doi=10.1007{\%}2F978-3-319-07476-4{\_}14{\&}partnerID=40{\&}md5=abad0c02763837f5b09d5b8705ae9233},
volume = {293},
year = {2014}
}
@inproceedings{delBimbo:2017:MCV:3078971.3079005,
address = {New York, NY, USA},
author = {del Bimbo, Alberto},
booktitle = {Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval},
doi = {10.1145/3078971.3079005},
isbn = {978-1-4503-4701-3},
keywords = {artwork recognition,deep learning,museum and city visits,smart guide},
pages = {2},
publisher = {ACM},
series = {ICMR '17},
title = {{Making a Cultural Visit with a Smart Mate}},
url = {http://doi.acm.org/10.1145/3078971.3079005},
year = {2017}
}
@inproceedings{DelPero20122719,
abstract = {We propose a method for understanding the 3D geometry of indoor environments (e.g. bedrooms, kitchens) while simultaneously identifying objects in the scene (e.g. beds, couches, doors). We focus on how modeling the geometry and location of specific objects is helpful for indoor scene understanding. For example, beds are shorter than they are wide, and are more likely to be in the center of the room than cabinets, which are tall and narrow. We use a generative statistical model that integrates a camera model, an enclosing room box, frames (windows, doors, pictures), and objects (beds, tables, couches, cabinets), each with their own prior on size, relative dimensions, and locations. We fit the parameters of this complex, multi-dimensional statistical model using an MCMC sampling approach that combines discrete changes (e.g, adding a bed), and continuous parameter changes (e.g., making the bed larger). We find that introducing object category leads to state-of-the-art performance on room layout estimation, while also enabling recognition based only on geometry. {\textcopyright} 2012 IEEE.},
annote = {cited By 60},
author = {{Del Pero}, L and Bowdish, J and Fried, D and Kermgard, B and Hartley, E and Barnard, K},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2012.6247994},
keywords = {3D geometry; Camera model; Continuous parameters;,Computer vision; Sampling,Geometry},
pages = {2719--2726},
title = {{Bayesian geometric modeling of indoor scenes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866636410{\&}doi=10.1109{\%}2FCVPR.2012.6247994{\&}partnerID=40{\&}md5=ff40b5d36e8c2973e4898a8f57ff21cd},
year = {2012}
}
@inproceedings{Delage20062418,
abstract = {When we look at a picture, our prior knowledge about the world allows us to resolve some of the ambiguities that are inherent to monocular vision, and thereby infer 3d information about the scene. We also recognize different objects, decide on their orientations, and identify how they are connected to their environment. Focusing on the problem of autonomous 3d reconstruction of indoor scenes, in this paper we present a dynamic Bayesian network model capable of resolving some of these ambiguities and recovering 3d information for many images. Our model assumes a "floor-wall." geometry on the scene and is trained to recognize the floor-wall boundary in each column of the image. When the image is produced under perspective geometry, we show that this model can be used for 3d reconstruction from a single image. To our knowledge, this was the first monocular approach to automatically recover 3d reconstructions from single indoor images. {\textcopyright} 2006 IEEE.},
annote = {cited By 128},
author = {Delage, E and Lee, H and Ng, A Y},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2006.23},
keywords = {Bayesian networks; Indoor images; Monocular vision,Computer vision; Geometry; Image reconstruction;,Three dimensional computer graphics},
pages = {2418--2428},
title = {{A dynamic Bayesian network model for autonomous 3d reconstruction from a single indoor image}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845573635{\&}doi=10.1109{\%}2FCVPR.2006.23{\&}partnerID=40{\&}md5=7a315380d845cd1e87a3243a6181a4e4},
volume = {2},
year = {2006}
}
@inproceedings{Dellaert1999588,
abstract = {To navigate reliably in indoor environments, a mobile robot must know where it is. This includes both the ability of globally localizing the robot from scratch, as well as tracking the robot's position once its location is known. Vision has long been advertised as providing a solution to these problems, but we still lack efficient solutions in unmodified environments. Many existing approaches require modification of the environment to function properly, and those that work within unmodified environments seldomly address the problem of global localization. In this paper we present a novel, vision-based localization method based on the CONDENSATION algorithm, a Bayesian filtering method that uses a sampling-based density representation. We show how the CONDENSATION algorithm can be used in a novel way to track the position of the camera platform rather than tracking an object in the scene. In addition, it can also be used to globally localize the camera platform, given a visual map of the environment. Based on these two observations, we present a vision-based robot localization method that provides a solution to a difficult and open problem in the mobile robotics community. As evidence for the viability of our approach, we show both global localization and tracking results in the context of a state of the art robotics application.},
annote = {cited By 162},
author = {Dellaert, Frank and Burgard, Wolfram and Fox, Dieter and Thrun, Sebastian},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {Algorithms; Mobile robots; Monte Carlo methods; Ro,Computer vision,Localization methods},
pages = {588--594},
title = {{Using the CONDENSATION algorithm for robust, vision-based mobile robot localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032657835{\&}partnerID=40{\&}md5=f0a2cd209fc9a06e49983c39e090b243},
volume = {2},
year = {1999}
}
@inproceedings{Delzanno2018277,
abstract = {Physical Web enables smartphone users to interact with physical objects and locations through the use of beacon technology. Beacons are small devices placed on physical objects or at specific places that can be detected by users' smartphones when within a range of up to some tens of meters. In this way, users can receive notifications on their handset or associate their presence with a specific place, enabling indoor localization. In this paper, we present the design and the prototype development of a platform for Smart Campus management based on the Physical Web metaphor. This beacon-enabled platform provides services for the registration and analysis of student attendance and for the scheduling of lectures, classrooms allocation, and event notifications (e.g., notify students when teachers are in their office). The software prototype has been implemented using state-of-the-practice technologies such as Node.js, Android, and MySQL and has been preliminary tested in real setting in the context of the Computer Science Bachelor degree at the University of Genova obtaining encouraging results. Copyright {\textcopyright} 2018 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved},
annote = {cited By 0},
author = {Delzanno, G and Guerrini, G and Leotta, M and Ribaudo, M},
booktitle = {WEBIST 2018 - Proceedings of the 14th International Conference on Web Information Systems and Technologies},
keywords = {Database security; Event notification; Indoor loc,Information systems; Information use; Internet of,Software prototyping},
pages = {277--284},
title = {{Physical web for smart campus management}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059023652{\&}partnerID=40{\&}md5=2819e6784a1284fff9091e45539c2727},
year = {2018}
}
@inproceedings{DeMarziani2005,
abstract = {Systems that characterize the state of an entity or object are very important in the "smart spaces" and "ubiquitous computing"; this information is usually known as the entity's "context". Those applications, which describe or characterize these entities and interact with it, are often referred as "context-aware computing". One of the most important information is the position of an object with the purpose of offering the most suitable services to him. The mechanisms and techniques that determine these space relations are named "location"; and the computing applications, based on the position, are called "location-aware computing". This article presents an indoor localization system in order to make a relative positioning among entities, fixed or mobile, without use an external infrastructure and only using acoustic transducers for their use in ubiquitous computing applications. Also, an analysis of the positioning algorithm, based on multidimensional scaling technique (MDS), is carried out in order to verify the errors in the position estimation when there are errors in the mechanism of ranging distances.},
annote = {cited By 0},
author = {DeMarziani, C and Ure{\~{n}}a, J and Hern{\'{a}}ndez, {\'{A}} and Mazo, M and Jim{\'{e}}nez, A and Alvarez, F and Villadangos, J M},
booktitle = {CEUR Workshop Proceedings},
keywords = {Computing applications; Context-aware computing; I,Errors,Ubiquitous computing},
title = {{Relative positioning system using acoustic sensors for ubiquitous computing applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883620459{\&}partnerID=40{\&}md5=ea78ac9e2851d090a02a3a8f1a0b3ad4},
volume = {132},
year = {2005}
}
@inproceedings{Deng:2005:CMP:1078030.1079052,
address = {Washington, DC, USA},
author = {Deng, Da and Zhang, Jianhua},
booktitle = {Proceedings of the Third International Conference on Information Technology and Applications (ICITA'05) Volume 2 - Volume 02},
doi = {10.1109/ICITA.2005.99},
isbn = {0-7695-2316-1},
pages = {720--725},
publisher = {IEEE Computer Society},
series = {ICITA '05},
title = {{Combining Multiple Precision-Boosted Classifiers for Indoor-Outdoor Scene Classification}},
url = {http://dx.doi.org/10.1109/ICITA.2005.99},
year = {2005}
}
@inproceedings{Deng2017398,
abstract = {This paper addresses the problem of amodal perception of 3D object detection. The task is to not only find object localizations in the 3D world, but also estimate their physical sizes and poses, even if only parts of them are visible in the RGB-D image. Recent approaches have attempted to harness point cloud from depth channel to exploit 3D features directly in the 3D space and demonstrated the superiority over traditional 2.5D representation approaches. We revisit the amodal 3D detection problem by sticking to the 2.5D representation framework, and directly relate 2.5D visual appearance to 3D objects. We propose a novel 3D object detection system that simultaneously predicts objects' 3D locations, physical sizes, and orientations in indoor scenes. Experiments on the NYUV2 dataset show our algorithm significantly outperforms the state-of-the-art and indicates 2.5D representation is capable of encoding features for 3D amodal object detection. All source code and data is on https://github.com/phoenixnn/ Amodal3Det. {\textcopyright} 2017 IEEE.},
annote = {cited By 13},
author = {Deng, Z and Latecki, L J},
booktitle = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
doi = {10.1109/CVPR.2017.50},
keywords = {3-D object detections; 3d locations; Bounding box,Computer vision; Object recognition; Pattern recog,Object detection},
pages = {398--406},
title = {{Amodal detection of 3D objects: Inferring 3D bounding boxes from 2D ones in RGB-depth images}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044260122{\&}doi=10.1109{\%}2FCVPR.2017.50{\&}partnerID=40{\&}md5=6e441fe889d171cd9f7581b6837eadd5},
volume = {2017-Janua},
year = {2017}
}
@article{DiFlora2004383,
abstract = {The Java Community Process (JCP) has recently finalized a Java Specification Request (JSR) to cope with location-awareness (JSR-179) in Connected Limited Device Configuration (CLDC). Implementations of this specification may rely on several location methods, including satellite based methods like GPS, as well as short-range positioning methods based on Received Signal Strength (RSS). Though RSS is a good location fingerprint for indoor positioning, no standard technique to tailor RSS-based approaches to the JSR-179 API has been proposed yet. In this paper we propose such a technique, and we evaluate its effectiveness through a Bluetooth-based prototype. Specifically, we show how to extend the Java APIs for Bluetooth (JSR-82) in order to provide the Location API with RSS-based position-information. Moreover, we show how to adapt RSS-based approaches to Location-API's semantics. Our solution is based on the insertion of a specific component into the JSR-82 API. This is in charge of producing all the information needed to build Location objects as defined in the JSR-179. We evaluate the effectiveness of the approach by examining preliminary experimental results obtained from the first system prototype. {\textcopyright} Springer-Verlag 2004.},
annote = {cited By 5},
author = {{Di Flora}, C and Ficco, M and Russo, S},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {383--393},
title = {{Indoor positioning for location-aware applications on Java-based mobile devices}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-35048890653{\&}partnerID=40{\&}md5=f16d0866ac8f9e161128eaa00b9a43ae},
volume = {3292},
year = {2004}
}
@inproceedings{DiLascio:2016:LBP:2959355.2959415,
address = {Piscataway, NJ, USA},
author = {{Di Lascio}, Elena and Varshney, Ambuj and Voigt, Thiemo and P{\'{e}}rez-Penichet, Carlos},
booktitle = {Proceedings of the 15th International Conference on Information Processing in Sensor Networks},
isbn = {978-1-5090-0802-5},
pages = {60:1----60:2},
publisher = {IEEE Press},
series = {IPSN '16},
title = {{LocaLight: A Battery-free Passive Localization System Using Visible Light: Poster Abstract}},
url = {http://dl.acm.org/citation.cfm?id=2959355.2959415},
year = {2016}
}
@article{Diakit2018213,
abstract = {As we realize that we spend most of our time in increasingly complex indoor environments, applications to assist indoor activities (e.g. guidance) have gained a lot of attention in the recent years. The advances in ubiquitous computing made possible the development of several spatial models intending to support context- aware and fine-grained indoor navigation systems. However, the available models often rely on simplified representations (e.g. 2D plans) and ignore the indoor features (e.g. furniture), thereby missing to reflect the complexity of the indoor environment. In this paper, we introduce the Flexible Space Subdivision framework (FSS) that allows to automatically identify the spaces that can be used for indoor navigation purpose. We propose a classification of indoor objects based on their ability to autonomously change location and we define a spatial subdivision of the indoor environment based on the classified objects and their functions. The framework can consider any 3D indoor configuration, the static and dynamic activities it hosts and it enables the possibility to consider all types of locomotion (e.g. walking, flying, etc.). It relies on input 3D models with geometric, semantic and topological information and identifies a set of subspaces with dedicated properties. We assess the framework against criteria defined in previous researches and we provide an example. {\textcopyright} 2017 The Author(s).},
annote = {cited By 10},
author = {Diakit{\'{e}}, A A and Zlatanova, S},
doi = {10.1080/13658816.2017.1376066},
journal = {International Journal of Geographical Information Science},
number = {2},
pages = {213--235},
title = {{Spatial subdivision of complex indoor environments for 3D indoor navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029468423{\&}doi=10.1080{\%}2F13658816.2017.1376066{\&}partnerID=40{\&}md5=f3791f6cf34f0adca15b5f60279c11d1},
volume = {32},
year = {2018}
}
@inproceedings{Diana2012,
abstract = {This paper presents the design and results of a localization prototype indoor based on ZigBee technology, which is capable of finding two-dimensional position of a moving object, using empirical propagation models as well as an algorithm spherical trilateration, it was possible to calculate coordinates of the system in order to develop a graphical interface in Matlab to allow log, track and monitoring the position of mobile node. (Full paper is written in Spanish). {\textcopyright} 2012 IEEE.},
annote = {cited By 1},
author = {Diana, C O C and Mayra, A J V and {Jose David}, C C},
booktitle = {2012 IEEE 4th Colombian Workshop on Circuits and Systems, CWCAS 2012 - Conference Proceedings},
doi = {10.1109/CWCAS.2012.6404066},
keywords = {Algorithms; Surveying,Graphical interface; Indoor localization; Indoor p,Zigbee},
title = {{Indoor localization prototype using ZigBee}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873159131{\&}doi=10.1109{\%}2FCWCAS.2012.6404066{\&}partnerID=40{\&}md5=2c0b6ff70d76b5c96f4dbe4efc72e861},
year = {2012}
}
@article{Dibos:2009:AWD:1658360.1658365,
address = {Philadelphia, PA, USA},
author = {Dibos, Fran{\c{c}}oise and Koepfler, Georges and Pelletier, Sylvain},
doi = {10.1137/070710500},
issn = {1936-4954},
journal = {SIAM J. Img. Sci.},
keywords = {a contrario method,cluster,false alarm,real-time detection,video segmentation},
number = {1},
pages = {1--19},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Adapted Windows Detection of Moving Objects in Video Scenes}},
url = {http://dx.doi.org/10.1137/070710500},
volume = {2},
year = {2009}
}
@inproceedings{1276849,
abstract = {Context awareness will become increasingly important in future domestic consumer electronics. In many domestic context aware applications, there is a need for location and orientation information about persons, devices or objects in the home. This information can be provided by a dedicated indoor location system. A consumer location system should be robust, safe, easy to set up, low cost, and should have a minimal infrastructure. In this paper, a step towards consumer location systems is taken by proposing an ultrasonic positioning method that needs just a single compact base station to measure 3D positions of mobile devices in a room. The method employs ultrasound time-of-flight tri-lateration to estimate device positions, using a base station containing an array of three ultrasound transducers. Five potential problems of the proposed method are identified; the main problem being line-of-sight path occlusion. The method has been prototyped, and initial results show an accuracy of 1.41 m or better for 95{\%} of the position estimates, in case of a good line-of-sight path. It is concluded that the method is promising for providing 3D position information at around 1 m accuracy for context aware applications, but that the problem of line-of-sight occlusion requires further investigation.},
author = {Dijk, E O and van Berkel, C H and Aarts, R M and van Loenen, E J},
booktitle = {Second IEEE Annual Conference on Pervasive Computing and Communications, 2004. Proceedings of the},
doi = {10.1109/PERCOM.2004.1276849},
keywords = {mobile computing;indoor radio;ultrasonic transduce},
pages = {101--110},
title = {{3-D indoor positioning method using a single compact base station}},
year = {2004}
}
@article{Dijk2003133,
abstract = {In indoor context awareness applications the location of people, devices or objects is often required. Ultrasound technology enables high resolution indoor position measurements. A disadvantage of state-of-the-art ultrasonic systems is that several base stations are required to estimate 3D position. Since fewer base stations leads to lower cost and easier setup, a novel method is presented that requires just one base station. The method uses information from acoustic reflections in a room, and estimates 3D positions using an acoustic room-model. The method has been implemented, and verified within an empty room. It can be concluded that ultrasonic reflection data provides useful clues about the 3D position of a device. {\textcopyright} Springer-Verlag Berlin Heidelberg 2003.},
annote = {cited By 6},
author = {Dijk, E and {Van Berkel}, K and Aarts, R and {Van Loenen}, E},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {133--148},
title = {{Ultrasonic 3D position estimation using a single base station}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0242424266{\&}partnerID=40{\&}md5=b228780a75fb6f70984341e448f65ed8},
volume = {2875},
year = {2003}
}
@article{Din2018133,
abstract = {A system that allows users to find and track a specific position is known as positioning system. Global Positioning System (GPS) is one of top known position tracking system that commonly used to find position and location of object outdoor. Tracking an object indoor using GPS is not highly recommended because the signals transmitted through a satellite to a device indoor gets blocked and resulted in weak signals. Thus, an indoor positioning system (IPS) that tracks and positions object indoor has been implemented to overcome the issues of signals multipath that resulted from GPS. The aim of this paper is to provide up to date indoor positioning technologies and compares the technologies according to its technical perspectives. {\textcopyright} 2018 Marina Md Din et. al.},
annote = {cited By 1},
author = {Din, M M and Jamil, N and Maniam, J and Mohamed, M A},
journal = {International Journal of Engineering and Technology(UAE)},
number = {2.14 Special Issue 14},
pages = {133--137},
title = {{Indoor positioning: Technology comparison analysis}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051007514{\&}partnerID=40{\&}md5=03773818d43bc6817e198485069dd73b},
volume = {7},
year = {2018}
}
@inproceedings{Do20181410,
abstract = {We present an Integrated Ambient Intelligence System to perceive the presence of people, identify them, determine their locations, and provide suitable interaction with them. The proposed framework can be applied in various application domains such as a smart house, robotics, authorization, surveillance, crime prevention and many others. The proposed system has five components: body tracking, face recognition, controller, monitoring device, and interaction modules. The system deploys RGB cameras and Kinect depth sensors to obtain human information for execution. The proposed recognition-Tracking system works at around 10Hz. The developed system is designed to be a fast and reliable system for indoor environments. {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Do, D and King, S A and Sheta, A and Hu, J},
booktitle = {Proceedings - 15th IEEE International Symposium on Parallel and Distributed Processing with Applications and 16th IEEE International Conference on Ubiquitous Computing and Communications, ISPA/IUCC 2017},
doi = {10.1109/ISPA/IUCC.2017.00214},
keywords = {Ambient intelligence systems; Awareness systems;,Ambient intelligence; Intelligent systems; Trackin,Face recognition},
pages = {1410--1416},
title = {{Implementation of an integrated ambient intelligence system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048360676{\&}doi=10.1109{\%}2FISPA{\%}2FIUCC.2017.00214{\&}partnerID=40{\&}md5=7c96e4875630d4564eb55e797ffda194},
year = {2018}
}
@inproceedings{Dobrc2011317,
abstract = {Recently, a lot of localization systems have been studied. These systems are successfully used in many real-world applications as inventory management, asset tracking, location detection of products stored in a warehouse, location detection of medical personnel, patients or equipment in a hospital, and so on. For finding location of an object, a system using Tag4M devices is proposed in this paper. The localization is based on distance measurement using received signal strength indicator. The distances between the Wi-Fi tag and each access point are represented as circles having the centre in the access point locations which have known coordinates. The target's position is given by the point at the intersection of the circles. {\textcopyright} 2011 IEEE.},
annote = {cited By 4},
author = {Dob{\^{i}}rc, A and Folea, S and Vlean, H and Bordencea, D},
booktitle = {2011 19th Telecommunications Forum, TELFOR 2011 - Proceedings of Papers},
doi = {10.1109/TELFOR.2011.6143553},
keywords = {Access points; Asset tracking; Indoor localization,Human resource management; Inventory control; Wi-,Tracking (position)},
pages = {317--320},
title = {{Indoor localization system based on low power Wi-Fi technology}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857498956{\&}doi=10.1109{\%}2FTELFOR.2011.6143553{\&}partnerID=40{\&}md5=06ca30d71f296a44e15eb3ac7e5d6a2e},
year = {2011}
}
@inproceedings{NoAuthor2012,
abstract = {The proceedings contain 226 papers. The topics discussed include: a comparative study on the stability of software metric selection techniques; optimal tile size selection problem using machine learning; a Treeboost model for software effort estimation based on use case points; a hybrid approach to coping with high dimensionality and class imbalance for software defect prediction; the state of machine learning methodology in software fault prediction; error-driven adaptive, virtual machine model-based control with high availability platform; prognosis based on handling drifts in dynamical environments - application to a wind turbine benchmark; location type classification using Tweet content; a hybrid transfer learning mechanism for object classification across view; topological indoor localization {\&} navigation for autonomous industrial mobile manipulator; fast time series classification based on infrequent shapelets; and minimal norm support vector machines for large classification tasks.},
annote = {cited By 0},
author = {Doi, Ieee},
booktitle = {Proceedings - 2012 11th International Conference on Machine Learning and Applications, ICMLA 2012},
doi = {10.1109/ICMLA.2012.76},
isbn = {9780769549132},
pages = {421--426},
title = {{2012 11th International Conference on Machine Learning and Applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873597906{\&}partnerID=40{\&}md5=bf732d1fba2bca1354409781494b8871},
volume = {2},
year = {2012}
}
@inproceedings{Dollner:2005:CLM:1097064.1097089,
address = {New York, NY, USA},
author = {D{\"{o}}llner, J{\"{u}}rgen and Buchholz, Henrik},
booktitle = {Proceedings of the 13th Annual ACM International Workshop on Geographic Information Systems},
doi = {10.1145/1097064.1097089},
isbn = {1-59593-146-5},
keywords = {3D GIS,buildings,city models,level-of-detail,virtual reality},
pages = {173--181},
publisher = {ACM},
series = {GIS '05},
title = {{Continuous Level-of-detail Modeling of Buildings in 3D City Models}},
url = {http://doi.acm.org/10.1145/1097064.1097089},
year = {2005}
}
@article{Doush2017181,
abstract = {Generally, indoor navigation is considered as a challenging task, especially when people navigate through an unfamiliar place (e.g. a university or a mall). It is even a more challenging endeavor for the visually impaired and blind community. This paper presents an innovative approach to the precise indoor navigation challenge for the blind individuals using a multi-tier solution with the help of an intuitive smartphone interface. We utilize a set of different communication technologies (WiFi, Bluetooth and radio-frequency identification) to help users reach an object with high accuracy. As a proof of concept, we deploy a fully functional testbed and we evaluate our entire solution inside our university library by helping blind users find a specific book. Our results demonstrate the high accuracy of the proposed system to reach an object with accuracy up to 10 cm. The intuitive smartphone interface provides step-by-step navigation voice instructions of the least hazardous path for the blind users while minimizing the cognitive load on their short-term memory. In addition, we show that our iterative improvements on our smartphone's interface has improved the system's efficiency and its accuracy in reaching specific objects successfully. {\textcopyright} The Author 2016. Published by Oxford University Press on behalf of The British Computer Society. All rights reserved.},
annote = {cited By 4},
author = {Doush, I A and Alshatnawi, S and Al-Tamimi, A.-K. and Alhasan, B and Hamasha, S},
doi = {10.1093/iwc/iww016},
journal = {Interacting with Computers},
keywords = {Air navigation; Mobile phones; Navigation systems;,Blind users; Communication technologies; In-door,Indoor positioning systems},
number = {2},
pages = {181--202},
title = {{ISAB: Integrated indoor navigation system for the blind}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016323318{\&}doi=10.1093{\%}2Fiwc{\%}2Fiww016{\&}partnerID=40{\&}md5=fa4d5ecfae75d40652991136f655683c},
volume = {29},
year = {2017}
}
@inproceedings{Dubrawski19982518,
abstract = {One of the essential problems in navigation of a mobile robot is to accurately determine its location using data obtained by range sensors. In this paper we present a novel approach to track changes of orientation and position of a robot equipped with a scanning laser range finder and designed to work in partially structured environments. It is shown experimentally on a real robot that the proposed approach is more robust against sensory noise than the method of angle histograms, which is often used to track orientation and position of indoor vehicles equipped with scanning range sensors. {\textcopyright}1998 IEEE.},
annote = {cited By 22},
author = {Dubrawski, A and Siemiatkowska, B},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.1998.680720},
keywords = {Gesture recognition; Graphic methods; Machine desi,Histograms; Laser noise; Laser transition; Noise,Mobile robots; Mobile robots,Scanning laser range finders},
pages = {2518--2523},
title = {{A method for tracking the pose of a mobile robot equipped with a scanning laser range finder}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031638803{\&}doi=10.1109{\%}2FROBOT.1998.680720{\&}partnerID=40{\&}md5=acb57e6a75c1570205f8f2049b679a62},
volume = {3},
year = {1998}
}
@article{Duckett2001117,
abstract = {The topic of mobile robot self-localization is often divided into the sub-problems of global localization and position tracking. Both are now well understood individually, but few mobile robots can deal simultaneously with the two problems in large, complex environments. In this paper, we present a unified approach to global localization and position tracking which is based on a topological map augmented with metric information. This method combines a new scan matching technique, using histograms extracted from local occupancy grids, with an efficient algorithm for tracking multiple location hypotheses over time. The method was validated with experiments in a series of real world environments, including its integration into a complete navigating robot. The results show that the robot can localize itself reliably in large, indoor environments using minimal computational resources.},
annote = {cited By 19},
author = {Duckett, T and Nehmzow, U},
doi = {10.1016/S0921-8890(00)00116-0},
journal = {Robotics and Autonomous Systems},
keywords = {Gaussian location hypotheses; Mobile robot self-l,Kalman filtering; Object recognition; State estima,Mobile robots},
number = {2-3},
pages = {117--129},
title = {{Mobile robot self-localization using occupancy histograms and a mixture of Gaussian location hypotheses}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034831830{\&}doi=10.1016{\%}2FS0921-8890{\%}2800{\%}2900116-0{\&}partnerID=40{\&}md5=fc0c696d8be7862480d13cefcc7e6e9b},
volume = {34},
year = {2001}
}
@article{NoAuthor2003,
abstract = {The proceedings contains 45 papers from the conference on Computer Graphics Forum. Topics discussed include: intrinsic parameterizations of surface meshes; geometric snakes for triangular meshes; stylizing silhouettes at interactive rates; transparency in interactive technical illustrations; space-optimized texture maps; image-swept volumes and hardware accelerated interactive vector field visualization.},
annote = {cited By 1},
author = {Duke, David and Scopigno, Roberto},
doi = {10.1111/j.1467-8659.2003.00715.x},
journal = {Computer Graphics Forum},
keywords = {Animation; Bubbles (in fluids); Computational geom,EiRev; Feature lines; Flowing motion; Indoor samp,Three dimensional computer graphics},
number = {4},
pages = {662--662},
title = {{ Computer Graphics forum }},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045290899{\&}partnerID=40{\&}md5=24dd7780ee37c5a19fb34b80de03add1},
volume = {22},
year = {2004}
}
@inproceedings{Edirisinghe20141078,
abstract = {The Australian construction industry is identified as one among five industries to receive priority attention under the Australian Work Health and Safety Strategy 2012-2022. Among the recorded construction fatalities in 2012, vehicle incidents accounted for 15{\%} and being hit by moving objects accounted for 10{\%}. Tracking of individuals on-site could provide a technological solution to improve safety. This paper proposes a novel, non-tagging-based, wireless networking solution (called device-free localization) to enhance safety on site. Device free localization techniques use radio signal propagation effects such as multi-path fading and shadowing caused by the obstruction(s). The proposed solution defines zones in the construction site. Zone identification is based on the risk associated with the location map of the site. Defining risk profiles considers the activities associated with the geographic location, such as loading/unloading areas, truck, and vehicle entering area. The presence of workers entering a particular zone is detected based on this device-free detection technique, which will later be extended to localization. This paper proposes a framework for defining risk-associated zones for the construction sites for the effective implementation of device-free detection systems. Feasibility of the proposed device-free detection technique is verified by preliminary experiments done in an indoor environment with high multi-path fading. {\textcopyright} ASCE 2014.},
annote = {cited By 2},
author = {Edirisinghe, R and Lingard, H and Blismas, N and Dias, D and Wakefield, R},
booktitle = {Computing in Civil and Building Engineering - Proceedings of the 2014 International Conference on Computing in Civil and Building Engineering},
doi = {10.1061/9780784413616.134},
pages = {1078--1085},
title = {{Device-free detection to improve construction work health and safety}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934312378{\&}doi=10.1061{\%}2F9780784413616.134{\&}partnerID=40{\&}md5=226d949bd0dc9b0aea6f9cf2510f4df5},
year = {2014}
}
@article{Ekvall:2007:ODM:1394742.1394747,
address = {New York, NY, USA},
author = {Ekvall, Staffan and Kragic, Danica and Jensfelt, Patric},
doi = {10.1017/S0263574706003237},
issn = {0263-5747},
journal = {Robotica},
keywords = {Active object recognition,Receptive field color co-occurence histograms,SLAM},
number = {2},
pages = {175--187},
publisher = {Cambridge University Press},
title = {{Object Detection and Mapping for Service Robot Tasks}},
url = {http://dx.doi.org/10.1017/S0263574706003237},
volume = {25},
year = {2007}
}
@article{El-Absi201854355,
abstract = {Highly accurate indoor localization based on significantly low complex infrastructure has recently gained great interest for a variety of innovative location-based applications. In this regards, the chipless radio frequency identification (RFID) system is presented to be the low-cost solution, while time-based ranging using the ultrawide-band spectrum is promising to offer precise ranging capability. However, the current wide-band systems suffer from the spectrum and power limitations, which restrict the function of chipless RFID-based localization systems. Therefore, we propose terahertz (THz)-based chipless RFID localization system that enables a smart object localizing itself using the infrastructure composed from reference chipless tags. In more details, THz band offers huge bandwidth providing superior-resolution localization and large coding capacity. Moreover, we utilize the combination between dielectric resonator (DR) and lens to be designed as a frequency-coded chipless tag, where this combination increases the radar cross section of the chipless tags and, hence, extends their coverage zone. This cost-efficient design of the tag enables the dense deployment of low-cost infrastructure acting as reference anchors. Furthermore, we investigate the link budget of the proposed system in order to characterize the tag and distance-dependent spectral windows that are feasible for RFID-based localization. Afterward, the time-domain backscattered signal from a DR-Lens tag is analyzed in order to perform ranging and to calculate the relative distances between the DR-Lens tags and the reader leading to determining the reader position. Measurements are performed to prove the concept of the DR-Lens tag, while the numerical simulation is conducted to evaluate the proposed localization system. Simulation results show that the proposed system can reach superior accuracy of millimeter-levels. {\textcopyright} 2013 IEEE.},
annote = {cited By 1},
author = {El-Absi, M and {Alhaj Abbas}, A and Abuelhaija, A and Zheng, F and Solbach, K and Kaiser, T},
doi = {10.1109/ACCESS.2018.2871960},
journal = {IEEE Access},
keywords = {Backscattering; Bandwidth; Broadband networks; Bud,Chipless radio frequency identifications (RFID);,Indoor positioning systems},
pages = {54355--54368},
title = {{High-Accuracy Indoor Localization Based on Chipless RFID Systems at THz Band}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054697135{\&}doi=10.1109{\%}2FACCESS.2018.2871960{\&}partnerID=40{\&}md5=2e96113464269434066e95e55ae8bd4e},
volume = {6},
year = {2018}
}
@phdthesis{Elnahrawy:2006:ILU:1292893,
address = {New Brunswick, NJ, USA},
annote = {AAI3249292},
author = {Elnahrawy, Eiman},
publisher = {Rutgers University},
title = {{Indoor Localization Using Signal Strength}},
year = {2006}
}
@inproceedings{Engstrm2013,
abstract = {There exist several tools and methods for camera resectioning, i.e. geometric calibration for the purpose of estimating intrinsic and extrinsic parameters. The intrinsic parameters represent the internal properties of the camera such as focal length, principal point and distortion coefficients. The extrinsic parameters relate the cameras position to the world, i.e. how is the camera positioned and oriented in the world. With both sets of parameters known it is possible to relate a pixel in one camera to the world or to another camera. This is important in many applications, for example in stereo vision. The existing methods work well for standard visual cameras in most situations. Intrinsic parameters are usually estimated by imaging a well-defined pattern from different angles and distances. Checkerboard patterns are very often used for calibration since it is a well-defined pattern with easily detectable features. The intersections between the black and white squares form high contrast points which can be estimated with sub pixel accuracy. Knowing the precise dimension and structure of the pattern makes enables calculation of the intrinsic parameters. Extrinsic calibration can be performed in a similar manner if the exact position and orientation of the pattern is known. A common method is to distribute markers in the scene and to measure their exact locations. The key to good calibration is well-defined points and accurate measurements. Thermal cameras are a subset of infrared cameras that work with long wavelengths, usually between 9 and 14 microns. At these wavelengths all objects above absolute zero temperature emit radiation making it ideal for passive imaging in complete darkness and widely used in military applications. The issue that arises when trying to perform a geometric calibration of a thermal camera is that the checkerboard emits more or less the same amount of radiation in the black squares as in the white. In other words, the calibration board that is optimal for calibration of visual cameras might be completely useless for thermal cameras. A calibration board for thermal cameras should ideally be a checkerboard with high contrast in thermal wavelengths. (It is of course possible to use other sorts of objects or patterns but since most tools and software expect a checkerboard pattern this is by far the most straightforward solution.) Depending on the application it should also be more or less portable and work booth in indoor and outdoor scenarios. In this paper we present several years of experience with calibration of thermal cameras in various scenarios. Checkerboards with high contrast both for indoor and outdoor scenarios are presented as well as different markers suitable for extrinsic calibration. {\textcopyright} 2013 SPIE.},
annote = {cited By 4},
author = {Engstr{\"{o}}m, P and Larsson, H and Rydell, J},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.2030952},
keywords = {Absolute zero temperature; Checkerboard patterns;,Calibration,Cameras; Dynamic random access storage; Geometry;},
title = {{Geometric calibration of thermal cameras}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890014425{\&}doi=10.1117{\%}2F12.2030952{\&}partnerID=40{\&}md5=63e89bb0aa591f1e7fa24fa311bb3521},
volume = {8897},
year = {2013}
}
@inproceedings{Eslim2014185,
abstract = {RFID technology as an enabler of the Internet of Things (IoT) is extensively utilized for object localization. Existing RFID-based object localization techniques follow a centralized and coordinated approach. Indeed, none is designed to leverage RFID crowdsourcing for the purpose of object localization. In this paper, we propose a cooperative scheme to localize mobile RFID tags using heterogeneous, distributed and dynamic mobile RFID readers in indoor/outdoor environments. In addition, we introduce the concept of Time-Shifted Multilateration (TSM) to enhance location estimation accuracy of mobile tags when sufficient synchronous detection information is not available. We validate the proposed scheme and the TSM technique through extensive simulations using ns-3. Results show that our approach can achieve accurate location estimation in typical IoT settings. {\textcopyright} 2014 IEEE.},
annote = {cited By 3},
author = {Eslim, L M and Hassanein, H S and Ibrahim, W M and Alma'Aitah, A},
booktitle = {Proceedings - Conference on Local Computer Networks, LCN},
doi = {10.1109/LCN.2014.6925771},
keywords = {Cooperative localization; Crowdsourcing; IoT; loca,Radio frequency identification (RFID)},
pages = {185--192},
title = {{A cooperative localization scheme using RFID crowdsourcing and time-shifted multilateration}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908319924{\&}doi=10.1109{\%}2FLCN.2014.6925771{\&}partnerID=40{\&}md5=bade731cb5e09a2ebf30f870e33c6827},
year = {2014}
}
@article{Falomir:2013:QDQ:2451998.2452287,
address = {New York, NY, USA},
author = {Falomir, Zoe and Museros, Lled{\'{o}} and Castell{\'{o}}, Vicent and Gonzalez-Abril, Luis},
doi = {10.1016/j.patrec.2012.08.012},
issn = {0167-8655},
journal = {Pattern Recogn. Lett.},
keywords = {Fuzzy logic,Qualitative colour,Qualitative shape,Qualitative spatial orientation,Sensor data integration,Topology},
number = {7},
pages = {731--743},
publisher = {Elsevier Science Inc.},
title = {{Qualitative Distances and Qualitative Image Descriptions for Representing Indoor Scenes in Robotics}},
url = {http://dx.doi.org/10.1016/j.patrec.2012.08.012},
volume = {34},
year = {2013}
}
@inproceedings{Fan2016474,
abstract = {To solve the problem of low accuracy in real-time localization in indoor environment, we propose a novel localization algorithm with Multiple Kernel Learning (MKL). In our work, the indoor localization is viewed as multiple classification. First we select some reference nodes in the indoor area, and measure the WiFi signal strength of reference nodes for multiple times to construct the classifiers based on multiple kernel learning. When the object enters into the location area, we measure its WiFi signal strength and input it into classifiers to discriminate its label. According to the classification result, the location of the object can be estimated. Experimental results demonstrate that our algorithm is able to effectively locate the object in indoor environment. {\textcopyright} 2016 IEEE.},
annote = {cited By 2},
author = {Fan, H and Chen, Z},
booktitle = {Proceedings of 2016 8th IEEE International Conference on Communication Software and Networks, ICCSN 2016},
doi = {10.1109/ICCSN.2016.7587204},
keywords = {Classification results; Fingerprint algorithm; In,Indoor positioning systems,Learning algorithms; Wireless local area networks},
pages = {474--477},
title = {{WiFi based indoor localization with multiple kernel learning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994493615{\&}doi=10.1109{\%}2FICCSN.2016.7587204{\&}partnerID=40{\&}md5=0c7c4c632f8ba547177dc527d9db2c4b},
year = {2016}
}
@inproceedings{Fan:2014:HHD:2565585.2565587,
address = {New York, NY, USA},
author = {Fan, Mingming and Liu, Qiong and Tang, Hao and Chiu, Patrick},
booktitle = {Proceedings of the 15th Workshop on Mobile Computing Systems and Applications},
doi = {10.1145/2565585.2565587},
isbn = {978-1-4503-2742-8},
keywords = {AR,coded light,interactive space,mobile computing},
pages = {6:1----6:6},
publisher = {ACM},
series = {HotMobile '14},
title = {{HiFi: Hide and Find Digital Content Associated with Physical Objects via Coded Light}},
url = {http://doi.acm.org/10.1145/2565585.2565587},
year = {2014}
}
@inproceedings{Fang2006,
abstract = {As video databases become increasingly important for full exploitation of multimedia resources, this paper aims at describing our recent efforts in feasibility studies towards building up a content-based and high-level video retrieval/management system. The study is focused on constructing a semantic tree structure via combination of low-level image processing techniques and high-level interpretation of visual content. Specifically, two separate algorithms were developed to organise input videos in terms of two layers: the shot layer and the key-frame layer. While the shot layer is derived by developing a multi-featured shot cut detection, the key frame layer is extracted automatically by a genetic algorithm. This paves the way for applying pattern recognition techniques to analyse those key frames and thus extract high level information to interpret the visual content or objects. Correspondingly, content-based video retrieval can be conducted in three stages. The first stage is to browse the digital video via the semantic tree at structural level, the second stage is match the key frame in terms of low-level features, such as colour, shape of objects, and texture etc. Finally, the third stage is to match the high-level information, such as conversation with indoor background, moving vehicles along a seaside road etc. Extensive experiments are reported in this paper for shot cut detection and key frame extraction, enabling the tree structure to be constructed. {\textcopyright} 2006 SPIE-IS{\&}T.},
annote = {cited By 0},
author = {Fang, H and Yin, Y and Jiang, J},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
keywords = {Content-based video retrieval; Info retrieval tre,Genetic algorithms; Image processing; Information,Information retrieval systems},
title = {{A tree-based paradigm for content-based video retrieval and management}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33645987579{\&}partnerID=40{\&}md5=3215d033d3f504f95aa3d6f420fdb7c9},
volume = {6073},
year = {2006}
}
@inproceedings{Fayssal2014117,
abstract = {Tracking of indoor wireless devices is gaining more attention from both academia and industry. Geography is different in every indoor map mainly after considering attenuation and space (3-D) factors. Most previous related research publications focus on signal attenuation but neglect other factors (e.g., reflections). Triangulation is a very popular method for device tracking but lacks precision. Graphic methods can provide more accurate results but translating their outcomes into machine-readable data can be challenging. In this paper, we survey most possible factors that affect indoor tracking and present a new deterministic formula to reduce ambiguity for reaching decisions. We propose the concept of Point of Interest that helps in scaling large-map analysis and in finding understudied locations; we present a formula that uses history data to build confidence. To test our formula, we built a test-bed and ran hundreds of experiments. Our results show large improvements in calculating distances between objects as well as making decisions on object locations. {\textcopyright} 2014 IEEE.},
annote = {cited By 1},
author = {Fayssal, S},
booktitle = {2014 IEEE International Inter-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support, CogSIMA 2014},
doi = {10.1109/CogSIMA.2014.6816550},
keywords = {Decision support systems,Device tracking; History data; Indoor tracking; M,Graphic methods; Network security; Wireless networ},
pages = {117--123},
title = {{Reducing ambiguity in indoor tracking using point of interest}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902096372{\&}doi=10.1109{\%}2FCogSIMA.2014.6816550{\&}partnerID=40{\&}md5=d45f8beb5a8791b8ddab708205f08704},
year = {2014}
}
@phdthesis{Fehlman:2008:CNG:1571348,
address = {Williamsburg, VA, USA},
annote = {AAI3340946},
author = {{Fehlman II}, William L},
isbn = {978-0-549-96081-2},
publisher = {College of William {\&} Mary},
title = {{Classification of Non-heat Generating Outdoor Objects in Thermal Scenes for Autonomous Robots}},
year = {2008}
}
@inproceedings{Feng20168444,
abstract = {The real-time localization problem of the passive target in the multi-view system was addressed. The 3D localization method was proposed to fuse the 2D image coordinates from the multi-views. It is a fundamental solution to obtain the 3D location of the moving object in the research field of computer vision. Improved Common Perpendicular Centroid (ICPC) algorithm was presented to reduce the error variance and improve localization accuracy. The experimental results showed the algorithm can complete accurate positioning in indoor multi-view monitoring and reduce the complexity. {\textcopyright} 2016 TCCT.},
annote = {cited By 1},
author = {Feng, S and Wu, C and Zhang, Y},
booktitle = {Chinese Control Conference, CCC},
doi = {10.1109/ChiCC.2016.7554704},
pages = {8444--8447},
title = {{Passive target localization in multi-view system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987905082{\&}doi=10.1109{\%}2FChiCC.2016.7554704{\&}partnerID=40{\&}md5=d5b403eec2503c912598fc058786cdfb},
volume = {2016-Augus},
year = {2016}
}
@article{Feng2018,
abstract = {In this research, the authors have addressed the collaboration calibration and real-time three-dimensional (3D) localization problem in the multi-view system. The 3D localization method is proposed to fuse the two-dimensional image coordinates from multi-views and provide the 3D space location in real time. It is a fundamental solution to obtain the 3D location of the moving object in the research field of computer vision. Improved common perpendicular centroid algorithm is presented to reduce the side effect of the shadow detection and improve localization accuracy. The collaboration calibration is used to generate the intrinsic and extrinsic parameters of multi-view cameras synchronously. The experimental results show that the algorithm can complete accurate positioning in indoor multi-view monitoring and reduce the complexity. {\textcopyright} The Author(s) 2018.},
annote = {cited By 0},
author = {Feng, S and Wu, C and Zhang, Y and Shen, S},
doi = {10.1177/1729881418813778},
journal = {International Journal of Advanced Robotic Systems},
keywords = {Calibration,Cameras; Computerized tomography; Wireless sensor,Centroid algorithm; Intrinsic and extrinsic param},
number = {6},
title = {{Collaboration calibration and three-dimensional localization in multi-view system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056737537{\&}doi=10.1177{\%}2F1729881418813778{\&}partnerID=40{\&}md5=138d2ef6cd94cbb0db5fce0bc80cda0e},
volume = {15},
year = {2018}
}
@inproceedings{Feng200699,
abstract = {An algorithm for realizing multilayer occlusion in augmented reality (AR) is presented in this paper. We have designed a special scene graph tree comprised of some special nodes, namely EMO nodes. According to the location of real moving object, different EMO node will be activated in real-time, consequently realizing the multilayer occlusion. Differing qualitatively from previous work in AR occlusion, our algorithm realizes multilayer occlusion, and its application domain involves indoor-field occluded objects, which are several meters distant from the viewer. Previous related work has focused on monolayer occlusion, and near-field occluded objects, which are within or just beyond arm's reach. In addition, BP neural network is improved to correct the nonlinear error of magnetic sensor, consequently to detect occlusion more effectively. Experimental results are provided to demonstrate the multilayer indoor-field occlusion. {\textcopyright} The Eurographics Association 2006.},
annote = {cited By 0},
author = {Feng, Y and Chen, Y and Tang, W},
booktitle = {Theory and Practice of Computer Graphics 2006, TPCG 2006 - Eurographics UK Chapter Proceedings},
keywords = {Algorithms; Augmented reality; Monolayers; Neural,BP neural networks; ITS applications; Moving objec,Multilayers},
pages = {99--104},
title = {{Augmented reality with multilayer occlusion}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878222586{\&}partnerID=40{\&}md5=2e56a785217024a933fb5c39fe3cc932},
year = {2006}
}
@inproceedings{Fernndez20114,
abstract = {This paper proposes a way to improve the position estimates in an indoor location systems (ILS) based on readings from the power levels (RSSI) of an ad hoc ZigBee network. A mobile object, also equipped with a ZigBee device, can be located, positioned, and tracked by the system. The initial estimate of the mobile node position is extracted from IC devices from Texas Instruments, equipped with a specific hardware module for this function called Location Engine; it computes its position from RSSI readings of the signals coming from a set of reference beacons. Positioning of the blind nodes is enhanced by a post-filtering of the initial estimates by adjusting them into a Metric Description Graph (MDG) of the building, which includes information on distances and connectivity among the various enclosures of the coverage area of the ILS. The system has been experimentally verified in localization tasks of pedestrians in indoor environments. {\textcopyright} 2011 IEEE.},
annote = {cited By 10},
author = {Fern{\'{a}}ndez, S and Gualda, D and Garc{\'{i}}a, J C and Garc{\'{i}}a, J J and Ure{\~{n}}a, J and Guti{\'{e}}rrez, R},
booktitle = {WISP 2011 - IEEE International Symposium on Intelligent Signal Processing, Proceedings},
doi = {10.1109/WISP.2011.6051706},
keywords = {Coverage area; Indoor environment; Indoor location,Estimation,Signal processing},
pages = {4--8},
title = {{Indoor location system based on ZigBee devices and metric description graphs}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80955124606{\&}doi=10.1109{\%}2FWISP.2011.6051706{\&}partnerID=40{\&}md5=b4d1c76c15b0b2d818d2c26e4c4753fd},
year = {2011}
}
@article{Ficco:2016:UMM:2957204.2957217,
address = {Berlin, Heidelberg},
author = {Ficco, Massimo and Pietrantuono, Roberto and Russo, Stefano},
doi = {10.1007/s00500-015-1665-x},
issn = {1432-7643},
journal = {Soft Comput.},
number = {7},
pages = {2641--2664},
publisher = {Springer-Verlag},
title = {{Using Multi-objective Metaheuristics for the Optimal Selection of Positioning Systems}},
url = {http://dx.doi.org/10.1007/s00500-015-1665-x},
volume = {20},
year = {2016}
}
@inproceedings{Finlayson:1999:CIA:2227953.2227960,
address = {Swindon, UK},
author = {Finlayson, Graham D and Tian, Gui Yun},
booktitle = {Proceedings of the 1999 International Conference on Challenge of Image Retrieval},
pages = {7},
publisher = {BCS Learning {\&} Development Ltd.},
series = {IM'99},
title = {{Colour Indexing Across Illumination}},
url = {http://dl.acm.org/citation.cfm?id=2227953.2227960},
year = {1999}
}
@inproceedings{7479747,
abstract = {We present an indoor positioning system based on time-of-arrival (TOA) and angle-of-arrival (AOA/bearing) estimations using ultrasonic signals. Sensor anchor nodes deployed in the area of interest detect incoming signals from a mobile ultrasonic transmitter. The developed algorithm uses the range-bearing positioning method and can deal with ambiguous AOA sensor data. The system delivers 2D locations. We tested our positioning system inside an office building. Our system can locate objects with an error well below 10 cm even under these conditions with multipath reflections.},
author = {Flores, S and Gei{\ss}, J and Vossiek, M},
booktitle = {2016 IEEE/ION Position, Location and Navigation Symposium (PLANS)},
doi = {10.1109/PLANS.2016.7479747},
issn = {2153-3598},
keywords = {acoustic signal detection;direction-of-arrival est},
pages = {572--576},
title = {{An ultrasonic sensor network for high-quality range-bearing-based indoor positioning}},
year = {2016}
}
@inproceedings{Fluerasu2008,
abstract = {This paper describes a detailed numerical simulation study of indoor propagation carried out in order to evaluate multipath effects on the GNSS repeater based indoor positioning approach in various environments. Previous work [1] studied multipath effects in a very restricted area of about 50 square meters with metallic walls. The goal of the present paper is to provide the required complementary information to evaluate the multipath problem in typical indoor environments and to propose some directions of optimisation. The theory of the GNSS repeater based approach, together with experimental results validating its principle, was presented in previous paper [2]. The main idea of this method consists in using GNSS repeaters in a sequential mode in order to carry out measurements of code phase jumps at the instant of transition from one repeater to the next. Once obtained, three such jumps allow the indoor location calculation, through a classical GNSS computation. In order to carry out multipath evaluation, and optimisation, we use a deterministic propagation simulation software called Ergospace. Some extensions and customized features of the simulation package were developed to make the software more suitable for the GNSS repeater approach. The software takes into account all the elements concerning the satellites, the antennas and the environment, and can be used for both static and dynamic simulations. The considered environment is completely described using VRML (Virtual Reality Modelling Language). Each object encountered in the environment (wall, ceiling, floor or furniture) is characterized by its geometrical and electrical properties. The patterns of all considered antennas were measured in 3D in order to have a precise description of their performances. The propagation is determined using Ray Tracing algorithms. In order to consider multipath, the interactions (reflections, transmissions and diffractions) between rays and the considered environment are calculated until a maximum number is reached. Furthermore, the software is divided into two parts, the Outdoor Module and the Indoor Module. The main results given and discussed in the paper concern different aspects such as:  Various typical environments (exhibition halls, amphitheatres, office buildings, houses, laboratories, etc.)  Effect of limited displacements around a given location in order to evaluate the small scale variations of the multipath  Determination of criteria for an optimised deployment, depending on the environments, for both the repeater and the receiving antennas  Impact of different radiation patterns for the repeater antennas (standard GPS antenna, directional antenna, etc.) First simulations are also carried out in a specific configuration where the repeaters are located outside the building and are transmitting indoors. Such a deployment could be envisaged in a situation of emergency for fire brigade or police operations in a building where no on site repeaters are available.},
annote = {cited By 3},
author = {Fluerasu, A and Jardak, N and Boschetti, M and Samama, N},
booktitle = {ENC-GNSS 2008 - European Navigation Conference},
keywords = {Communication channels (information theory); Compu,Directional Antenna; Indoor environment; Indoor p,Global positioning system},
title = {{Multipath modelisation of typical indoor environments optimisation of GNSS based indoor positioning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924127934{\&}partnerID=40{\&}md5=16a91942548ab7ae0866b380a01a1511},
year = {2008}
}
@inproceedings{Fonseca:2013:TOS:2650288.2650912,
address = {Washington, DC, USA},
author = {da Fonseca, Vin$\backslash$'$\backslash$icius Prado and Rosa, Paulo F F},
booktitle = {Proceedings of the 2013 BRICS Congress on Computational Intelligence and 11th Brazilian Congress on Computational Intelligence},
doi = {10.1109/BRICS-CCI-CBIC.2013.101},
isbn = {978-1-4799-3194-1},
keywords = {Indoors Location System,RSSI,ZigB},
pages = {574--579},
publisher = {IEEE Computer Society},
series = {BRICS-CCI-CBIC '13},
title = {{Tracking Objects in a Smart Home}},
url = {http://dx.doi.org/10.1109/BRICS-CCI-CBIC.2013.101},
year = {2013}
}
@inproceedings{Foresti:2003:FDV:942799.943516,
address = {Washington, DC, USA},
author = {Foresti, G L and Micheloni, C and Snidaro, L and Marchiol, C},
booktitle = {Proceedings of the 12th International Conference on Image Analysis and Processing},
isbn = {0-7695-1948-2},
pages = {115----},
publisher = {IEEE Computer Society},
series = {ICIAP '03},
title = {{Face Detection for Visual Surveillance}},
url = {http://dl.acm.org/citation.cfm?id=942799.943516},
year = {2003}
}
@inproceedings{Fraga-Lamas2017161,
abstract = {The pipes of a ship, which exist in heterogeneous typology and massive number, are one of the key elements in a shipyard, and their real-Time monitoring constitutes a prospective Cyber-Physical System (CPS). Their improved location, from production and through their lifetime, can enhance shipyard productivity and safety. Navantia, one of the ten largest shipbuilders in the world, has improved its pipe workshop thanks to the concept of smart pipe, which is defined as an object able to transmit signals periodically that allows for providing added-value services in a shipyard. In this paper it is evaluated the use of passive UHF RFID (Radio Frequency Identification) for implementing the concept of smart pipe. Promising indoor positioning results obtained in a pipe workshop are presented, showing that multi-Antenna algorithms and Kalman filtering can help to stabilize Received Signal Strength (RSS) and improve the overall accuracy of the pipe monitoring system in a real-world scenario. {\textcopyright} 2017 IEEE.},
annote = {cited By 14},
author = {Fraga-Lamas, P and Fernandez-Carames, T M and Noceda-Davila, D and Vilar-Montesinos, M},
booktitle = {2017 IEEE International Conference on RFID, RFID 2017},
doi = {10.1109/RFID.2017.7945603},
keywords = {Added-value services; Cyber-physical systems (CPS,Cyber Physical System; Embedded systems; Monitorin,Ships},
pages = {161--166},
title = {{RSS stabilization techniques for a real-Time passive UHF RFID pipe monitoring system for smart shipyards}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021213162{\&}doi=10.1109{\%}2FRFID.2017.7945603{\&}partnerID=40{\&}md5=199f43deb7d5a9082aef455f216e0de2},
year = {2017}
}
@article{Franceschini2009698,
abstract = {Wireless sensor networks (WSNs) typically consist of a large number of densely populated sensor nodes. Due to important advances in integrated circuits and radio technologies, the use of distributed sensor networks is becoming increasingly widespread for a variety of applications, e.g. indoor navigation, environmental monitoring, people and object tracking, logistics, industrial diagnostics, quality control, and other manufacturing activities. In many cases, such as in objects tracking, knowing the physical location of network nodes is essential. Locating elements of WSNs is not a trivial task. Manual methods are wearisome and may be inaccurate, especially for large-scale networks. Therefore, many self-locating methods - where nodes cooperate with each other without human involvement - have recently been studied and implemented. The purpose of this work is to analyse the most significant methods for automatic location of distributed WSNs. The first part of the paper provides a description of the most common criteria used to categorize existing network localization algorithms. A taxonomy is then suggested that may be a useful tool to help evaluate, compare and select such algorithms. Five of the most representative algorithms are explained and discussed in detail in order to identify their strong points and their limitations.},
annote = {cited By 66},
author = {Franceschini, F and Galetto, M and Maisano, D and Mastrogiacomo, L},
doi = {10.1080/09511920601182217},
journal = {International Journal of Computer Integrated Manufacturing},
keywords = {Algorithms; Customer satisfaction; Location; Netw,Automatic location; Common criteria; Distributed s,Wireless sensor networks},
number = {7},
pages = {698--716},
title = {{A review of localization algorithms for distributed wireless sensor networks in manufacturing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-72349096542{\&}doi=10.1080{\%}2F09511920601182217{\&}partnerID=40{\&}md5=b9fca9617d5d48f82ad5c5dd285f0a1a},
volume = {22},
year = {2009}
}
@article{Fujii2003868,
annote = {cited By 0},
author = {Fujii, A and Meguro, M and Kaneko, M},
doi = {10.3169/itej.57.868},
journal = {Kyokai Joho Imeji Zasshi/Journal of the Institute of Image Information and Television Engineers},
number = {7},
pages = {868--872},
title = {{Detection of object regions in indoor surveillance images and recording of their locations}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041427834{\&}doi=10.3169{\%}2Fitej.57.868{\&}partnerID=40{\&}md5=ffd51adb78c6ffb08ef6b78a79439cce},
volume = {57},
year = {2003}
}
@inproceedings{Fukuju200353,
abstract = {Determining physical location of indoor objects is one of the key issues in development of context-aware applications in ubiquitous computing environments. This is mainly because context information obtained from sensor networks is meaningful only when the physical location of the context information source is determined. Recently, several indoor location information systems, such as Active Bat and Cricket, have been developed for precise indoor object localization. However, to provide accurate physical location tracking in large-scale space, those systems requires a lot of manual configuration for all the ultrasonic sensor nodes. To reduce configuration costs, we developed a new indoor positioning system called DOLPHIN. The DOLPHIN system consists of distributed wireless sensor nodes which are capable of sending and receiving RF and ultrasonic signals. These nodes are attached to various indoor objects. And using a novel distributed positioning algorithm in the nodes, DOLPHIN enables autonomous positioning of the objects with minimal manual configuration. This paper describes the design and implementation of the DOLPHIN system, and evaluates basic performance through several experiments in an indoor environment. {\textcopyright} 2003 IEEE.},
annote = {cited By 103},
author = {Fukuju, Y and Minami, M and Morikawa, H and Aoyama, T},
booktitle = {Proceedings - IEEE Workshop on Software Technologies for Future Embedded Systems, WSTFES 2003},
doi = {10.1109/WSTFES.2003.1201360},
keywords = {Balloons; Costs; Dolphins (structures); Embedded s,Context aware applications; Design and implementa,Ubiquitous computing},
pages = {53--56},
title = {{DOLPHIN: An autonomous indoor positioning system in ubiquitous computing environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905708965{\&}doi=10.1109{\%}2FWSTFES.2003.1201360{\&}partnerID=40{\&}md5=8ae49911e6c9938c3820500e112480bf},
year = {2003}
}
@inproceedings{Funka-Lea:1995:CCG:839277.839994,
address = {Washington, DC, USA},
author = {Funka-Lea, G and Bajcsy, R},
booktitle = {Proceedings of the Fifth International Conference on Computer Vision},
isbn = {0-8186-7042-8},
keywords = {active vision,active visual recognition,actively obtained shadows,color image segmentation method,colour,computational geometry,computer vision,cues,extendable probe,image recognition,image segmentation,light source location,light source obstruction,light sources,lighting,observer,penumbra,scene,scene geometry,scene lighting,shadow identification,shadows,single image regions,single material surface recovery,umbra},
pages = {203----},
publisher = {IEEE Computer Society},
series = {ICCV '95},
title = {{Combining Color and Geometry for the Active, Visual Recognition of Shadows}},
url = {http://dl.acm.org/citation.cfm?id=839277.839994},
year = {1995}
}
@phdthesis{Funka-Lea:1994:VRS:221460,
address = {Philadelphia, PA, USA},
annote = {UMI Order No. GAX95-21031},
author = {Funka-Lea, Gareth-David},
publisher = {University of Pennsylvania},
title = {{The Visual Recognition of Shadows by an Active Observer}},
year = {1994}
}
@inproceedings{Galov2014457,
abstract = {This paper describes the algorithm for positioning of both indoor base stations and pedestrians in nanoLOC (IEEE 802.15.4a) wireless network. The algorithm uses three sources of information: Time-of-flight ranging results between a mobile tag and base stations, the trajectory obtained from an embedded inertial measurement unit, and the map of the building. The iterative algorithm consists of two consequent interconnected stages. The particle filter is used to localize the mobile object on the map, whereas the discrete Bayes filter (grid filter) is applied for estimating the positions of base stations. Time-of-flight non-line-of-sight error distribution function was used as a likelihood in the discrete Bayes filter. Simulation shows that the described SLAM algorithm can be effectively used for setting the initial positions of base stations on the predefined map to save the installation time without significant decrease of localization accuracy. The proposed technique was applied in RealTrac local positioning technology. {\textcopyright} 2014 IEEE.},
annote = {cited By 2},
author = {Galov, A and Moschevikin, A},
booktitle = {IPIN 2014 - 2014 International Conference on Indoor Positioning and Indoor Navigation},
doi = {10.1109/IPIN.2014.7275517},
keywords = {Algorithms; Base stations; Distribution functions;,Bayes filter; Bayesian filtering; Indoor navigati,Indoor positioning systems},
pages = {457--464},
title = {{Simultaneous localization and mapping in indoor positioning systems based on round trip time-of-flight measurements and inertial navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988288809{\&}doi=10.1109{\%}2FIPIN.2014.7275517{\&}partnerID=40{\&}md5=d7fe4b87f7de878a36cd0a34df8a29b1},
year = {2014}
}
@inproceedings{Gandhi2016,
abstract = {One of the most significant topics under extensive research in ubiquitous computing is indoor localization and mapping. The current outdoor techniques using GSM, GPS and Wi-Fi are very expensive and infeasible for indoor mapping. This document presents a unique method of real time indoor localization and mapping using digitally coded electromagnetic waves (ASK and FSK). Localization is acquired with respect to 2-D array (NxM) of transmitter modules in rows and columns (i.e. length and breadth of the indoor region). All the transmitters of row array are tuned at same frequency but each transmitter emits a unique 12 bit digital code. Same is the case with column transmitters. The geometrical wave model of these transmitters renders family of circles, where radius of each circle represents 'Received Signal Strength Indicator' (RSSI) value corresponding to a particular transmitter. For locating the object in (NxM) grid, differential mechanism is used i.e. comparing RSSI values of all the adjacent transmitters of row and column respectively at the location of object. Indoor region of particular dimensions can be discretized into NxM grids. Object is installed with customized FPGA core, 2 RF demodulators (for row and column) and two PLL ICs for calculating RSSI values (in 4 bit resolution). For real time response, 2 parallel I2C buses are connected to FPGA core. Wireless control over RF transmitters is used to prevent unwanted RF radiation. Overall, real world is discretized into grids. Also detailed comparison is shown as to how this technique is better than triangulation method. {\textcopyright} 2016 IEEE.},
annote = {cited By 1},
author = {Gandhi, A S and Bhurchandi, K M and Deshmukh, S and Dubey, A},
booktitle = {2016 8th International Conference on Communication Systems and Networks, COMSNETS 2016},
doi = {10.1109/COMSNETS.2016.7439927},
keywords = {Electromagnetic waves; Field programmable gate arr,Geometrical waves; Indoor localization; Real time,Indoor positioning systems},
title = {{Real-Time indoor localization and mapping using digitally coded RF waves with implementation on FPGA}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966473440{\&}doi=10.1109{\%}2FCOMSNETS.2016.7439927{\&}partnerID=40{\&}md5=84d7448f7da6745591fe00b34e59ca41},
year = {2016}
}
@article{Gao2016460,
abstract = {Mainstream indoor localization technologies rely on RF signatures that require extensive human efforts to measure and periodically recalibrate signatures. The progress to ubiquitous localization remains slow. In this study, we explore Sextant, an alternative approach that leverages environmental reference objects such as store logos. A user uses a smartphone to obtain relative position measurements to such static reference objects for the system to triangulate the user location. Sextant leverages image matching algorithms to automatically identify the chosen reference objects by photo-taking, and we propose two methods to systematically address image matching mistakes that cause large localization errors. We formulate the benchmark image selection problem, prove its NP-completeness, and propose a heuristic algorithm to solve it. We also propose a couple of geographical constraints to further infer unknown reference objects. To enable fast deployment, we propose a lightweight site survey method for service providers to quickly estimate the coordinates of reference objects. Extensive experiments have shown that Sextant prototype achieves 2-5 m accuracy at 80-percentile, comparable to the industry state-of-the-art, while covering a 150  75 m mall and 300  200m train station requires a one time investment of only 2-3 man-hours from service providers. {\textcopyright} 2015 IEEE.},
annote = {cited By 23},
author = {Gao, R and Tian, Y and Ye, F and Luo, G and Bian, K and Wang, Y and Wang, T and Li, X},
doi = {10.1109/TMC.2015.2418205},
journal = {IEEE Transactions on Mobile Computing},
keywords = {Algorithms; Heuristic algorithms; Indoor positioni,Environmental references; Image matching algorith,Image matching},
number = {2},
pages = {460--474},
title = {{Sextant: Towards ubiquitous indoor localization service by photo-taking of the environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978225970{\&}doi=10.1109{\%}2FTMC.2015.2418205{\&}partnerID=40{\&}md5=2005e10eb5a03a593eea00c51e266a57},
volume = {15},
year = {2016}
}
@article{Gao20183,
abstract = {The lack of indoor maps is a critical reason behind the current sporadic availability of indoor localization service. Service providers have to go through effort-intensive and time-consuming business negotiations with building operators, or hire dedicated personnel to gather such data. In this chapter, we propose Jigsaw, a floor plan reconstruction system that leverages crowdsensed data from mobile users. It extracts the position, size, and orientation information of individual landmark objects from images taken by users. It also obtains the spatial relation between adjacent landmark objects from inertial sensor data, and then computes the coordinates and orientations of these objects on an initial floor plan. By combining user mobility traces and locations where images are taken, it produces complete floor plans with hallway connectivity, room sizes, and shapes. It also identifies different types of connection areas (e.g., escalators, stairs) between stories, and employs a refinement algorithm to correct detection errors. Our experiments on three stories of two large shopping malls show that the 90-percentile errors of positions and orientations of landmark objects are about 1 {\~{}} 2m and 5 {\~{}} 9, while the hallway connectivity and connection areas between stories are 100{\%} correct. {\textcopyright} The Author(s) 2018.},
annote = {cited By 0},
author = {Gao, R and Ye, F and Luo, G and Cong, J},
doi = {10.1007/978-981-10-8378-5_2},
journal = {SpringerBriefs in Computer Science},
number = {9789811083778},
pages = {3--30},
title = {{Indoor map construction via mobile crowdsensing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044950266{\&}doi=10.1007{\%}2F978-981-10-8378-5{\_}2{\&}partnerID=40{\&}md5=caa510db051a6add928da5fa0edff500},
year = {2018}
}
@article{Gao201851,
abstract = {Mainstream indoor localization technologies rely on RF signatures that require extensive human efforts to measure and periodically recalibrate signatures. The progress to ubiquitous localization remains slow. In this chapter, we explore Sextant, an alternative approach that leverages environmental reference objects such as store logos. A user uses a smartphone to obtain relative position measurements to such static reference objects for the system to triangulate the user location. Sextant leverages image matching algorithms to automatically identify the chosen reference objects by photo-taking, and we propose two methods to systematically address image matching mistakes that cause large localization errors. We formulate the benchmark image selection problem, prove its NP-completeness, and propose a heuristic algorithm to solve it. We also propose a couple of geographical constraints to further infer unknown reference objects. To enable fast deployment, we propose a lightweight site survey method for service providers to quickly estimate the coordinates of reference objects. Extensive experiments have shown that Sextant prototype achieves 25 m accuracy at 80-percentile, comparable to the industry state of the art, while covering a 150  75 m mall and 300  200 m train station requires a one-time investment of only 23 man-hours from service providers. {\textcopyright} The Author(s) 2018.},
annote = {cited By 0},
author = {Gao, R and Ye, F and Luo, G and Cong, J},
doi = {10.1007/978-981-10-8378-5_4},
journal = {SpringerBriefs in Computer Science},
number = {9789811083778},
pages = {51--79},
title = {{Indoor localization by photo-taking of the environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044976932{\&}doi=10.1007{\%}2F978-981-10-8378-5{\_}4{\&}partnerID=40{\&}md5=d1e98a5e1adb7d06e670f153de707d06},
year = {2018}
}
@article{Gao20161427,
abstract = {The lack of floor plans is a critical reason behind the current sporadic availability of indoor localization service. Service providers have to go through effort-intensive and time-consuming business negotiations with building operators, or hire dedicated personnel to gather such data. In this paper, we propose Jigsaw, a floor plan reconstruction system that leverages crowdsensed data from mobile users. It extracts the position, size, and orientation information of individual landmark objects from images taken by users. It also obtains the spatial relation between adjacent landmark objects from inertial sensor data, then computes the coordinates and orientations of these objects on an initial floor plan. By combining user mobility traces and locations where images are taken, it produces complete floor plans with hallway connectivity, room sizes, and shapes. It also identifies different types of connection areas (e.g., escalators and stairs) between stories, and employs a refinement algorithm to correct detection errors. Our experiments on three stories of two large shopping malls show that the 90-percentile errors of positions and orientations of landmark objects are about 1 2m and 59 , while the hallway connectivity and connection areas between stories are 100 percent correct. {\textcopyright} 2002-2012 IEEE.},
annote = {cited By 19},
author = {Gao, R and Zhao, M and Ye, T and Ye, F and Luo, G and Wang, Y and Bian, K and Wang, T and Li, X},
doi = {10.1109/TMC.2016.2550040},
journal = {IEEE Transactions on Mobile Computing},
keywords = {Business negotiations; Floorplans; Indoor localiz,Computer networks; Mobile computing,Floors},
number = {6},
pages = {1427--1442},
title = {{Multi-story indoor floor plan reconstruction via mobile crowdsensing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969752789{\&}doi=10.1109{\%}2FTMC.2016.2550040{\&}partnerID=40{\&}md5=eb13d796b852c23da0ecba4352f446de},
volume = {15},
year = {2016}
}
@phdthesis{Gao:2005:SSI:1104040,
address = {Williamsburg, VA, USA},
annote = {AAI3172890},
author = {Gao, Wen},
isbn = {0-542-09782-6},
publisher = {College of William {\&} Mary},
title = {{Sonar Sensor Interpretation for Ectogeneous Robots}},
year = {2005}
}
@inproceedings{Garg20176863,
abstract = {The place recognition problem comprises two distinct subproblems; recognizing a specific location in the world ('specific' or 'ordinary' place recognition) and recognizing the type of place (place categorization). Both are important competencies for mobile robots and have each received significant attention in the robotics and computer vision community, but usually as separate areas of investigation. In this paper, we leverage the powerful complementary nature of place recognition and place categorization processes to create a new hybrid place recognition system that uses place context to inform place recognition. We show that semantic place categorization creates an informative natural segmenting of physical space that in turn enables significantly better place recognition performance in comparison to existing techniques. In particular, this new semantically-informed approach adds robustness to significant local changes within the environment, such as transitioning between indoor and outdoor environments or between dark and light rooms in a house, complementing the capabilities of current condition-invariant techniques that are robust to globally consistent change (such as day to night cycles). We perform experiments using 4 novel benchmark datasets and show that semantically-informed place recognition outperforms the previous state-of-the-art systems. Like it does for object recognition [1], we believe that semantics can play a key role in boosting conventional place recognition and navigation performance for robotic systems. {\textcopyright} 2017 IEEE.},
annote = {cited By 6},
author = {Garg, S and Jacobson, A and Kumar, S and Milford, M},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2017.8206608},
keywords = {Benchmark datasets; Navigation performance; Outdo,Computer vision,Image segmentation; Intelligent robots; Object rec},
pages = {6863--6870},
title = {{Improving condition- and environment-invariant place recognition with semantic place categorization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032259618{\&}doi=10.1109{\%}2FIROS.2017.8206608{\&}partnerID=40{\&}md5=1420b43634db912d51aa83fcf97a910b},
volume = {2017-Septe},
year = {2017}
}
@inproceedings{Genco:2005:HFR:1084009.1084045,
address = {Washington, DC, USA},
author = {Genco, Alessandro and Varrica, Emanuele},
booktitle = {Proceedings of the Seventh International Workshop on Computer Architecture for Machine Perception},
doi = {10.1109/CAMP.2005.57},
isbn = {0-7695-2255-6},
keywords = {Adaptive control,Location-Based Services,Mobile Distributed Environments,Pervasive Systems},
pages = {237--242},
publisher = {IEEE Computer Society},
series = {CAMP '05},
title = {{Human Figure Recognition and the Estimation of Its Direction}},
url = {http://dx.doi.org/10.1109/CAMP.2005.57},
year = {2005}
}
@inproceedings{Georgakis2017,
abstract = {Detection of objects in cluttered indoor environments is one of the key enabling functionalities for service robots. The best performing object detection approaches in computer vision exploit deep Convolutional Neural Networks (CNN) to simultaneously detect and categorize the objects of interest in cluttered scenes. Training of such models typically requires large amounts of annotated training data which is time consuming and costly to obtain. In this work we explore the ability of using synthetically generated composite images for training state-of-the-art object detectors, especially for object instance detection. We superimpose 2D images of textured object models into images of real environments at variety of locations and scales. Our experiments evaluate different superimposition strategies ranging from purely image-based blending all the way to depth and semantics informed positioning of the object models into real scenes. We demonstrate the effectiveness of these object detector training strategies on two publicly available datasets, the GMUKitchens [5] and the Washington RGB-D Scenes v2 [11]. As one observation, augmenting some hand-labeled training data with synthetic examples carefully composed onto scenes yields object detectors with comparable performance to using much more hand-labeled data. Broadly, this work charts new opportunities for training detectors for new objects by exploiting existing object model repositories in either a purely automatic fashion or with only a very small number of human-annotated examples. {\textcopyright} 2017 MIT Press Journals. All rights reserved.},
annote = {cited By 4},
author = {Georgakis, G and Mousavian, A and Berg, A C and Ko{\v{s}}eck{\'{a}}, J},
booktitle = {Robotics: Science and Systems},
keywords = {Annotated training data; Deep convolutional neura,Deep neural networks; Neural networks; Object reco,Object detection},
title = {{Synthesizing training data for object detection in indoor scenes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048806147{\&}partnerID=40{\&}md5=85a285e8f931a6ed068d3e93b28e2763},
volume = {13},
year = {2017}
}
@inproceedings{4753251,
abstract = {Diverse security applications often require monitoring of a narrow passage, such as an indoor corridor, a tunnel, a bridge; either to protect critical assets at the end of such a passage or to control the passage over it, or both. Often, sensors are arranged in a vector along such a passage and are capable of registering the crossing of a target but not its identity. In this paper, we consider coordinated tracking by such a vector of sensors where each sensor learns timings of objects passing at monitored spots from its predecessors. Hence, the problem we are solving could be formulated as an assignment or matching of target identities to arrival times of the targets at the subsequent sensors in a vector. We introduce a cost function that is the sum of squares of the difference between each target's predicted and observed arrival time at each sensor. We use target's speed as computed from the arrival times of the target at previous two sensors to predict the time of arrival at the current sensor. In such a scheme, the simple matching algorithm that sorts predicted and actual arrival times in two separated lists and then matches both lists by positions minimizes this and similar cost functions for each sensor locally in {\textless}i{\textgreater}O{\textless}/i{\textgreater}({\textless}i{\textgreater}n{\textless}/i{\textgreater} log {\textless}i{\textgreater}n{\textless}/i{\textgreater}) time. We have also developed more costly algorithms that yield higher quality global solution at the cost of communication, computation and memory. In the paper, we evaluate analytically, and by simulations, different variants of this matching algorithm and their complexity and performance.},
author = {Geyik, S C and Szymanski, B K},
booktitle = {MILCOM 2008 - 2008 IEEE Military Communications Conference},
doi = {10.1109/MILCOM.2008.4753251},
issn = {2155-7578},
keywords = {computational complexity;graph theory;minimisation},
month = {nov},
pages = {1--7},
title = {{Multi-target tracking and identification by a vector of sensors}},
year = {2008}
}
@inproceedings{Ghadiok20114645,
abstract = {This paper presents an implementation of autonomous indoor aerial gripping using a low-cost, custom-built quadrotor. Such research extends the typical functionality of micro air vehicles (MAV) from passive observation and sensing to dynamic interaction with the environment. To achieve this, three major challenges are overcome: precise positioning, sensing and manipulation of the object, and stabilization in the presence of disturbance due to interaction with the object. Navigation in unstructured, GPS-denied environments is achieved using a visual SLAM algorithm that relies on an onboard monocular camera. A secondary camera, capable of detecting infrared light sources, is used to estimate the 3D location of the object, while an under-actuated and passively compliant manipulator is designed for effective gripping under uncertainty. The system utilizes nested PID controllers for attitude stabilization, vision-based navigation and gripping. The quadrotor is therefore able to autonomously navigate, locate and grasp an object, using only onboard sensors. {\textcopyright} 2011 IEEE.},
annote = {cited By 79},
author = {Ghadiok, V and Goldin, J and Ren, W},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2011.6048786},
keywords = {Attitude stabilization; Compliant manipulators; Dy,Cameras; Light sources; Micro air vehicle (MAV);,Intelligent robots},
pages = {4645--4651},
title = {{Autonomous indoor aerial gripping using a quadrotor}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84455185211{\&}doi=10.1109{\%}2FIROS.2011.6048786{\&}partnerID=40{\&}md5=c75a56520d2bc670c21776ba80322c86},
year = {2011}
}
@inproceedings{7743615,
abstract = {This paper presents a series of tests and analyses undertaken to investigate the performance capabilities of an active RFID system (Freaquent{\textregistered}) for asset tracking and personal mobility. The RFID system was tested exhaustively considering a number of user requirements including maximum operating distance, antenna orientation, position accuracy, the influences caused by nearby objects and the operating environment. For this purpose, various positioning techniques were applied based on the lateration and fingerprinting positioning concepts. Analysis revealed that the lateration technique is sensitive to operational environment; however, as long as a representative RSS to distance model is established the method can deliver accuracies of the order of 0.7 m at unobstructed line-of-sight conditions. Location fingerprinting has shown that large temporal variations can occur partly which effect the radio maps of RSS distributions significantly. Thus, RSS training measurements have to performed at regular intervals to guarantee acceptable positioning accuracies on the meter-level.},
author = {Gikas, V and Dimitratos, A and Perakis, H and Retscher, G and Ettlinger, A},
booktitle = {2016 International Conference on Indoor Positioning and Indoor Navigation (IPIN)},
doi = {10.1109/IPIN.2016.7743615},
issn = {2471-917X},
keywords = {antennas;position control;radiofrequency identific},
pages = {1--8},
title = {{Full-scale testing and performance evaluation of an active RFID system for positioning and personal mobility}},
year = {2016}
}
@inproceedings{Giovannangeli20063293,
abstract = {This article presents an efficient and mature vision-based navigation algorithm based on sensory-motor learning. Neither Cartesian nor topological map are required, but a set of biologically inspired place cells. Each place cell defines a location by a spatial constellation of online learned landmarks. Their activity provides an internal measure of localization. A simple set of place-action associations enable a robot to go back to a learned location or to follow an arbitrary visual path. The system is able to achieve sensory-motor tasks in indoor as well as in large outdoor environments with similar computation load. The behavior is robust to kidnapping, object and landmark addition or removal, presence of mobile obstacles and severe visual field occlusions. {\textcopyright} 2006 IEEE.},
annote = {cited By 20},
author = {Giovannangeli, C and Gaussier, P and D{\'{e}}silles, G},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2006.282501},
keywords = {Algorithms; Computational methods; Computer visio,Navigation algorithms; Sensory motor learning; Top,Navigation systems},
pages = {3293--3300},
title = {{Robust mapless outdoor, vision-based navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250629985{\&}doi=10.1109{\%}2FIROS.2006.282501{\&}partnerID=40{\&}md5=11d28e222829c82b0614ceb829d5f00d},
year = {2006}
}
@inproceedings{Gmez-Conde2010,
abstract = {Behavior determination and multiple object tracking for video surveillance are two of the most active fields of machine vision. We describe our system, which we are developing for applications in tele-assistance for the elderly, as an early warning monitor for anomalous events. Our system is based upon the computer vision library OpenCV. In this article we describe the algorithms we have developed for tracking multiple people in indoor environments. We also describe a simple histogram based algorithm for discriminating arm movements and body positions.},
annote = {cited By 2},
author = {G{\'{o}}mez-Conde, I and Olivieri, D N and Vila, X A and Rodr{\'{i}}guez-Li{\~{n}}ares, L},
booktitle = {Proceedings of the 5th Iberian Conference on Information Systems and Technologies, CISTI 2010},
keywords = {Active field; Anomalous events; Arm movements; Beh,Computer vision,Image retrieval; Information systems; Security sy},
title = {{Smart telecare video monitoring for anomalous event detection}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77957824900{\&}partnerID=40{\&}md5=b3fdfd11bf03b63996c300d3c8bc241d},
year = {2010}
}
@inproceedings{Gomez:2005:ORI:2099369.2099380,
address = {Berlin, Heidelberg},
author = {G{\'{o}}mez, Nicol{\'{a}}s Amezquita and Alqu{\'{e}}zar, Ren{\'{e}}},
booktitle = {Proceedings of the 10th Iberoamerican Congress Conference on Progress in Pattern Recognition, Image Analysis and Applications},
doi = {10.1007/11578079_10},
isbn = {3-540-29850-9, 978-3-540-29850-2},
pages = {93--102},
publisher = {Springer-Verlag},
series = {CIARP'05},
title = {{Object Recognition in Indoor Video Sequences by Classifying Image Segmentation Regions Using Neural Networks}},
url = {http://dx.doi.org/10.1007/11578079{\_}10},
year = {2005}
}
@inproceedings{Goncalves2004178,
abstract = {Among the numerous challenges of building autonomous/unmanned vehicles is that of reliable and autonomous localization in an unknown environment. In this paper we present a system that can efficiently and autonomously solve the robotics 'SLAM' problem, where a robot placed in an unknown environment, simultaneously must localize itself and make a map of the environment. The system is vision-based, and makes use of Evolution Robotic's powerful object recognition technology. As the robot explores the environment, it is continuously performing four tasks, using information from acquired images and the drive system odometry. The robot: recognizes previously created 3-D visual landmarks builds new 3-D visual landmarks updates the current estimate of its location, using the map. updates the landmark map In indoor environments, the system can build a map of a 5m by 5m area in approximately 20 minutes, and can localize itself with an accuracy of approximately 15 cm in position and 3 degrees in orientation relative to the global reference frame of the landmark map. The same system can be adapted for outdoor, vehicular use.},
annote = {cited By 4},
author = {Goncalves, L and Karlsson, N and Ostrowski, J and Bernardo, E D and Pirjanian, P},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.543846},
keywords = {3-D visual landmarks; Autonomous localization; Ob,Cameras; Image sensors; Mapping; Object recognitio,Vision},
pages = {178--185},
title = {{VSLAM: Vision-based SLAM for autonomous vehicle navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-10444248000{\&}doi=10.1117{\%}2F12.543846{\&}partnerID=40{\&}md5=843b99e3751ae00cad65eecd0f329c11},
volume = {5422},
year = {2004}
}
@article{Gopalakrishna201493,
abstract = {Object recognition in the video sequence or images is one of the subfield of computer vision. Moving object recognition from a video sequence is an appealing topic with applications in various areas such as airport safety, intrusion surveillance, video monitoring, intelligent highway, etc. Moving object recognition is the most challenging task in intelligent video surveillance system. In this regard, many techniques have been proposed based on different methods. Despite of its importance, moving object recognition in complex environments is still far from being completely solved for low resolution videos, foggy videos, and also dim video sequences. All in all, these make it necessary to develop exceedingly robust techniques. This paper introduces multiple moving object recognition in the video sequence based on LoG Gabor-PCA approach and Angle based distance Similarity measures techniques used to recognize the object as a human, vehicle etc. Number of experiments are conducted for indoor and outdoor video sequences of standard datasets and also our own collection of video sequences comprising of partial night vision video sequences. Experimental results show that our proposed approach achieves an excellent recognition rate. Results obtained are satisfactory and competent. {\textcopyright} Springer International Publishing Switzerland 2014.},
annote = {cited By 1},
author = {Gopalakrishna, M T and Ravishankar, M and Rameshbabu, D R},
doi = {10.1007/978-3-319-01778-5_10},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Airport security; Computer vision; Monitoring; Sec,Complex environments; Intelligent video surveilla,Object recognition},
pages = {93--100},
title = {{Multiple moving object recognitions in video based on log gabor-PCA approach}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927636362{\&}doi=10.1007{\%}2F978-3-319-01778-5{\_}10{\&}partnerID=40{\&}md5=072377a887af124449aba9a67ca2c5c0},
volume = {235},
year = {2014}
}
@inproceedings{8578528,
abstract = {We introduce Interactive Question Answering (IQA), the task of answering questions that require an autonomous agent to interact with a dynamic visual environment. IQA presents the agent with a scene and a question, like: "Are there any apples in the fridge?" The agent must navigate around the scene, acquire visual understanding of scene elements, interact with objects (e.g. open refrigerators) and plan for a series of actions conditioned on the question. Popular reinforcement learning approaches with a single controller perform poorly on IQA owing to the large and diverse state space. We propose the Hierarchical Interactive Memory Network (HIMN), consisting of a factorized set of controllers, allowing the system to operate at multiple levels of temporal abstraction. To evaluate HIMN, we introduce IQUAD V1, a new dataset built upon AI2-THOR [35], a simulated photo-realistic environment of configurable indoor scenes with interactive objects. IQUAD V1 has 75,000 questions, each paired with a unique scene configuration. Our experiments show that our proposed model outperforms popular single controller based methods on IQUAD V1. For sample questions and results, please view our video: https://youtu.be/pXd3C-1jr98.},
author = {Gordon, D and Kembhavi, A and Rastegari, M and Redmon, J and Fox, D and Farhadi, A},
booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2018.00430},
issn = {2575-7075},
keywords = {data visualisation;interactive systems;learning (a},
pages = {4089--4098},
title = {{IQA: Visual Question Answering in Interactive Environments}},
year = {2018}
}
@article{Gramegna2004145,
abstract = {This paper presents an optimization of POSIT (Pose from Orthographic and Scaling with Iterations), a model-based camera location algorithm, in the domain of indoor mobile robot navigation. The method finds the rotation matrix and the translation vector of the camera with respect to an object. The novelty of the proposed modified algorithm is that it does not need the perfect knowledge of camera parameters. A new definition of the scaling factor has been introduced in the scaled orthographic projection. Due to the peculiarity of the indoor bounded workspace a new formulation of the translation vector has been used. The new method has been successfully applied in a real environment considering a goal-directed navigation task for our real robot Khepera. The experimentation has shown better results in comparison with the original POSIT algorithm. {\textcopyright} 2004 Elsevier B.V. All rights reserved.},
annote = {cited By 19},
author = {Gramegna, T and Venturino, L and Cicirelli, G and Attolico, G and Distante, A},
doi = {10.1016/j.robot.2004.05.001},
journal = {Robotics and Autonomous Systems},
keywords = {Algorithms; Cameras; Control systems; Iterative me,Autonomous navigation; Autonomous robot indoor na,Robotics},
number = {2-3},
pages = {145--162},
title = {{Optimization of the POSIT algorithm for indoor autonomous navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-4344586949{\&}doi=10.1016{\%}2Fj.robot.2004.05.001{\&}partnerID=40{\&}md5=af0a4fd266fccd8b9177e083ab603422},
volume = {48},
year = {2004}
}
@inproceedings{Graven201844,
abstract = {An autonomous robot rover has been designed and developed. The proposed robot rover is capable of self-localization and self-exploration of a room or an area inside a building. Self-driving and self-navigating in unknown environments, our robot constantly scans its surrounding, incrementally and dynamically constructing a global map of the visited room. Immediately after it detects an obstacle or an obstruction, the robot car does not only stop or diverge its route in order to avoid crashing into it, but also marks its location on the map as dangerously hazard. All unoccupied spaces are registered as a safe path. While exploring, the robot is programmed to take a large number of photographs of its surrounding, which includes multiple views of each scene from multiple different angles. These images collected are used to create a three-dimensional model of the interior of the room by photogrammetric methods. In addition to a general exploration of desired regions, a robot may be presented with a selected target object. It must then chooses its own path to locate the object and to circle around it in order to take many photographs of it from all directions and to create a corresponding 3D model. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Graven, O H and Srisuphab, A and Silapachote, P and Sirilertworakul, V and Ampornwathanakun, W and Anekwiroj, P and Maitrichit, N},
booktitle = {1st International ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering, ECTI-NCON 2018},
doi = {10.1109/ECTI-NCON.2018.8378279},
keywords = {3-d modeling; Exploration robots; Global map; Mul,Accidents; Photogrammetry; Photography,Robots},
pages = {44--47},
title = {{An autonomous indoor exploration robot rover and 3D modeling with photogrammetry}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049961144{\&}doi=10.1109{\%}2FECTI-NCON.2018.8378279{\&}partnerID=40{\&}md5=9bd29d0949738c1cd0161a59f8475409},
year = {2018}
}
@inproceedings{GroBwindhager:2018:SUS:3274783.3274844,
address = {New York, NY, USA},
author = {Gro$\backslash$sswindhager, Bernhard and Rath, Michael and Kulmer, Josef and Bakr, Mustafa S and Boano, Carlo Alberto and Witrisal, Klaus and R{\"{o}}mer, Kay},
booktitle = {Proceedings of the 16th ACM Conference on Embedded Networked Sensor Systems},
doi = {10.1145/3274783.3274844},
isbn = {978-1-4503-5952-8},
keywords = {Indoor localization,multipath,single-anchor,ultra-wideband},
pages = {132--144},
publisher = {ACM},
series = {SenSys '18},
title = {{SALMA: UWB-based Single-Anchor Localization System Using Multipath Assistance}},
url = {http://doi.acm.org/10.1145/3274783.3274844},
year = {2018}
}
@inproceedings{NoAuthor2009,
abstract = {Title from The ACM Digital Library.},
annote = {cited By 0},
author = {Grunwald, Dirk. and {ACM Digital Library.} and {ACM SIGMOBILE.}},
booktitle = {Proceedings of the 6th International Conference on Mobile Technology, Application and Systems, Mobility '09},
isbn = {9781605581392},
pages = {296},
title = {{Proceedings of the 6th international conference on Mobile systems, applications, and services.}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950891957{\&}partnerID=40{\&}md5=c9d2c4f3302d1738e92e7d3fb630c3a2},
year = {2008}
}
@article{Grzechca2016371,
abstract = {This paper presents analysis of object location accuracy of a mobile device on the basis of the iBeacon technology. The research starts with radio signal strength indicator analysis along the corridor in order to create a path loss model for iBeacon. Two cases are taken into account: line of sight and non-line of sight for model creation. For both cases two tests: Chi-square, Shapiro-Wilk have been performed. It has also been checked if the HCI (Host Controller Interface) is a source with a memory. Acquired data have been filtered with different type of filters, e.g. median, moving average and then compared. Next, the authors evaluated the indoor positioning trilateration algorithms with the use of created model for exemplary hall. The RSSI map (radiomap) was created and the logarithm propagation model was designed. The logarithmic model estimated distance with average error 1.09m for 1 - 9m and 1.75m for 1-20m and after trilateration, the positions with average error 2.45m was achieved. A statistical analysis for acquiring data led to the final conclusion which enhanced knowledge about positioning based on the popular iBeacon technology. {\textcopyright} 2016 Damian E. Grzechca et al., published by De Gruyter Open.},
annote = {cited By 8},
author = {Grzechca, D E and Pelczar, P and Chruszczyk, L},
doi = {10.1515/eletel-2016-0051},
journal = {International Journal of Electronics and Telecommunications},
keywords = {Bluetooth; Mobile devices; Navigation; Radio links,Host controller interfaces; Indoor environment; I,Median filters},
number = {4},
pages = {371--378},
title = {{Analysis of Object Location Accuracy for iBeacon Technology based on the RSSI Path Loss Model and Fingerprint Map}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002271226{\&}doi=10.1515{\%}2Feletel-2016-0051{\&}partnerID=40{\&}md5=e01108022b5cf343794c61f217b37281},
volume = {62},
year = {2016}
}
@inproceedings{8336158,
abstract = {This paper focuses on the different filtering methods of movement around a circle whose acquisition was made using system based on the Ultra-wideband (UWB) technology. The main aim of this study is to get the most accurate way of filtering circular motion for the UWB system for statistical terms. Filtration presented in this paper can be used to locate objects using ultra-wideband technology, and thanks to the use of motion at speed up to 50km/h, it will be possible to use test results to reflect drones or autonomous vehicles, particularly where standard locations systems (e.g. GPS) is not available - such as tunnels, underground car parks, shopping centers. This document proposes an approach based on the filtration points that was assigned to the buckets placed in three-dimensional space on the expected trajectory of the circular object movement. During the data processing the following filters have been used: median, arithmetic mean, Savitzky-Golay in combination with arithmetic mean, and moving average in combination with arithmetic mean. The number of used measurement buckets, as well as their size, was also analyzed. The results were compared with the use of the length of the line, that traces the localized object in correlation with the number of measured buckets used.},
author = {Grzechca, D and Hanzel, K and Paszek, K},
booktitle = {2018 14th International Conference on Advanced Trends in Radioelecrtronics, Telecommunications and Computer Engineering (TCSET)},
doi = {10.1109/TCSET.2018.8336158},
keywords = {Global Positioning System;indoor radio;intelligent},
pages = {69--74},
title = {{Accuracy analysis for object positioning on a circular trajectory based on the UWB location system}},
year = {2018}
}
@inproceedings{Grzechca2014171,
abstract = {There is an increasing demand for indoor navigation and localization systems along with increasing popularity of location based services in last years. The paper presents our work in progress for locating indoor objects based on signal fusion. The location is based on two signals: RSSI (Received Signal Strength Indication) and video camera. This paper presents a vision-based system for human detection and tracking in indoor environment using a single static camera. However its accuracy depends on calibration methods and additional sensors. Most of related works used very complex approach of calibration. In this paper actual position is calculated by simple algorithm with fast computing time. {\textcopyright} 2014 IEEE.},
annote = {cited By 2},
author = {Grzechca, D and Wrobel, T and Bielecki, P},
booktitle = {Proceedings - 2014 International Conference on Mathematics and Computers in Sciences and in Industry, MCSI 2014},
doi = {10.1109/MCSI.2014.52},
keywords = {Calibration; Cameras; Indoor positioning systems;,Human detection and tracking; In-door navigations,Location based services},
pages = {171--174},
title = {{Indoor Location and Idetification of Objects with Video Survillance System and WiFi Module}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949926614{\&}doi=10.1109{\%}2FMCSI.2014.52{\&}partnerID=40{\&}md5=e03dcc0b193321a2daff85a693c5902c},
year = {2014}
}
@inproceedings{Grzenda:2013:PFI:3104813.3104892,
address = {Berlin, Heidelberg},
author = {Grzenda, Maciej},
booktitle = {Proceedings of the 26th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems},
doi = {10.1007/978-3-642-38577-3_63},
isbn = {978-3-642-38576-6},
pages = {610--619},
publisher = {Springer-Verlag},
series = {IEA/AIE'13},
title = {{On the Prediction of Floor Identification Credibility in RSS-based Positioning Techniques}},
url = {https://doi.org/10.1007/978-3-642-38577-3{\_}63},
year = {2013}
}
@article{Gu20071603,
abstract = {The location sensing system (also called positioning system) is an underlying component for location-aware computing in Smart Space, which not only demands the location sensing system to locate multiple objects with desirable precision, but also superimposes the requirements, such as directional characteristic and portability etc, on it. This paper presents an indoor location sensing system, Cicada. This system is based on the TDoA (Time Difference of Arrival) between radiofrequency and ultrasound to estimate distance, and employs a technology integrating Slide Window Filter and Extended Kalman Filter to calculate location. As the experiments prove, Cicada can provide the average 5 cm location precision both for static objects and for mobile objects, owns a nearly omni-directional working area ranging from -90 degree to +90 degree. Besides, it is able to run independently, mini and light so that it is convenient to be portable and even embedded into people s paraphernalia. Further, it is also flexible in scalability, for neither quantity range nor constraint of structure form is demanded on its infrastructure. Last, it is fairly facile to be employed, attributing to the wireless connectivity in its infrastructure. Those advantages illuminate that it is able to be competent for all-round location sensing requirements of Smart Space.},
annote = {cited By 4},
author = {Gu, H.-L. and Shi, Y.-C. and Shen, R.-M. and Chen, Y},
journal = {Jisuanji Xuebao/Chinese Journal of Computers},
keywords = {Cicada; Location aware computing; Location sensin,Extended Kalman filters; Mobile computing; Trackin,Ubiquitous computing},
number = {9},
pages = {1603--1611},
title = {{A multi-object tracking indoor positioning system for Smart Space}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-35748934503{\&}partnerID=40{\&}md5=c13dee1146aa10959448ae096568f2f4},
volume = {30},
year = {2007}
}
@inproceedings{Gu20161770,
abstract = {Environment perception is a key technology for robot control and moving. Image information has the advantage of low-cost to perceive the indoor environment. Stitching multiple images is helpful to realize the full range of global view of indoor environment. Our research devotes to showing a large field of view by dynamic image stitching when there is a moving object in the environment. The images of two ceiling cameras were stitched by using methods of image stitching. A core process of image mosaic is adjusting intensity and seeking optimal seam line. The optimal seam line was computed to avoid the moving object, which solved the abnormal stitching caused by parallax influence. Our experiment was divided into two stages: preparation and test. Initial setup got the stitching parameters and built background. This reduced time for the test stage. We designed an experiment of moving robot real-time location and control. We used this experiment to test our methods. The experiment results show that we can well achieve dynamic image stitching. {\textcopyright} 2016 IEEE.},
annote = {cited By 3},
author = {Gu, X and Song, P and Rao, Y and Soo, Y G and Yeong, C F and Tan, J T C and Asama, H and Duan, F},
booktitle = {2016 IEEE International Conference on Robotics and Biomimetics, ROBIO 2016},
doi = {10.1109/ROBIO.2016.7866585},
keywords = {Biomimetics; Geometrical optics; Robotics,Environment perceptions; Image information; Image,Image processing},
pages = {1770--1775},
title = {{Dynamic image stitching for moving object}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016825256{\&}doi=10.1109{\%}2FROBIO.2016.7866585{\&}partnerID=40{\&}md5=c5d1592fdd3ed8591bda1212e0cd9359},
year = {2016}
}
@phdthesis{Guan:2010:MDS:1925595,
address = {Chapel Hill, NC, USA},
annote = {AAI3402440},
author = {Guan, Li},
isbn = {978-1-109-74552-8},
publisher = {University of North Carolina at Chapel Hill},
title = {{Multi-view Dynamic Scene Modeling}},
year = {2010}
}
@inproceedings{4584714,
abstract = {An indoor localization and communication project is described that proposes to use RFID (radio-frequency identification) tags, placed in the building beforehand, as navigation waypoints for an inertial navigation system carried by a first responder. RFID devices commonly are attached to persons or to moveable objects so that the objects can be tracked by using fixed readers (special-purpose radio receivers) at different locations. In this project, we explore the "flip side" of this practice. Our concept is that detection of RFID devices in known, fixed locations by a moving reader provides a precise indication of location for tracking the person or moving object that is carrying the reader. This information can then be used to correct for any errors of an inertial tracking system.},
author = {Guerrieri, J R and Francis, M H and Wilson, P F and Kos, T and Miller, L E and Bryner, N P and Stroup, D W and Klein-Berndt, L},
booktitle = {2006 First European Conference on Antennas and Propagation},
doi = {10.1109/EUCAP.2006.4584714},
issn = {2164-3342},
keywords = {indoor radio;inertial navigation;radiofrequency id},
month = {nov},
pages = {1--6},
title = {{RFID-assisted indoor localization and communication for first responders}},
year = {2006}
}
@article{Gnther2017336,
abstract = {This paper presents an approach to creating a semantic map of an indoor environment incrementally and in closed loop, based on a series of 3D point clouds captured by a mobile robot using an RGB-D camera. Based on a semantic model about furniture objects (represented in an OWL-DL ontology with rules attached), we generate hypotheses for locations and 6DoF poses of object instances and verify them by matching a geometric model of the object (given as a CAD model) into the point cloud. The result, in addition to the registered point cloud, is a consistent mesh representation of the environment, further enriched by object models corresponding to the detected pieces of furniture. We demonstrate the robustness of our approach against occlusion and aperture limitations of the RGB-D frames, and against differences between the CAD models and the real objects. We evaluate the complete system on two challenging datasets featuring partial visibility and totaling over 800 frames. The results show complementary strengths and weaknesses of processing each frame directly vs. processing the fully registered scene, which accord with intuitive expectations. {\textcopyright} 2014 Elsevier B.V.},
annote = {cited By 10},
author = {G{\"{u}}nther, M and Wiemann, T and Albrecht, S and Hertzberg, J},
doi = {10.1016/j.artint.2014.12.007},
journal = {Artificial Intelligence},
keywords = {3D point cloud; CAD modeling; Closed loops; Model,Birds; Mapping; Object recognition; Semantics,Computer aided design},
pages = {336--351},
title = {{Model-based furniture recognition for building semantic object maps}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922801530{\&}doi=10.1016{\%}2Fj.artint.2014.12.007{\&}partnerID=40{\&}md5=f8a4c1d1ad74b0c2b515a7d92e96148d},
volume = {247},
year = {2017}
}
@inproceedings{Guo:2007:HSL:1249248.1249873,
address = {Washington, DC, USA},
author = {Guo, Bin and Imai, Michita},
booktitle = {Proceedings of the 21st International Conference on Advanced Networking and Applications},
doi = {10.1109/AINA.2007.76},
isbn = {0-7695-2846-5},
pages = {378--385},
publisher = {IEEE Computer Society},
series = {AINA '07},
title = {{Home-Explorer: Search, Localize and Manage the Physical Artifacts Indoors}},
url = {http://dx.doi.org/10.1109/AINA.2007.76},
year = {2007}
}
@phdthesis{Guo:2009:NSL:1714259,
address = {Boston, MA, USA},
annote = {AAI3357651},
author = {Guo, Dong},
isbn = {978-1-109-15205-0},
publisher = {Boston University},
title = {{A New Statistical Localization Framework for Wireless Sensor Networks}},
year = {2009}
}
@article{6810181,
abstract = {Robust tracking of a human in a video sequence is an essential prerequisite to an increasing number of applications, where a robot needs to interact with a human user or operates in a human-inhabited environment. This paper presents a robust approach that enables a mobile robot to detect and track a human using an onboard RGB-D sensor. Such robots could be used for security, surveillance, and assistive robotics applications. The proposed approach has real-time computation power through a unique combination of new ideas and well-established techniques. In the proposed method, background subtraction is combined with depth segmentation detector and template matching method to initialize the human tracking automatically. A novel concept of head and hand creation based on depth of interest is introduced in this paper to track the human silhouette in a dynamic environment, when the robot is moving. To make the algorithm robust, a series of detectors (e.g., height, size, and shape) is utilized to distinguish target human from other objects. Because of the relatively high computation time of the silhouette-matching-based method, a confidence level is defined, which allows using the matching-based method only where it is imperative. An unscented Kalman filter is used to predict the human location in the image frame to maintain the continuity of the robot motion. The efficacy of the approach is demonstrated through a real experiment on a mobile robot navigating in an indoor environment.},
author = {Gupta, M and Behera, L and Subramanian, V K and Jamshidi, M M},
doi = {10.1109/JSYST.2014.2317777},
issn = {1932-8184},
journal = {IEEE Systems Journal},
keywords = {image filtering;image matching;image segmentation;},
number = {4},
pages = {1363--1375},
title = {{A Robust Visual Human Detection Approach With UKF-Based Motion Tracking for a Mobile Robot}},
volume = {9},
year = {2015}
}
@inproceedings{Gupta20171,
abstract = {With the advancement in the technology, objects can be represented effectively in their 3D digital models which accurately represents their physical counterparts. Navigation services and mapping based on geographical data have become very popular in supporting our everyday lives. Much of these services are currently available mostly for outdoor purposes, however applications for indoor purposes are being explored where most of the human activities takes place. This can help transform cities into "Smart Cities". The aim of this study is to develop an indoor mapping system for data collection in a building environment by exploring new, efficient and cost effective scanning devices. The conventional devices currently in use are expensive which makes them difficult to implement for large scale applications. The data will be collected using a 3D scanning camera technology which develops depth maps of various locations. Xbox's Kinect Sensor and Stereolab's ZED camera are being used and compared in this study. Comparisons based on resolution, lighting, accuracy, speed and memory are being made in this study. Their pros and cons over conventional scanning devices are also discussed. The study shows the possibility of using this technology in a large scale building environment in an autonomous method for the future. This technology can then be potentially used for commercial purposes especially to track progress at construction sites, security purposes, facility management, retail and augmented reality applications. {\textcopyright} 2017 IEEE.},
annote = {cited By 4},
author = {Gupta, T and Li, H},
booktitle = {2017 International Conference on Indoor Positioning and Indoor Navigation, IPIN 2017},
doi = {10.1109/IPIN.2017.8115909},
keywords = {Augmented reality applications; Building environm,Augmented reality; Cameras; Cost effectiveness; In,Smart city},
pages = {1--8},
title = {{Indoor mapping for Smart Cities-An affordable approach: Using kinect sensor and ZED stereo camera}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043604510{\&}doi=10.1109{\%}2FIPIN.2017.8115909{\&}partnerID=40{\&}md5=08f76cd459b2a6dfbe14edf209ccc929},
volume = {2017-Janua},
year = {2017}
}
@inproceedings{Gur2009452,
abstract = {A novel patent pending change detection system (CDS) is presented. We define change detection system as a system that scans the environment and compares, in real time, the current scan with previous scans. This system has both military and civilian robotic applications. It is may be used for detecting changes in fences and their surrounding. It is useful for navigating out doors as well as indoors with no GPS. It is used with collaboration with the European community for a robot inside buildings with crowded areas like airports. Our laser CDS compares pixel by pixel of the environment uses laser collimated beams, so that the resolution is fairly constant (choosing the system parameters so that diffraction effects do not cause great discrepancy) over the whole range. An alarm is given only if the pixel has been really changed. In addition, the use of NIR fiber laser and gating technologies, allows us to operate in day/night and various adverse conditions and exploit the 3D nature of the laser range finder capability. Other solutions like video CDS do not compete with these capabilities. Our system demonstrates relatively high resolution, yet being capable of detecting changes while on the move and operating in about 100 meter environments. The resolution is achieved with accurate laser scanners. The laser CDS is based on three laser scanners. Two lasers are used for calculating the location and attitude of the car with laser scanners. This is achieved by scanning horizontally and vertically a long reference object such as the poles and wires in the case of a fence (or fence like objects) in outdoor applications - or the various openings, corners and entrances of various kinds walls and corridors in indoor applications. All this is possible with the help of appropriate LUT s prepared in a suitable calibration stage. The third laser is used for scanning the surrounding of the fence and is used for change detection. The basic scan, which is the reference for the change detection is obtained in the above mentioned calibration stage. Our feasibility demonstration system was built and driven on railroad along a fence, built for the experiment. The calibration results are shown; the scanning of the fence and its surrounding is clearly demonstrated during the motion of the car. Change detection is demonstrated using object placed near the fence. Our preliminary results clearly show the great potential of the system.},
annote = {cited By 0},
author = {Gur, J},
booktitle = {AUVSI Unmanned Systems North America Conference 2009},
keywords = {Calibration; Data storage equipment; Fences; Fibe,CdS; Change detection; Collimated beams; Diffracti,Three dimensional},
pages = {452--465},
title = {{Laser change detection system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77649223149{\&}partnerID=40{\&}md5=c6246f72e83862da1c8b5099eba7b788},
volume = {1},
year = {2009}
}
@article{Habert1997341,
abstract = {In this paper, an uncertain representation of an indoor environment is used to provide the robot with an a priori map. The major originality of such a representation comes from its human origin. In our specific disabled-oriented application, the on-board person is used as an "intelligent sensor" which provides the system with some pertinent prior knowledge of its environment. No current sensor is able to provide information such as shape, dimensions and location relative evaluation of obstacles, etc. with such accuracy and rapidity. Using a man-made representation raises the problem of uncertainties in interpretation and evaluation. Our solution consists in using proximity relations between the geometrical primitives of the object, thus simply modeling human behavior when representing the surrounding. The dynamic aspect of multivalue number coding is used for the first time which allows real-time alterations of the encoded objects. The proposed dynamic modeling process has been tested in a real indoor environment using an experimental wheelchair equipped with ultrasonic sensors and a dead-reckoning system.},
annote = {cited By 4},
author = {Habert, O and Pruski, A},
doi = {10.1016/S0921-8890(96)00050-4},
journal = {Robotics and Autonomous Systems},
keywords = {Artificial intelligence; Collision avoidance; Imag,Autonomous navigation; Cooperative construction,Mobile robots},
number = {4},
pages = {341--353},
title = {{Cooperative construction and maintenance of maps for autonomous navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031245750{\&}doi=10.1016{\%}2FS0921-8890{\%}2896{\%}2900050-4{\&}partnerID=40{\&}md5=e70e572fdb7607a306bac6f792eca7fb},
volume = {21},
year = {1997}
}
@inproceedings{Hcker200325,
abstract = {This paper describes our current work in developing a vision-based tracking and trajectory prediction system for an aerial robot based on low-cost digital cameras, image processing techniques, and a filtering and prediction algorithm. The system determines the pose (location and orientation) of a miniature airship, online during indoor flight, and will be used in a development framework for a future autonomous flight control system. Object localization is achieved by tracking an infra-red target array mounted to a model airship. Its pose in three-dimensional space can be computed from corresponding points in the images of two cameras which are calibrated in a global coordinate system. The calibration procedure and the localization, as well as some aspects of the measurement accuracy achieved, are discussed. Real-world applications provide an uncertain static or dynamic environment which complicates the tracking of a target. To overcome problems due to noisy data or even failed target detection in image frames, a filtering procedure is applied for estimating the airship's pose. In a first step, points in the two-dimensional image planes are directly tracked and propagated forward to the vehicle pose. In a second step, an adaptive noise Kalman filter is applied for estimating and predicting the flight trajectory. Its state is propagated back to points in the image planes to guide the detection algorithm by defining regions of confidence. Both approaches are combined in a tracking algorithm. In-flight measurements are used to validate the parameters of the adaption procedure. Some experimental results are shown.},
annote = {cited By 6},
author = {H{\"{a}}cker, J and Kr{\"{o}}plin, B.-H.},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.487579},
keywords = {Adaptive filtering; Airships; Algorithms; Calibrat,Digital cameras,Robots},
pages = {25--36},
title = {{An experimental study of visual flight trajectory tracking and pose prediction for the automatic computer control of a miniature airship}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0344945628{\&}doi=10.1117{\%}2F12.487579{\&}partnerID=40{\&}md5=880e7739a134234b82b72f706137c7bc},
volume = {5103},
year = {2003}
}
@article{Ham2018,
abstract = {The field reporting methods in the architecture/engineering/construction and facility management (AEC/FM) industry are in the middle of a major change in terms of how tasks are being conducted in the field. One of the key components in this trend is the reliable capability of localizing distant target objects in need of monitoring and documentation without preinstalled systems in any built environments including Global Positioning System (GPS) and wireless-denied indoor and outdoor environments. This paper proposes a new infrastructure-free approach for three-dimensional (3D) localization of distant target objects by integrating the following two sources of information on a mobile device: (1) embedded motion sensors in the mobile device such as an accelerometer and gyroscope - localizing a user equipped with the mobile device through the probabilistic integration of multiple dead-reckoning paths, which provides the location information of each camera center in the global coordinate system; and (2) an embedded visual sensor (i.e., camera) - localizing distant target objects of interest through the image-based 3D localization by leveraging photos taken from multiviews for the objects. To test the proposed method, several case studies were conducted in an existing instructional facility, and approximately 3{\%} of the averaged distance errors were reported. Experimental results promise that the proposed multimodal mobile sensing and analytics have significant potential to robustly localize distant in-building assets and reduce the drift errors accumulated in proportion to the moving distance. In addition, the stereoscopic view provides more semantics on the distant target objects, which enables practitioners to improve the associated situational awareness about their performance (e.g., the as-is physical condition). The perceived benefits of the proposed mobile computing system and related open research challenges are discussed in detail. {\textcopyright} 2018 American Society of Civil Engineers.},
annote = {cited By 1},
author = {Ham, Y and Yoon, H},
doi = {10.1061/(ASCE)CP.1943-5487.0000767},
journal = {Journal of Computing in Civil Engineering},
keywords = {Cameras; Mobile computing; Mobile devices; Navigat,Dead reckoning; Global coordinate systems; Locali,Global positioning system},
number = {4},
title = {{Motion and Visual Data-Driven Distant Object Localization for Field Reporting}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044646456{\&}doi=10.1061{\%}2F{\%}28ASCE{\%}29CP.1943-5487.0000767{\&}partnerID=40{\&}md5=268534fb00e71a6248c02e873fd6dd7f},
volume = {32},
year = {2018}
}
@inproceedings{8628462,
abstract = {During recent years, the use of real-time location tracking technologies has increased immensely in many industries. Many GPS based apps such as Google maps are widely being used almost everywhere for this purpose. However despite being widely used these apps can only be helpful for tracking locations that can be found on geographical map i.e. outdoor locations only. Whereas in order to locate a position in an indoor environment, GPS shows a lot of inconsistencies, therefore, it calls for using an entirely different approach. This is due to the higher diversity of the semantic interpretations by which closed environments are characterized. This fact makes the visual contact with the GPS satellite difficult hence making GPS technology an unreliable technique for determining positions of objects in indoor places. Hence for efficiently tracking such locations, many other technologies are being used. This research provides a thematic analysis of various indoor positioning applications that are developed based on different technologies. This paper also includes a practical implementation of an indoor positioning technique that is best suitable for locating positions of objects in a shopping mart's navigation module.},
author = {Hameed, A and Ahmed, H A},
booktitle = {2018 12th International Conference on Mathematics, Actuarial Science, Computer Science and Statistics (MACS)},
doi = {10.1109/MACS.2018.8628462},
keywords = {Global Positioning System;indoor radio;indoor posi},
month = {nov},
pages = {1--5},
title = {{Survey on indoor positioning applications based on different technologies}},
year = {2018}
}
@inproceedings{Hamer2011126,
abstract = {GPS is widely used to pinpoint locations of objects in many locations. One of the major shortcomings of the GPS systems is its inability to work indoors. GPS requires line of sight access to three satellites in geosynchronous orbit about the Earth. When sending rescue workers into a building after a catastrophe such as an earthquake, it is desirable to be able to correctly location such personnel. This research proposes using commodity 802.11 wireless access points deployed around the site to correctly locate persons wearing an 802.11 transmitter. In this research we also propose to use off the shelf WiFi device, which significantly contributes to the real-world practicability of this research. Copyright {\textcopyright} 2011 by the International Society for Computers and Their Applications (ISCA).},
annote = {cited By 0},
author = {Hamer, G and Fourney, R and Wang, W and Vaidya, A},
booktitle = {Proceedings of the ISCA 26th International Conference on Computers and Their Applications, CATA 2011},
keywords = {802.11 networks; Geosynchronous orbits; Line-of-si,Computer applications; Research; Ubiquitous compu,Tracking (position)},
pages = {126--131},
title = {{Using 802.11 signal strength for indoor location tracking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871980556{\&}partnerID=40{\&}md5=5df40dc706ae082e0c0c35b9969a2e6f},
year = {2011}
}
@article{Han2013295,
abstract = {Video On Demand (VOD) service that allows users to select and watch video content is the most popular IPTV service and it is known that most of Internet traffic is for VOD service. It would be very attractive if a VOD service correctly recognizes the situation where the user wants to watch a video, finds out what video the user wants to watch, and actively plays the video for the user. Our VOD system does those things and is called Smart VOD. Smart VOD is a client-server system. The client is an Android app that collects sensor values, displays a floor map, and plays a video. The main components of the server are the floor maps repository system and the VOD server. The repository system allows users to upload electronic floor maps, draws maps, retrieves the requested floor map, downloads a graphical floor map, and manages information of points of interest. The VOD manages information of users, determines user's current location, and recognizes the object that the user is watching. This paper describes implementation detail of the whole system. {\textcopyright}2013 SERSC.},
annote = {cited By 0},
author = {Han, C and Yim, J},
doi = {10.14257/ijsh.2013.7.6.28},
journal = {International Journal of Smart Home},
keywords = {Android app; Client-server systems; Indoor positio,Floors; IPTV; Robots; Watches,Video on demand},
number = {6},
pages = {295--304},
title = {{Implementation of a smart VOD system prototype}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891823311{\&}doi=10.14257{\%}2Fijsh.2013.7.6.28{\&}partnerID=40{\&}md5=7c65fd98c2ddce673ff13e23ae7105d2},
volume = {7},
year = {2013}
}
@article{Han2012,
abstract = {Radio Frequency Identification (RFID) becomes a prevalent labeling and localizing technique in the recent years. Deploying indoor RFID localization systems facilitates many applications. Previous approaches, however, are most based on 2D design and cannot provide 3D location information. The lack of one-dimensional information may lead 2D-based systems to inaccurate localization. In this paper, we develop an indoor 3D RFID localization system based on active tag array. In particular, we employ the geometric mean to filter the explicit 3D location information with high accuracy. The experimental results show that our system is efficient in tracking objects and improving the localization accuracy. {\textcopyright} Copyright 2012 Jinsong Han et al.},
annote = {cited By 8},
author = {Han, J and Zhao, Y and Cheng, Y S and Wong, T L and Wong, C H},
doi = {10.1155/2012/865184},
journal = {International Journal of Distributed Sensor Networks},
keywords = {Active tag; Geometric mean; Localization accuracy;,Radio frequency identification (RFID),Three dimensional},
title = {{Improving accuracy for 3D RFID localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862297627{\&}doi=10.1155{\%}2F2012{\%}2F865184{\&}partnerID=40{\&}md5=e5346677fc2e799d89581ec6bf0a748a},
volume = {2012},
year = {2012}
}
@inproceedings{Handa20165737,
abstract = {We introduce Scenenet, a framework for generating high-quality annotated 3D scenes to aid indoor scene understanding. Scenenet leverages manually-annotated datasets of real world scenes such as nYUv2 to learn statistics about object co-occurrences and their spatial relationships. Using a hierarchical simulated annealing optimisation, these statistics are exploited to generate a potentially unlimited number of new annotated scenes, by sampling objects from various existing databases of 3D objects such as Modelnet, and textures such as OpenSurfaces and ArchiveTextures. Depending on the task, Scenenet can be used directly in the form of annotated 3D models for supervised training and 3D reconstruction benchmarking, or in the form of rendered annotated sequences of RGB-D frames or videos. {\textcopyright} 2016 IEEE.},
annote = {cited By 12},
author = {Handa, A and Patraucean, V and Stent, S and Cipolla, R},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2016.7487797},
keywords = {3D reconstruction; Annotated datasets; Co-occurre,Content based retrieval; Robotics; Sampling; Simul,Three dimensional computer graphics},
pages = {5737--5743},
title = {{Scenenet: An annotated model generator for indoor scene understanding}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977576539{\&}doi=10.1109{\%}2FICRA.2016.7487797{\&}partnerID=40{\&}md5=88634629312e1cebb7436fda388d0945},
volume = {2016-June},
year = {2016}
}
@inproceedings{Hanel2018433,
abstract = {Visual SLAM algorithms allow localizing the camera by mapping its environment by a point cloud based on visual cues. To obtain the camera locations in a metric coordinate system, the metric scale of the point cloud has to be known. This contribution describes a method to calculate the metric scale for a point cloud of an indoor environment, like a parking garage, by fusing multiple individual scale values. The individual scale values are calculated from structures and objects with a-priori known metric extension, which can be identified in the unscaled point cloud. Extensions of building structures, like the driving lane or the room height, are derived from density peaks in the point distribution. The extension of objects, like traffic signs with a known metric size, are derived using projections of their detections in images onto the point cloud. The method is tested with synthetic image sequences of a drive with a front-looking mono camera through a virtual 3D model of a parking garage. It has been shown, that each individual scale value improves either the robustness of the fused scale value or reduces its error. The error of the fused scale is comparable to other recent works. {\textcopyright} Authors 2018.},
annote = {cited By 0},
author = {Hanel, A and Mitschke, A and Boerner, R and {Van Opdenbosch}, D and Hoegner, L and Brodie, D and Stilla, U},
booktitle = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
doi = {10.5194/isprs-archives-XLII-2-433-2018},
keywords = {Building structure; Camera locations; Co-ordinate,Cameras; Conformal mapping; Indoor positioning sys,Garages (parking)},
number = {2},
pages = {433--440},
title = {{Metric scale calculation for visual mapping algorithms}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048368313{\&}doi=10.5194{\%}2Fisprs-archives-XLII-2-433-2018{\&}partnerID=40{\&}md5=2580fe4620bd90a0d41fe74bb0060b22},
volume = {42},
year = {2018}
}
@article{Hanford2014714,
abstract = {Cognitive architectures, computer programs that define mechanisms that are important for domain-independent intelligent behavior, have the potential for generating intelligent and autonomous behavior in unmanned vehicles. The cognitive robotic system has demonstrated how the Soar cognitive architecture can be integrated with common robotic motor and perceptual systems that complement the strengths of Soar for unmanned vehicle control. The cognitive robotic system has been tested using an indoor search mission, during which the cognitive robotic system searches a building for common intersection types and an object of interest using information from robotic mapping, computer vision, and fuzzy logic algorithms. The Soar agent builds a topological map of the environment, using information about the intersections the cognitive robotic system detects, and it uses this topological model to make intelligent decisions about how to effectively search the building. Once the object of interest has been detected, the Soar agent uses the topological map to make decisions about how to efficiently return to the location where the mission started as well as to generate step-by-step directions using the intersections in the environment as landmarks that describe a direct path from the mission's start location to the object of interest. Copyright {\textcopyright} 2014 by Scott D. Hanford and Lyle N. Long. Published by the American Institute of Aeronautics and Astronautics, Inc., with permission.},
annote = {cited By 1},
author = {Hanford, S D and Long, L N},
doi = {10.2514/1.I010191},
journal = {Journal of Aerospace Information Systems},
keywords = {Autonomous behaviors; Cognitive architectures; Do,Cognitive systems; Computer architecture; Computer,Robotics},
number = {10},
pages = {714--725},
title = {{Development of a mobile robot system based on the soar cognitive architecture}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936879880{\&}doi=10.2514{\%}2F1.I010191{\&}partnerID=40{\&}md5=87729616c517a761746b7f2db6da77c4},
volume = {11},
year = {2014}
}
@phdthesis{Hanford:2011:CRS:2521169,
address = {University Park, PA, USA},
annote = {AAI3501001},
author = {Hanford, Scott D},
isbn = {978-1-267-21706-6},
publisher = {Pennsylvania State University},
title = {{A Cognitive Robotic System Based on the Soar Cognitive Architecture for Mobile Robot Navigation, Search, and Mapping Missions}},
year = {2011}
}
@article{Haque:2014:SBI:2664677.2664791,
address = {London, UK, UK},
author = {Haque, Israat Tanzeena},
doi = {10.1016/j.jnca.2014.06.001},
issn = {1084-8045},
journal = {J. Netw. Comput. Appl.},
keywords = {Fingerprint based localization,Indoor localization,Localization error,RF-based localization,Received signal strength,Robust localization},
pages = {220--229},
publisher = {Academic Press Ltd.},
title = {{A Sensor Based Indoor Localization Through Fingerprinting}},
url = {http://dx.doi.org/10.1016/j.jnca.2014.06.001},
volume = {44},
year = {2014}
}
@inproceedings{Harle2007,
abstract = {As location systems provide increasingly fine-grained locations for mobile entities, location-aware systems that react appropriately and autonomously to location events will be in demand. Although much research has been devoted to indexing schemes for very large scale GIS applications (where the systems are predominantly query-based), comparably little attention has been given to the use of spatial indexing within location-aware systems leveraging local positioning systems (predominantly event-based). This paper reviews the notion of spatial indexing (the representation of a tracked user's space to facilitate spatial event generation based on incoming locations) for event-based systems. It establishes the principles and requirements of a wide-area spatial indexer, reviews the R-tree, Quadtree and RQ-tree methods proposed before for indoor location-awareness, and significantly adapts the latter to meet the requirements. The proposed indexing method uses a combination of R-trees (for high level spatial information, down to structural level) and Quadtrees (for lower level representation of objects). It proposes the use of linear Quadtrees to exploit the ease of direct node movement rather than the re-rasterisation of polygons used in systems to date. This approach is compared in simulation with other approaches.},
annote = {cited By 2},
author = {Harle, R K},
booktitle = {Proceedings of the 4th Annual International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services, MobiQuitous 2007},
doi = {10.1109/MOBIQ.2007.4451027},
keywords = {Decision trees; Indexing (of information); Locatio,Event-based systems; GIS applications; Indexing m,Ubiquitous computing},
title = {{Spatial indexing for location-aware systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-50249090977{\&}doi=10.1109{\%}2FMOBIQ.2007.4451027{\&}partnerID=40{\&}md5=9747be6d853092dfd85ab4243496e1b6},
year = {2007}
}
@inproceedings{Harris2008,
abstract = {A system has been developed to enable a robot vehicle to autonomously explore and map an indoor environment using only visual sensors. The vehicle is equipped with a single camera, whose output is wirelessly transmitted to an off-board standard PC for processing. Visual features within the camera imagery are extracted and tracked, and their 3D positions are calculated using a Structure from Motion algorithm. As the vehicle travels, obstacles in its surroundings are identified and a map of the explored region is generated. This paper discusses suitable criteria for assessing the performance of the system by computer-based simulation and practical experiments with a real vehicle. Performance measures identified include the positional accuracy of the 3D map and the vehicle's location, the efficiency and completeness of the exploration and the system reliability. Selected results are presented and the effect of key system parameters and algorithms on performance is assessed. This work was funded by the Systems Engineering for Autonomous Systems (SEAS) Defence Technology Centre established by the UK Ministry of Defence. {\textcopyright} 2008 SPIE.},
annote = {cited By 0},
author = {Harris, C and Evans, R and Tidey, E},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.800100},
keywords = {3D positions; Autonomous exploration; Autonomous s,Cameras; Computer vision; Object recognition; Rob,Sensor networks},
title = {{Assessment of a visually guided autonomous exploration robot}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-62449244083{\&}doi=10.1117{\%}2F12.800100{\&}partnerID=40{\&}md5=6165cd15a4f209d50b75dfcd5980aa2c},
volume = {7112},
year = {2008}
}
@inproceedings{7156024,
abstract = {The importance of location based services (LBS) has largely increased for consumer applications and becoming more and more relevant in industrial applications. For example location dependent information can support occupational safety staff to ensure the safety at work in emergency scenarios. In outdoor environments localization can be obtained easily by using a global navigation satellite system (GNSS). For harsh indoor environments, however, where most industrial applications require localization, an accurate localization remains a challenge in general. In this paper we present a hybrid localization system enabling navigation in challenging environments. The hybrid system fuses received signal strength (RSS) based wireless sensor network (WSN) ranging and a foot mounted inertial measurement unit (IMU). The key contribution of this paper is a hybrid localization concept and experimental results using a deployed system in an industrial environment. We characterize the wireless sensor network signal propagation and evaluate the magnetic field for heading stabilization in such environments. The accuracy analysis shows a typical error of 2 meters. In comparison to a pure inertial navigation system (INS) approach, we demonstrate the enhancements introduced by the combination of an inertial navigation system and a wireless sensor network received signal strength based localization.},
author = {Hartmann, F and Gaedeke, T and Leibold, P and Niestoruk, L and Stork, W},
booktitle = {Smart SysTech 2014; European Conference on Smart Objects, Systems and Technologies},
doi = {10.1109/SmartSysTech.2014.7156024},
keywords = {Wireless sensor networks;Sensors;Smart phones;Navi},
pages = {1--8},
title = {{Navigation for Occupational Safety in Harsh Industrial Environments}},
year = {2014}
}
@inproceedings{7750889,
abstract = {Location based services (LBS), in the context of Industry 4.0 and Internet of Things (IoT), provide new possibilities to optimize many processes in industry. Logistics on a construction site, for example, can be optimized by finding the most efficient route, to ensure on the point deliveries and further tracking of delivered goods. Although a key factor for their appliance is a tight cost-value ratio. Therefore localization systems need to conciliate constraints from the application-specific and the system's inherent properties. The availability of electrical power, the network density, the lifetime of the localization system and its accuracy represent an example of conditioned constraints, especially in dynamic environments with no fixed infrastructure. In this paper, we present an energy aware two-staged localization concept, considering power and cost constraints while preserving high position update rates and long system lifetimes. For this purpose a low power wireless sensor network is combined with a high update rate wireless sensor network. As the key contribution of this paper achievable accuracies in such an two staged localization system are evaluated.},
author = {Hartmann, F and Worms, K and Pistorius, F and Wanjek, M and Stork, W},
booktitle = {Smart SysTech 2016; European Conference on Smart Objects, Systems and Technologies},
pages = {1--6},
title = {{Energy Aware, Two-staged Localization Concept for Dynamic Indoor Environments}},
year = {2016}
}
@inproceedings{8657642,
abstract = {Today scientific knowledge relentlessly bringing change and comfort in day to day life. In Present generation, an autonomous robot has been a popular technology which is widely used in many areas. Robots are used to share the work and act more autonomously in performing the jobs faster than humans. Usually, Robots are more intelligent with endless energy levels and more precise in handling the jobs perfectly. However, the proposed robot design is about researching and investigating hazardous environments, exploration, remote assistance and Military services. In the given system design, a robot system is built to monitor and identify the motion in achieving better security and surveillance of indoor environments. This autonomous system is built by using an embedded system to perform specific tasks and function as defined. This robotic system has five different systems such as robotic arms for pick and place of the objects from conveyor belts, an ultrasonic sensor for distance calculation, a visionary system for recording the motion of invader and sending the pictures through video transmission system through a network. Fire sensor is used for detection of fire and a giving alarm in the environment. The location of the robotic system is defined with GPS longitude and latitude values. This information is sent through a network using things speak and the same information is displayed on the LCD. A GSM message is sent through mobile for giving an alert about the operation. The robot designed has two modes of operation. One is the autonomous mode, and the other is the manual mode using a remote supervisory system. The deigned work combines the sensory and remote supervising system for better robotic security. The path planning is also carried out in a robotic system for achieving the motion in real time and obstacle avoidance. In the carried work the results are clearly discussed and overall work is defined with the coding details as well.},
author = {Hasan, R and {Asif Hussain}, S and {Azeemuddin Nizamuddin}, S and Mahmood, S},
booktitle = {2018 9th IEEE Control and System Graduate Research Colloquium (ICSGRC)},
doi = {10.1109/ICSGRC.2018.8657642},
keywords = {Robot sensing systems;Security;DC motors;Service r},
pages = {201--206},
title = {{An Autonomous Robot for Intelligent Security Systems}},
year = {2018}
}
@article{Hasnath2016164,
abstract = {With the recent development of smartphone technologies and indoor positioning systems, it is now possible to provide a large variety of location-based services (LBSs) in indoor spaces. Due to the complex nature of indoor space modeling (i.e. re-creating floor plans), the applicability of indoor LBS has been limited to few big installations such as airports, big shopping centers, etc. To facilitate the growth of indoor LBSs to end users, we overcome this major limitation of indoor space recreation by automatically converting an AutoCad DXF file, the most widely used design format, to a Spatialite database for smartphones. We develop algorithms that first pre-process the data from a DXF file and then effectively recognize rooms, doors, corridors and obstacles, and finally convert these objects for indoor space navigation through smartphones. We develop a working prototype, AutoCadroid, in Android that enables a user to build her own indoor navigation system of her own office or home from an AutoCad DXF file. {\textcopyright} Springer International Publishing AG 2016.},
annote = {cited By 0},
author = {Hasnath, S and Ali, M E and Abdullah, M K and Farhad, S M},
doi = {10.1007/978-3-319-46922-5_13},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {AutoCAD files; Automated tools; Complex nature; D,Database systems; Location based services; Navigat,Indoor positioning systems},
pages = {164--176},
title = {{AutoCadroid: An automated tool for building smartphone indoor navigation system from AutoCad files}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990049616{\&}doi=10.1007{\%}2F978-3-319-46922-5{\_}13{\&}partnerID=40{\&}md5=1a9bc389a3a487efff18f7732184005b},
volume = {9877 LNCS},
year = {2016}
}
@inproceedings{7754772,
abstract = {This paper introduces the design and implementation of a Bluetooth based on indoor location tracking system. This system utilizes the integrated Bluetooth modules in any today's mobile phones to specify and display the location of the individuals in a certain building. The proposed system aim for location tracking/monitoring and marketing applications for whom want to locate individuals carrying mobile phones and advertise products and services. It is an integrated embedded and desktop system that helps the user to get the location of customers/inhabitants/employee within a certain region. The system is composed of a Server Module which is a java application that runs over desktop PC and is used to display the locations of the nearby mobile phones and send location based advertising message. This paper is aimed also to enhance the system positioning estimation accuracy by choosing the suitable number of neurons used in the neural network.},
author = {Hassan, A M A},
booktitle = {2016 International Conference on Electrical, Electronics, and Optimization Techniques (ICEEOT)},
doi = {10.1109/ICEEOT.2016.7754772},
keywords = {Bluetooth;indoor navigation;mobile computing;mobil},
pages = {73--78},
title = {{Indoor location tracking system using neural network based on bluetooth}},
year = {2016}
}
@inproceedings{4554642,
abstract = {The proliferation of mobile computing devices and wireless geolocation networks has fostered a growing interest in location-aware systems and devices. Most technologies always use at least three base stations for computing the position of the target objects, including RFID (radiofrequency identification). This paper suggests a novel algorithm, using the RFID-system, to support one reader for localizing target tags amid the clutter of indoor interference environments, based on the metrics of the received signal strength and the time of flight. This algorithm attempts to specify the target tag among four-nearest neighbors as the four-reference tags, and adapt the weighted-center of gravity technique. The method provides a level of accuracy of about 1.07 m as the total error average of positioning 10-target tags in various interference environments that are generated on all sector-functions. The total error averages of the 3-6 sectors functions are 1.18 m, 0.74 m, 1.6 m, and 0.78 m on one reader in an area of 12 m by 10 m. The effects of interference in the simulation indicated that the accuracy is better for the even-sector-functions as the input-signals' generator for this algorithm.},
author = {Hatthasin, U and Vibhatavanij, K and Worasawate, D},
booktitle = {2007 Asia-Pacific Microwave Conference},
doi = {10.1109/APMC.2007.4554642},
issn = {2165-4727},
keywords = {clutter;Global Positioning System;radiofrequency i},
pages = {1--4},
title = {{One Base Station Approach for Indoor Geolocation System using RFID}},
year = {2007}
}
@article{Havasi2007503,
abstract = {This paper presents a robust walk-detection algorithm, based on our symmetry approach which can be used to extract gait characteristics from video-image sequences. To obtain a useful descriptor of a walking person, we temporally track the symmetries of a person's legs. Our method is suitable for use in indoor or outdoor surveillance scenes. Determining the leading leg of the walking subject is important, and the presented method can identify this from two successive walk steps (one walk cycle). We tested the accuracy of the presented walk-detection method in a possible application: Image registration methods are presented which are applicable to multicamera systems viewing human subjects in motion. {\textcopyright} 2006 IEEE.},
annote = {cited By 33},
author = {Havasi, L and Szl{\'{a}}vik, Z and Szir{\'{a}}nyi, T},
doi = {10.1109/TIP.2006.888339},
journal = {IEEE Transactions on Image Processing},
keywords = {Algorithms; Artificial Intelligence; Computer Sec,Automated; Reproducibility of Results; Sensitivit,Biological; Pattern Recognition,Computer-Assisted; Imaging,Image registration,Motion compensation; Motion estimation; Motion pic,Three-Dimensional; Information Storage and Retrie,Video-image sequence; Walk-detection algorithm,algorithm; article; artificial intelligence; auto},
number = {2},
pages = {503--510},
title = {{Detection of gait characteristics for scene registration in video surveillance system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847744668{\&}doi=10.1109{\%}2FTIP.2006.888339{\&}partnerID=40{\&}md5=4717cca5a6d761bf45f2c4886a136c4b},
volume = {16},
year = {2007}
}
@article{Hayashi2008346,
abstract = {Autonomous and mobile robots are being expected to provide various services in human living environments. However, many problems remain to be solved in the development of autonomous robots that can work like humans. When a robot moves, it is important that it be able to have self-localization abilities and recognize obstacles. For a human, the present location can be correctly checked through a comparison between memorized information assuming, it is correct, and the present situation. In addition, the distance to an object and the perception of its size can be estimated by a sense of distance based on memory or experience. Therefore, the environment for robotic activity assumed in this study was a finite-space such as a family room, an office, or a hospital room. Because an accurate estimation of position is important to the success of a robot, we have developed a navigation system with self-localization ability which uses only a CCD camera that can detect whether the robot is moving accurately in a room or corridor. This article describes how this system has been implemented and tested with our developed robot. {\textcopyright} 2008 International Symposium on Artificial Life and Robotics (ISAROB).},
annote = {cited By 5},
author = {Hayashi, E},
doi = {10.1007/s10015-007-0488-y},
journal = {Artificial Life and Robotics},
keywords = {Accurate estimation; Autonomous navigation; Autono,Cameras; Mobile robots; Navigation systems,Navigation},
number = {1-2},
pages = {346--352},
title = {{Navigation system for an autonomous robot using an ocellus camera in an indoor environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-58049207615{\&}doi=10.1007{\%}2Fs10015-007-0488-y{\&}partnerID=40{\&}md5=1144257b44b3775d3dc5f57be133981d},
volume = {12},
year = {2008}
}
@article{Hayashi2009324,
abstract = {We have developed a technology for a robot that uses an indoor navigation system based on visual methods to provide the required autonomy. For robots to run autonomously, it is extremely important that they are able to recognize the surrounding environment and their current location. Because it was not necessary to use plural external world sensors, we built a navigation system in our test environment that reduced the burden of information processing mainly by using sight information from a monocular camera. In addition, we used only natural landmarks such as walls, because we assumed that the environment was a human one. In this article we discuss and explain two modules: a self-position recognition system and an obstacle recognition system. In both systems, the recognition is based on image processing of the sight information provided by the robot's camera. In addition, in order to provide autonomy for the robot, we use an encoder and information from a two-dimensional space map given beforehand. Here, we explain the navigation system that integrates these two modules. We applied this system to a robot in an indoor environment and evaluated its performance, and in a discussion of our experimental results we consider the resulting problems. {\textcopyright} 2009 International Symposium on Artificial Life and Robotics (ISAROB).},
annote = {cited By 7},
author = {Hayashi, E and Kinoshita, T},
doi = {10.1007/s10015-009-0671-4},
journal = {Artificial Life and Robotics},
keywords = {Autonomous mobile robot; Indoor environment; Indoo,Cameras; Data processing; Information use; Mobile,Navigation},
number = {3},
pages = {324--328},
title = {{Development of an indoor navigation system for a monocular-vision-based autonomous mobile robot}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-72449161242{\&}doi=10.1007{\%}2Fs10015-009-0671-4{\&}partnerID=40{\&}md5=f501478cfc7932e4b765ee3a82742075},
volume = {14},
year = {2009}
}
@article{Hayat20164829,
abstract = {Unlike standard object classification, where the image to be classified contains one or multiple instances of the same object, indoor scene classification is quite different since the image consists of multiple distinct objects. Furthermore, these objects can be of varying sizes and are present across numerous spatial locations in different layouts. For automatic indoor scene categorization, large-scale spatial layout deformations and scale variations are therefore two major challenges and the design of rich feature descriptors which are robust to these challenges is still an open problem. This paper introduces a new learnable feature descriptor called 'spatial layout and scale invariant convolutional activations' to deal with these challenges. For this purpose, a new convolutional neural network architecture is designed which incorporates a novel 'spatially unstructured' layer to introduce robustness against spatial layout deformations. To achieve scale invariance, we present a pyramidal image representation. For feasible training of the proposed network for images of indoor scenes, this paper proposes a methodology, which efficiently adapts a trained network model (on a large-scale data) for our task with only a limited amount of available training data. The efficacy of the proposed approach is demonstrated through extensive experiments on a number of data sets, including MIT-67, Scene-15, Sports-8, Graz-02, and NYU data sets. {\textcopyright} 2016 IEEE.},
annote = {cited By 11},
author = {Hayat, M and Khan, S H and Bennamoun, M and An, S},
doi = {10.1109/TIP.2016.2599292},
journal = {IEEE Transactions on Image Processing},
keywords = {Convolution; Deformation; Distributed computer sys,Convolutional neural network; Image representatio,Image classification},
number = {10},
pages = {4829--4841},
title = {{A Spatial Layout and Scale Invariant Feature Representation for Indoor Scene Classification}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986208898{\&}doi=10.1109{\%}2FTIP.2016.2599292{\&}partnerID=40{\&}md5=05671cc9fbd6758170c76ad11ad74f58},
volume = {25},
year = {2016}
}
@inproceedings{Heidari200656,
abstract = {In TOA based indoor geolocation systems ranging error is a function of the bandwidth of the system and the availability of the direct path between the transmitter and the receiver. With a Detected Direct Path (DDP) condition and UWB transmission, precise range estimates are feasible while in Undetected Direct Path (UDP) conditions large ranging errors occur which can not be cured with the increase of the transmission power or bandwidth. This paper uses Markov chain and the results of measurement calibrated Ray Tracing with 500MHz bandwidth in a typical office environment to introduce a novel model for the behavior of the ranging errors observed by a randomly moving mobile terminal in an indoor area. The model divides the behavior of the ranging error into three categories. The first is DDP where the errors are usually small and mainly caused by multipath. The second category, Natural UDP (NUDP), is caused by path-loss and exhibits medium ranging errors. The third category, Shadowed UDP (SUDP), is caused by objects blocking the direct path and demonstrates very large ranging errors. Parameters of the Markov model are calculated from the results of wideband channel characteristics for different locations of a mobile. Results of the simulated errors from the modeling and the actual errors from the channel profile show close agreement. {\textcopyright} 2006 IEEE.},
annote = {cited By 7},
author = {Heidari, M and Pahlavan, K},
booktitle = {IEEE Vehicular Technology Conference},
doi = {10.1109/VTCF.2006.22},
keywords = {Bandwidth; Computer simulation; Errors; Markov pr,Channel modeling; Detected Direct Path (DDP); Geol,Dynamic models},
pages = {56--60},
title = {{A model for dynamic behavior of ranging errors in TOA-based indoor geolocation systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548853760{\&}doi=10.1109{\%}2FVTCF.2006.22{\&}partnerID=40{\&}md5=721f04f66716182a38d0ad4e06ace857},
year = {2006}
}
@inproceedings{Hengzhou:2014:ILS:2606264.2606887,
address = {Washington, DC, USA},
author = {Hengzhou, Zhu and Fuqiang, Liu and Hao, Zhou},
booktitle = {Proceedings of the 2014 Sixth International Conference on Measuring Technology and Mechatronics Automation},
doi = {10.1109/ICMTMA.2014.84},
isbn = {978-1-4799-3435-5},
keywords = {Distance Relative Attenuation,Fingerprinting,Indoor Location,Wifi},
pages = {341--344},
publisher = {IEEE Computer Society},
series = {ICMTMA '14},
title = {{Indoor Location Service Based on Fingerprinting and Distance Relative Attenuation Model}},
url = {https://doi.org/10.1109/ICMTMA.2014.84},
year = {2014}
}
@inproceedings{Hernandez-Alamilla2006,
abstract = {This paper introduces a global localization system based on natural landmarks for indoor mobile robots. The proposed approach is based on recognition of natural landmarks from laser scanner data. A previously built grid-based map is pre-processed off-line to obtain a model of landmarks and their attributes for each cell. The robot's position and orientation are calculated by finding correspondence between the identified landmarks from robot's current position and the landmarks associated to the model. This proposed approach called GL2 follows a two stage process. Initially a fast initial filter based on the number and type of landmarks is used to substantially reduce the search space. The second stage uses a modified discrete relaxation algorithm to perform a more detailed analysis and find the robot's location and orientation. It is shown the robustness of the algorithm in complex and real office like environments, even in the presence of previously unknown obstacles. {\textcopyright} 2006 IEEE.},
annote = {cited By 12},
author = {Hernandez-Alamilla, S F and Morales, E F},
booktitle = {2006 IEEE Conference on Robotics, Automation and Mechatronics},
doi = {10.1109/RAMECH.2006.252692},
keywords = {Algorithms; Global optimization; Mathematical mode,Global localization; Grid maps; Natural landmarks,Object recognition},
title = {{Global localization of mobile robots for indoor environments using natural landmarks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547277530{\&}doi=10.1109{\%}2FRAMECH.2006.252692{\&}partnerID=40{\&}md5=38b6e7ab88589e3af7994e58fa3fcbee},
year = {2006}
}
@article{Hernandez:2008:AIW:2275720.2279617,
address = {Piscataway, NJ, USA},
author = {Hernandez, A and Badorrey, R and Choliz, J and Alastruey, I and Valdovinos, A},
doi = {10.1109/TCE.2008.4560103},
issn = {0098-3063},
journal = {IEEE Trans. on Consum. Electron.},
number = {2},
pages = {381--389},
publisher = {IEEE Press},
title = {{Accurate Indoor Wireless Location with IR UWB Systems a Performance Evaluation of Joint Receiver Structures and TOA Based Mechanism}},
url = {http://dx.doi.org/10.1109/TCE.2008.4560103},
volume = {54},
year = {2008}
}
@inproceedings{1613610,
abstract = {Determining the physical location of indoor objects is a key issue in ubiquitous computing. Although there have been many proposals to provide physical location, these have had several restrictions such as dependence on the type and size of objects and trade-offs between location accuracy and the number of sensing devices. We propose an approach to removing these restrictions using mobile detectors. This paper describes the design of a goods tracking system called MobiTra that estimates the locations of any indoor objects using detection histories sent by mobile detectors. MobiTra is separated by several components and two data flows. A prototype for MobiTra was developed using an active RF system and Cricket, which can obtain a high degree of accuracy. We evaluated how accurately MobiTra estimated location in an environment that generated MTR errors. The errors affected the size of the estimated area and its position. We propose a new method of estimating location to be used in environments that generate MTR errors.},
author = {Hida, K and Mizutani, M and Miyamaru, T and Mineno, H and Miyauchi, N and Mizuno, T},
booktitle = {2006 1st International Symposium on Wireless Pervasive Computing},
doi = {10.1109/ISWPC.2006.1613610},
keywords = {mobile radio;indoor radio;radio tracking;goods tra},
month = {jan},
pages = {6 pp.--6},
title = {{Design of goods tracking system with mobile detectors}},
year = {2006}
}
@phdthesis{Hightower:2004:LS:1086906,
address = {Seattle, WA, USA},
annote = {AAI3151613},
author = {Hightower, Jeffrey},
isbn = {0-496-12032-8},
publisher = {University of Washington},
title = {{The Location Stack}},
year = {2004}
}
@article{Hile:2008:POI:1443191.1443199,
address = {Los Alamitos, CA, USA},
author = {Hile, Harlan and Borriello, Gaetano},
doi = {10.1109/MCG.2008.80},
issn = {0272-1716},
journal = {IEEE Comput. Graph. Appl.},
keywords = {Location-based services,assistive technologies,augmented reality,mobile applications,ubiquitous computing,visual navigation},
number = {4},
pages = {32--39},
publisher = {IEEE Computer Society Press},
title = {{Positioning and Orientation in Indoor Environments Using Camera Phones}},
url = {https://doi.org/10.1109/MCG.2008.80},
volume = {28},
year = {2008}
}
@inproceedings{4022257,
abstract = {We consider a wireless data access scenario where a centralized server provides data items to its clients with a fee. To reduce the total charges incurred, clients perform "peer-to-peer (P2P) sharing" - clients exchange data items at a lower cost. Specifically, P2P sharing cost is determined by two factors: energy and bandwidth. Neighboring clients share data objects among themselves if it is mutually beneficial. This would inevitably lead to reduced server's revenue. We investigate the effectiveness in using pricing as a strategy for the server to indirectly regulate the amount of P2P sharing. We propose an auction pricing mechanism that allows clients to bid for their desired data objects. Simulation results show that the proposed pricing strategy effectively deters sharing in lightly-loaded network while judiciously leverages sharing when the network is congested},
author = {{Ho Yeung}, M K and Kwok, Y},
booktitle = {2006 IEEE 17th International Symposium on Personal, Indoor and Mobile Radio Communications},
doi = {10.1109/PIMRC.2006.253996},
issn = {2166-9570},
keywords = {client-server systems;data communication;game theo},
pages = {1--5},
title = {{On Maximizing Revenue for Client-Server Based Wireless Data Access in the Presence of Peer-To-Peer Sharing}},
year = {2006}
}
@article{Hoene200933,
abstract = {In order to simplify processes in logistics, warehousing, and surveillance, our interdisciplinary joint project AmbiSense has combined solutions for efficient acquisition and mapping of environments. These environments are equipped with diverse ambient technology such as WLAN, Bluetooth, and RFID. The research is based on techniques stemming from the fields of robotics, embedded systems, augmented reality (AR) and Enterprise Resource Planning (ERP).More precisely, we present a novel complete system for machine-aided inventory. Our system covers automatic product identification using RFID, localization based on ambient sensors, the enrichment of raw RFID data with product information from ERP backend systems and real-time augmented reality visualization.One key component of our project is the continuous integration of all developed algorithms and techniques into a real-world demonstrator to illustrate their practicability and usefulness. We have chosen warehousing and retail as our current application scenario: Robot-assisted inventory is applied in a supermarket as we expect goods to be labeled individually with RFID tags in the near future. This enables products to be tracked from production to sale consistently and to be localized permanently.In order to provide a working demonstrator, we set up an application scenario resembling a supermarket at the AmbiSense lab at the University of T{\"{u}}bingen. It consists of individually tagged products placed in typical shop shelves. Our robot, equipped with an RFID reader, traverses the supermarket environment while constantly detecting products within its range. The data are transmitted using WLAN to a central computer which holds a model of the current state of the system. We augment these data by additional product-specific information provided by the ERP system. The detected objects as well as additional product data are visualized using AR techniques.This scenario aims at synchronizing the product stock of supermarkets or stores automatically. Other sample tasks could be the identification of products that are past their sell-by dates or located in the wrong places.In addition the robot localizes itself using the existing infrastructure of different, cost-efficient ambient wireless sensors. To achieve the location we develop and combine novel positioning techniques using passive UHF RFID, Bluetooth, and WLAN. We thereby employ three orthogonal measuring techniques: detection rates, signal strength, and round trip time. The orthogonality of the methods is designed to achieve robustness to noise and unforeseen changes in the surroundings. Moreover, due to their different read ranges, the technologies can complement each other at different scales of the environment. An effective and cost-efficient indoor location solution can only be achieved with multiple and heterogeneous ambient sensors combined together. {\textcopyright} Springer-Verlag Berlin Heidelberg 2009.},
annote = {cited By 2},
author = {Hoene, C},
doi = {10.1007/978-3-642-10607-1_6},
journal = {Communications in Computer and Information Science},
keywords = {Application scenario; Continuous integrations; Ent,Augmented reality; Bluetooth; Enterprise resource,Radio frequency identification (RFID)},
pages = {33--34},
title = {{AmbiSense: Identifying and Locating Objects with Ambient Sensors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880465981{\&}doi=10.1007{\%}2F978-3-642-10607-1{\_}6{\&}partnerID=40{\&}md5=fbdec032fe8c72c0fb49995109bf7374},
volume = {32},
year = {2009}
}
@article{Hollinger:2009:EMS:1497541.1497543,
address = {Thousand Oaks, CA, USA},
author = {Hollinger, Geoffrey and Singh, Sanjiv and Djugash, Joseph and Kehagias, Athanasios},
doi = {10.1177/0278364908099853},
issn = {0278-3649},
journal = {Int. J. Rob. Res.},
keywords = {POMDPs,approximation algorithms,autonomous search,decentralized computation,multi-robot coordination,range-only sensing},
number = {2},
pages = {201--219},
publisher = {Sage Publications, Inc.},
title = {{Efficient Multi-robot Search for a Moving Target}},
url = {http://dx.doi.org/10.1177/0278364908099853},
volume = {28},
year = {2009}
}
@article{Hu2013784,
abstract = {Autonomous mapping systems execute multiple tasks that include navigation, location, and map generation via the collaborative work of multiple sensors. They are the object of a substantial research focus in the fields of robotics and remote sensing. Although the state-of-the-art mobile mapping systems typically found in readymade vehicles or robots are reliable, they are rather large and heavy, their cost is high, and they generally use GPS and an inertial measurement unit to position, so their working environments are limited. After reviewing the current state of autonomous mapping systems, we describe the design and development of a small and lightweight autonomousmapping system (ASQ-6DMapSys) without GPS, which incorporates low-cost sensors and components.We describe the layout and selection strategy for sensors and other components in detail, and we present the design methodology for each subsystem. The ASQ-6DMapSys employs a two-dimensional (2D) lidar, an inclinometer, and two wheel encoders, which constitute a pose subsystem that uses extended Kalman filtering and simultaneous localization and mapping techniques to compute the pose of the vehicle body. A lowcost 3D lidar that we developed is also installed on the vehicle body, and the resultant data are aligned with the corresponding pose data of the vehicle body to build a 3D point cloud that describes the global geometry of the environment.We designed and developed every subsystem of the ASQ-6DMapSys, including the robot vehicle, so it will be easy to expand its functions in the future. The ASQ-6DMapSys performs well in indoor, outdoor, and tunnel environments, and the experiments in different environments show that the ASQ-6DMapSys is an effective, small, and lightweight autonomousmapping system with a high performance/price ratio. {\textcopyright} 2013 Wiley Periodicals, Inc.},
annote = {cited By 6},
author = {Hu, S and Chen, C and Zhang, A and Sun, W and Zhu, L},
doi = {10.1002/rob.21465},
journal = {Journal of Field Robotics},
keywords = {Collaborative Work; Design and Development; Extend,Global positioning system; Mathematical technique,Robots},
number = {5},
pages = {784--802},
title = {{A small and lightweight autonomous laser mapping system without gps}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884816757{\&}doi=10.1002{\%}2Frob.21465{\&}partnerID=40{\&}md5=db5d86c48c31e23c2031e56eb7410a52},
volume = {30},
year = {2013}
}
@inproceedings{Hu2008,
abstract = {This paper presents a novel integrated background model for video surveillance. Our model uses a primal sketch representation for image appearance and 3D scene geometry to capture the ground plane and major surfaces in the scene. The primal sketch model divides the background image into three types of regions - flat, sketchable and textured. The three types of regions are modeled respectively by mixture of Gaussians, image primitives and LBP histograms. We calibrate the camera and recover important planes such as ground, horizontal surfaces, walls, stairs in the 3D scene, and use geometric information to predict the sizes and locations of foreground blobs to further reduce false alarms. Compared with the state-of-the-art background modeling methods, our approach is more effective, especially for indoor scenes where shadows, highlights and reflections of moving objects and camera exposure adjusting usually cause problems. Experiment results demonstrate that our approach improves the performance of background/foreground separation at pixel level, and the integrated video surveillance system at the object and trajectory level. {\textcopyright}2008 IEEE.},
annote = {cited By 20},
author = {Hu, W and Gong, H and Zhu, S.-C. and Wang, Y},
booktitle = {26th IEEE Conference on Computer Vision and Pattern Recognition, CVPR},
doi = {10.1109/CVPR.2008.4587541},
keywords = {3-D scene geometry; 3D scenes; Background images;,Alarm systems; Artificial intelligence; Cameras; C,Three dimensional},
title = {{An integrated background model for video surveillance based on primal sketch and 3D scene geometry}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-51949114421{\&}doi=10.1109{\%}2FCVPR.2008.4587541{\&}partnerID=40{\&}md5=d131ad780358c3d9e939b9fa52531c9e},
year = {2008}
}
@inproceedings{Huang201158,
abstract = {With the advances in information and communication technologies, wireless sensor networks has made Ambient Intelligence (AmI) applications possible that can monitor the situation around the persons or objects and give certain responses for their needs. The location awareness is an important technology for AmI applications. The advantages of ZigBee wireless sensor networks such as low cost, high scalability, high availability and supporting dynamic routing topology make ZigBee more suitable for indoor location system. In this research, we propose a ZigBEe-bAsed indoor loCatiON (ZigBEACON) system for the AmI applications. The proposed approach is based on the k-nearest neighbor algorithm. According to the Received Signal Strength Indication's (RSSI) path loss distribution, the RSSI values are defined into four classes. The signals that belong to different classes will be adjusted by the different ratio and will be referred to as weighted RSSI. The use of weighted RSSI can effectively choose the p-nearest reference nodes. Finally, the position of mobile node would be derived by calculating the coordinates of p-nearest reference nodes. Comparing the results with that of ZigBee-based LANDMARC system, our approach has 29{\%} improvement on average error distance. The approach not only improves the accuracy, but also provides less calculation complexity than other improvement methods of LANDMARC. The ZigBEACON approach is an adequate solution to the indoor location system for AmI applications. {\textcopyright} 2011 Published by Elsevier Ltd.},
annote = {cited By 39},
author = {Huang, C.-N. and Chan, C.-T.},
booktitle = {Procedia Computer Science},
doi = {10.1016/j.procs.2011.07.010},
keywords = {Ambient intelligence; Indoor positioning systems;,High availability; High scalabilities; Improvemen,Zigbee},
pages = {58--65},
title = {{ZigBee-based indoor location system by K-nearest neighbor algorithm with weighted RSSI}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863018930{\&}doi=10.1016{\%}2Fj.procs.2011.07.010{\&}partnerID=40{\&}md5=4b678cbe402110fca82ce472010d998a},
volume = {5},
year = {2011}
}
@article{Huang:2016:GIR:2912589.2912790,
address = {Tarrytown, NY, USA},
author = {Huang, Wei and Sun, Min and Li, Songnian},
doi = {10.1016/j.eswa.2016.01.037},
issn = {0957-4174},
journal = {Expert Syst. Appl.},
keywords = {3D GIS,ARGIS,Augmented reality,Registration},
number = {C},
pages = {48--58},
publisher = {Pergamon Press, Inc.},
title = {{A 3D GIS-based Interactive Registration Mechanism for Outdoor Augmented Reality System}},
url = {http://dx.doi.org/10.1016/j.eswa.2016.01.037},
volume = {55},
year = {2016}
}
@inproceedings{Huang2009,
abstract = {Pervasive computing applications, which are location-aware systems becoming increasingly important as part of our daily life. Real-time position localization of moving objects in an indoor environment is an encouraging technology for realizing the vision of creating numerous novel locationaware services and applications in various market segments. An off the shelf development platform that uses Radio Signal Strength Indication (RSSI) based location technique is always used for testing. In this paper we investigated at the affects of polarization on an indoor location tracking system. The target of this paper is to present an optimal design for RSSI location technology. We created a model for determining range form RSSI demonstrated that this model fits our experimental setup. Antenna polarization will affect RSSI and thus range accuracy. The experiments and its errors are carefully analyzed and found that the traditional least squares method of determining the parameters of the range model will give unacceptably high location error. A simple and cheap method of determining polarization angle is introduced with an accelerometer, which also increase the battery life of the node. {\textcopyright} 2009 IEEE.},
annote = {cited By 10},
author = {Huang, X},
booktitle = {2009 4th International Symposium on Wireless and Pervasive Computing, ISWPC 2009},
doi = {10.1109/ISWPC.2009.4800570},
keywords = {Antennas; Curve fitting; Least squares approximat,RF; RFID; RSSI; Sensor networking; ZigBee,Wireless networks},
title = {{Antenna polarization as complementarities on RSSI based location identification}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-65249149669{\&}doi=10.1109{\%}2FISWPC.2009.4800570{\&}partnerID=40{\&}md5=9a46d91226476ad5ea2a0d7f8832dfea},
year = {2009}
}
@inproceedings{Huang2009151,
abstract = {Real-time position localization of moving objects in an indoor environment is an encouraging technology for realizing the vision of creating numerous novel location-aware services and applications in various market segments. An off the shelf development platform that uses Radio Signal Strength Indication (RSSI) based location tracking technique is studied. In this paper we investigate the affects of polarization on the accuracy of an indoor location tracking system. We present an approach to increase system accuracy based on this investigation. We established a model for determining range from RSSI and showed that the model fits our own experimental data. The model includes parameters used to account of environmental effects and we use the least squares method of determining the parameter values. Antenna polarization angle will affect RSSI and thus range accuracy. We empirically show that the model is still valid for polarization mismatch but with different environmental parameter values. A method based on semi-automated trail and error is proposed as a better method for selecting the environmental parameters. Using experimental data we show that if we adjust the model parameters to account for polarization angle then we can increase location accuracy. A practical solution for determining the polarization angle is with an accelerometer. The addition of an accelerometer could also be used to increase the battery life of the node. {\textcopyright} 2009 IEEE.},
annote = {cited By 6},
author = {Huang, X and Barralet, M and Sharma, D},
booktitle = {Proceedings - International Conference on Networks Security, Wireless Communications and Trusted Computing, NSWCTC 2009},
doi = {10.1109/NSWCTC.2009.49},
keywords = {Accelerometers; Antennas; Computer science; Polar,Battery life; Development platform; Environmental,Parameter estimation},
pages = {151--154},
title = {{Behaviors of antenna polarization for RSSI location identification}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650447645{\&}doi=10.1109{\%}2FNSWCTC.2009.49{\&}partnerID=40{\&}md5=95b7d47c3eda1d9c32033750e812b3c1},
volume = {1},
year = {2009}
}
@article{6718051,
abstract = {This paper is intended to provide a solution for developing context-aware smart applications preserving the users' privacy in the Internet of Things (IoT). In this sense, we present a framework called Semantic Web-based Context Management (SeCoMan) aimed at offering a set of predefined queries to provide applications with information about indoor location of users and objects, as well as context-aware services. SeCoMan uses a semantic-oriented IoT vision where semantic technologies play a key role. In fact, SeCoMan uses Semantic Web for modeling description of things, reasoning over data to infer new knowledge, and defining context-aware policies. SeCoMan also defines a layered architecture, including functions related to the management of the users' privacy in a manner that accommodate IoT requirements, in addition to not affecting system performance nor introducing excessive overheads. A thorough discussion on other related works, together with some experiments to measure the throughput and scalability, confirm that SeCoMan is a solution that improves the most relevant proposals existing so far.},
author = {{Huertas Celdr{\'{a}}n}, A and {Garc{\'{i}}a Clemente}, F J and {Gil P{\'{e}}rez}, M and {Mart{\'{i}}nez P{\'{e}}rez}, G},
doi = {10.1109/JSYST.2013.2297707},
issn = {1932-8184},
journal = {IEEE Systems Journal},
keywords = {data privacy;Internet of Things;semantic Web;ubiqu},
number = {3},
pages = {1111--1124},
title = {{SeCoMan: A Semantic-Aware Policy Framework for Developing Privacy-Preserving and Context-Aware Smart Applications}},
volume = {10},
year = {2016}
}
@inproceedings{Hui2014181,
abstract = {In recent years, the Global Positioning System (GPS) has been commonly employed for outdoor positioning and location tracking. On the other hand, there has also been growing interest in developing indoor location tracking systems. Advancements in radio frequency identification (RFID) technology make it a promising technology for use in indoor location tracking systems. In this paper, we present an RFID-based location tracking system using a peer-to-peer (P2P) network architecture, which can provide flexibility for system implementation and cost-effectiveness for system maintenance. The proposed system employs active RFID technology to estimate the location of users/objects, and ZigBee to build a P2P network for communication purposes. It can be used for various purposes, such as asset management and customer relationship management.},
annote = {cited By 2},
author = {Hui, F C P and Chan, H C B and Fung, S H},
booktitle = {Lecture Notes in Engineering and Computer Science},
keywords = {Balloons; Computer architecture; Cost effectivenes,Customer relationship management; Indoor location,Peer to peer networks},
number = {January},
pages = {181--185},
title = {{RFID-based location tracking system using a peer-to-peer network architecture}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938218389{\&}partnerID=40{\&}md5=2b9780d2a0bcac33e9ec38bc9b26c611},
volume = {2209},
year = {2014}
}
@article{Hung20181,
abstract = {With the advancement of medical technology and the rise of medical awareness, the average life expectancy has risen. Advanced countries have stepped into the aged society successively. Building a senior citizen-friendly environment has become an important issue. On one hand, senior citizens are likely to forget where key items are placed due to hypomnesia. Life is inconvenient for them. On the other hand, the proportion of elderly living alone or living only with spouse increases. Without children's accompany, a senior citizen's life could be in danger if he or she suddenly feels uncomfortable, and cannot find the therapeutic drugs instantly. As the information and communication technology has improved in recent years, the Internet of Things technology has gradually become more mature. The arisen of IoT is not only helpful to our daily life in terms of traffic and shopping, but also with clinical knowledge and experience is applicable to build the environment of health care and increase the quality of home care service for senior citizens. In this paper, we attempt to build a life supporting mechanism in the home environment of senior citizens based on the architecture of Internet of Things. This work proposes a new type of hybrid calculation algorithm which combines xBeacon sensing equipment, Received Signal Strength Indication (RSSI) positioning, event analysis method and intelligent cutting algorithm to cut the possible range where the object may be placed into sections, so as to estimate the location of the key items. By tracking key items, elderly people can reduce anxiety and uncomfortable feeling caused by missing key items. To effectively record and analyze routine behavior pattern, this proposed mechanism can support the mobility of the elderly to maintain independent daily life and is helpful for the implementation of home-based care for the aged and aging in place. {\textcopyright} 2018 Springer Science+Business Media, LLC, part of Springer Nature},
annote = {cited By 0; Article in Press},
author = {Hung, L.-P. and Chao, Y.-H. and Chen, C.-L.},
doi = {10.1007/s11036-018-1083-2},
journal = {Mobile Networks and Applications},
keywords = {Assisted living technologies; Average life expect,Assisted living; Biomedical engineering; Cutting e,Internet of things},
pages = {1--10},
title = {{A Hybrid Key Item Locating Method to Assist Elderly Daily Life Using Internet of Things}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049208525{\&}doi=10.1007{\%}2Fs11036-018-1083-2{\&}partnerID=40{\&}md5=da0ffed6f180d153ebca6695c293d67a},
year = {2018}
}
@inproceedings{Hung2010548,
abstract = {This paper develops a ZigBee indoor positioning scheme based on the location fingerprinting approach. The proposed scheme includes four workflows: (1) creating the location fingerprint table, (2) training the locating model using neural network (NN), (3) preprocessing data through the Signal-Index-Pair method, and (4) estimating the coordinate of the mobile target instantly. Testing results show that within the error distance of 5 meters, the NN locating model with the Signal-Index-Pair data preprocess method can increase the positioning precision by 17{\%} compared with the original NN, in terms of the cumulative error probability (CEP). It also achieves 5{\%} CEP higher than the k (k=5) nearest neighbor method and the weighted k (k=5) nearest neighbor method. Potential applications include patient tracking in hospitals, object tracking for factory monitoring, self-navigation of autonomous robots, and visitors monitoring in military buildings, and so on. {\textcopyright}2010 IEEE.},
annote = {cited By 4},
author = {Hung, M.-H. and Lin, S.-S. and Cheng, J.-Y. and Chien, W.-L.},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2010.5509128},
keywords = {Autonomous robot; Cumulative errors; Error distanc,Location; Military applications; Neural networks;,Robotics},
pages = {548--553},
title = {{A ZigBee indoor positioning scheme using signal-index-pair data preprocess method to enhance precision}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955780852{\&}doi=10.1109{\%}2FROBOT.2010.5509128{\&}partnerID=40{\&}md5=b6de21ac0bd281015da82b024b23cec4},
year = {2010}
}
@inproceedings{Huo2016,
abstract = {This paper proposes a spatial language generation system to communicate with a person about the location of an object in an indoor environment. It aims at finding a short, accurate and human-like description for building a natural and friendly interface between robots and humans using spatial language interaction. The system performs an inverse procedure to spatial language grounding which links natural commands to robot actions. The system works in two steps. It will first search for the best matching grounding model which describes the spatial relations between the target object and the references; then it will generate the natural language by mimicking a human's talking style. A corpus of 149 spatial language commands for an indoor environment fetch task is used to train the language generation model. An early-stage experiment is conducted and the results illustrate a potential for further development. {\textcopyright} 2016 IEEE.},
annote = {cited By 2},
author = {Huo, Z and Skubic, M},
booktitle = {2016 IEEE International Conference on Smart Computing, SMARTCOMP 2016},
doi = {10.1109/SMARTCOMP.2016.7501708},
keywords = {Best matching; Indoor environment; Language gener,Computational linguistics; Robotics; Robots,Human robot interaction},
title = {{Natural Spatial Description Generation for Human-Robot Interaction in Indoor Environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979555690{\&}doi=10.1109{\%}2FSMARTCOMP.2016.7501708{\&}partnerID=40{\&}md5=c4c714c38f3a7cdb87e34fcb70d22724},
year = {2016}
}
@article{Hwang2017459,
abstract = {A BLE beacon is often used as a method for indoor positioning in the latest IoT technology. The calculation of a position by measuring the information from a beacon can bring about different measured values according to the signal strength and obstacles. A mobile device that receives information from a fixed beacon can also use the service. This study suggests a method to accurately measure the location of a portable beacon as against a fixed beacon, and uses ontology as a way of implementing this. The RSSI value is typically measured and used to calculate the distance of a beacon. Since accuracy can deteriorate due to noise and error, a given value is filtered through the Kalman filter algorithm. This value provides ontology by normalization through correlation analysis of the values. This ontology infers the location information of the moving beacon. It provides the ability to offer services for other users to distinguish an object with a beacon. This enables quick and accurate location identification and fulfills the demand for such indoor services. {\textcopyright} 2017 International Information Institute.},
annote = {cited By 0},
author = {Hwang, C.-G. and Lee, D and Yoon, C.-P.},
journal = {Information (Japan)},
number = {1},
pages = {459--464},
title = {{A ontology-based indoor path tracking system using a portable beacon}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85033405772{\&}partnerID=40{\&}md5=f379c8914407810ecbc3b3514243ce0f},
volume = {20},
year = {2017}
}
@inproceedings{6936134,
abstract = {Designing mobile robots that navigate indoor environments autonomously is known to be a difficult problem. A critical issue is in the formulation of robust motion control algorithms capable of reliably sensing partial or incomplete information from the environment and using this information to choose appropriate actions to achieve its designed goals. As an example, suppose we wish to deploy a mobile robot that autonomously patrols defined locations at a hazardous high-security facility. The robot must maintain accurate knowledge of its location, while using sensory data to recognize objects and obstacles in its immediate vicinity. Its task is to inspect the desired locations within a defined time period and provide real-time data in the event of an incident. The problem is thus to choose appropriate actions that result in accomplishing the patrol in a minimal amount of time in the partially structured environment. To solve this problem we adopt the Partially Observable Markov Decision Processes (POMDP) formalism to find near-optimal and efficient policies that provides a description the robot's motion in environments with incomplete state information. POMDP is a generalization of Markov Decision Processes (MDPs). It models a system as a coupling of an agent/decision maker (robots in our case) and an environment. We also present a methodology called Goal-Specific Representation (GSR) to reduce the size of the state-space for computational efficiency and propose an extension to the methodology.},
author = {Ibekwe, H I and Kamrani, A K},
booktitle = {2014 World Automation Congress (WAC)},
doi = {10.1109/WAC.2014.6936134},
issn = {2154-4824},
keywords = {indoor environment;Markov processes;mobile robots;},
pages = {1--5},
title = {{Navigation for autonomous robots in partially observable facilities}},
year = {2014}
}
@inproceedings{Iolu2006413,
abstract = {We describe the design, implementation, and test of VIOLAS, a vision-based system for object location and occupancy sensing in sentient buildings. Sentient building operations require the existence of a dynamic and self-updating model of building context, components, spaces, systems, processes, and occupancy. Such a model can support applications in building and facility management as well as indoor environmental controls. Specifically, comprehensive self-updating models can facilitate the implementation of simulation-based building systems control strategies (e.g. for heating, cooling, ventilation, lighting). Since the underlying model for such operations must possess the capability to autonomously update itself, a versatile sensing mechanism is required that provides context awareness, i.e., real-time facility state information. The research described in this paper aims to examine and demonstrate the potential of vision-based sensing solutions to meet this requirement. For the generation of a comprehensive, self-updating space model, the prototype system particularly requires object identification and location sensing as well as occupancy detection. Toward this end, VIOLAS offers a flexible and scalable arrangement of hardware and software components (tied together via internet), which is generally well-suited to the requirements of sentient buildings. {\textcopyright} 2006 Taylor {\&} Francis Group.},
annote = {cited By 0},
author = {I{\c{c}}olu, O and Mahdavi, A},
booktitle = {Proceedings of the 6th European Conference on Product and Process Modelling - eWork and eBusiness in Architecture, Engineering and Construction, ECPPM 2006},
keywords = {Building operations; Building systems; Context aw,Computer software; Cooling systems; Management; Of,Identification (control systems)},
pages = {413--420},
title = {{Construction of self-updating and reusable space models via vision-based sensing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-61849148315{\&}partnerID=40{\&}md5=90f446700dea7823756c789b7518fdb8},
year = {2006}
}
@inproceedings{NoAuthor2014,
abstract = {The proceedings contain 57 papers. The topics discussed include: video generation method based on user's tendency of viewpoint selection for multi-view video contents; Tearsense: a sensor system for illuminating and recording teardrops for entertainment; unloading muscle activation enhances force perception; multi-touch steering wheel for in-car tertiary applications using infrared sensors; evaluating effect of types of instructions for gesture recognition with an accelerometer; on achieving dependability for wearable computing by device bypassing; on the tip of my tongue - a non-invasive pressure-based tongue interface; emotional priming of mobile text messages with ring-shaped wearable device using color lighting and tactile expressions; CarCast: a framework for situated in-car conversation sharing; representing indoor location of objects on wearable computers with head-mounted displays; and two-level fast-forwarding using speech detection for rapidly perusing video.},
annote = {cited By 0},
author = {Ikeuchi, Kohki and Otsuka, Tomoaki and Yoshii, Akihito and Sakamoto, Mizuki and Nakajima, Tatsuo},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/2582051.2582104},
isbn = {9781450327619},
pages = {1 {\textless}last{\_}page{\textgreater} 2},
title = {{Proceedings of the 5th Augmented Human International Conference on - AH '14; KinecDrone }},
url = {http://dx.doi.org/10.1145/2582051.2582104},
year = {2014}
}
@inproceedings{Imtiaz2014,
abstract = {Within a manufacturing system, a smart human-machine interface reduces the chances of human error and helps users to make informed decisions, especially in critical situations. This paper presents a concept for a flexible context specific assistance system for industrial applications using camera based localization. As a central element, a modular and service oriented context aware system aggregates relevant data from different sources. An object recognition service applies image analysis techniques on a video stream, captured from a top mounted multi-camera system to detect a person's location and associate it with a mobile device. A semantically enriched OPC UA server provides access to process data, and a web-service provides connection to a user interface hosted on a tablet PC. A case study provides an application of the proposed solution for the maintenance support and indoor navigation is implemented as a proof of concept. {\textcopyright} 2014 IEEE.},
annote = {cited By 4},
author = {Imtiaz, J and Koch, N and Flatt, H and Jasperneite, J and Voit, M and {Van De Camp}, F},
booktitle = {19th IEEE International Conference on Emerging Technologies and Factory Automation, ETFA 2014},
doi = {10.1109/ETFA.2014.7005273},
keywords = {Assistance system; Context-aware systems; Human M,Cameras; Factory automation; Indoor positioning sy,Tracking (position)},
title = {{A flexible context-aware assistance system for industrial applications using camera based localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946688177{\&}doi=10.1109{\%}2FETFA.2014.7005273{\&}partnerID=40{\&}md5=d39fa26a4c43bc50766e770303afc71b},
year = {2014}
}
@inproceedings{5648183,
abstract = {With the emergence of satellite based positioning techniques, outdoor environments have been covered well by GNSS positioning capabilities. Recent focus has shifted towards the indoor environment where the satellite signal propagates poorly. We consider the potential to locate objects and people indoors as a substantial building block for the human development. If we are looking towards seamless positioning in all environments, the indoor environment poses the crux. Several indoor positioning applications are waiting for a satisfactory technical solution in industrial automation, product tracking, stock-keeping, pedestrian navigation in hospitals, homes for the impaired, burning buildings, museums, for the purpose of ambient assisted living, for location based systems and further applications.},
author = {Ingensand, H and Mautz, R},
booktitle = {2010 International Conference on Indoor Positioning and Indoor Navigation},
doi = {10.1109/IPIN.2010.5648183},
keywords = {indoor radio;satellite navigation;satellite based},
pages = {1},
title = {{Message of the conference directors}},
year = {2010}
}
@inproceedings{Ionescu201445,
abstract = {The arrival of Bluetooth Low Energy (BLE) creates opportunities for great innovations. One possible application is object localisation. We present our unique software that can track objects and help finding their location within a house perimeter. With the help of Bluetooth beacons that can be attached to different items, we can estimate the distance between the mobile device and the object with an accuracy of less than one meter. In this paper, we describe our system and the techniques we use, the experiments we conducted along with the results. In addition, we briefly present some work in progress using an indoor positioning system that helps locating the objects. Copyright {\textcopyright} (2014) by International Academy.},
annote = {cited By 12},
author = {Ionescu, G and {De La Osa}, C M and Deriaz, M},
booktitle = {SENSORCOMM 2014 - 8th International Conference on Sensor Technologies and Applications},
keywords = {Bluetooth,Bluetooth low energies (BLE); Bluetooth low energ,Mobile devices; Object recognition},
pages = {45--49},
title = {{Improving distance estimation in object localisation with bluetooth low energy}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929320159{\&}partnerID=40{\&}md5=cc7f1075a5900d82c75d64b8c5845f1d},
year = {2014}
}
@inproceedings{5759258,
abstract = {Nowadays using the GPS locating technologies it is possible to solve most of situations were location and tracking of people and objects are necessary in open spaces. Besides that, with wireless networks is possible to communicate location information to a central control point. However when it has to be done in an indoor environment, where GPS signal can not be used and multiple people and objects are moving in the area, there are not a good solutions to cover the locating, tracking and identity of each element without confusion. We will present a complete solution which combines RFID identification ability with a complex machine vision tracking using multiples IP cameras, to improve the strength of both technologies, allowing the identification, location and tracking of humans and vehicles in a wide area.},
author = {Isasi, A and Rodriguez, S and Armentia, J L D and Villodas, A},
booktitle = {European Workshop on Smart Objects: Systems, Technologies and Applications},
pages = {1--6},
title = {{Location, tracking and identification with RFID and vision data fusion}},
year = {2010}
}
@article{Ishikawa2009454,
abstract = {We propose a 3D modeler for supporting in-situ indoor modeling effectively. The modeler allows a user easily to create models from a single photo by interaction techniques taking advantage of features in indoor space and visualization techniques. In order to integrate the models, the modeler provides automatic integration functions using Visual SLAM and pedestrian dead-reckoning (PDR), and interactive tools to modify the result. Moreover, for preventing shortage of texture images to be used for the models, our modeler automatically searches from 3D models created by the user for un-textured regions and intuitively visualizes shooting positions to take a photo for the regions. These functions make it possible that the user easily create photorealistic indoor 3D models that have enough textures on the fly. {\textcopyright} 2009 Springer Berlin Heidelberg.},
annote = {cited By 14},
author = {Ishikawa, T and Thangamani, K and Kourogi, M and Gee, A P and Mayol-Cuevas, W and Jung, K and Kurata, T},
doi = {10.1007/978-3-642-02771-0_51},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {3D models; Dead reckoning; In-situ; Indoor space;,Content based retrieval; Sensors; Textures; Virtu,Three dimensional; Indoor positioning systems},
pages = {454--464},
title = {{In-situ 3D indoor modeler with a camera and self-contained sensors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-76649129535{\&}doi=10.1007{\%}2F978-3-642-02771-0{\_}51{\&}partnerID=40{\&}md5=068dfc2630953eae23151fafbdf0ee3d},
volume = {5622 LNCS},
year = {2009}
}
@inproceedings{Itagaki2012,
abstract = {Moving objects, especially autonomous mobile robots, require information of indoor self-location with high accuracy to reach their destination safely and correctly. In this study, we aimed to measure the indoor position of a moving object using SS (spread spectrum) ultrasonic waves, and we discussed the accuracy of the moving distance measured using a newly developed hardware device. In the case of static object, we showed that because of the noise tolerance of SS waves, a distance up to 20 [m] could be measured between a transmitter and a receiver on cm-order. To detect the SS ultrasonic signals, correlation calculations were carried out between a range of received waves and same range of replica signals; the replica signals were the same as the transmitted SS signals. Popular positioning systems using SS electrical waves employ signal acquisition to calculate coordinates of objects from correlation values and signal tracking to measure the relative shift of distances of moving objects. It is difficult for the system using SS ultrasonic waves to continue tracking because of the decrease in the self-correlation value due to the Doppler effect that acted on a moving object. To solve this problem, we proposed a tracking method for keeping correlation values by limited range of correlation calculations. In this study, for obtaining real-time updates of positional information from the relative shift, an experiment of distance measurement was also conducted using a newly developed hardware device that was used to carry out signal acquisition and the proposed tracking method. The results show that real-time signal tracking with our method could be realized, same as existing software between +/- 0.5 [m/s]. This paper reports that we can expect self-localization of robots using this system. {\textcopyright} 2012 IEEE.},
annote = {cited By 13},
author = {Itagaki, Y and Suzuki, A and Iyota, T},
booktitle = {2012 International Conference on Indoor Positioning and Indoor Navigation, IPIN 2012 - Conference Proceedings},
doi = {10.1109/IPIN.2012.6418850},
keywords = {Autonomous Mobile Robot; Correlation value; Electr,Hardware; Robots; Signal analysis; Spectroscopy;,Ultrasonic waves},
title = {{Indoor positioning for moving objects using a hardware device with spread spectrum ultrasonic waves}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874256950{\&}doi=10.1109{\%}2FIPIN.2012.6418850{\&}partnerID=40{\&}md5=e0e975cc4b100366a4e5b8699fcc7f5d},
year = {2012}
}
@article{Ito201564,
abstract = {To expand the range of activities by unmanned aerial vehicles (UAVs), whose use at disaster sites and other dangerous locations has raised high expectations, UAVs must be capable of several functions, e.g., flight both indoor and outdoor environments. This requires making the airframe and major sensors as compact and light-weight as possible. To do so, we are developing uniaxial laser rangefinders to replace conventional scanning laser rangefinders. One developmental approach to uniaxial laser rangefinders and results regarding their validity are reported in this paper. Using a simulated model  a modified scanning laser rangefinder  we discuss the effectiveness of our approach. Specifically, this is to reduce the range drift due to heat, for which we propose using a multiecho to measure two echoes from a reference plate whose distance is known and that is placed outside of the sensor, and the target object, instead using the internal reference plate used in conventional two-dimensional scanning laser rangefinders. We also report the results of experiments verifying its validity. {\textcopyright} 2015, Fuji Technology Press. All rights reserved.},
annote = {cited By 0},
author = {Ito, K and Ohya, A and Shimaji, N and Aoki, T},
journal = {Journal of Robotics and Mechatronics},
keywords = {Laser range finders; Multiecho sensing; Outdoor e,Range finders,Scanning; Unmanned aerial vehicles (UAV)},
number = {1},
pages = {64--73},
title = {{Reduction of distance drift with temperature in uniaxial laser rangefinder by using multiecho sensing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927928531{\&}partnerID=40{\&}md5=9056c43511623ba286072e4078379e2f},
volume = {27},
year = {2015}
}
@inproceedings{Iturralde20141165,
abstract = {In this paper we introduce a novel localization algorithm based on visible light communications (VLC) and the trilateration technique. The new algorithm can be used for tracking people or machinery in an underground mining environment. The proposed method utilizes the concept of reference points in order to reduce the location estimation error. The proposed algorithm outperforms the LANDMARC (location identification based on dynamic active radio frequency identification (RFID) calibration) algorithm, which uses RFID tags to determine the location of an object, in terms of the location estimation error. {\textcopyright} 2014 IEEE.},
annote = {cited By 12},
author = {Iturralde, D and Azurdia-Meza, C and Krommenacker, N and Soto, I and Ghassemlooy, Z and Becerra, N},
booktitle = {2014 9th International Symposium on Communication Systems, Networks and Digital Signal Processing, CSNDSP 2014},
doi = {10.1109/CSNDSP.2014.6924006},
keywords = {Active radio frequency identifications; Indoor po,Algorithms,Frequency estimation; Light; Machinery; Radio freq},
pages = {1165--1169},
title = {{A new location system for an underground mining environment using visible light communications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910647251{\&}doi=10.1109{\%}2FCSNDSP.2014.6924006{\&}partnerID=40{\&}md5=6b961fd9d3fdac37767ec06b9ea0c607},
year = {2014}
}
@inproceedings{5196076,
abstract = {Currently, the main challenge of CBIR is bridging the so-called semantic gap. A question emerges whether visual similarity is reliable for grading semantic similarity and how complex the problem of semantic interpretation of an image really is? Using the UML class diagram, a model for semantic interpretation of general images is presented. A general model for still images of outdoor and indoor scenes is defined, independent of domain the image belongs to and the objects it contains. Analysis and visual presentation of key model elements aid in observing the problem in whole and simplify the process of finding new solutions.},
author = {Ivasic-Kos, M and Pavlic, M and Poscic, P},
booktitle = {Proceedings of the ITI 2009 31st International Conference on Information Technology Interfaces},
doi = {10.1109/ITI.2009.5196076},
issn = {1330-1012},
keywords = {image processing;image retrieval;programming langu},
pages = {181--186},
title = {{The analysis and overview of semantic image interpretation}},
year = {2009}
}
@inproceedings{4540311,
abstract = {A strength prediction algorithm based on unscented Kalman filter (SPKF) is proposed to fuse the mobile localization estimation obtained from received signal strength in wireless sensor network. The algorithm is particularly suitable for indoor applications where the presence of furniture, objects, walls and the induced diffraction, reflection and multi-path effects. The unscented Kalman filter is used to predict the tendency of received signal strength, and cooperates with dynamic triangular location algorithm achieves an improved accuracy and provides a lower fluctuation of received signal strength than the grey prediction when mobile user is moving. It is also proved to grey prediction when mobile user is moving. It is also proved to be able to dramatically outperform and reduce the fluctuation of received signal strength when mobile user is moving.},
author = {j. Wang, L and Wang, J and Wang, Y and Liu, X},
booktitle = {2008 International Conference on Microwave and Millimeter Wave Technology},
doi = {10.1109/ICMMT.2008.4540311},
keywords = {Kalman filters;mobility management (mobile radio);},
pages = {96--99},
title = {{Location estimation of mobile user in wireless sensor network based on Unscented Kalman Filter}},
volume = {1},
year = {2008}
}
@inproceedings{Jabnoun2017,
abstract = {Developing assisting system of handicapped persons become a challenging ask in research projects. Recently, a variety of tools are designed to help visually impaired or blind people object as a visual substitution system. The majority of these tools are based on the conversion of input information into auditory or tactile sensory information. Furthermore, object recognition and text retrieval are exploited in the visual substitution systems. Text detection and recognition provides the description of the surrounding environments, so that the blind person can readily recognize the scene. In this work, we aim to introduce a method for detecting and recognizing text in indoor scene. The process consists on the detection of the regions of interest that should contain the text using the connected component. Then, the text detection is provided by employing the images correlation. This component of an assistive blind person should be simple, so that the users are able to obtain the most informative feedback within the shortest time. {\textcopyright} 2017 SPIE.},
annote = {cited By 3},
author = {Jabnoun, H and Benzarti, F and Amiri, H},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.2268399},
keywords = {Character recognition,Computer vision; Information retrieval; Object rec,Connected component; Image correlations; Regions},
title = {{A new method for text detection and recognition in indoor scene for assisting blind people}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029958377{\&}doi=10.1117{\%}2F12.2268399{\&}partnerID=40{\&}md5=5445c7d05fd8e31dab20f6c4295a4539},
volume = {10341},
year = {2017}
}
@inproceedings{Jafer:2009:SRC:1607720.1608026,
address = {Washington, DC, USA},
author = {Jafer, Essa and O'Flynn, Brendan and O'Mathuna, Cian and Spinar, Rosta},
booktitle = {Proceedings of the 2009 Third International Conference on Sensor Technologies and Applications},
doi = {10.1109/SENSORCOMM.2009.41},
isbn = {978-0-7695-3669-9},
keywords = {Building monitoring,Motes deployment,RF Characterestics,Wireless Sensor Network},
pages = {206--211},
publisher = {IEEE Computer Society},
series = {SENSORCOMM '09},
title = {{A Study of the RF Characteristics for Wireless Sensor Deployment in Building Environment}},
url = {https://doi.org/10.1109/SENSORCOMM.2009.41},
year = {2009}
}
@inproceedings{Jaimes:2003:MKO:1760167.1760199,
address = {Berlin, Heidelberg},
author = {Jaimes, Alejandro and Tseng, Belle L and Smith, John R},
booktitle = {Proceedings of the 2Nd International Conference on Image and Video Retrieval},
isbn = {3-540-40634-4},
pages = {248--259},
publisher = {Springer-Verlag},
series = {CIVR'03},
title = {{Modal Keywords, Ontologies, and Reasoning for Video Understanding}},
url = {http://dl.acm.org/citation.cfm?id=1760167.1760199},
year = {2003}
}
@article{Jama201477,
abstract = {Localization based on Received Signal Strength (RSS) is a key method for locating objects in Wireless Sensor Networks (WSNs). However, current RSS-based methods are ineffective at both deployment and operation design levels. First, they usually require a labor-intensive pre-deployment profiling operations to map the RSS to either locations or distances. Second often rely on heavy processing operations. These two design problems limit the possibility of implementing such localization techniques on resource-constrained sensor nodes, and also restrict their scalability and use in practice. In this book chapter, we discuss the challenges and limitations of RSS-based localization mechanisms and we propose, EasyLoc, an autonomous and practical RSS-based localization technique that improves on previous approaches in terms of ease of deployment and ease of implementation, while still providing a reasonable accuracy. EasyLoc is a plug-and-play and fully distributed RSS-based localization method that requires zero pre-deployment configuration. The idea consists in exploiting the available distance information between anchors to derive an online and anchor-specific RSS to distance mapping. We show that, in addition to its simplicity, EasyLoc provides, in the best case, a reasonable average distance error of 2 m in an indoor environment of 30 m 2. {\textcopyright} 2014 Springer-Verlag Berlin Heidelberg.},
annote = {cited By 2},
author = {Jam{\^{a}}a, M B and Koub{\^{a}}a, A and Baccour, N and Kayani, Y and Al-Shalfan, K and Jmaiel, M},
doi = {10.1007/978-3-642-39301-3_5},
journal = {Studies in Computational Intelligence},
pages = {77--98},
title = {{Easy loc: Plug-and-play rss-based localization in wireless sensor networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886601970{\&}doi=10.1007{\%}2F978-3-642-39301-3{\_}5{\&}partnerID=40{\&}md5=8a99dc65080e91d663ab0103538a76ff},
volume = {507},
year = {2014}
}
@inproceedings{Jang20181,
abstract = {The time-varying, unstable nature of RF signals has limited the accuracy of RF-based indoor positioning techniques such as Wi-Fi fingerprinting. Positioning errors of over 10 meters are reported in large-scale indoor environment such as airport and department stores. Compared to RF or ultrasound signals, the geomagnetic field signal exhibits stable signal strength in time domain. However, the existing geomagnetic field based indoor localization still relies on the fingerprinting technique, which is borrowed from the RF-based indoor positioning. This cannot resolve the distribution of the same geomagnetic field values and thus became a major reason for diminished performance of geomagnetic- based indoor localization. In this paper, we propose a novel indoor localization technique that uses magnetometer sensor readings as input to the artificial neural network models. The idea is that although there can be multiple locations having the same magnetic field value, as a pedestrian moves the sequence of magnetic field values will lead to a unique pattern of the sensor readings over time. We use a recurrent neural network (RNN) since it can characterize a particular location based on the current input as well as the past sequence of inputs. We first build a geomagnetic field map on our campus test-bed. Then, we generate a million traces of various pedestrian walking patterns from the map. We use Google Tensorflow with NVIDIA cuDNN library as a Deep Learning framework. 95{\%} of the traces are used for training and 5{\%} of the traces are used for localization evaluation. In this preliminary evaluation, we show an average positioning error of 1.062 meters compared to the average error of 3.14 meters of our BLE fingerprinting results. We cannot only improve the localization accuracy but we are also able to address the problem of continuous route tracking, which was not possible with the RF-based fingerprinting. {\textcopyright} 2017 IEEE.},
annote = {cited By 2},
author = {Jang, H J and Shin, J M and Choi, L},
booktitle = {2017 IEEE Global Communications Conference, GLOBECOM 2017 - Proceedings},
doi = {10.1109/GLOCOM.2017.8254556},
keywords = {Artificial neural network models; Average positio,Deep learning; Errors; Geomagnetism; Magnetic fiel,Indoor positioning systems},
pages = {1--6},
title = {{Geomagnetic field based indoor localization using recurrent neural networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046428600{\&}doi=10.1109{\%}2FGLOCOM.2017.8254556{\&}partnerID=40{\&}md5=3ffcb2bb9766ed326a1c7dfb406038a8},
volume = {2018-Janua},
year = {2018}
}
@inproceedings{Jauregui-Ortiz:2012:SEA:2357491.2358104,
address = {Washington, DC, USA},
author = {Jauregui-Ortiz, Salvador and Siller, Mario and Ramos, Felix and Scalabrin, Edson},
booktitle = {Proceedings of the 2012 Eighth International Conference on Intelligent Environments},
doi = {10.1109/IE.2012.38},
isbn = {978-0-7695-4741-1},
keywords = {Context-Aware Localization,Information Fusion,Node Localization,Wireless Sensor Network},
pages = {222--227},
publisher = {IEEE Computer Society},
series = {IE '12},
title = {{Smart Environmental Architecture for Node Localization in a Wireless Sensor Network}},
url = {http://dx.doi.org/10.1109/IE.2012.38},
year = {2012}
}
@article{Jayabharathy2013125,
abstract = {The important goal of location based services is to fix accurately the position of the user or an object. location based services are becoming attractive with the deployment of next generation wireless networks and broad band multimeha wireless technolopes. in this study, an effort is made to compare the performance of hfferent range based indoor localization for uwb raho. location estimation systems are based on received signal strength inhcator (rssi), time of arrival (toa) and time difference of arrival (tdoa) methods. the kalman filter is employed to estimate real time positioning of the user. ultra wide band (tjwb) radio is to provide high time resolution and very good accuracy in the case of time based techniques. finally this paper compares the performance of these three hfferent range based methods by simulation using matlab. results show that the accuracy is better in tdoa using generalized cross correlation method (gcc). the proposed system is composed of uwb nodes (receiver or reference node whose position is known), uwb tags (transmitter or source or unknown position of the target) and an tjwb location server to calculate the position of the tags accurately. {\textcopyright} 2013 Academic Journals Inc.},
annote = {cited By 2},
author = {Jayabharathy, R and Prithiviraj, V and Varadarajan, R},
doi = {10.39231rjit.2013.125.136},
journal = {Research Journal of Information Technology},
number = {2},
pages = {125--136},
title = {{Performance comparison of context aware range based indoor real time localization for UWB Applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881366751{\&}doi=10.39231rjit.2013.125.136{\&}partnerID=40{\&}md5=8949f5d1cf44e636088c41621c69705f},
volume = {5},
year = {2013}
}
@inproceedings{7377713,
abstract = {Cooperative research has been conducted to improve navigation services for vision impaired when they are moving through an indoor environment. Hence, to facilitate vision impaired individual in indoor environment requires a formal modelling approach for map generation and decision making about navigation pathways avoiding obstacles. The proposed data model consists "AccessBIM" database (DB) and API functions. The "AccessBIM" features such as, database connection initiation, function call, function return and database connection termination are organized as a series of function objects that meet the various needs of the database to maintain the relational schema. The proposed API primarily consists of two components, namely; DB connector and the API functions. Proposed "AccessBIM" DB will be implemented using real-time database such as "PostgreSQL". The weighted focus will be given to the areas such as Queries, Indexes and Transactions in relation to tuning the DB and the queries. The performance of the proposed API will be evaluated based on the time required to parse and Data insert rate and retrieval rates.},
author = {Jayakody, J A D C A and Murray, I and Herrmann, J},
booktitle = {2015 Fifteenth International Conference on Advances in ICT for Emerging Regions (ICTer)},
doi = {10.1109/ICTER.2015.7377713},
keywords = {application program interfaces;database management},
pages = {280},
title = {{Database modelling for vision impaired indoor navigation systems: Extended abstract}},
year = {2015}
}
@inproceedings{7346760,
abstract = {Navigation in indoor environments is highly challenging for both vision impaired and sighted people, particularly in unknown environments visited for the first time. Several solutions have been implemented and proposed to deal with this challenge. Although some of them have shown to be useful in real scenarios, each solution involves a significant deployment effort or describes objects in a manner that is unfamiliar or incomprehensible to an individual with severe blindness. This paper presents a model of adding informational point of interest to the typical indoor topological map; with particular attention to the semantic labels of the different type of indoor places and proposes a simple way to include the tags to build the topological map. Using this POI and the semantic information, the system determines the user's path, locates possible obstacles on that route, and offers navigation information to assist vision impaired navigation.},
author = {Jayakody, J A D C A and Murray, I and Herrmann, J},
booktitle = {2015 International Conference on Indoor Positioning and Indoor Navigation (IPIN)},
doi = {10.1109/IPIN.2015.7346760},
keywords = {geographic information systems;handicapped aids;in},
pages = {1--8},
title = {{An algorithm for labeling topological maps to represent point of interest for vision impaired navigation}},
year = {2015}
}
@inproceedings{Jayakody2018352,
abstract = {The complexity of indoor environments has made navigation difficult for vision impaired individuals as well as individuals with clear vision. Although handheld mobility devices have been developed to assist the vision impaired in navigation, they are incapable of capturing parameters such as distance, angle and direction. This paper presents an appraised framework; the Accessible Building Information Model (AccessBIM), which could be used for generating an indoor map in real-time with the classification of real world objects and their locations. The AccessBIM database is equipped with two optimization algorithms; a database optimization algorithm that reduces the time of query execution through indexing, query re-writing, schema redesigning and a memory optimization algorithm known as 'Memcache'. Five scenarios were tested using a simulator to determine the accuracy of the map that is generated. The use of the two algorithms ensured that the real-time map generated through the data collected from the simulation environment was similar to the actual floor plan. Hence, it can be concluded that the AccessBIM framework has the potential to play an integral role in assistive technologies related to localization and mapping, thus significantly improving the quality of life for individuals with vision impairment. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Jayakody, J.A.D.C. and Murray, I and Hermann, J and Lokuliyana, S and Dunuwila, V R},
booktitle = {13th International Conference on Computer Science and Education, ICCSE 2018},
doi = {10.1109/ICCSE.2018.8468690},
keywords = {Algorithmic implementation; Database optimization,Classification (of information); Database systems;,Indoor positioning systems},
pages = {352--357},
title = {{Enhanced algorithmic implementation to assist real-time indoor map generation for vision impaired individuals}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055594253{\&}doi=10.1109{\%}2FICCSE.2018.8468690{\&}partnerID=40{\&}md5=f26811b0f75c12cf908ac047ef4ec69e},
year = {2018}
}
@inproceedings{Jeamwatthanachai201791,
abstract = {A map is a basic component used in a part of navigation in everyday life, which helps people to find information regarding locations, landmarks, and routes. By GPS and online service map e.g. Google maps, navigating outdoors is easier. Inside buildings, however, navigating would not be so easy due to natural characteristics and limitations of GPS, which has led to the creations of indoor navigation system. Even though the indoor navigation systems have been developed for long time, there are still some limitation in accuracy, reliability and indoor spatial information. Navigating inside without indoor spatial information would be a challenge for the users. Regarding the indoor spatial information, a research question has been drawn on finding an appropriate framework towards map data representation of an indoor public spaces and buildings in order to promote indoor navigation for people, robotics, and autonomous systems. This paper has purposed a list of factors and components used towards the design framework for map data representation of indoor public spaces and buildings. The framework, in this paper, has been presented as a form of a multiple-layered model, which each layer designed for a different propose, with object and information classifications. {\textcopyright} 2016 IEEE.},
annote = {cited By 0},
author = {Jeamwatthanachai, W and Wald, M and Wills, G},
booktitle = {International Conference on Information Society, i-Society 2016},
doi = {10.1109/i-Society.2016.7854184},
keywords = {Accessibility; Data representations; Framework; I,Classification (of information); Global positionin,Indoor positioning systems},
pages = {91--96},
title = {{Map data representation for indoor navigation : A design framework towards a construction of indoor map}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016009887{\&}doi=10.1109{\%}2Fi-Society.2016.7854184{\&}partnerID=40{\&}md5=cd67fc25171d0f340d5a8fb25fb4f104},
year = {2017}
}
@article{JebaMalar20171,
abstract = {The monitoring of personnel movements, package tracking and other constructional material based tracking is a top concern in pervasive smart environment. Wireless sensor network (WSN) has given its own individuality in tracking scenario. The challenges faced in this paper deals about an effective 2-dimensional movable system tracking and finding the possible prediction of its exact location of the object in the sensing area. An indoor based WSN with wireless sensor nodes has been created, in which RSSI based location sensing methodology is used. The sensing area is classified as shells and the movement of the node is judged with markov model. The proposed algorithm is tested with various speed conditions suitable for IoT applications. Real study shows the effectiveness of the proposed two dimensional algorithms. The obtained results show minimal location error and accurate location of the object. The proposed methodology serves as the better solution for IoT applications. The proposed algorithm outperforms the existing algorithm with reduced error rate and computing iterations or complexity. A cloud enabled IoT based application is developed to location the elderly and post-surgical people. The developed application serves as a better solution for monitoring the elderly people inside the smart home environment without disturbing their privacy. {\textcopyright} 2017 Springer Science+Business Media, LLC, part of Springer Nature},
annote = {cited By 1; Article in Press},
author = {{Jeba Malar}, A C and Kousalya, G and Ma, M},
doi = {10.1007/s10586-017-1494-z},
journal = {Cluster Computing},
keywords = {Automation; Intelligent buildings; Location; Marko,Constructional material; Developed applications;,Internet of things},
pages = {1--8},
title = {{Markovian model based indoor location tracking for Internet of Things (IoT) applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038826439{\&}doi=10.1007{\%}2Fs10586-017-1494-z{\&}partnerID=40{\&}md5=a17bd5dfdf2acffc54e6095f9f43ea9a},
year = {2017}
}
@inproceedings{Jedari2015,
abstract = {Location positioning in indoor environments is a major challenge. Various algorithms have been developed over years to address the problem of indoor positioning. One of the most cost effective choice for indoor positioning is based on received signal strength indicator (RSSI) using existing Wi-Fi networks in commercial and/or public areas. This solution is infrastructure-free and offers meter-range accuracy. In this paper, machine learning approaches including k-nearest neighbor (k-NN), a rules-based classifier (JRip), and random forest have been investigated to estimate the indoor location of a user or an object using RSSI based fingerprinting method. Experimental measurements were carried out using 1500 reference points with received RSSIs of 86 installed APs in the second floor of Centre for Engineering Innovation (CEI) building at the University of Windsor. The results indicate that the random forest classifier presents the best performance as compared to k-NN and JRip classifiers with positioning accuracy higher than 91{\%}. {\textcopyright} 2015 IEEE.},
annote = {cited By 24},
author = {Jedari, E and Wu, Z and Rashidzadeh, R and Saif, M},
booktitle = {2015 International Conference on Indoor Positioning and Indoor Navigation, IPIN 2015},
doi = {10.1109/IPIN.2015.7346754},
keywords = {Algorithms; Artificial intelligence; Cost effectiv,Engineering innovations; Fingerprinting methods;,Indoor positioning systems},
title = {{Wi-Fi based indoor location positioning employing random forest classifier}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959282249{\&}doi=10.1109{\%}2FIPIN.2015.7346754{\&}partnerID=40{\&}md5=866a5b24ae284e91696d03bfd02758dd},
year = {2015}
}
@inproceedings{Jensen:2009:GMB:1590953.1591000,
address = {Washington, DC, USA},
author = {Jensen, Christian S and Lu, Hua and Yang, Bin},
booktitle = {Proceedings of the 2009 Tenth International Conference on Mobile Data Management: Systems, Services and Middleware},
doi = {10.1109/MDM.2009.23},
isbn = {978-0-7695-3650-7},
pages = {122--131},
publisher = {IEEE Computer Society},
series = {MDM '09},
title = {{Graph Model Based Indoor Tracking}},
url = {http://dx.doi.org/10.1109/MDM.2009.23},
year = {2009}
}
@article{Ji2018327,
abstract = {In recent years, Wireless Access Point (WAP)-based Received Signal Strength Indication (RSSI) indoor localization technology has been of intriguing interest to deduce the coordinates of an object or an observer in the scene with RSSI being collected by various WAPs in a Range of Interest (ROI). The Radio Map construction by fingerprints is of great importance for indoor localization. Existing methods of Radio Map construction have encountered bottlenecks in this area, which will limit the application of indoor localization technology due to the deployment is massive and cumbersome. The spatial correlation between RSSI observations is adopted and the manifold alignment algorithm will be adopted to locate the user's current location without a complete Radio Map so as to reduce the requirements of the calibration fingerprints. Simulated Radio Map (SRM) scheme and Plan Coordinate (PC) scheme will be proposed and simulated separately to verify the correctness and efficiency of the proposed scheme. {\textcopyright} ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2018.},
annote = {cited By 0},
author = {Ji, P and Qin, D and Feng, P and Zhang, Y},
doi = {10.1007/978-3-030-00557-3_33},
journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
keywords = {Artificial intelligence; Cellular telephone system,Indoor localization; Manifold alignments; Radio m,Indoor positioning systems},
pages = {327--337},
title = {{Manifold alignment-based radio map construction in indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055563856{\&}doi=10.1007{\%}2F978-3-030-00557-3{\_}33{\&}partnerID=40{\&}md5=17a7ee71ff902e0374a907589ba9b4b9},
volume = {251},
year = {2018}
}
@article{Jian20171177,
abstract = {An Augmented virtual environment (AVE) is concerned with the fusion of real-time video with 3D models or scenes so as to augment the virtual environment. In this paper, a new approach to establish an AVE with a wide field of view is proposed, including real-time video projection, multiple video texture fusion and 3D visualization of moving objects. A new diagonally weighted algorithm is proposed to smooth the apparent gaps within the overlapping area between the two adjacent videos. A visualization method for the location and trajectory of a moving virtual object is proposed to display the moving object and its trajectory in the 3D virtual environment. The experimental results showed that the proposed set of algorithms are able to fuse multiple real-time videos with 3D models efficiently, and the experiment runs a 3D scene containing two million triangles and six real-time videos at around 55 frames per second on a laptop with 1GB of graphics card memory. In addition, a realistic AVE with a wide field of view was created based on the Digital Earth Science Platform by fusing three videos with a complex indoor virtual scene, visualizing a moving object and drawing its trajectory in the real time. {\textcopyright} 2017 Informa UK Limited, trading as Taylor {\&} Francis Group.},
annote = {cited By 2},
author = {Jian, H and Liao, J and Fan, X and Xue, Z},
doi = {10.1080/17538947.2017.1306126},
journal = {International Journal of Digital Earth},
number = {12},
pages = {1177--1196},
title = {{Augmented virtual environment: fusion of real-time video and 3D models in the digital earth system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016302871{\&}doi=10.1080{\%}2F17538947.2017.1306126{\&}partnerID=40{\&}md5=66f5be004231a78c638f17172996a562},
volume = {10},
year = {2017}
}
@article{Jiang2013363,
abstract = {Bei'an to Heihe expressway utilizes the original second-class highway to widen and expand for expressway, restricted by the original location of old road, widen subgrade of some sections locate in tailing edge of the landslides, influenced by the landform, geological condition, climate and anthropogenic factors, are in unstable states, bring great difficulties to widening and expanding implementation. In process of landslide researching, firstly identify the space form of landslide, analyze the formation mechanism of landslide, evaluate the stability condition and the development tendency of landslide, and then determine the prevention and treatment measures. Took the Bei'an to Heihe expressway cut layer rocky landslide as the research object, employed the geological survey, topographic mapping, geological drilling, indoor test, numerical simulation, field monitoring and theoretical analysis methods to carry an integrated study on the development mechanism and damage mode of the landslide. Through systematic study, drew the conclusions that: the rupture surface is located in completely weathered mudstone; during surveying, the landslide is temporarily in steady state, when the water content continues to increase to 34.7{\%}, the landslide will reach the state of limit equilibrium; atmospheric precipitation, the island permafrost which scattered in the mountain valley melting water, snowmelt water and seasonally frozen soil thawing water provide a continued water source for landslide, surface water and ground water supply the Cretaceous pore water by infiltration and lateral runoff through surface thermal shrinkage cracks and shallow high permeability rock and soil, low permeability mudstone under the loose overburden forms aquiclude, completely weathered mudstone above the aquiclude which is influenced by the Cretaceous pore water to be soften forms rupture surface; due to the permafrost distribution discontinuities and geological conditions difference, the landslide has gradual, low angle, creeping characteristics. {\textcopyright} 2013, Springer-Verlag Berlin Heidelberg.},
annote = {cited By 0},
author = {Jiang, H and Hu, Z and Guo, Y and Wang, C and Shan, W},
doi = {10.1007/978-3-642-29107-4_19},
journal = {Environmental Science and Engineering (Subseries: Environmental Science)},
keywords = {Anthropogenic factors; Atmospheric precipitation;,Aquifers; Frozen soils; Geology; Groundwater; Land,Landslides},
number = {9783642291067},
pages = {363--371},
title = {{Cut layer rocky landslide development mechanism in Lesser Khingan Mountain}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029482672{\&}doi=10.1007{\%}2F978-3-642-29107-4{\_}19{\&}partnerID=40{\&}md5=8cdbe039fe00c359c5cd78f78228ab18},
year = {2013}
}
@inproceedings{Jiang20081,
abstract = {An improved single odor/gas source searching approach using a mobile robot by combining image recognition in complex environments is presented. First, color image segmentation of prospective visual candidates is achieved using Support Vector Machines (SVM). Second, the features of those candidates, such as color, shape and orientation (the posture of the object) are extracted. Third, the robot finds a salient object according to the characteristics of analysis areas. Last, the robot moves towards the object which is the most likely to be an odor/gas source. The robot moves upwind if gas concentration is detected. Otherwise, the robot moves along the new direction obtained from the further analysis. Experimental results show the efficiency and practicality of the approach for localizing a leaking ethanol bottle in complex indoor environments. {\textcopyright} 2008 IEEE.},
annote = {cited By 6},
author = {Jiang, P and Zeng, M and Meng, Q.-H. and Li, F and Li, Y.-H.},
booktitle = {2008 IEEE International Conference on Robotics, Automation and Mechatronics, RAM 2008},
doi = {10.1109/RAMECH.2008.4681447},
keywords = {Color image segmentations; Complex environment; G,Ethanol; Image processing; Image recognition; Imag,Robots},
pages = {1--5},
title = {{A novel object recognition method for mobile robot localizing a single odor/gas source in complex environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-58049104338{\&}doi=10.1109{\%}2FRAMECH.2008.4681447{\&}partnerID=40{\&}md5=f14999fb982ab333565e519242df9501},
year = {2008}
}
@inproceedings{Jiang2006536,
abstract = {The wireless sensor network based localization system-Cicada is designed to support the location-awareness in indoor environment. The system is based on TDOA (time difference of arrival) between radio frequency and ultrasonic to measure the distances, uses the SWF (slide window filter) and least square fitting for the rough distance correction, adopts the UKF (unscented kalman filter) to ultimately estimate the coordinates, and then sends the coordinate values to the network to provide location services. The system has several notable merits: it not only can provide the coordinates within 5cm average deviation either for static object or for mobile object, but also can support multiple objects at the same time; it not only has a nearly omni-directional working area, but also be convenient for deployment and portability. Compared with other indoor localization system, the Cicada system adopts a more accurate algorithm and the whole system is more portable and convenient to deploy. Experiment results show the system can well satisfy the requirements in smart space.{\textcopyright}2006 IEEE.},
annote = {cited By 1},
author = {Jiang, W and Chen, Y and Shi, Y and Sun, Y},
booktitle = {Proceedings - 16th International Conference on Artificial Reality and Telexistence - Workshops, ICAT 2006},
doi = {10.1109/ICAT.2006.128},
keywords = {Average deviation; Experiment results; Indoor env,Control theory; Curve fitting; Detectors; Hybrid s,Wireless sensor networks},
pages = {536--541},
title = {{The design and implementation of the Cicada wireless sensor network indoor localization system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-46449096266{\&}doi=10.1109{\%}2FICAT.2006.128{\&}partnerID=40{\&}md5=52ab64e3d65867eabf7a757e70954a73},
year = {2006}
}
@inproceedings{Jiang:2012:DEW:2185677.2185735,
address = {New York, NY, USA},
author = {Jiang, Xiaofan and Liang, Chieh-Jan Mike and Chen, Kaifei and Zhang, Ben and Hsu, Jeff and Liu, Jie and Cao, Bin and Zhao, Feng},
booktitle = {Proceedings of the 11th International Conference on Information Processing in Sensor Networks},
doi = {10.1145/2185677.2185735},
isbn = {978-1-4503-1227-1},
keywords = {localization,magneto-inductive,tracking,virtual zone},
pages = {221--232},
publisher = {ACM},
series = {IPSN '12},
title = {{Design and Evaluation of a Wireless Magnetic-based Proximity Detection Platform for Indoor Applications}},
url = {http://doi.acm.org/10.1145/2185677.2185735},
year = {2012}
}
@inproceedings{8115865,
abstract = {Some location-aware use cases imply that a person desires to find an object relative to his position. This is the case of museum visits or any indoors/outdoors activity where the objects of interest are not geo-referenced or even can move with time. For these use cases, a user does not need an absolute localization, but a relative information consisting of the range to the object and the heading angle between that object and the user's moving direction. In this paper we study two different radio technologies for finding an object of interest: Ultra-Wide-Band (UWB) and Bluetooth Low Energy (BLE). Range and orientation estimation performance is studied when using just the distance or the Received-Signal-Strength (RSS) provided by UWB and BLE systems, respectively. Both approaches are combined with Pedestrian Dead-reckoning (PDR) estimation in order to analyze the benefits that PDR information provides. For completeness we compare the cases where only one tag is fixed to the object to locate (the simpler and more flexible case) with the more ideal case where several geo-referenced objects of interest, each one with a tag, jointly cooperate to improve the relative location to one of the objects of interest (in both cases the user carries a mobile phone with BLE 4.0 or UWB radio). The UWB ranging radio, not common in most smartphones, but very accurate, is used as our reference to define the best achievable performance goal, in order to compare with BLE RSS-based performance. We demonstrate that the common BLE low ranging-accuracy technology combined with smartphone-based PDR estimation is capable, after some initial user's walking, of finding with decent range and heading accuracy the objects of interest in a museum-like set-up.},
author = {Jim{\'{e}}nez, A R and Seco, F},
booktitle = {2017 International Conference on Indoor Positioning and Indoor Navigation (IPIN)},
doi = {10.1109/IPIN.2017.8115865},
issn = {2471-917X},
keywords = {Bluetooth;indoor radio;mobile computing;pedestrian},
pages = {1--8},
title = {{Finding objects using UWB or BLE localization technology: A museum-like use case}},
year = {2017}
}
@inproceedings{Jimnez2008,
abstract = {This paper presents a method for robustly tracking and estimating the face pose of a person in both indoor and outdoor environments. The method-is invariant to identity and that does not require previous training. A face model is automatically initialized and constructed on-line, when the face is frontal to the stereo camera system. To build the model, a fixed, point distribution is superposed over the frontal face, and, several appropriate points close to those locations are chosen for tracking. Using the stereo correspondence of the two cameras, the 3D coordinates of these points are extracted, wad the 3D model is created, RAN SAC and POSIT are used for tracking and 3D pose calculation at each frame. The approach runs in real time, and has been tested on sequences recorded in the laboratory and in a moving car. {\textcopyright} 2008 IEEE.},
annote = {cited By 9},
author = {Jim{\'{e}}nez, P and Nuevo, J and Bergasa, L M},
booktitle = {2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, CVPR Workshops},
doi = {10.1109/CVPRW.2008.4563051},
keywords = {3-D modeling; 3D coordinates; Face pose; Face pos,Artificial intelligence; Cameras; Computer vision;,Three dimensional},
title = {{Face pose estimation and tracking using automatic 3D model construction}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-51849161394{\&}doi=10.1109{\%}2FCVPRW.2008.4563051{\&}partnerID=40{\&}md5=5e64560df6e7256c5b69ae7cdba1c56e},
year = {2008}
}
@inproceedings{8559703,
abstract = {Radio tomographic imaging (RTI) is an emerging device-free localization (DFL) technology enabling the localization of people and other objects without requiring them to carry any electronic device. This paper uses the way of channel diversity to improve the RTI's positioning accuracy against the issues which are vulnerable to environmental noise. In this paper, based on the multi-channel RTI, an improved joint sparse multi-channel fusion method (IJSM) is proposed. The method decomposes each channel's RTI image into high frequency components and low frequency components, and designs corresponding fusion rules respectively to realize the refined fusion of multi-channel information. Experimental results show that this method can fully explore the correlation among channels and synthesize the favorable information of each channel so as to remove pseudo targets and background noise. Finally this method achieves a well positioning performance.},
author = {Jin, J and Ke, W and Lu, J and Wang, Y and Salcic, Z},
booktitle = {2018 Ubiquitous Positioning, Indoor Navigation and Location-Based Services (UPINLBS)},
doi = {10.1109/UPINLBS.2018.8559703},
keywords = {compressed sensing;diversity reception;image fusio},
pages = {1--6},
title = {{Multi-channel RTI fusion based on improved joint sparse model}},
year = {2018}
}
@article{Jin2015209,
abstract = {The increasing deployment of indoor positioning technologies like RFID, Wi-fi, and Bluetooth offers the possibility to obtain users' trajectories in indoor spaces. In this paper, based on indoor moving-object trajectories, we aim to detect hotspots from indoor trajectory data. Such information is helpful for users to understand the surrounding locations as well as to enable indoor trajectory mining and location recommendation. We first define a new kind of query called indoor hotspot query. Then, we introduce a pre-processing step to remove meaningless locations and obtain indoor stay trajectories. Further, we propose a new approach to answering indoor hotspot queries w.r.t. two factors: (1) users' interests in indoor locations, and (2) the mutual reinforcement relationship between users and indoor locations. Particularly, we construct a userlocation matrix and use an iteration-based technique to compute the hotness of indoor locations. We evaluate our proposal on 223,564 indoor tracking records simulating 100 users' movements over a period of one month in a six-floor building. The results in terms of MAP, P@n, and nDCG show that our proposal outperforms baseline methods like rank-by-visit, rank-by-density, and rank-byduration. {\textcopyright} 2015, Springer International Publishing Switzerland, All rights Reserved.},
annote = {cited By 5},
author = {Jin, P and Du, J and Huang, C and Wan, S and Yue, L},
doi = {10.1007/978-3-319-18120-2_13},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Baseline methods; Hot spot; Indoor moving objects,Database systems; Iterative methods; Location; Que,Trajectories},
pages = {209--225},
title = {{Detecting hotspots from trajectory data in indoor spaces}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942605403{\&}doi=10.1007{\%}2F978-3-319-18120-2{\_}13{\&}partnerID=40{\&}md5=854c9369bd6b62e789288e415e7c0242},
volume = {9049},
year = {2015}
}
@article{Jin20151777,
abstract = {As a survey indicated, people spend around 87{\%} of their time in indoor spaces, e. g., office buildings, shopping malls, and metro stations. With the rapid development of the Internet of Things (IoT) and indoor positioning technologies such as RFID and Wi-Fi, how to effectively manage the rapidly increasing indoor moving objects has been a common and fundamental issue in a lot of application areas including public security and business services. Based on the special features of indoor space regarding space constraint, positioning techniques, and distance measurement, in this paper we summarize the key issues in indoor moving-object databases as well as the recent advances in this area. In particular, we mainly discuss the representation models for indoor spaces, the location and trajectory models for indoor moving objects, the index structures for indoor spaces and indoor moving objects, and the query processing methods for indoor moving objects. Finally, we present some future research topics in indoor moving-object data management. {\textcopyright}, 2015, Jisuanji Xuebao/Chinese Journal of Computers. All right reserved.},
annote = {cited By 8},
author = {Jin, P.-Q. and Wang, N and Zhang, X.-X. and Yue, L.-H.},
doi = {10.11897/SP.J.1016.2015.01777},
journal = {Jisuanji Xuebao/Chinese Journal of Computers},
keywords = {Indoor moving objects; Indoor positioning; Indoor,Information management,Object-oriented databases; Office buildings; Radio},
number = {9},
pages = {1777--1795},
title = {{Moving object data management for indoor spaces}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942881492{\&}doi=10.11897{\%}2FSP.J.1016.2015.01777{\&}partnerID=40{\&}md5=7dc23ac6f0e33a4add34ca16cbfe454f},
volume = {38},
year = {2015}
}
@inproceedings{5509285,
abstract = {In this paper, we consider the problem of how background knowledge about usual object arrangements can be utilized by a mobile robot to more efficiently find an object in an unknown environment. We decompose the action selection problem during the search into two parts. First, we compute a belief over the location of the object and subsequently use the belief to select the next target location the robot should visit. For the inference part, we utilize a maximum entropy model which models the conditional distribution over possible locations of the target object given the observations made so far. The model is based on co-occurrences of objects and object attributes in different spatial contexts. The parameters are learned by maximizing the data likelihood using gradient ascent. We evaluate our approach by simulated search runs based on data obtained from different real-world environments. Our results show a significant improvement over a standard search technique which does not employ domain-specific background knowledge.},
author = {Joho, D and Burgard, W},
booktitle = {2010 IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2010.5509285},
issn = {1050-4729},
keywords = {belief maintenance;entropy;gradient methods;infere},
pages = {723--728},
title = {{Searching for objects: Combining multiple cues to object locations using a maximum entropy model}},
year = {2010}
}
@inproceedings{Joshi:2015:WFD:2789770.2789784,
address = {Berkeley, CA, USA},
author = {Joshi, Kiran and Bharadia, Dinesh and Kotaru, Manikanta and Katti, Sachin},
booktitle = {Proceedings of the 12th USENIX Conference on Networked Systems Design and Implementation},
isbn = {978-1-931971-218},
pages = {189--204},
publisher = {USENIX Association},
series = {NSDI'15},
title = {{WiDeo: Fine-grained Device-free Motion Tracing Using RF Backscatter}},
url = {http://dl.acm.org/citation.cfm?id=2789770.2789784},
year = {2015}
}
@inproceedings{Joy2007261,
abstract = {Determining the location of objects or people in a smart space is one of the prerequisites enabling smart applications. The ideal location system makes use of existing infrastructure such as wireless LAN or cellular communication systems. However, in indoor environment typical wireless LAN systems do not provide sufficient accuracy for many smart applications and such as WLAN based location system needs to be enhanced. This paper involves proposal of a heterogeneous location system based on a combination of IEEE 802.11 WLAN and a sensor network based ultra wideband radar system. The proposed system provides greater accuracy than other proposed systems and provides the added advantage that the sensor network can be utilized for other ubiquitous computing applications. {\textcopyright} 2007 IEEE.},
annote = {cited By 7},
author = {Joy, V and {Laxman P}, V},
booktitle = {NGMAST 2007 - The 2007 International Conference on Next Generation Mobile Applications, Services and Technologies, Proceedings},
doi = {10.1109/NGMAST.2007.4343431},
keywords = {Applications; Cellular radio systems; Communicatio,Cellular communication systems; Computing applica,Local area networks},
pages = {261--266},
title = {{Smart spaces: Indoor wireless location management system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-47849091477{\&}doi=10.1109{\%}2FNGMAST.2007.4343431{\&}partnerID=40{\&}md5=1d50c5a5a45a378f0c9dcd7d2606f296},
year = {2007}
}
@inproceedings{Jung:2008:ICT:1444448.1445117,
address = {Washington, DC, USA},
author = {Jung, Tae-Woong and Pyeon, Mu-Wook and Koo, Jee-Hee and Kim, Jong-Hwa},
booktitle = {Proceedings of the 2008 Fourth International Conference on Networked Computing and Advanced Information Management - Volume 01},
doi = {10.1109/NCM.2008.266},
isbn = {978-0-7695-3322-3},
keywords = {U-space,indoor space,real space,u-GIS,ubiquitous},
pages = {469--473},
publisher = {IEEE Computer Society},
series = {NCM '08},
title = {{Informative Construction Technology Innovation Based on Ubiquitous GIS}},
url = {https://doi.org/10.1109/NCM.2008.266},
year = {2008}
}
@article{Kabbai20181,
abstract = {Several techniques have recently been proposed to extract the features of an image. Feature extraction is one of the most important steps in various image processing and computer vision applications such as image retrieval, image classification, matching, object recognition. Relevant feature (global or local) contains discriminating information and is able to distinguish one object from others. Global features describe the entire image, whereas local features describe the image patches (small group of pixels). In this paper, we present a novel descriptor to extract the color-texture features via two information types. Our descriptor named concatenation of local and global color features is based on the fusion of global features using wavelet transform and a modified version of local ternary pattern, whereas, for the local features, speeded-up robust feature descriptor and bag of words model were used. All the features are extracted from the three color planes. To evaluate the effectiveness of our descriptor for image classification, we carried out experiments using the challenging datasets: New-BarkTex, Outex-TC13, Outex-TC14, MIT scene, UIUC sports event, Caltech 101 and MIT indoor scene. Experimental results showed that our descriptor outperforms the existing state-of-the-art methods. {\textcopyright} 2018 Springer-Verlag GmbH Germany, part of Springer Nature},
annote = {cited By 2; Article in Press},
author = {Kabbai, L and Abdellaoui, M and Douik, A},
doi = {10.1007/s00371-018-1503-0},
journal = {Visual Computer},
keywords = {Bag-of-words models; Color texture features; Imag,Classification (of information); Color; Image retr,Image classification},
pages = {1--15},
title = {{Image classification by combining local and global features}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045061862{\&}doi=10.1007{\%}2Fs00371-018-1503-0{\&}partnerID=40{\&}md5=1cdd00ff468a2afa3c6e91714f910f2a},
year = {2018}
}
@inproceedings{1613601,
abstract = {Indoor positioning systems are platforms required to provide location information for indoor location-aware computing. This study focuses on a type of indoor positioning systems called location fingerprinting technique that utilizes received signal strength indication (RSSI) of wireless local area network (WLAN) interfaces. Thus far, many characteristics of RSSI have not been thoroughly investigated. Many researchers have relied on the RSSI as sensor information to determine objects location while ignoring the characteristic of RSSI. Therefore, this paper looks into underlying mechanism of RSSI from the indoor positioning systems perspective. In particular, the distributions of RSSI from five different IEEE 802.11b/g WLAN interfaces are investigated using extensive measurement experiments. Desired properties of WLAN interfaces for location fingerprinting are also identified based on the measurement results. The ultimate goal is to use additional knowledge gained here to improve positioning performance and to model location fingerprinting based indoor positioning systems.},
author = {Kaemarungsi, K},
booktitle = {2006 1st International Symposium on Wireless Pervasive Computing},
doi = {10.1109/ISWPC.2006.1613601},
keywords = {wireless LAN;indoor radio;WLAN;received signal str},
month = {jan},
pages = {6 pp.--6},
title = {{Distribution of WLAN received signal strength indication for indoor location determination}},
year = {2006}
}
@phdthesis{Kaemarungsi:2005:DIP:1123917,
address = {Pittsburgh, PA, USA},
annote = {AAI3188962},
author = {Kaemarungsi, Kamol},
isbn = {0-542-31142-9},
publisher = {University of Pittsburgh},
title = {{Design of Indoor Positioning Systems Based on Location Fingerprinting Technique}},
year = {2005}
}
@article{Kanaris:2016:SSD:2938794.2939041,
address = {New York, NY, USA},
author = {Kanaris, Loizos and Kokkinis, Akis and Fortino, Giancarlo and Liotta, Antonio and Stavrou, Stavros},
doi = {10.1016/j.comnet.2015.12.015},
issn = {1389-1286},
journal = {Comput. Netw.},
keywords = {Evaluation,Indoor positioning systems,Internet of Things,Localization error,Positioning accuracy,Sample size},
number = {C},
pages = {169--177},
publisher = {Elsevier North-Holland, Inc.},
title = {{Sample Size Determination Algorithm for Fingerprint-based Indoor Localization Systems}},
url = {http://dx.doi.org/10.1016/j.comnet.2015.12.015},
volume = {101},
year = {2016}
}
@inproceedings{Kang200933,
abstract = {In this paper, we propose a data driven approach to firstperson vision. We propose a novel image matching algorithm, named Re-Search, that is designed to cope with selfrepetitive structures and confusing patterns in the indoor environment. This algorithm uses state-of-art image search techniques, and it matches a query image with a two-pass strategy. In the first pass, a conventional image search algorithm is used to search for a small number of images that are most similar to the query image. In the second pass, the retrieval results from the first step are used to discover features that are more distinctive in the local context. We demonstrate and evaluate the Re-Search algorithm in the context of indoor localization, with the illustration of potential applications in object pop-out and data-driven zoom-in. {\textcopyright} 2009 IEEE.},
annote = {cited By 36},
author = {Kang, H and Efros, A A and Hebert, M and Kanade, T},
booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2009},
doi = {10.1109/CVPR.2009.5204357},
keywords = {Art image; Data-driven; Data-driven approach; Imag,Computer vision; Image retrieval; Learning algori,Image matching},
pages = {33--40},
title = {{Image matching in large scale indoor environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449602002{\&}doi=10.1109{\%}2FCVPR.2009.5204357{\&}partnerID=40{\&}md5=26f391e7ee22a0dda23166167e007ea2},
year = {2009}
}
@inproceedings{Kang2016303,
abstract = {Sophisticated indoor design and growing development in urban architecture make indoor spaces more complex. And the indoor spaces are easily connected to public transportations such as subway and train stations. These phenomena allow to transfer outdoor activities to the indoor spaces. Constant development of technology has a significant impact on people knowledge about services such as location awareness services in the indoor spaces. Thus, it is required to develop the low-cost system to create the 3D model of the indoor spaces for services based on the indoor models. In this paper, we thus introduce the rotating stereo frame camera system that has two cameras and generate the indoor 3D model using the system. First, select a test site and acquired images eight times during one day with different positions and heights of the system. Measurements were complemented by object control points obtained from a total station. As the data were obtained from the different positions and heights of the system, it was possible to make various combinations of data and choose several suitable combinations for input data. Next, we generated the 3D model of the test site using commercial software with previously chosen input data. The last part of the processes will be to evaluate the accuracy of the generated indoor model from selected input data. In summary, this paper introduces the low-cost system to acquire indoor spatial data and generate the 3D model using images acquired by the system. Through this experiments, we ensure that the introduced system is suitable for generating indoor spatial information. The proposed low-cost system will be applied to indoor services based on the indoor spatial information.},
annote = {cited By 0},
author = {Kang, J and Lee, I},
booktitle = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
doi = {10.5194/isprsarchives-XLI-B4-303-2016},
keywords = {3D modelling; Accuracy evaluation; Camera systems,Cameras,Costs; Image acquisition; Input output programs; R},
pages = {303--308},
title = {{3D modelling of an indoor space using a rotating stereo frame camera system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978034207{\&}doi=10.5194{\%}2Fisprsarchives-XLI-B4-303-2016{\&}partnerID=40{\&}md5=18000053581f70308626694073709560},
volume = {41},
year = {2016}
}
@inproceedings{Kanwar2014719,
abstract = {Recognition using gait is a behavioral biometric technique which is based on the idea that no two persons in the world can have same walking style on feet. Gait refers to a particular way or manner of walking on feet. People can be monitored and identified at a distance without knowledge to subject. This paper gait recognition system, which is insensitive to view, clothing and lightning conditions. In the proposed work, an infrared camera is used to capture videos of moving objects. After that background subtraction is performed i.e. foreground objects (moving objects) like human, vehicles and animals are extracted by estimating background information. This is achieved using Gaussian Mixture Model (GMM) followed by morphological median filtering operation to remove noise in the background subtracted image. A classification metric is used to separate human being from other foreground objects. Shape and boundary information is used in the moving target classification. Subsequently, width vector of the outer contour of binary silhouette and the MPEG-7 Angular Radial Transform coefficients are taken as the feature vector. Binary silhouette obtained is used to produce gait features of a person. Independent Component Analysis (ICA) applied to reduce dimensionality of the features vectors. These feature vectors used to train Support Vector Machine (SVM) for recognition of some individual. Length of gait cycle, maximum feet and hands distance, contour height, center of mass and color are taken as key feature. Proposed approach is tested over a self created database of thirteen different people with different resolution conditions. In indoor environment an average recognition percentage upto 97.73{\%} and for outdoor conditions recognition is upto 86.28{\%} (daylight) and 78.32{\%} recognition at night hours is observed. Use of infrared cameras makes it quite advantageous to be used at night. {\textcopyright} 2014 IEEE.},
annote = {cited By 1},
author = {Kanwar, A and Upadhyay, P},
booktitle = {Proceedings of the 2014 International Conference on Issues and Challenges in Intelligent Computing Techniques, ICICT 2014},
doi = {10.1109/ICICICT.2014.6781369},
keywords = {Angular radial transform; Angular radial transfor,Biometrics; Face recognition; Gait analysis; Image,Support vector machines},
pages = {719--724},
title = {{An appearance based approach for gait identification using infrared imaging}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899093819{\&}doi=10.1109{\%}2FICICICT.2014.6781369{\&}partnerID=40{\&}md5=1029cacdc1dcd885c3cc0e8caf878bb2},
year = {2014}
}
@inproceedings{Karaoguz2017844,
abstract = {In this paper, we present an object based approach for human-centric partitioning of the environment. Our approach for determining the human-centric regions is to detect the objects that are commonly associated with frequent human presence. In order to detect these objects, we employ state of the art perception techniques. The detected objects are stored with their spatio-temporal information in the robot's memory to be later used for generating the regions. The advantages of our method is that it is autonomous, requires only a small set of perceptual data and does not even require people to be present while generating the regions. The generated regions are validated using a 1-month dataset collected in an indoor office environment. The experimental results show that although a small set of perceptual data is used, the regions are generated at densely occupied locations. {\textcopyright} 2017 IEEE.},
annote = {cited By 1},
author = {Karaoguz, H and Bore, N and Folkesson, J and Jensfelt, P},
booktitle = {RO-MAN 2017 - 26th IEEE International Symposium on Robot and Human Interactive Communication},
doi = {10.1109/ROMAN.2017.8172401},
keywords = {Human-centric; Object based; Office environments;,Object detection,Robots},
pages = {844--850},
title = {{Human-centric partitioning of the environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045847052{\&}doi=10.1109{\%}2FROMAN.2017.8172401{\&}partnerID=40{\&}md5=ccb67054b645bfd6bd0c9141f9053a3f},
volume = {2017-Janua},
year = {2017}
}
@phdthesis{Karliga:2011:FHB:2231354,
address = {Seattle, WA, USA},
annote = {AAI3452727},
author = {Karliga, Ibrahim},
isbn = {978-1-124-60470-1},
publisher = {University of Washington},
title = {{A Framework for Human Body Video Object Segmentation and Body Parts Tracking}},
year = {2011}
}
@inproceedings{Karmacharya2015,
abstract = {Modern instruments like laser scanner and 3D cameras or image based techniques like structure from motion produce huge point clouds as base for further object analysis. This has considerably changed the way of data compilation away from selective manually guided processes towards automatic and computer supported strategies. However it's still a long way to achieve the quality and robustness of manual processes as data sets are mostly very complex. Looking at existing strategies 3D data processing for object detections and reconstruction rely heavily on either data driven or model driven approaches. These approaches come with their limitation on depending highly on the nature of data and inability to handle any deviation. Furthermore, the lack of capabilities to integrate other data or information in between the processing steps further exposes their limitations. This restricts the approaches to be executed with strict predefined strategy and does not allow deviations when and if new unexpected situations arise. We propose a solution that induces intelligence in the processing activities through the usage of semantics. The solution binds the objects along with other related knowledge domains to the numerical processing to facilitate the detection of geometries and then uses experts' inference rules to annotate them. The solution was tested within the prototypical application of the research project 'Wissensbasierte Detektion von Objekten in Punktwolken f{\"{u}}r Anwendungen im Ingenieurbereich (WiDOP)'. The flexibility of the solution is demonstrated through two entirely different USE Case scenarios: Deutsche Bahn (German Railway System) for the outdoor scenarios and Fraport (Frankfort Airport) for the indoor scenarios. Apart from the difference in their environments, they provide different conditions, which the solution needs to consider. While locations of the objects in Fraport were previously known, that of DB were not known at the beginning. {\textcopyright} 2015 SPIE.},
annote = {cited By 1},
author = {Karmacharya, A and Boochs, F and Tietz, B},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.2184801},
keywords = {Cameras; Data handling; Expert systems; Object det,Detection and identifications; Image-based techni,Three dimensional computer graphics},
title = {{Knowledge guided object detection and identification in 3D point clouds}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954111763{\&}doi=10.1117{\%}2F12.2184801{\&}partnerID=40{\&}md5=fdeb3224cba77258b7c4c5a2e0c81818},
volume = {9528},
year = {2015}
}
@inproceedings{Karppinen2000274,
abstract = {Free-space optical transmission provides large bandwidth, small size, lightweight, low cost and good security. Diffuse infrared link configuration is also rather robust against shadowing. Its disadvantages are, however, bandwidth degradation due to multipath dispersion, sensitivity to ambient light and limited transmission distance due to the limitations of optical power budget. To specify the bandwidth and power budget requirements of the diffuse link, we performed ray-trace simulations for different room geometries and dimensions, and different transmitter and receiver locations. We considered both diffuse and specular reflections as well as shadowing and reflection effects due to blocking objects, such as furniture. The simulations were verified by analytically calculating the impulse response in simple diffuse reflection geometry. We also analyzed stray light induced shot noise effects. Furthermore, we simulated some properties of a quasi-diffuse link comprising of multi-beam transmitters with restricted beam divergences as well as detectors with narrow fields of view. Based on the study, novel Monte Carlo ray-tracing software packages, such as ASAP, can be used for diffuse link multipath dispersion and optical power path loss analysis. Ray tracing can also be used for parallel channel crosstalk and stray light analysis. Potential applications for these systems are high-bit-rate wireless LANs and free-space optical interconnects.},
annote = {cited By 1},
author = {Karppinen, Mikko and Juuso, Sanna and Makinen, Jukka-Tapani and Rajaniemi, Hannu and Karioja, Pentti},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
keywords = {Bandwidth; Communication channels (information the,Free-space optical transmission; Indoor data link,Optical communication},
pages = {274--285},
title = {{Ray-tracing simulations of free-space optical channels for impulse response studies of indoor data links}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033730954{\&}partnerID=40{\&}md5=a84e0c919409b0655b1d2b2a0951e208},
volume = {3952},
year = {2000}
}
@inproceedings{Kathiravan2009488,
abstract = {RFID is fast becoming a part of all applications, which involve automatic identification and information retrieval. The more recent applications of RFID include garbage management and health monitor. In addition to the inventory and supply chain management applications for which it was originally designed, RFID can also be used for location tracking of objects. Use of RFID system for location tracking purposes helps increase supply chain and assembly line visibility. Indoor location sensing suffers from a variety of problems, which are absent in the case of outdoor location sensing. In our proposed system, we are going to use directional antenna along with RFID reader. In the proposed method, an RFID reader has multi-sensing ranges. Therefore the proposed method can perform the prompt positional estimation, i.e. the method can produce the accurate estimation of tag's positions. {\textcopyright} 2009 IEEE.},
annote = {cited By 0},
author = {Kathiravan, K and Pradeep, P and Ronak, G and Roshan, S S},
booktitle = {EMS 2009 - UKSim 3rd European Modelling Symposium on Computer Modelling and Simulation},
doi = {10.1109/EMS.2009.46},
keywords = {Accurate estimation; Assembly line; Automatic iden,Ad hoc networks,Automation; Computer simulation; Directional patt},
pages = {488--493},
title = {{Modeling location monitoring system using directional antennas}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951021437{\&}doi=10.1109{\%}2FEMS.2009.46{\&}partnerID=40{\&}md5=92f586b01607c435b7ff54f53fed3518},
year = {2009}
}
@article{Kattenbeck2012338,
abstract = {Due to increasing pervasiveness of mobile computing, pedestrian navigation systems have become quite popular to users. In contrast to vehicle navigation systems, users, who walk, prefer salient objects, i. e. landmarks, to orient themselves. However, neither the topological relation between users and landmarks, nor the composition of landmarks has been used in prototypes before. The goal of the dissertation is to fill this gap, i. e. to gain an insight into the preconditions of in situ use of the theoretical work already done. This kind of research is deeply rooted in the fields of Information Processing, Information Retrieval and Human-Computer Interaction and hence in Information Science in general.},
annote = {cited By 0},
author = {Kattenbeck, M},
doi = {10.1515/iwp-2012-0068},
journal = {Information-Wissenschaft und Praxis},
number = {5},
pages = {338--342},
title = {{Data models of landmarks - From an information science perspectice. An experience-based approach for indoor and outdoor navigation [Handlungsorientierte Modellierung von Landmarken im Innen- und Au{\ss}enbereich. Eine informationswissenschaftliche Fragestellu}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879019626{\&}doi=10.1515{\%}2Fiwp-2012-0068{\&}partnerID=40{\&}md5=a1a1cd889bfd2c292e83f88f6d89e814},
volume = {63},
year = {2012}
}
@inproceedings{Kawai2005498,
abstract = {In recent years, many papers have demonstrated "ubiquitous" services for indoor human location. Under the conventional method of position detection, the major approach is to generate electromagnetic waves or light rays as in Active Badge or RFID tags. However, in the case of practical applications for infant education, parents are wary of methods that employ radiated electromagnetic waves. In this article we propose a high-precision positioning system for children in a room, using only a combination of image data and passive motion sensors. We evaluate some alternative implementations experimentally. These evaluations probe whether the combination of a pedometer approach to analyze motion sensor data and moving-object detection from video camera images is the best combination with respect to ease of operation and accuracy. The proposed method cannot yet analyze data in real time. It may, however, be possible to apply the technique to various fields with little need for expansion, based on location information.},
annote = {cited By 10},
author = {Kawai, J and Shintani, K and Haga, H and Kaneda, S},
booktitle = {Proceedings of the IASTED International Conference on Web-Based Education, WBE 2005},
keywords = {Activity tracking; Conventional methods; High-prec,Educational technology; Electromagnetic waves; Im,Radio frequency identification (RFID)},
pages = {498--504},
title = {{Identification and positioning based on motion sensors and a video camera}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887309900{\&}partnerID=40{\&}md5=389d2c2335f8b17f5e1e774bddc951ad},
year = {2005}
}
@inproceedings{Kawauchi2012477,
abstract = {Mobile devices have become wide spread, as a result of improvements in hardware and communication technologies. These devices are equipped with some sensors to protect themselves. In recently years, technologies have been developed that allow a device to recognize its environments using sensor data are developed. However, in an indoor environment, there are objects that affect sensor data. Therefore, sensors required either calibration to adjust their behavior, or clarification of the cause of incorrect behavior. This requires large amounts of sensor data to be collected indoors, but it is difficult for humans to collect this data in the indoor environment. Methods of data collection by humans are limited by the number of observation points that can reasonably be attained. In this paper, we proposed the FineMesh method for dense sampling using an autonomous robot. Our proposed method aims to increase the number of observation points. We constructed an autonomous robot that collects signals at 10 cm intervals using positioning estimates with camera images. To confirm the effect of collecting signals in more detail, we evaluate the accuracy of a Wi-Fi indoor positioning system constructed by our robot. We then use our platform to evaluate the efficacy of detailed signal collection. {\textcopyright} 2012 IEEE.},
annote = {cited By 1},
author = {Kawauchi, K and Rekimoto, J},
booktitle = {Proceedings - 2012 IEEE Int. Conf. on Green Computing and Communications, GreenCom 2012, Conf. on Internet of Things, iThings 2012 and Conf. on Cyber, Physical and Social Computing, CPSCom 2012},
doi = {10.1109/GreenCom.2012.56},
keywords = {Communication technologies; Digital compass; Indoo,Internet; Mobile devices; Robots; Wi-Fi,Sensors},
pages = {477--486},
title = {{FineMesh: High-density sampling platform using an autonomous robot}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875488139{\&}doi=10.1109{\%}2FGreenCom.2012.56{\&}partnerID=40{\&}md5=826d80c6239fe78a6350650fdc59d508},
year = {2012}
}
@article{Kawsar2009483,
abstract = {One of the primary requirements for future ubiquitous environment is to exploit location information to provide contextual services. Typical indoor location systems are heavily infra-structured making it difficult to deploy practically in home settings. In this article we propose a lightweight location model utilizing existing physical objects in our environment. Our approach is to use sensor augmented daily life objects surrounding us for extracting location information. Some of these everyday objects are static in nature and have designated location, like a bed in the bedroom, a refrigerator in the kitchen, etc. Utilizing this characteristics, we present "Spreha", a light weight hierarchical location model where static physical objects are used as reference points for identifying mobile objects like a chair, a watch, a lamp, etc. The model is organized in a tree structure representing the containment relationship and is independent of underlying sensing infrastructure. A prototype implementation of the model has been constructed as a pluggable module of a generic middleware using Bluetooth technology. This paper discusses about the design, architecture and findings of the prototype implementation. The implication of such lightweight location model is very important in realizing future environments where ubiquitous services will merge with grid services.},
annote = {cited By 2},
author = {Kawsar, F and Fujinami, K and Park, J H and Nakajima, T and Lee, J B and Rim, K W},
journal = {Journal of Internet Technology},
keywords = {Bluetooth technology; Daily lives; Grid services;,Grid computing; Middleware,Software prototyping},
number = {5},
pages = {483--496},
title = {{A smart object centric indoor location model for future ubiquitous and grid services}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950301857{\&}partnerID=40{\&}md5=7d4e79b2c178064b0fdce4dfde9a00ea},
volume = {10},
year = {2009}
}
@inproceedings{Kempke2016,
abstract = {We introduce Harmonium, a novel ultra-wideband RF localization architecture that achieves decimeter-scale accuracy indoors. Harmonium strikes a balance between tag simplicity and processing complexity to provide fast and accurate indoor location estimates. Harmonium uses only commodity components and consists of a small, inexpensive, lightweight, and FCC-compliant ultra-wideband transmitter or tag, fixed infrastructure anchors with known locations, and centralized processing that calculates the tag's position. Anchors employ a new frequency-stepped narrowband receiver architecture that rejects narrowband interferers and extracts high-resolution timing information without the cost or complexity of traditional ultra-wideband approaches. In a complex indoor environment, 90{\%} of position estimates obtained with Harmonium exhibit less than 31 cm of error with an average 9 cm of inter-sample noise. In non-line-of-sight conditions (i.e. through-wall), 90{\%} of position error is less than 42 cm. The tag draws 75 mW when actively transmitting, or 3.9 mJ per location fix at the 19 Hz update rate. Tags weigh 3 g and cost {\$}4.50 USD at modest volumes. Harmonium introduces a new design point for indoor localization and enables localization of small, fast objects such as micro quadrotors, devices previously restricted to expensive optical motion capture systems. {\textcopyright} 2016 IEEE.},
annote = {cited By 9},
author = {Kempke, B and Pannuto, P and Dutta, P},
booktitle = {2016 15th ACM/IEEE International Conference on Information Processing in Sensor Networks, IPSN 2016 - Proceedings},
doi = {10.1109/IPSN.2016.7460675},
keywords = {Broadband networks,Centralized processing; Commodity components; Ind,Complex networks; Costs; Indoor positioning system},
title = {{Harmonium: Asymmetric, Bandstitched UWB for Fast, Accurate, and Robust Indoor Localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971249872{\&}doi=10.1109{\%}2FIPSN.2016.7460675{\&}partnerID=40{\&}md5=f3dc452e7cb0c7d5226c8b6332e651dc},
year = {2016}
}
@inproceedings{Khalaf-Allah2007,
abstract = {Dead reckoning (DR) via direction and distance could provide an accurate way of maintaining location information for mobile terminals when loss of GPS signals occurs. Furthermore, DR would provide reliable solutions in indoor/outdoor transitions, street canyons, and heavy tree canopies where GPS information is almost always inapplicable. Thus, DR is a desirable option for security and commercial applications that value position information. This paper describes and investigates how DR could provide accurate and reliable positioning using radio profile databases and map-matching. The proposed technique solves both the position tracking and global localization problems, so that mobile terminal localization could be achieved in case of GPS outage or even without any GPS information at all respectively. {\textcopyright} 2007 IEEE.},
annote = {cited By 0},
author = {Khalaf-Allah, M and Kyamakya, K},
booktitle = {IEEE Workshop on Signal Processing Advances in Wireless Communications, SPAWC},
keywords = {Cellular networks; Commercial applications; Dead,Cellular neural networks; Cellular telephone syste,Tracking (position)},
title = {{Position tracking and global localization of mobile terminals in cellular networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-48049118192{\&}partnerID=40{\&}md5=5dbcafee4e4c4a046a6500c4dc39d2d2},
year = {2007}
}
@article{Khan20151326,
abstract = {Localization, finding the coordinates of an object with respect to other objects with known coordinates - hereinafter, referred to as anchors, is a nonlinear problem, as it involves solving circle equations when relating distances to Cartesian coordinates, or, computing Cartesian coordinates from angles using the law of sines. This nonlinear problem has been a focus of significant attention over the past two centuries and the progress follows closely with the advances in instrumentation as well as applied mathematics, geometry, statistics, and signal processing. The Internet-of-Things (IoT), with massive deployment of wireless tagged things, has renewed the interest and activity in finding novel, expert, and accurate indoor self-localization methods, where a particular emphasis is on distributed approaches. This paper is dedicated to reviewing a notable alternative to the nonlinear localization problem, i.e., a linear-convex method, based on Khan et al.'s work. This linear solution utilizes relatively unknown geometric concepts in the context of localization problems, i.e., the barycentric coordinates and the Cayley-Menger determinants. Specifically, in an {\$}m{\$} -dimensional Euclidean space, a set of {\$}m+1{\$} anchors, objects with known locations, is sufficient (and necessary) to localize an arbitrary collection of objects with unknown locations - hereinafter, referred to as sensors, with a linear-iterative algorithm. To ease the presentation, we discuss the solution under a structural convexity condition, namely, the sensors lie inside the convex hull of at least {\$}m+1{\$} anchors. Although rigorous results are included, several remarks and discussion throughout this paper provide the intuition behind the solution and are primarily aimed toward researchers and practitioners interested in learning about this challenging field of research. Additional figures and demos have been added as auxiliary material to support this aim. {\textcopyright} 2013 IEEE.},
annote = {cited By 5},
author = {Khan, U A and Kar, S and Moura, J M F},
doi = {10.1109/ACCESS.2015.2464812},
journal = {IEEE Access},
keywords = {Algorithms; Computation theory; Computational mech,Barycentric coordinates; Cartesian coordinate; Ca,Indoor positioning systems},
pages = {1326--1339},
title = {{Linear Theory for Self-Localization: Convexity, Barycentric Coordinates, and Cayley-Menger Determinants}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959853665{\&}doi=10.1109{\%}2FACCESS.2015.2464812{\&}partnerID=40{\&}md5=0aacc4a78f1a83a459db8367120a4ffa},
volume = {3},
year = {2015}
}
@inproceedings{Kho2015152,
abstract = {This paper presents a conceptual design for tracking the location of a moving object within an indoor array of wireless transceivers passively, without the need for an electronic device or tag attached to the object. The conventional problem of signal attenuation due to object blocking, or shadowing prevalent in a typical wireless communication system is exploited to track an object. This is based on the principle of signal attenuation resulting from the object blocking the line-of-sight (LOS) link in a transceiver set. In particular, Wi-Fi transceivers operating at a frequency of 2.4 GHz (IEEE 802.11g standard) have been investigated. The estimated location is approximated using the measured received signal strength (RSS) and the relative distances between the transmitters and a receiver. Experimental results within a 3 m  5 m area show that it is possible to track a human being using the proposed configuration. {\textcopyright} 2015 IEEE.},
annote = {cited By 5},
author = {Kho, Y H and Chong, N S and Ellis, G A and Kizilirmak, R C},
booktitle = {I4CT 2015 - 2015 2nd International Conference on Computer, Communications, and Control Technology, Art Proceeding},
doi = {10.1109/I4CT.2015.7219556},
keywords = {Conceptual design; Location; RSS; Signal processin,Indoor positioning; Object Tracking; Radio freque,Radio transceivers},
pages = {152--156},
title = {{Exploiting RF signal attenuation for passive indoor location tracking of an object}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944389823{\&}doi=10.1109{\%}2FI4CT.2015.7219556{\&}partnerID=40{\&}md5=6febe7cf95d1f225daa8e65f100cbac7},
year = {2015}
}
@inproceedings{Khoury2007838,
abstract = {This paper presents research that is investigating the requirements of an automated location-based methodology to rapidly identify and retrieve contextual project information on indoor and outdoor construction sites for supporting decision-making tasks of site personnel. The proposed approach to this retrieval task is the design and implementation of a dynamic user-viewpoint tracking scheme that can allow identification of construction entities visible in a user's field of view at any given time and location. For outdoor applications, a geo-referencing based algorithm has been developed using Global Positioning System (GPS) receivers and magnetic orientation tracking devices to successfully track user's dynamic viewpoint. For indoor applications, this research is studying the applicability of Wireless Local Area Networks (WLAN) for dynamic user position tracking. The objectives of this paper are to describe the overall methodology being designed as well as to describe the proof of concept experiments performed outdoors and indoors. The obtained results highlighted the potential of using location-aware technologies for rapidly detecting contextual objects in construction environments. {\textcopyright} 2007 American Society of Civil Engineers.},
annote = {cited By 9},
author = {Khoury, H M and Kamat, V R},
booktitle = {Congress on Computing in Civil Engineering, Proceedings},
doi = {10.1061/40937(261)99},
keywords = {Civil engineering; Tracking (position); Wireless,Construction environment; Contextual information;,Global positioning system},
pages = {838--845},
title = {{WLAN based user position tracking for contextual information access in indoor construction environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891326200{\&}doi=10.1061{\%}2F40937{\%}28261{\%}2999{\&}partnerID=40{\&}md5=66a57a05ee4d007361231e75348039b4},
year = {2007}
}
@inproceedings{Kianoush20171253,
abstract = {Device-free localization (DFL) technology exploits target-induced fading over machine-type wireless links for passive object localization and tracking. In most cases, single frequency measurements are employed for DFL systems. However, machine-type communication protocols often employ slotted or time-division hopping policies over multiple channels, i.e. frequencies. In this paper, we propose a DFL system designed to extract and track the locations of the targets that are hidden into multi-frequency received signal strength (RSS) measurements. Due to strong multipath phenomena and in-band interferences, the use of some noisy channels might worsen the localization accuracy. A statistical model is thus proposed to relate RSS values obtained at various frequencies to the target location. Two different approaches based on optimal frequency selection and subspace decomposition are then proposed to identify the frequency measurements that maximize the localization accuracy. Experimental validation in an indoor multipath-limited environment reveals that the approach can improve the accuracy of both single and double target detection and localization with respect to the conventional single channel DFL approach. {\textcopyright} 2017 IEEE.},
annote = {cited By 2},
author = {Kianoush, S and Savazzi, S and Rampa, V},
booktitle = {2017 IEEE International Conference on Communications Workshops, ICC Workshops 2017},
doi = {10.1109/ICCW.2017.7962830},
keywords = {Detection and localization; Device-free localizat,Fading (radio); Internet of things; Object recogni,Wireless sensor networks},
pages = {1253--1259},
title = {{Tracking of frequency selectivity for device-free detection of multiple targets}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026255828{\&}doi=10.1109{\%}2FICCW.2017.7962830{\&}partnerID=40{\&}md5=0684fe9579d1970b4613f8c9a96bf51f},
year = {2017}
}
@inproceedings{Kiatdarakun201396,
abstract = {RFID system uses sources emitting electromagnetic waves (RFID readers) to locate one or more targets (RFID tags), with the possible use of additional RFID tags as references. RFID positioning system is useful for localization, and is challenging for indoor environments. This research focuses on a 3-D based RFID positioning system, and the simulations are based on a hexahedron shape which can be a room or a container. The system enable many applications such as locating a small piece of object or person in a room or buildings, implementing indoor navigation system and so forth. Our scheme uses small number of readers whereas the locations are set to yield minimal interference. Small number of readers lead to lower cost of the system, and lower interference means higher performance for our system in a practical usage. Our calculation is based on the power level of each reader. In this paper, we propose the power searching scheme to improve the performance, and also a shift algorithm to improve the localization accuracy at the edge. With the help of a Gr{\"{o}}bner basis, the estimation can be well accomplished. {\textcopyright} 2013 IEEE.},
annote = {cited By 1},
author = {Kiatdarakun, T and Suksompong, P and Charoenlarpnopparut, C and Taparugssanagorn, A},
booktitle = {13th International Symposium on Communications and Information Technologies: Communication and Information Technology for New Life Style Beyond the Cloud, ISCIT 2013},
doi = {10.1109/ISCIT.2013.6645830},
keywords = {Algorithms; Communication; Navigation systems; Ra,Emitting electromagnetic waves; Indoor environment,Information technology},
pages = {96--100},
title = {{3-D localization algorithm using double-planar passive RFID arrays}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891137291{\&}doi=10.1109{\%}2FISCIT.2013.6645830{\&}partnerID=40{\&}md5=01b2e183a7de9267b9a75996ce73b3f8},
year = {2013}
}
@article{988659,
abstract = {The new video-coding standard MPEG-4 enables content-based$\backslash$nfunctionality, as well as high coding efficiency, by taking into account$\backslash$nshape information of moving objects. A novel algorithm for segmentation$\backslash$nof moving objects in video sequences and extraction of video object$\backslash$nplanes (VOPs) is proposed . For the case of multiple video objects in a$\backslash$nscene, the extraction of a specific single video object (VO) based on$\backslash$nconnected components analysis and smoothness of VO displacement in$\backslash$nsuccessive frames is also discussed. Our algorithm begins with a robust$\backslash$ndouble-edge map derived from the difference between two successive$\backslash$nframes. After removing edge points which belong to the previous frame,$\backslash$nthe remaining edge map, moving edge (ME), is used to extract the VOP.$\backslash$nThe proposed algorithm is evaluated on an indoor sequence captured by a$\backslash$nlow-end camera as well as MPEG-4 test sequences and produces promising$\backslash$nresults},
author = {Kim, Changick and Hwang, Jenq Neng},
doi = {10.1109/76.988659},
issn = {10518215},
journal = {IEEE Transactions on Circuits and Systems for Video Technology},
keywords = {Change detection,Object tracking,Video object,Video object segmentation},
number = {2},
pages = {122--129},
title = {{Fast and automatic video object segmentation and tracking for content-based applications}},
volume = {12},
year = {2002}
}
@phdthesis{Kim:1994:IRN:922933,
address = {Los Angeles, CA, USA},
annote = {AAI9621618},
author = {Kim, Dongsung},
publisher = {University of Southern California},
title = {{Indoor Robot Navigation with a Generic Map}},
year = {1994}
}
@inproceedings{Kim1994475,
abstract = {We introduce a spatial representation, s-map, for an indoor navigation robot. The s-map represents the locations of obstacles in a planar domain, where obstacles are defined as any objects that can block movement of the robot. In building the s-map, the viewing triangle constraint and the stability constraint are introduced for efficient verification of vertical surfaces. These verified vertical surfaces and 3-D segments of obstacles smaller than a robot, are mapped to the s-map by simply dropping height information. Thus, the s-map is made directly form 3-D segments with simple verification, and represents obstacles in a planar domain so that it becomes a navigable map for the robot without further processing. In addition to efficient map building, the s-map represents the environment more realistically and completely. Furthermore, the s-map converts many navigation problems in 3-D, such as map fusion and path planning, into 2-D ones. We present the analysis of the s-map in terms of complexity and reliability, and discuss its pros and cons. Moreover, we show the results of the s-maps for indoor environments.},
annote = {cited By 9},
author = {Kim, Dongsung and Nevatia, Ramakant},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
keywords = {Computational complexity; Constraint theory; Maps;,Computer vision,Generic map; Indoor navigation; Navigation robots},
pages = {475--482},
title = {{Representation and computation of the spatial environment for indoor navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0028096375{\&}partnerID=40{\&}md5=7e5655e103a914646e7d8a26313a70da},
year = {1994}
}
@article{Kim2009164,
abstract = {There are Location Based Service (LBS) localization techniques such as Global Positioning System (GPS), Angle of Arrival (AOA) and Time Difference of Arrival (TDOA). To use these methods it should be guaranteed that received signals propagate through a Line-of-Sight (LoS) path. Fingerprinting methods have appeared to perform better in None Line-of-Sight (NLoS) environment. But these also have a problem in the dynamic environment where moving obstructions disrupt the signal propagation. To solve these problems we propose a method and algorithm. Tags are mapped to geographical coordinates and deployed on the ceiling with grid spacing. RFID reader is equipped on the target moving object and obtains the information from the tags on the ceiling. And it sends to location engine. The location engine can determine the location of the target object via the collected tags set with proposed Onion Skin Location Determination (OSLE) algorithm. {\textcopyright} 2009 Springer-Verlag Berlin Heidelberg.},
annote = {cited By 1},
author = {Kim, G and Hong, B},
doi = {10.1007/978-3-642-10549-4_20},
journal = {Communications in Computer and Information Science},
keywords = {Angle of arrival; Dynamic environments; Geographic,Error analysis; Grid computing; Mesh generation;,Tracking (position)},
pages = {164--175},
title = {{RFID-based onion skin location estimation technique in indoor environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952284890{\&}doi=10.1007{\%}2F978-3-642-10549-4{\_}20{\&}partnerID=40{\&}md5=498c8e3e1b98d434d0000c4ae9f7596b},
volume = {63},
year = {2009}
}
@article{Kim201771,
abstract = {Beacons can provide various application services such as context awareness related to objects, content push, indoor location technology, and auto check in, and thus, it is emerging as a core technology that supports the amalgamation of online and off-line services. Moreover, a demand for Internet of Things (IoT) services is constantly increasing. Among Internet of Things (IoT) technologies, beacon service technology is receiving particular attention because it can generate new, diverse services for customers. Above all, beacon service serves as both a reference point that provides location-related information and a milestone for supporting beacon location technology. Furthermore, as beacons can be effectively used as an information enhancement service and indoor location technology, they are expected to be useful for business marketing. In this study, an education information service for use in universities was designed and implemented with a focus on the location technology offered by beacon and Internet of Things (IoT) technologies. Indeed, educational sites intend to provide various information services to the consumers they support with education. It is anticipated that beacon and Internet of Things (IoT) technologies can be used to facilitate the configuration of an application service that assists the supply of information services. {\textcopyright} 2017 SERSC Australia.},
annote = {cited By 0},
author = {Kim, H J and Kim, M S},
doi = {10.14257/ijast.2017.108.07},
journal = {International Journal of Advanced Science and Technology},
pages = {71--82},
title = {{Design and implementation of user-specific information service applying beacon and Internet of Things technologies at education sites}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037165193{\&}doi=10.14257{\%}2Fijast.2017.108.07{\&}partnerID=40{\&}md5=8c04b99ca7b048f105faffb3242754f6},
volume = {108},
year = {2017}
}
@inproceedings{Kim201232,
abstract = {Recently the WSN technology has been applied to various network environments. And, the tracking accuracy and the efficiency of the indoor localization technology has been issued from the WSN. Generally, when we performed the outdoor localization, the GPS has a high accuracy. But, the GPS that the localization is performed by using the satellites is not applied the indoor localization. So, we performed the indoor localization by using the WSN technology. In this paper, we suggest a new localization algorithm called a Ratiometric GPS Iteration (RGI) algorithm using the GPS and the RVI. The suggested method estimates an accurate location of any indoor target object through the relative distance ratio by RSSI of RVI and GPS. We execute simulation tests to prove the efficiency of the suggested RGI algorithm. {\textcopyright} 2012 AICIT.},
annote = {cited By 0},
author = {Kim, H and Park, C and Cho, Y and Shin, C and Park, J and Park, D},
booktitle = {Proceedings - 2012 7th International Conference on Computing and Convergence Technology (ICCIT, ICEI and ICACT), ICCCT 2012},
keywords = {Algorithms; Iterative methods; RSS; Technology,Global positioning system,Indoor localization; Iteration algorithms; Localiz},
pages = {32--35},
title = {{A study on a Ratiometric GPS Iteration algorithm for indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881187173{\&}partnerID=40{\&}md5=68c7b6deb2e4212d4ab47c89aecac059},
year = {2012}
}
@inproceedings{Kim2018621,
abstract = {In this paper we propose a cuboid-based air-Tight indoor room geometry estimation method using combination of audio-visual sensors. Existing vision-based 3D reconstruction methods are not applicable for scenes with transparent or reflective objects such as windows and mirrors. In this work we fuse multi-modal sensory information to overcome the limitations of purely visual reconstruction for reconstruction of complex scenes including transparent and mirror surfaces. A full scene is captured by 360C cameras and acoustic room impulse responses (RIRs) recorded by a loudspeaker and compact microphone array. Depth information of the scene is recovered by stereo matching from the captured images and estimation of major acoustic reflector locations from the sound. The coordinate systems for audio-visual sensors are aligned into a unified reference frame and plane elements are reconstructed from audio-visual data. Finally cuboid proxies are fitted to the planes to generate a complete room model. Experimental results show that the proposed system generates complete representations of the room structures regardless of transparent windows, featureless walls and shiny surfaces. {\textcopyright} 2017 IEEE.},
annote = {cited By 2},
author = {Kim, H and Remaggi, L and Jackson, P J and Fazi, F M and Hilton, A},
booktitle = {Proceedings - 2017 International Conference on 3D Vision, 3DV 2017},
doi = {10.1109/3DV.2017.00076},
keywords = {3D reconstruction; Acoustic reflectors; Acoustic,Audio systems; Geometry; Loudspeakers; Mirrors; St,Image reconstruction},
pages = {621--629},
title = {{3D room geometry reconstruction using audio-visual sensors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048761927{\&}doi=10.1109{\%}2F3DV.2017.00076{\&}partnerID=40{\&}md5=00ccabe418e9193c507b5443780005cd},
year = {2018}
}
@article{Kim2015996,
abstract = {In this paper, we present an effective system for the 3D scene labeling of objects from RGB-D videos. Our system uses a Markov Random Field (MRF) over a voxel representation of the 3D scene. In order to estimate the correct label of each voxel, the probabilistic graphical model integrates both scores from sliding window-based object detectors and also from object location prior maps. Both the object detectors and the location prior maps are pre-trained from manually labeled RGB-D images. Additionally, the model integrates the scores from considering the geometric constraints between adjacent voxels in the label estimation. We show excellent experimental results for the RGB-D Scenes Dataset built by the University of Washington, in which each indoor scene contains tabletop objects. {\textcopyright} ICROS 2015.},
annote = {cited By 0},
author = {Kim, J.-H. and Kim, I.-C.},
doi = {10.5302/J.ICROS.2015.15.0159},
journal = {Journal of Institute of Control, Robotics and Systems},
keywords = {3D scenes; Geometric constraint; Markov Random Fi,Location; Markov processes; Object recognition; Th,Object detection},
number = {11},
pages = {996--1002},
title = {{Efficient 3D Scene Labeling using object detectors and location prior maps}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946728584{\&}doi=10.5302{\%}2FJ.ICROS.2015.15.0159{\&}partnerID=40{\&}md5=c25b9577f2b79692e0f355e436221502},
volume = {21},
year = {2015}
}
@book{Kim:2013:RIT:2484538,
author = {Kim, Jong-Hwan and Matson, Eric T and Myung, Hyun and Xu, Peter},
isbn = {3642373739, 9783642373732},
publisher = {Springer Publishing Company, Incorporated},
title = {{Robot Intelligence Technology and Applications 2012: An Edition of the Presented Papers from the 1st International Conference on Robot Intelligence}},
year = {2013}
}
@inproceedings{Kim:2018:RSI:3282461.3282466,
address = {New York, NY, USA},
author = {Kim, Taehoon and Li, Ki-Joune},
booktitle = {Proceedings of the 9th ACM SIGSPATIAL International Workshop on Indoor Spatial Awareness},
doi = {10.1145/3282461.3282466},
isbn = {978-1-4503-6033-3},
keywords = {Cellular Space Model,Hidden Markov Model,Indoor Positioning,Symbolic Indoor Map Matching},
pages = {15--24},
publisher = {ACM},
series = {ISA'18},
title = {{Real-time Symbolic Indoor Map Matching}},
url = {http://doi.acm.org/10.1145/3282461.3282466},
year = {2018}
}
@inproceedings{Kim20161104,
abstract = {In this paper, we propose a robust multi-object tracking algorithm for acquiring object oriented multi-Angle videos, which takes advantages of two different tracking techniques represented by subdivided color histogram based tracking and labeling based tracking. Object models based on color histograms are further subdivided to differentiate similar color regions. Another tracking technique utilizes automatic detection by background subtraction and matches labels by comparing previous tracking results and detected object locations. The developed tracking algorithm more robustly recovers from tracking failure cases such as missing objects or overlapping objects than histogram based tracking. To cover large areas of interest, multiple camera images are integrated using homography based transformation. Based on tracking results in the integrated coordinate system, panning-Tilting-zooming (PTZ) cameras are incorporated to acquire multi-Angle videos of the tracking object. The feasibility of the proposed tracking based multi-Angle video acquisition is demonstrated through real indoor sport game scenarios. {\textcopyright} 2016 IEEE.},
annote = {cited By 1},
author = {Kim, Y and Cho, K.-S.},
booktitle = {2016 International Conference on Information and Communication Technology Convergence, ICTC 2016},
doi = {10.1109/ICTC.2016.7763379},
keywords = {Automatic Detection; Background subtraction; Homo,Cameras; Color; Graphic methods; Object detection;,Tracking (position)},
pages = {1104--1107},
title = {{Robust multi-object tracking to acquire object oriented videos in indoor sports}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015796285{\&}doi=10.1109{\%}2FICTC.2016.7763379{\&}partnerID=40{\&}md5=e6b92a3675c3ecc517d94a9806de3225},
year = {2016}
}
@article{Kimpe:1999:FCT:615597.615661,
address = {Piscataway, NJ, USA},
author = {Kimpe, Marc and Leib, Harry and Maquelin, Olivier and Szymanski, Ted H},
doi = {10.1109/5992.743620},
issn = {1521-9615},
journal = {Computing in Science and Engg.},
number = {1},
pages = {31--41},
publisher = {IEEE Educational Activities Department},
title = {{Fast Computational Techniques for Indoor Radio Channel Estimation}},
url = {http://dx.doi.org/10.1109/5992.743620},
volume = {1},
year = {1999}
}
@article{Kirly201715,
abstract = {Industrial, logistic, and several other applications require the discovery, localization, and tracking of objects using existing passive radio frequency identification (RFID) based sys-tems. We have analysed system concepts, methods, and protocols to enhance accuracy and coverage of RFID localization systems in order to find a moving transponder in an area with high precision over time using reading parameters and also to estimate the location of the transponder with low error rate if the reading information is not available. This research is also focusing on the infrastructure requirements of determining or recovering the location or path of the tag. The extension of the RFID localization beyond the area covered by the RFID reader system could be a solution. This can be carried out by using a special device called "Nodding antenna" or by supplying the transponders and antennas with the information on how to determine or store their respective positions. Advantages and application areas of the Location-on-Tag (LoT) concept and a novel localization method based on intelligent antennas that can enhance reliability and robustness of indoor RFID localization systems and ensure inter-building tag path tracking are introduced in this paper.},
annote = {cited By 1},
author = {Kir{\'{a}}ly, R and Helfenbein, T and Kir{\'{a}}ly, S and Kov{\'{a}}cs, E and Balla, T},
journal = {Infocommunications Journal},
keywords = {Antennas; Location; Mobile antennas; Radio frequen,Application area; Indoor localization; Intelligen,Indoor positioning systems},
number = {2},
pages = {15--24},
title = {{Novel concepts based indoor localization and Intelligent Antennas}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027727787{\&}partnerID=40{\&}md5=ed01ce22187b669505b929f71af582b4},
volume = {9},
year = {2017}
}
@inproceedings{Kjaergaard:2006:AIS:1114689.1114981,
address = {Washington, DC, USA},
author = {Kjaergaard, Mikkel Baun},
booktitle = {Proceedings of the 4th Annual IEEE International Conference on Pervasive Computing and Communications Workshops},
doi = {10.1109/PERCOMW.2006.19},
isbn = {0-7695-2520-2},
pages = {18----},
publisher = {IEEE Computer Society},
series = {PERCOMW '06},
title = {{An API for Integrating Spatial Context Models with Spatial Reasoning Algorithms}},
url = {http://dx.doi.org/10.1109/PERCOMW.2006.19},
year = {2006}
}
@inproceedings{Klinec2000324,
abstract = {The research project "NEXUS" aims at the development of a generic platform that supports location aware applications for mobile users. It is currently being carried out within a so-called research group supported by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) in cooperation between the Institute for Photogrammetry, the Institute of Parallel and Distributed High-Performance Systems and the Institute of Communication Networks and Computer Engineering of the University of Stuttgart. A major task of the platform is the providing of a positioning service in outdoor and indoor locations. Additionally a communication environment must be defined to facilitate an exchange between the external information sources and virtual objects. The spatially aware applications are available for the user on small handheld devices like PDAs (Personal Digital Assistants). These computers arc equipped with sensors for positioning and mobile communication. In this way, die application is aware of the users' position within the spatial models. Users are "location aware'" and can receive spatial data from distributed servers. In order to support them on their way, several functionalities have to be provided: users have to be able to navigate and to perform queries on their environment, thus an interface to GIS has to be implemented. {\textcopyright} 2000 International Society for Photogrammetry and Remote Sensing. All rights reserved.},
annote = {cited By 4},
author = {Klinec, D and Volz, S},
booktitle = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
keywords = {Communication environments; External informations,Data handling; Digital devices; Geographic informa,Distributed computer systems},
pages = {324--330},
title = {{Nexus-positioning and communication environment for spatially aware applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-35248860097{\&}partnerID=40{\&}md5=8d87852a179c483e122a237428626011},
volume = {33},
year = {2000}
}
@inproceedings{Koch2007271,
abstract = {The need for robust indoor localisation for all types of entities has been under continuous research by the ubiquitous community. Intelligent environments have to be supported with contextual information in order to facilitate intelligent behaviour. These contextual information include the location of humans and objects within the particular environment. Intelligent environments can be living areas with home automation, smart industrial plants, sensor-equipped office areas and indoor-emergency applications. So far technical solutions are either quite expensive or lack of precision for robust usage as components in intelligent service federations. We present rather low-cost localisation systems with great scalability based on active and passive RFID technology to locate humans, mobile service robots and objects of the daily use. The trade-off between technical effort and costs on the one hand and sufficient data accuracy for the application on the other hand is discussed. A motivation of our scenario, the technical concept and solution as well as the implementation and the integration that so far have been performed will be presented. Current prototypes of the proposed system are already being tested in a project aiming on development of smart assisted living environments. {\textcopyright} 2007 IEEE.},
annote = {cited By 34},
author = {Koch, J and Wettach, J and Bloch, E and Berns, K},
booktitle = {Proceedings - 7th International Conference on Hybrid Intelligent Systems, HIS 2007},
doi = {10.1109/ICHIS.2007.4344063},
keywords = {Assisted living; Contextual information; Daily us,Industrial plants; Intelligent control; Mobile rob,Intelligent systems},
pages = {271--276},
title = {{Indoor localisation of humans, objects, and mobile robots with RFID infrastructure}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-47149090935{\&}doi=10.1109{\%}2FICHIS.2007.4344063{\&}partnerID=40{\&}md5=f6d2d363e2b5e0f5b45c07a5f19cc5b8},
year = {2007}
}
@inproceedings{Koch2017377,
abstract = {3D laser scanners are favoured sensors for mapping in mobile service robotics at indoor and outdoor applications, since they deliver precise measurements at a wide scanning range. The resulting maps are detailed since they have a high resolution. Based on these maps robots navigate through rough terrain, fulfil advanced manipulation, and inspection tasks. In case of specular reflective and transparent objects, e.g., mirrors, windows, shiny metals, the laser measurements get corrupted. Based on the type of object and the incident angle of the incoming laser beam there are three results possible: a measurement point on the object plane, a measurement behind the object plane, and a measurement of a reflected object. It is important to detect such situations to be able to handle these corrupted points. This paper describes why it is difficult to distinguish between specular reflective and transparent surfaces. It presents a 3D-Reflection-Pre-Filter Approach to identify specular reflective and transparent objects in point clouds of a multi-echo laser scanner. Furthermore, it filters point clouds from influences of such objects and extract the object properties for further investigations. Based on an Iterative-Closest-Point-algorithm reflective objects are identified. Object surfaces and points behind surfaces are masked according to their location. Finally, the processed point cloud is forwarded to a mapping module. Furthermore, the object surface corners and the type of the surface is broadcasted. Four experiments demonstrate the usability of the 3D-Reflection-Pre-Filter. The first experiment was made in a empty room containing a mirror, the second experiment was made in a stairway containing a glass door, the third experiment was made in a empty room containing two mirrors, the fourth experiment was made in an office room containing a mirror. This paper demonstrate that for single scans the detection of specular reflective and transparent objects in 3D is possible. It is more reliable in 3D as in 2D. Nevertheless, collect the data of multiple scans and post-filter them as soon as the object was bypassed should pursued. This is why future work concentrates on implementing a post-filter module. Besides, it is the aim to improve the discrimination between specular reflective and transparent objects.},
annote = {cited By 1},
author = {Koch, R and May, S and N{\"{u}}chter, A},
booktitle = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
doi = {10.5194/isprs-archives-XLII-2-W3-377-2017},
keywords = {3D Laser scanning; Iterative closest point algori,Algorithms; Electric power factor correction; Erro,Laser mirrors},
number = {2W3},
pages = {377--384},
title = {{Detection and purging of specular reflective and transparent object influences in 3D range measurements}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021753621{\&}doi=10.5194{\%}2Fisprs-archives-XLII-2-W3-377-2017{\&}partnerID=40{\&}md5=76aa024396054f58cd99a4dd26366357},
volume = {42},
year = {2017}
}
@phdthesis{Kollar:2011:LUS:2338176,
address = {Cambridge, MA, USA},
annote = {AAI0823797},
author = {Kollar, Thomas},
publisher = {Massachusetts Institute of Technology},
title = {{Learning to Understand Spatial Language for Robotic Navigation and Mobile Manipulation}},
year = {2011}
}
@inproceedings{Kolodziej:2011:UMM:2055442.2056201,
address = {Washington, DC, USA},
author = {Kolodziej, Joanna and Xhafa, Fatos},
booktitle = {Proceedings of the 2011 International Conference on Complex, Intelligent, and Software Intensive Systems},
doi = {10.1109/CISIS.2011.84},
isbn = {978-0-7695-4373-4},
keywords = {Data Partitioning,Indoor Environment,Markov Chain,Markov Jump Process,Nonparametric Belief Propagation,Wireless Network},
pages = {513--518},
publisher = {IEEE Computer Society},
series = {CISIS '11},
title = {{Utilization of Markov Model and Non-Parametric Belief Propagation for Activity-Based Indoor Mobility Prediction in Wireless Networks}},
url = {https://doi.org/10.1109/CISIS.2011.84},
year = {2011}
}
@article{Kong:2015:RWS:2816618.2816628,
address = {Chichester, UK},
author = {Kong, Liang and Bauer, Gavin and Hale, John},
doi = {10.1002/cpe.3443},
issn = {1532-0626},
journal = {Concurr. Comput. : Pract. Exper.},
keywords = {context awareness,fuzzy logic,indoor localization,wireless signal},
number = {11},
pages = {2839--2850},
publisher = {John Wiley and Sons Ltd.},
title = {{Robust Wireless Signal Indoor Localization}},
url = {http://dx.doi.org/10.1002/cpe.3443},
volume = {27},
year = {2015}
}
@article{Konis2013150,
abstract = {Building occupants represent a rich source of information for evaluating environmental design practices and building operations. This article presents a scalable diagnostic technology for collecting real-time indoor environmental quality (IEQ) feedback from building occupants: an interactive desktop polling station. The device demonstrates the potential of ubiquitous computing, a model of human-computer interaction in which information processing is integrated into everyday objects, to engage occupants in providing IEQ feedback in real work environments. Example data from a field study of a high-performance office building are presented demonstrating the applicability of multiple devices to acquire detailed feedback over daily and seasonal variations in climatic conditions. Sample results show how polling station data can help identify the frequency and magnitude of discomfort with the spatial and temporal granularity needed to assess, validate, and improve the performance of environmentally responsive building technologies, controls, and design strategies. Analysis of repeated-measures subjective assessments paired with concurrent physical measurements is performed to demonstrate how existing standards and assumptions for occupant comfort could be evaluated and refined using detailed occupant feedback from buildings in use. Results are discussed regarding implications for improving decision-making for the design, certification, and operation of environmentally responsive buildings. {\textcopyright} 2013 Copyright Taylor and Francis Group, LLC.},
annote = {cited By 9},
author = {Konis, K S},
doi = {10.1080/17508975.2013.781499},
journal = {Intelligent Buildings International},
keywords = {Building technologies; Diagnostic technologies; Hi,Data processing; Human computer interaction; Huma,Structural design,air quality; air sampling; building; decision mak},
number = {3},
pages = {150--161},
title = {{Leveraging ubiquitous computing as a platform for collecting real-time occupant feedback in buildings}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880636784{\&}doi=10.1080{\%}2F17508975.2013.781499{\&}partnerID=40{\&}md5=8c7af1cbb1612e3a99bbec5b9b6b3b04},
volume = {5},
year = {2013}
}
@article{7118199,
abstract = {Indoor Positioning Systems (IPS) have recently received considerable attention, mainly because GPS is unavailable in indoor spaces and consumes considerable energy. On the other hand, predominant Smartphone OS localization subsystems currently rely on server-side localization processes, allowing the service provider to know the location of a user at all times. In this paper, we propose an innovative algorithm for protecting users from location tracking by the localization service, without hindering the provisioning of fine-grained location updates on a continuous basis. Our proposed Temporal Vector Map (TVM) algorithm, allows a user to accurately localize by exploiting a k-Anonymity Bloom (kAB) filter and a bestNeighbors generator of camouflaged localization requests, both of which are shown to be resilient to a variety of privacy attacks. We have evaluated our framework using a real prototype developed in Android and Hadoop HBase as well as realistic Wi-Fi traces scaling-up to several GBs. Our analytical evaluation and experimental study reveal that TVM is not vulnerable to attacks that traditionally compromise k-anonymity protection and indicate that TVM can offer fine-grained localization in approximately four orders of magnitude less energy and number of messages than competitive approaches.},
author = {Konstantinidis, A and Chatzimilioudis, G and Zeinalipour-Yazti, D and Mpeis, P and Pelekis, N and Theodoridis, Y},
doi = {10.1109/TKDE.2015.2441724},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Android (operating system);data handling;data priv},
month = {nov},
number = {11},
pages = {3042--3055},
title = {{Privacy-Preserving Indoor Localization on Smartphones}},
volume = {27},
year = {2015}
}
@phdthesis{Koppal:2009:MIS:1925274,
address = {Pittsburgh, PA, USA},
annote = {AAI3405179},
author = {Koppal, Sanjeev Jagannatha},
isbn = {978-1-109-70482-2},
publisher = {Carnegie Mellon University},
title = {{Modeling Illumination for Scene Recovery Through the Motion, Occlusion and Strobing of Light-sources}},
year = {2009}
}
@inproceedings{Kosako19951273,
abstract = {This study is done in the context of a navigation support system in which image understanding is used to guide the navigating agent in an unfamiliar environment. We are concerned with modeling which allows recognition under varying viewing angles and/or when occlusions are present. We present an approach to object extraction based on an extension of the parametric eigenspace method using local features from the image of the object of interest. Spatial constraints for the local features used to model the object are also recorded. Based on the detection of local features, and their location constraints several object regions are hypothesized in an input image. Fuzzy logic is used to grade the goodness of these regions allowing to discriminate between them in order to achieve accurate object extraction. The approach is illustrated for an object in an indoor scene environment.},
annote = {cited By 2},
author = {Kosako, Akinori and Ralescu, Anca L},
booktitle = {IEEE International Conference on Fuzzy Systems},
keywords = {Computational complexity; Constraint theory; Eigen,Feature based parametric eigenspace method; Navig,Feature extraction},
pages = {1273--1278},
title = {{Feature based parametric eigenspace method for object extraction}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029232402{\&}partnerID=40{\&}md5=b8fd1003eeff13acd49d358a8c95c4e9},
volume = {3},
year = {1995}
}
@article{Koeck200527,
abstract = {The localization capability of a mobile robot is central to basic navigation and map building tasks. We describe a probabilistic environment model which facilitates global localization scheme by means of location recognition. In the exploration stage the environment is partitioned into locations, each characterized by a set of scale-invariant keypoints. The descriptors associated with these keypoints can be robustly matched despite changes in contrast, scale and viewpoint. We demonstrate the efficacy of these features for location recognition, where given a new view the most likely location from which this view came from is determined. The misclassifications due to dynamic changes in the environment or inherent appearance ambiguities are overcome by exploiting location neighborhood relationships captured by a Hidden Markov Model. We report the recognition performance of this approach in an indoor environment consisting of eighteen locations and discuss the suitability of this approach for a more general class of recognition problems. Once the most likely location has been determined we demonstrate how to robustly compute the relative pose between the representative view and the current view. {\textcopyright} 2005 Elsevier B.V. All rights reserved.},
annote = {cited By 0},
author = {Ko{\v{s}}eck{\'{a}}, J and Li, F and Yang, X},
doi = {10.1016/j.robot.2005.03.008},
journal = {Robotics and Autonomous Systems},
keywords = {Global localization; Hidden Markov Model (HMM); R,Image sensors; Markov processes; Mathematical mode,Mobile robots},
number = {1},
pages = {27--38},
title = {{Global localization and relative positioning based on scale-invariant keypoints}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-20744459004{\&}doi=10.1016{\%}2Fj.robot.2005.03.008{\&}partnerID=40{\&}md5=b01923432689e2fd5c20f5622ca4350c},
volume = {52},
year = {2005}
}
@inproceedings{Kosecka:2004:GLR:1018430.1021225,
address = {Washington, DC, USA},
author = {Kosecka, Jana and Yang, Xiaolong},
booktitle = {Proceedings of the Pattern Recognition, 17th International Conference on (ICPR'04) Volume 4 - Volume 04},
doi = {10.1109/ICPR.2004.418},
isbn = {0-7695-2128-2},
pages = {319--322},
publisher = {IEEE Computer Society},
series = {ICPR '04},
title = {{Global Localization and Relative Pose Estimation Based on Scale-Invariant Features}},
url = {http://dx.doi.org/10.1109/ICPR.2004.418},
year = {2004}
}
@article{Koyuncu201374,
abstract = {Jennic type wireless sensor nodes are utilized together with a novel particle filtering technique for indoor localization. Target objects are localized with an accuracy of around 0.25 meters. The proposed technique introduces a new particle generation and distribution technique to improve current estimation of object positions. Particles are randomly distributed around the object in the sensing area within a circular strip of 2 STD of object distance measurements. Particle locations are related to object locations by using Gaussian weight distribution methods. Object distances from the transmitters are determined by using received RSSI values and ITU-R indoor propagation model. Measured object distances are used together with the particle distances from the transmitters to predict the object locations. {\textcopyright} 2013 CCIS.},
annote = {cited By 1},
author = {Koyuncu, H and {\c{C}}evik, A},
doi = {10.24138/jcomss.v9i1.159},
journal = {Journal of Communications Software and Systems},
number = {1},
pages = {74--83},
title = {{Indoor localization by using particle filtering approach with wireless sensor nodes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876374045{\&}doi=10.24138{\%}2Fjcomss.v9i1.159{\&}partnerID=40{\&}md5=6d82141d2eeec982e0840e89967769be},
volume = {9},
year = {2013}
}
@inproceedings{Krejcar2007,
abstract = {The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. Additionally, the ability to let a mobile device determine its location in an indoor environment at a fine-grained level supports the creation of a new range of mobile control system applications. Main area of interest is in model of radio-frequency (RF) based system enhancement for locating and tracking users of our control system inside buildings. The framework described here joins the concepts of location and user tracking in an extended existing control system. The experimental framework prototype uses a WiFi network infrastructure to let a mobile device determine its indoor position as well as to deliver IP connectivity. User location is used to data pre-buffering and pushing information from server to user's PDA. Experiments show that location determination can be realized with a room level granularity. {\textcopyright} 2007 IEEE.},
annote = {cited By 0},
author = {Krejcar, O},
booktitle = {2nd International Conference on Systems, ICONS 2007},
doi = {10.1109/ICONS.2007.15},
keywords = {Area of Interest (AOI); Building information syst,Control system applications,Internet protocols; Local area networks; Location;},
title = {{Building information system with wireless connected mobile device - Testing phase of PDPT framework}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-46349109294{\&}doi=10.1109{\%}2FICONS.2007.15{\&}partnerID=40{\&}md5=1ed5d583d60dbf5022d4827f73d95874},
year = {2007}
}
@inproceedings{Krejcar2009,
abstract = {The proliferation of mobile computing devices and localarea wireless networks has fostered a growing interest in location-aware systems and services. We consider location as prime form of context information. The developed framework joins the concepts of location and user tracking as an extension for a new type of mobile information systems. The framework uses a WiFi network infrastructure to let a mobile device determine its indoor position. User location is used for data prebuffering and pushing information from server to user's PDA. All server data are saved as artifacts (together) with its position information in building. The accessing of prebuffered data on mobile device can highly improve response time needed to view large multimedia data. {\textcopyright} 2009 IEEE.},
annote = {cited By 11},
author = {Krejcar, O},
booktitle = {2009 4th International Symposium on Wireless and Pervasive Computing, ISWPC 2009},
doi = {10.1109/ISWPC.2009.4800591},
keywords = {Context informations; In buildings; Location conte,Information systems; Local area networks; Mobile,Wireless networks},
title = {{Large multimedia artifacts prebuffering in mobile information systems as location context awareness}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-65249115334{\&}doi=10.1109{\%}2FISWPC.2009.4800591{\&}partnerID=40{\&}md5=f5fcd4d33ecd01974b0f7f38c485ac07},
year = {2009}
}
@inproceedings{Krejcar2008179,
abstract = {The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. Additionally, the ability to let a mobile device determine its location in an indoor environment supports the creation of a new range of mobile control system applications. Main area of interest is in model of radio-frequency based system enhancement for locating and tracking users of our control system inside buildings. The developed framework described here joins the concepts of location and user tracking as an extension for new control system. The experimental framework prototype uses a WiFi network infrastructure to let a mobile device determine its indoor position. User location is used to data prebuffering and pushing information from server to user's PDA. All the server data are saved as artefacts with their position info in building. {\textcopyright} 2008 IEEE.},
annote = {cited By 0},
author = {Krejcar, O},
booktitle = {3rd International Conference on Systems, ICONS 2008},
doi = {10.1109/ICONS.2008.44},
keywords = {Computer networks; Data transfer; Local area netwo,Control system applications,Information systems; International conferences; L},
pages = {179--183},
title = {{A way to boost the data transfer speed in control and information systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-50649102321{\&}doi=10.1109{\%}2FICONS.2008.44{\&}partnerID=40{\&}md5=ae3db3584b12dcfea969d417633815e4},
year = {2008}
}
@inproceedings{Krejcar2008111,
abstract = {The proliferation of mobile computing devices and local-area wireless networks has fostered a growing interest in location-aware systems and services. Additionally, the ability to let a mobile device determine its location in an indoor environment supports the creation of a new range of mobile control system applications. Main area of interest is in model of radio-frequency based system enhancement for locating and tracking users of our control system inside buildings. The developed framework described here joins the concepts of location and user tracking as an extension for new control system. The experimental framework prototype uses a Wi-Fi network infrastructure to let a mobile device determine its indoor position. User location is used to data pre-buffering and pushing information from server to user's PDA. All the server data are saved as artefacts with their position info in building. These technique allow to exceed the data transfer speed limits in mobile control systems.},
annote = {cited By 34},
author = {Krejcar, O},
booktitle = {ICINCO 2008 - Proceedings of the 5th International Conference on Informatics in Control, Automation and Robotics},
keywords = {802.11b; Buffering; Framework; Localization; PDA;,Automation; Control system analysis; Control syst,Control systems},
pages = {111--114},
title = {{Prebuffering as a way to exceed the data transfer speed limits in mobile control systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-55849083930{\&}partnerID=40{\&}md5=c0219211f17859249645ed72a655e327},
volume = {2 RA},
year = {2008}
}
@article{Krejcar2008489,
abstract = {Location-aware services can benefit from indoor location tracking. The widespread adoption of Wi-Fi as the network infrastructure creates the opportunity of deploying WiFi-based location services with no additional hardware costs. Additionally, the ability to let a mobile device determine its location in an indoor environment supports the creation of a new range of mobile control system applications. Main area of interest is in a model of a radio-frequency based system enhancement for locating and tracking users of our control system inside the buildings. The developed framework as it is described here joins the concepts of location and user tracking as an extension for a new control system. The experimental framework prototype uses a WiFi network infrastructure to let a mobile device determine its indoor position. User location is used for data pre-buffering and pushing information from server to user's PDA. All server data is saved as artifacts (together) with its position information in building. {\textcopyright} 2008 Springer-Verlag Berlin Heidelberg.},
annote = {cited By 28},
author = {Krejcar, O and Cernohorsky, J},
doi = {10.1007/978-3-540-69384-0_54},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Area of Interest (AOI); Computational sciences; H,Control system applications,Local area networks; Location; Mobile devices; Mod},
number = {PART 1},
pages = {489--498},
title = {{Database prebuffering as a way to create a mobile control and information system with better response time}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-47749107605{\&}doi=10.1007{\%}2F978-3-540-69384-0{\_}54{\&}partnerID=40{\&}md5=3bf2107b183098d5e5578dae4e870d1e},
volume = {5101 LNCS},
year = {2008}
}
@inproceedings{Krejcar2008199,
abstract = {Main area of interest is in a model of data prebuffering based system enhancement for locating and tracking users of our control system inside the buildings. The developed framework joins the concepts of location and user tracking as an extension for a new information system. The experimental framework prototype uses a WiFi network infrastructure to let a mobile device determine its indoor position. User location is used for data pre-buffering and pushing information from server to user's PDA. All server data is saved as artifacts (together) with its position information in building. The accessing of prebuffered data on mobile device can highly improve response time needed to view large multimedia data. On mobile device the SQL Server CE database is used. Mobile device operate with Windows Mobile 6.0 operation system which is real time. All operations in such mobile clients are deterministic. {\textcopyright}2008 IEEE.},
annote = {cited By 1},
author = {Krejcar, O and Cernohorsky, J},
booktitle = {2008 International Conference on Innovations in Information Technology, IIT 2008},
doi = {10.1109/INNOVATIONS.2008.4781763},
keywords = {Area of interest; In-building; Mobile client; Mult,Innovation; Local area networks; Location; Mobile,Wireless networks},
pages = {199--203},
title = {{Data prebuffering using SQL CE database on real time operation system windows mobile 6.0}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-67649460890{\&}doi=10.1109{\%}2FINNOVATIONS.2008.4781763{\&}partnerID=40{\&}md5=938ef46f15555dfddabaa52e028250a6},
year = {2008}
}
@inproceedings{Krishnan201613,
abstract = {The smart walking stick, the Assistor, helps visually challenged people to identify obstacles and provide assistance to reach their destination. The Assistor works based on the technology of echolocation, image processing and a navigation system. The Assistor may serve as a potential aid for people with visual disabilities and hence improves their quality of life. There is a lot of work and research being done to find ways to improve life for visually challenged people. There are multiple walking sticks and systems which help the user to move around, indoor and outdoor locations but none of them provide runtime autonomous navigation along with object detection and identification alerts. The Assistor uses ultrasonic sensors to echo sound waves and detect objects. An image sensor is used to identify the objects in front of the user and for navigation by capturing runtime images and a Smartphone app is used to navigate the user to the destination using GPS (Global Positioning System) and maps. {\textcopyright} 2016 IEEE.},
annote = {cited By 1},
author = {Krishnan, A and Deepakraj, G and Nishanth, N and Anandkumar, K M},
booktitle = {Proceedings of the 2016 2nd International Conference on Contemporary Computing and Informatics, IC3I 2016},
doi = {10.1109/IC3I.2016.7917927},
keywords = {Assistor; Autonomous walkings; Blind; Echolocatio,Global positioning system; Navigation systems; Obj,Image processing},
pages = {13--16},
title = {{Autonomous walking stick for the blind using echolocation and image processing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020018902{\&}doi=10.1109{\%}2FIC3I.2016.7917927{\&}partnerID=40{\&}md5=4e1d6a0146e8812adcc0597e7fdf0315},
year = {2016}
}
@article{Kristo201579,
abstract = {In object recognition, Spatial Pyramid Matching (SPM) has been the most popular framework to incorporate spatial information into the bag-of-words model. Dividing each layer of the pyramid into 2l2l spatial windows, SPM extracts histograms from each and concatenate them to create image representation. SPM offers an approximate spatial arrangement to the previously unordered collection of codeword histogram. This paper presents a detailed investigation on the optimality of the traditional SPM model and simultaneously offers a framework to obtain the most optimal spatial window arrangement from the set of possible spatial windows. Using such model, we are able to consistently achieve significant increase in recognition performance, up to 4.38{\%}. With nearly 40{\%} less memory cost, it shows that the traditional spatial window arrangement of SPM is indeed inefficient. We tested our proposed model using 15 Scene, Caltech 101, Caltech 256, MIT-Indoor, UIUC-Sport, and STL-10. {\textcopyright} 2015 Elsevier Inc. All rights reserved.},
annote = {cited By 2},
author = {Kristo and Chua, C S},
doi = {10.1016/j.jvcir.2015.02.005},
journal = {Journal of Visual Communication and Image Representation},
keywords = {Classification (of information); Cost effectivenes,Image representations; Overlapping window; Recogn,Information retrieval},
pages = {79--88},
title = {{Cost effective window arrangement for spatial pyramid matching}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924039298{\&}doi=10.1016{\%}2Fj.jvcir.2015.02.005{\&}partnerID=40{\&}md5=e67d98010c2bdd100490091394a2c39f},
volume = {29},
year = {2015}
}
@inproceedings{5647427,
abstract = {This paper presents a scale-independent (space and time) tracking framework for moving entities (objects, animals, humans). The framework allows for the integration, processing and visualization of spatio-temporal data obtained from heterogeneous sensor sources. The framework does not rely upon one tracking and localization technology for the data collection, but instead considers the combination of several technologies to obtain and calculate the best positioning result. Not only are typical localization and tracking technologies considered as data providers, but also keystroke sensors, like touch screens with a fixed location in the tracking environment. Different sizes and characteristics of moving entities are considered as well as different tracking environments or use cases in different domains. A prototypical implementation of basic functionalities processes the spatio-temporal data in a core and provides it by different internal and external interfaces. The modular framework consists of different usage modules. A visualization module is implemented as a first module for the framework. Thus the display of an existing three-dimensional environmental model with the sensors and the visualization of the tracked entities are possible. Furthermore, sensors can be added, changed and managed in the three-dimensional scene. The development of further modules for data analysis for different use cases allows for the analysis of large amounts of data, for example with machine learning techniques. Two different use cases (laboratory mice and service technicians) were used to develop and apply the framework.},
author = {Kritzler, M and Kr{\"{u}}ger, A},
booktitle = {2010 International Conference on Indoor Positioning and Indoor Navigation},
doi = {10.1109/IPIN.2010.5647427},
keywords = {Global Positioning System;target tracking;wireless},
pages = {1--10},
title = {{Tracking framework for heterogeneous sensor sources}},
year = {2010}
}
@article{Kubicek2018455,
abstract = {The Real-time Locating Systems (RTLS) are also well known as real-time location systems have recently become significantly important part of many location aware systems. RTLS systems are primarily used for the object tracking placed indoor. This area relates to the healthcare environment where tracking and monitoring of patients are important. The paper deals with the overview of the possible applications of the RTLS systems in the healthcare facilities and their potential benefits. The paper also brings conceptual information about two currently developed systems with the cooperation of Trauma Center of University Hospital in Ostrava with a target of the patient database and mobile application development on the base of the Internet of Things allowing for fully digital archiving patient records. The second system focuses on the development of RTLS system based on the Infra Red (IR) system with anchors where the location of the patient is acquired using IR tags. {\textcopyright} Springer International Publishing AG 2018.},
annote = {cited By 2},
author = {Kubicek, J and Michalek, L and Urbanczyk, T and Konecny, J and Tomis, M and Benes, F and Svub, J and Stasa, P and Pleva, L},
doi = {10.1007/978-3-319-76081-0_39},
journal = {Studies in Computational Intelligence},
pages = {455--464},
title = {{Novel Aproach for Localization of Patients in Urgent Admission Department}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043350105{\&}doi=10.1007{\%}2F978-3-319-76081-0{\_}39{\&}partnerID=40{\&}md5=1ef0ac6e5ce6035708392c9e16d929e6},
volume = {769},
year = {2018}
}
@inproceedings{Kumar2011,
abstract = {In this paper, a linear discriminant analysis (LDA) based classifier employed in a tree structure is presented to recognize the human actions in a wide and complex environment. In particular, the proposed classifier is based on a supervised learning process and achieves the required classification in a multi-step process. This multi-step process is performed simply by adopting a tree structured which is built during the training phase. Hence, there is no need of any priori information like in other classifiers such as the number of hidden neurons or hidden layers in a multilayer neural network based classifier or an exhaustive search as used in training algorithms for decision trees. A skeleton based strategy is adopted to extract the features from a given video sequence representing any human action. A Pan-Tilt-Zoom (PTZ) camera is used to monitor the wide and complex test environment. A background mosaic image is built offline and used to compute the background images in real time. A background subtraction strategy has been adopted for detecting the object in various frames and to extract their corresponding silhouette. A skeleton based process is used to extract attributes of a feature vector corresponding to a human action. Finally, the proposed framework is tested on various indoor and outdoor scenarios and encouraging results are achieved in terms of classification accuracy. {\textcopyright} 2011 SPIE-IS{\&}T.},
annote = {cited By 3},
author = {Kumar, S and Kumar, S and Raman, B and Sukavanam, N},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.872316},
keywords = {Change detection; Classification trees; Human acti,Decision trees; Discriminant analysis; Face recog,Image retrieval},
title = {{Human action recognition in a wide and complex environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952941805{\&}doi=10.1117{\%}2F12.872316{\&}partnerID=40{\&}md5=1368a07ae911b0abd0f804bd84ab6634},
volume = {7871},
year = {2011}
}
@article{Kung2015625,
abstract = {An indoor localization technology is increasingly critical as location-aware applications evolve. Researchers have proposed several indoor localization technologies. Because most of the proposed indoor localization technologies simply involve using the received signal strength indicator value of radio-frequency identification (RFID) for indoor localization, radio-frequency interference, and environmental factors often limit the accuracy of localization results. Therefore, this study proposes an accurate RFID localization based on the neural network (ARL-N2), a passive RFID indoor localization scheme for identifying tag positions in a room, combining a location identification based on dynamic active RFID calibration algorithm with a backpropagation neural network (BPN). The proposed scheme composed of two phases: in the training phase, an appropriate BPN architecture is constructed using the training data derived from the coordinates of reference tags and the coordinates obtained using the localization algorithm. By contrast, the online phase involves calculating the tracking tag coordinates and using these values as BPN inputs, thereby enhancing the estimated location. A performance evaluation of the ARL-N2 schemes confirms its high localization accuracy. The proposed method can be used to locate critical objects in difficult-to-find areas by creating minimal errors and applying and economical technique. Copyright {\textcopyright} 2013 John Wiley {\&} Sons, Ltd.},
annote = {cited By 9},
author = {Kung, H.-Y. and Chaisit, S and Phuong, N T M},
doi = {10.1002/dac.2692},
journal = {International Journal of Communication Systems},
keywords = {Back propagation neural networks; Indoor localiza,Backpropagation; Backpropagation algorithms; Envir,Indoor positioning systems},
number = {4},
pages = {625--644},
title = {{Optimization of an RFID location identification scheme based on the neural network}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922241273{\&}doi=10.1002{\%}2Fdac.2692{\&}partnerID=40{\&}md5=0f458499498161da167a2880ce95768b},
volume = {28},
year = {2015}
}
@article{Kung2012353,
abstract = {The Landmarc algorithm is the most common scheme to achieve the object location. However, Landmarc has been found with estimation errors due to the type of RSSI radio property. In the present study, we introduce an enhanced statistical approach in order to process RSSI data and estimate the tracking tag positions in a room. We proposed herein two location estimation scheme, namely, the ESL Average and ESL Median schemes. Both schemes periodically collect RSSI data within a fixed time period and calculate final data values to estimate location by using the Landmarc algorithm. For the ESL{\_}Average scheme, the final RSSI value is the average of all RSSI values measured in the given time period. The ESL Median scheme uses the median of RSSI values to estimate the tracking tag location. We also estimate the estimation accuracy of the two proposed schemes by experiment and comparison with the Landmarc algorithm. The result from performance evaluations reveals that the proposed schemes yield performed higher accuracy than the traditional Landmarc scheme. {\textcopyright} 2012 ICIC International.},
annote = {cited By 0},
author = {Kung, H.-Y. and Phuong, N T M and Chaisit, S},
journal = {ICIC Express Letters},
keywords = {Algorithms,Average; Indoor localization; Landmarc; Median; RS,Estimation},
number = {2},
pages = {353--358},
title = {{An enhancement of Landmarc using descriptive statistical concepts}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856956177{\&}partnerID=40{\&}md5=3b8cc91ef356c89525926461c3b39310},
volume = {6},
year = {2012}
}
@book{Kyriazakos:2008:MWC:1481050,
address = {Wharton, TX, USA},
author = {Kyriazakos, Sofoklis and Soldatos, Ioannis and Karetsos, George},
isbn = {8792329020, 9788792329028},
publisher = {River Publishers},
title = {{4G Mobile and Wireless Communications Technologies}},
year = {2008}
}
@inproceedings{Labbi:2018:ISH:3234698.3234700,
address = {New York, NY, USA},
author = {Labbi, Zouheir and Senhadji, Mohamed and Maarof, Ahmed and Belkasmi, Mostafa},
booktitle = {Proceedings of the Fourth International Conference on Engineering {\&} MIS 2018},
doi = {10.1145/3234698.3234700},
isbn = {978-1-4503-6392-1},
keywords = {IoT,Localization Technique,RFID,Smart Homes},
pages = {2:1----2:7},
publisher = {ACM},
series = {ICEMIS '18},
title = {{IoT Smart Homes Based on RFID Technology: Localization Systems Review}},
url = {http://doi.acm.org/10.1145/3234698.3234700},
year = {2018}
}
@inproceedings{Lai20181,
abstract = {Pyroelectric infrared (PIR) sensors are low-cost, low-power sensors, which are widely used in energy saving systems and alarm systems. Currently, two approaches are applied to detect the location of residents: terminal-based and non-terminal-based methods. The difference is whether the user needs to carry a terminal device. In this paper, PIR is used to compose the non-terminal indoor localization system mounted on the ceiling. The proposed PIR detection module (PDM) system consists of two PIR modules. The object space is divided into discrete cells by using appropriate reference structures. After analyzing collected infrared signal of human sensing, the target location can be estimated. To assess the system performance, two experiments are conducted to present the performance comparison among the proposed system and the existing methods. The experimental results show that the proposed system with 2 PIR modules achieve simplified system design and better estimation accuracy. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Lai, K.-C. and Ku, B.-H. and Wen, C.-Y.},
booktitle = {2018 27th Wireless and Optical Communication Conference, WOCC 2018},
doi = {10.1109/WOCC.2018.8372703},
keywords = {Alarm systems; Energy conservation; Optical commun,Detection modules; Energy saving systems; Human s,Indoor positioning systems},
pages = {1--5},
title = {{Using cooperative PIR sensing for human indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049384712{\&}doi=10.1109{\%}2FWOCC.2018.8372703{\&}partnerID=40{\&}md5=cc8ff9eaec5d5768fcec5c896dd47676},
year = {2018}
}
@inproceedings{Lam:2018:RLP:3213299.3213308,
address = {New York, NY, USA},
author = {Lam, E W and Little, T D C},
booktitle = {Proceedings of the 4th ACM MobiHoc Workshop on Experiences with the Design and Implementation of Smart Objects},
doi = {10.1145/3213299.3213308},
isbn = {978-1-4503-5857-6},
keywords = {active zone,lifi,localization,location based services,optical wireless communications,smart spaces,testbeds,visible light communications,visible light positioning},
pages = {9:1----9:8},
publisher = {ACM},
series = {SMARTOBJECTS '18},
title = {{Refining Light-based Positioning for Indoor Smart Spaces}},
url = {http://doi.acm.org/10.1145/3213299.3213308},
year = {2018}
}
@article{Lam:2016:HIP:3028143.3028145,
address = {Bristol, PA, USA},
author = {Lam, Luan D M and Tang, Antony and Grundy, John},
doi = {10.1080/17489725.2016.1232842},
issn = {1748-9725},
journal = {J. Locat. Based Serv.},
keywords = {Positioning systems,heuristics algorithms,indoor environments,systematic literature review},
number = {3},
pages = {178--211},
publisher = {Taylor {\&} Francis, Inc.},
title = {{Heuristics-based Indoor Positioning Systems: A Systematic Literature Review}},
url = {https://doi.org/10.1080/17489725.2016.1232842},
volume = {10},
year = {2016}
}
@book{LaMarca:2008:LSI:1386337,
author = {LaMarca, Anthony},
isbn = {1598295810, 9781598295818},
publisher = {Morgan and Claypool Publishers},
title = {{Location Systems: An Introduction to the Technology Behind Location (Synthesis Lectures on Mobile and Pervasive Computing)}},
year = {2008}
}
@inproceedings{Laoudias:2012:AIP:2411127.2411424,
address = {Washington, DC, USA},
author = {Laoudias, Christos and Constantinou, George and Constantinides, Marios and Nicolaou, Silouanos and Zeinalipour-Yazti, Demetrios and Panayiotou, Christos G},
booktitle = {Proceedings of the 2012 IEEE 13th International Conference on Mobile Data Management (Mdm 2012)},
doi = {10.1109/MDM.2012.68},
isbn = {978-0-7695-4713-8},
pages = {312--315},
publisher = {IEEE Computer Society},
series = {MDM '12},
title = {{The Airplace Indoor Positioning Platform for Android Smartphones}},
url = {http://dx.doi.org/10.1109/MDM.2012.68},
year = {2012}
}
@inproceedings{Lautner:2017:BCD:3019612.3019724,
address = {New York, NY, USA},
author = {Lautner, Douglas and Hua, Xiayu and Debates, Scott and Song, Miao and Shah, Jagat and Ren, Shangping},
booktitle = {Proceedings of the Symposium on Applied Computing},
doi = {10.1145/3019612.3019724},
isbn = {978-1-4503-4486-9},
keywords = {cellphone development,embedded system,energy efficiency,mobile device,mobile sensing},
pages = {550--556},
publisher = {ACM},
series = {SAC '17},
title = {{BaaS (Bluetooth-as-a-sensor): Conception, Design and Implementation on Mobile Platforms}},
url = {http://doi.acm.org/10.1145/3019612.3019724},
year = {2017}
}
@inproceedings{Lee2008375,
abstract = {Processing of location sensing information and visualization of 3D graphics on PDA either in outdoor or indoor environment had been presented as one of research issues nowadays. Famous tracking system such as GPS had gained its trust as a feasible and effective outdoor tracking system. Traditional tracking system with 2D-image standard presents only few and dull information to users. This paper aim to develop a highly accuracy real-time indoor tracking system with 3D scenes integrated on PDA to provide more useful location sensing information to user. VRML, a powerful 3D modeling tool is used for designing 3D objects in indoor environments. In order to reduce PDA's computing time and increases 3D objects rendering time, culling algorithm is implemented in our system. Generic RSSI-based (received signal strength indicator) location tracking method is used for indoor location tracking due to its low-cost solutions. Moreover, a reliable RSSI smoothing algorithm had been proposed to cater the reflecting and attenuating of objects in surrounding environment for RSSI ranging. Experiments had revealed an ideal result with rendering time of 3D objects in less than I sec and high accuracy of real-time RSSI position estimation in our system. {\textcopyright} 2008 IEEE.},
annote = {cited By 4},
author = {Lee, B.-G. and Lee, Y.-S. and Chung, W.-Y.},
booktitle = {Proceedings - 3rd International Conference on Convergence and Hybrid Information Technology, ICCIT 2008},
doi = {10.1109/ICCIT.2008.391},
keywords = {3D graphics; 3D modeling tools; 3D objects; 3d sc,Content based retrieval; Hand held computers; Indu,Three dimensional},
pages = {375--381},
title = {{3D map visualization for real time RSSI indoor location tracking system on PDA}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-57849148123{\&}doi=10.1109{\%}2FICCIT.2008.391{\&}partnerID=40{\&}md5=b7218f87a4dcd3bb102d0220feee959a},
volume = {1},
year = {2008}
}
@phdthesis{Lee:2011:TDR:2520908,
address = {Pittsburgh, PA, USA},
annote = {AAI3528725},
author = {Lee, David C},
isbn = {978-1-267-62658-5},
publisher = {Carnegie Mellon University},
title = {{Three Dimensional Representation and Reasoning for Indoor Scene Understanding}},
year = {2011}
}
@inproceedings{Lee2014235,
abstract = {Recently, an indoor navigation has attracted great attention in industries and research institutes. Also, a wearable device such as smart glasses has been emerging as the next-generation device to substitute the smartphone. We have a plan to develop an indoor navigation system based on smart glasses as soon as it is released in Republic of Korea. One of the most critical problems in vision-based indoor navigation is difficulty in the database construction when estimating the locations of users. Here, we propose a vision-based navigation system in indoor environments which uses an indoor map and does not require an image database. In each image, features are extracted to recognize the indoor objects without using image database. We define the metric about the four features which are pillar detection metric (PDM), hallway entrance detection metric (HEDM), hallway detection metric (HDM), and absence. Since the four metrics are normalized in the range of 0 or 1, we can classify them using the decision tree. After the classification, we estimate the position of the user through the angle-based matching between the recognized objects and the objects in an indoor map. We already know the angular information of each image using magnetometer and gyroscope built in smartphone. So, we can know the angle between the current position and recognized object. The current position of user is represented as a linear equation and we can solve it using pseudo inverse. To verify the performance of the proposed system, we conducted the positioning experiments in indoor environment. The indoor map is comprised of hall and hallway and we captured the image in six positions which were four halls and two hallways. In each position, we captured 18 images around the user with its angular information. The experimental results show an average recognition rate with 71.3{\%} and the positioning performance with 7 meters. Copyright {\textcopyright} (2014) by the Institute of Navigation. All rights reserved.},
annote = {cited By 0},
author = {Lee, H and Kim, J and Kim, C and Seo, M and Lee, S and Hur, S and Lee, T},
booktitle = {27th International Technical Meeting of the Satellite Division of the Institute of Navigation, ION GNSS 2014},
keywords = {Database construction; In-door navigations; Indoo,Database systems; Decision trees; Glass; Indoor po,Global positioning system},
pages = {235--242},
title = {{Vision-based navigation in indoor environments without using image database}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939249187{\&}partnerID=40{\&}md5=bdf4c83a31e36ae9864d2b190e2fab54},
volume = {1},
year = {2014}
}
@article{Lee1996193,
abstract = {This paper proposes a new approach for determining the location and orientation of a camera mounted on an autonomous vehicle. We choose road boundaries and objects with vertical edges, which can be found commonly in indoor and outdoor environments, to be the calibration objects. The camera models are derived by using two or three consecutive images under the assumption that the height of the camera and the distance during the photographing of images are known in advance. Since the direction of a line in 3D space is perpendicular to the normal of the plane formed by this line and the camera center, the tilt and swing angles can be computed from the first image. The pan angle can then be derived analytically by using the projections of vertical edges in three consecutive images. If the angle between the direction of movement of the autonomous vehicle and the direction of the road boundaries is large enough, then the variation of the projections of the road boundaries is apparent, and two images are sufficient to find the pan angle. If the moving direction is parallel to the direction of the road boundaries, only one image is needed to determine the pan angle. Finally, two translational parameters can be found analytically by employing the projections of vertical edges in two or three consecutive images.},
annote = {cited By 2},
author = {Lee, H.-J. and Deng, C.-T.},
journal = {Journal of Information Science and Engineering},
number = {2},
pages = {193--214},
title = {{Determining camera models from multiple frames}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-6044221096{\&}partnerID=40{\&}md5=e72a9279602dec601efe18a4fbb52255},
volume = {12},
year = {1996}
}
@inproceedings{Lee:2006:MLE:1193209.1193551,
address = {Washington, DC, USA},
author = {Lee, Hyung Su and Song, Byunghun and Youn, Hee Yong and Chung, Kwangsue},
booktitle = {Proceedings of the 2006 International Conference on Hybrid Information Technology - Volume 02},
doi = {10.1109/ICHIT.2006.241},
isbn = {0-7695-2674-8},
pages = {432--438},
publisher = {IEEE Computer Society},
series = {ICHIT '06},
title = {{The Method of Location Error Detection and Correcting in Smart Home Environments}},
url = {http://dx.doi.org/10.1109/ICHIT.2006.241},
year = {2006}
}
@inproceedings{Lee2015189,
abstract = {A series of panoramic images are usually used to generate a 720 panorama image. Although panoramic images are typically used for establishing tour guiding systems, in this research, we demonstrate the potential of using panoramic images acquired from multiple sites to create not only 720 panorama, but also three-dimensional (3D) point clouds and 3D indoor models. Since 3D modeling is one of the goals of this research, the location of the panoramic sites needed to be carefully planned in order to maintain a robust result for close-range photogrammetry. After the images are acquired, panoramic images are processed into 720 panoramas, and these panoramas which can be used directly as panorama guiding systems or other applications. In addition to these straightforward applications, interior orientation parameters can also be estimated while generating 720 panorama. These parameters are focal length, principle point, and lens radial distortion. The panoramic images can then be processed with closerange photogrammetry procedures to extract the exterior orientation parameters and generate 3D point clouds. In this research, VisaulSFM, a structure from motion software is used to estimate the exterior orientation, and CMVS toolkit is used to generate 3D point clouds. Next, the 3D point clouds are used as references to create building interior models. In this research, Trimble Sketchup was used to build the model, and the 3D point cloud was added to the determining of locations of building objects using plane finding procedure. In the texturing process, the panorama images are used as the data source for creating model textures. This 3D indoor model was used as an Augmented Reality model replacing a guide map or a floor plan commonly used in an on-line touring guide system. {\textless}br{\textgreater}{\textless}br{\textgreater} The 3D indoor model generating procedure has been utilized in two research projects: a cultural heritage site at Kinmen, and Taipei Main Station pedestrian zone guidance and navigation system. The results presented in this paper demonstrate the potential of using panoramic images to generate 3D point clouds and 3D models. However, it is currently a manual and labor-intensive process. A research is being carried out to Increase the degree of automation of these procedures. {\textcopyright} 2015, Copernicus. All rights reserved.},
annote = {cited By 3},
author = {Lee, I.-C. and Tsai, F},
booktitle = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
doi = {10.5194/isprsarchives-XL-4-W5-189-2015},
keywords = {3D point cloud; Close range photogrammetry; Exter,Augmented reality; Electric substations; Image acq,Three dimensional computer graphics},
number = {4W5},
pages = {189--192},
title = {{APPLICATIONS OF PANORAMIC IMAGES: FROM 720 PANORAMA TO INTERIOR 3D MODELS OF AUGMENTED REALITY}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933045928{\&}doi=10.5194{\%}2Fisprsarchives-XL-4-W5-189-2015{\&}partnerID=40{\&}md5=ab9688177c8c075c2a19ef040d1262f7},
volume = {40},
year = {2015}
}
@inproceedings{Lee2009,
abstract = {At present, the computer has tremendous impact on our life. Ubiquitous Networking and Computing Technology which provides users' demanding service to connect Broadcast service network from anywhere and for the convenience of users, is needed recently. Specially, service based on location in the Ubiquitous Infrastructure shall operate to communicate with variety of user services on Ubiquitous environment. Now, very short distance communication technology, GPS which is displayed user or object location, LBS(Location Based Service), RTLS(Real-Time Locating System), one of the wireless communicate technologies Wi-Fi(802.11b), ZigBee(802.15.4), UWB, RFID have a variety of form and communication. However these technologies concern with sending location information only, it is not concerned with user demands at indoor or at a particular place. Therefore this papers presents when the AP (Access Point) is automatically connected with Nomadic-Device (such as Smart-Phone or PDA or laptop etc.) while it enters the entrance of particular place, UDPS(User Demanding service based on Positioning System) will be provide to the Nomadic-Device with Hybrid Active Service via installing S/W attached personal ID.},
annote = {cited By 0},
author = {Lee, K.-S. and Jeong, J.-I. and Lee, S.-S.},
booktitle = {16th ITS World Congress},
keywords = {Automatically connected; Broadcast services; Comp,Intelligent systems; Intelligent vehicle highway s,Location based services},
title = {{The research of providing user positioning estimate with on-demanding service using UDPS}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954571674{\&}partnerID=40{\&}md5=4cc277aa5283253884b2b3ac5bb2b09e},
year = {2009}
}
@article{Lee2011455,
abstract = {Available techniques for indoor object locating systems, such as inertial sensor-based system or radio fingerprinting, hardly satisfy both cost-effectiveness and accuracy. In particular, inertial sensor-based locating systems are often supplemented with radio signals to improve localization accuracy. A radio-assisted localization system is still costly due to the infrastructure requirements and management overheads. In this paper, we propose a low-cost and yet accurate indoor pedestrian localization scheme with a small number of radio beacons whose location information is unknown. Our scheme applies the Simultaneous Location and Mapping (SLAM) technique used in robotics to mobile device, which is equipped with both inertial sensors and the IEEE802.15.4a Chirp Spread Spectrum (CSS) radio, to obtain accurate locations of pedestrians in indoor environment. The proposed system is validated with real implementations. The experiment results show approximately 1.5 m mean error observed during 276 m of pedestrian moving in a 380 m2 indoor environment with five position-unknown beacons. {\textcopyright} 2011 IEEE.},
annote = {cited By 53},
author = {Lee, S and Kim, B and Kim, H and Ha, R and Cha, H},
doi = {10.1109/TII.2011.2158832},
journal = {IEEE Transactions on Industrial Informatics},
keywords = {Chirp spread spectrum; IEEE 802.15.4a; particle fi,Inertial navigation systems; Mobile devices; Robo,Sensors},
number = {3},
pages = {455--466},
title = {{Inertial sensor-based indoor pedestrian localization with minimum 802.15.4a configuration}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051781496{\&}doi=10.1109{\%}2FTII.2011.2158832{\&}partnerID=40{\&}md5=7d04ac7b333783720405baec97409683},
volume = {7},
year = {2011}
}
@book{Lee:2012:FIA:2431382,
author = {Lee, Sukhan and Yoon, Kwang-Joon and Lee, Jangmyung},
isbn = {364235484X, 9783642354847},
publisher = {Springer Publishing Company, Incorporated},
title = {{Frontiers of Intelligent Autonomous Systems}},
year = {2012}
}
@inproceedings{6192945,
abstract = {Asset management is urgently needed in supply chain which requires to solve two basic problems 1) what assets do we have; and 2) where they are? Existing methods exploit barcode and RFID technologies to retrieve the information and quantity of assets. However, the location of asset is still hard to obtain for the lack of suitable location technologies. In this paper, a high precision location based asset management system named SpaceAnnotator is proposed. SpaceAnnotator is implemented based on TOA positioning method using Ultrasound and RF signals. Leveraging the centimeter level positioning accuracy provided by the positioning system, SpaceAnnotator maps the IDs of objects to their locations. Based on the location information, location based service (LBS) in provided for asset management. Compared with conventional location based asset management system, SpaceAnnotator works well even in managing small volume objects for its high accuracy.},
author = {{Lei Song} and {Yongcai Wang}},
booktitle = {IET International Conference on Communication Technology and Application (ICCTA 2011)},
doi = {10.1049/cp.2011.0748},
keywords = {asset management;information retrieval;radiofreque},
pages = {647--651},
title = {{SpaceAnnotator: a high precision location based asset management system in indoor environment}},
year = {2012}
}
@inproceedings{Lemieux:2009:WHI:1568199.1568209,
address = {New York, NY, USA},
author = {Lemieux, Nathan and Lutfiyya, Hanan},
booktitle = {Proceedings of the 2009 International Conference on Pervasive Services},
doi = {10.1145/1568199.1568209},
isbn = {978-1-60558-644-1},
keywords = {altimeter,feature extraction,indoor positioning system,wifi},
pages = {55--64},
publisher = {ACM},
series = {ICPS '09},
title = {{WHLocator: Hybrid Indoor Positioning System}},
url = {http://doi.acm.org/10.1145/1568199.1568209},
year = {2009}
}
@inproceedings{8355546,
abstract = {This paper presents an enhanced model to handle the radio-frequency (RF) signal to provide a real-time indoor localization service in a practical manner. This model is using the Bluetooth Low Energy (BLE) beacons as the RF signal for indoor localization service. The fingerprinting approach, Received Signal Strength Indicator (RSSI) is used to cut-down the cost of implementation and the accuracy can be further improved with more BLE beacons installed. The RSSI technique applied will be further improved with signal selecting algorithm to determine the right reference points for positioning service. An error compensation algorithm also will be applied to eliminate the false signal which will affect the system's accuracy. This proposed model includes implementation of enhanced RSSI technique with error compensation algorithm to determine the position of users or targeted objects with correct reference points to improve the positioning result.},
author = {Leong, C Y and Perumal, T and Yaakob, R and Peng, K W},
booktitle = {2017 IEEE International Symposium on Consumer Electronics (ISCE)},
doi = {10.1109/ISCE.2017.8355546},
issn = {2159-1423},
keywords = {Bluetooth;error compensation;indoor radio;Internet},
month = {nov},
pages = {52--55},
title = {{Enhancing indoor positioning service for location based Internet of Things (IoT): A source selecting approach with error compensation}},
year = {2017}
}
@article{Li2005153,
abstract = {Determining physical location of indoor objects is one of the key issues in development of context-aware applications in ubiquitous computing environment. This is mainly because context information obtained from sensor network is meaningful only when the physical location of context information source is determined. This paper surveys some important indoor locating technologies, and introduces several location-aware methods combining with the author's preliminarily research results. A general location-aware framework is discussed elaborately at last.},
annote = {cited By 0},
author = {Li, C and Cao, Q and Pu, F},
journal = {Jisuanji Gongcheng/Computer Engineering},
number = {21},
pages = {153--155},
title = {{Indoor location-aware of ubiquitous computing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-28244446186{\&}partnerID=40{\&}md5=d5f5fecf4649a3c8e5e6975b28decc23},
volume = {31},
year = {2005}
}
@phdthesis{Li:2011:HCS:2521961,
address = {Newark, DE, USA},
annote = {AAI3498529},
author = {Li, Feng},
isbn = {978-1-267-21501-7},
publisher = {University of Delaware},
title = {{A Hybrid Camera System for Low-light Imaging}},
year = {2011}
}
@article{Li2013157,
abstract = {RFID-based location awareness is becoming the most important issue in many fields in recent years, such as ubiquitous computing, mobile computing. In indoor localization systems RSSI-based methods are usually used in office buildings. However, RSSI is susceptible to external influences, and performances unstably due to the environmental factors affecting signal propagation. In this paper, we propose a new hybrid localization method for tracking moving object using the two typical methods which are signal propagation model and fingerprinting. According to a threshold which is defined as an effective working distance of signal propagation model between target tag and RFID reader, we choose the different localization algorithm to estimate the location of moving object. The threshold is obtained by calculating the slop of signal attenuation curve. If the distance is within the effective reading range of RFID reader, we revise signal propagation model by maximum likelihood estimation and use it to calculate the object position by minimum cumulative error. Otherwise, the fingerprinting location method is used in the external area, and the particle filter is also used as the core algorithm. The experimental results show that our method not only reduces the computation complexity but also ensures the accuracy in large indoor area {\textcopyright} 2013 SERSC.},
annote = {cited By 7},
author = {Li, J and Zhang, B and Liu, H and Yu, L and Wang, Z},
doi = {10.14257/ijsh.2013.7.6.15},
journal = {International Journal of Smart Home},
keywords = {Algorithms,Computation complexity; Environmental factors; Ext,Maximum likelihood estimation; Office buildings;},
number = {6},
pages = {157--170},
title = {{An indoor hybrid localization approach based on signal propagation model and fingerprinting}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891770940{\&}doi=10.14257{\%}2Fijsh.2013.7.6.15{\&}partnerID=40{\&}md5=2ec2613f0a6ba76785d75837121d3f34},
volume = {7},
year = {2013}
}
@article{Li2013670,
abstract = {In RSSI-based RFID(Radio Frequency IDentification) indoor localization system, the signal path loss model of each sub-region is different from others in the whole localization area due to the influence of the multi-path phenomenon and other environmental factors. Therefore, this paper divides the localization area into many sub-regions and constructs separately the signal path loss model of each sub-region. Then an improved LANDMARC method is proposed. Firstly, the deployment principle of RFID readers and tags is presented for constructing localization sub-region. Secondly, the virtual reference tags are introduced to create a virtual signal strength space with RFID readers and real reference tags in every sub-region. Lastly, k nearest neighbor (KNN) algorithm is used to locate the target object and an error compensating algorithm is proposed for correcting localization result. The results in real application show that the new method enhances the positioning accuracy to 18.2{\%} and reduces the time cost to 30{\%} of the original LANDMARC method without additional tags and readers. {\textcopyright} 2013 KSII.},
annote = {cited By 4},
author = {Li, J and Zhang, G and Yu, L and Wang, Z and Zhang, J},
doi = {10.3837/tiis.2013.04.004},
journal = {KSII Transactions on Internet and Information Systems},
keywords = {Algorithms,Environmental factors; Indoor localization systems,Error compensation; Radio frequency identificatio},
number = {4},
pages = {670--691},
title = {{An advanced RFID localization algorithm based on region division and error compensation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877031421{\&}doi=10.3837{\%}2Ftiis.2013.04.004{\&}partnerID=40{\&}md5=01fc79388f073811b7f4696402a99f6c},
volume = {7},
year = {2013}
}
@article{Li2013402,
abstract = {In an RSSI-based RFID indoor localization system, the signal propagation model in each subregion is different from others due to heterogeneity of environmental interference distribution in the area. A region division-based localization method is proposed to divide the localization region into many triangle subregions. A multi-round voting method is used to search the sub-region where the target object is located. We then build a signal propagation model by estimating the environmental factor and path loss value of that sub-region. By introducing virtual reference tags, we construct a virtual signal strength space and find the nearest neighbor tags, and then calculate coordinates of the target with a self-correcting K nearest neighbor algorithm presented in this paper. Simulation experiments show that estimation accuracy and adaptability of the proposed method are significantly higher than that of LANDMARC and VIRE, especially in complex and low tag density environments.},
annote = {cited By 0},
author = {Li, J.-H. and Zhang, G.-M. and Yu, L and Zhang, J},
doi = {10.3969/j.issn.0255-8297.2013.04.011},
journal = {Yingyong Kexue Xuebao/Journal of Applied Sciences},
number = {4},
pages = {402--410},
title = {{Environmental-adaptive localization method based on virtual reference tags}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885717614{\&}doi=10.3969{\%}2Fj.issn.0255-8297.2013.04.011{\&}partnerID=40{\&}md5=d3397232e54951baeac110bfcecfc5e8},
volume = {31},
year = {2013}
}
@article{Li20162697,
abstract = {RFID technology has been widely used for object tracking in indoor environment due to their low cost and convenience for deployment. Existing RFID localization approaches rely on signal strength to measure the distance between RFID reader and tags. However, because of the environmental complexity and inferences, the measurement of distance by signal strength is not accurate, which causes large error in localization. In this paper we develop a novel algorithm to improve the RFID localization accuracy. Our algorithm is based on particle swarm optimization. More importantly, we add reference tags in the deployment, and design a parameter named Correction Factor in PSO to measure the distances more accurately by signal strength. The result shows that compared with the previous method without the correction factor, our proposed approach can increase the accuracy by 50. This method has good application prospect in equipment management. {\textcopyright} 2016 - IOS Press and the authors. All rights reserved.},
annote = {cited By 11},
author = {Li, J.-Q. and Zhang, S.-P. and Yang, L and Fu, X.-H. and Ming, Z and Feng, G},
doi = {10.3233/JIFS-169109},
journal = {Journal of Intelligent and Fuzzy Systems},
keywords = {Application prospect; Correction factors; Environ,Optimization; Radio frequency identification (RFID,Particle swarm optimization (PSO)},
number = {5},
pages = {2697--2706},
title = {{Accurate RFID localization algorithm with particle swarm optimization based on reference tags}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84992065811{\&}doi=10.3233{\%}2FJIFS-169109{\&}partnerID=40{\&}md5=9b1e0e8380d1da6d0da937e303aeab5f},
volume = {31},
year = {2016}
}
@article{Li2013249,
abstract = {Existing mobile navigation techniques are not applicable for indoor navigation. Obviously, the best navigator is a human companion. In this paper, we explore to build a wearable virtual navigator for indoor navigation. A novel cognitive vision system is designed which consists of long-term memory and working memory for complicated vision tasks in dynamic environments. The long-term memory mimics the flexibility and scalability of human cognitive memory for domain knowledge representation, and the working memory emulates the routine process and attention selection in human cognitive model for online visual perception. Efficient algorithms for image classification and object detection are organized and performed under cognitive perception framework to achieve real-time performance. Field tests demonstrate its effectiveness and efficiency by recognizing scenes, locations, and landmark objects in real-time, and subsequently providing context-aware assistant to guide the user in the navigation of a complex office environment. {\textcopyright} Springer-Verlag 2013.},
annote = {cited By 0},
author = {Li, L and Wang, G S and Goh, W and Lim, J.-H. and Tan, C},
doi = {10.1007/978-3-642-42051-1_32},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Algorithms; Computer vision; Data processing; Ima,Cognitive architectures; In-door navigations; Long,Navigation},
number = {PART 3},
pages = {249--257},
title = {{A wearable cognitive vision system for navigation assistance in indoor environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893341981{\&}doi=10.1007{\%}2F978-3-642-42051-1{\_}32{\&}partnerID=40{\&}md5=6a86e0b5854485cd6ea5b8c325caab57},
volume = {8228 LNCS},
year = {2013}
}
@article{Li2015244,
abstract = {Density queries are defined as querying the dense regions that include more than a certain number of moving objects. Previous research studies mainly focus on how to answer the snap-shot density queries over historical trajectories. However, the real applications usually tend to predict whether a region is a dense region. Especially in indoor environments, such predictive density queries are valuable for high-level analysis but face tremendous challenges. In this paper, by leveraging the Markov correlations, we effectively predict the future locations of moving objects and conduct the density queries accordingly. In particular, we present an optimized framework which contains three phases to tackle this problem. First, we design an index structure based on the transition matrix to facilitate the search process. Second, we propose the space and probability pruning techniques to improve the query efficiency significantly. Finally, we apply an accurate method and an approximate sampling method to verify whether each unpruned region is a dense region. Extensive experiments on real datasets demonstrate that the proposed solutions can outperform the baseline algorithm by up to 2 orders of magnitudes in running time. {\textcopyright} 2015, Springer International Publishing Switzerland, All rights Reserved.},
annote = {cited By 1},
author = {Li, M and Gu, Y and Yu, G},
doi = {10.1007/978-3-319-18120-2_15},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Database systems,High-level analysis; Indoor environment; Indoor m,Query processing},
pages = {244--259},
title = {{Effective and efficient predictive density queries for indoor moving objects}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942580282{\&}doi=10.1007{\%}2F978-3-319-18120-2{\_}15{\&}partnerID=40{\&}md5=a46daeb1bb01736d6921cc85743bb76e},
volume = {9049},
year = {2015}
}
@article{Li2013476,
abstract = {Managing moving objects in indoor space has been a research focus in recent years, as most people live and work in indoor space, e.g. working in office, living in apartment, etc. In this paper, we present an extension of Oracle named IndoorDB to support indoor moving objects management in a practical way. The extension is developed as a PL/SQL package and can be integrated into Oracle to offer new data types and operations for indoor location-based queries such as indoor navigation, hot spots detection, KNN, range queries, and so on. After an overview of the general features of IndoorDB, we discuss the architecture and implementation of IndoorDB. And finally, a case study of IndoorDB's demonstration is presented. {\textcopyright} Springer-Verlag 2013.},
annote = {cited By 3},
author = {Li, Q and Jin, P and Zhao, L and Wan, S and Yue, L},
doi = {10.1007/978-3-642-37450-0_40},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Artificial intelligence; Computer science; Comput,Database systems,Hot spots detection; In-door navigations; Indoor m},
number = {PART 2},
pages = {476--480},
title = {{IndoorDB: Extending oracle to support indoor moving objects management}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892890854{\&}doi=10.1007{\%}2F978-3-642-37450-0{\_}40{\&}partnerID=40{\&}md5=4ea381565c525f557c01ff325d0dd730},
volume = {7826 LNCS},
year = {2013}
}
@book{Li:2009:UMC:1738949,
author = {Li, Qing and Shih, Timothy K},
edition = {1st},
isbn = {142009338X, 9781420093384},
publisher = {Chapman {\&} Hall/CRC},
title = {{Ubiquitous Multimedia Computing}},
year = {2009}
}
@article{Li20182335,
abstract = {Whether or not an indoor service robot can quickly and accurately search for objects is the key to completing the objects delivery task. Due to the location uncertainty of the objects to be searched, it is difficult to obtain the objects semantic and location information accurately and in real time at a long distance. To solve the problem, this paper proposes a vision-based real-time identification and location system that locates belonging objects by identification objects by simulating human's hierarchical perception of environment and combining location structure information between objects. Firstly, extracting ground in the scene by using the PCA and centroid coordinate, using the ground convex hull and improved region growth segmentation algorithm to achieve bottom-up clustering. Then the CVFH features are used to identify the identification objects in the identification database. After using the returned centroid to obtain the point cloud image for near distance, repeating the above steps to identify and locate the belonging objects in the child belonging database selected based on the identification belonging relationship. At last, experiment and analysis are carried out on the "Turtlebot" service robot platform to verify the effectiveness of the algorithm. {\textcopyright} 2018, Beijing China Science Journal Publishing Co. Ltd. All right reserved.},
annote = {cited By 0},
author = {Li, W and Wu, H and Tian, G},
doi = {10.3724/SP.J.1089.2018.17188},
journal = {Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics},
keywords = {Experiment and analysis; Global feature; Location,Image segmentation; Indoor positioning systems; Mo,Location},
number = {12},
pages = {2335--2343},
title = {{Objects Search Recognition and Localization for Indoor Service Robot Based on Identification Belonging Relationship []}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062505096{\&}doi=10.3724{\%}2FSP.J.1089.2018.17188{\&}partnerID=40{\&}md5=a07ab22f394c3eb0ccc49e16e0e340b1},
volume = {30},
year = {2018}
}
@inproceedings{Li2013546,
abstract = {This paper studies the problem about robot path planning, and puts forward an application of electronic compass and vision-based camera which used for robot navigation and map building. We can make sure the azimuth angle of robot by installing electronic compass on robot's control panel, and then locate the robot through the image information from the camera which is installed on the robot's head. Suppose the mobile environment of robot is indoor, and we can determine the original location, current location of robot and the object's location through combining the data which from electronic compass with the data from camera. We also can build the map information by a comprehensive analysis of these data and build a new data structure which is special constructed for electric compass. The result shows that the micro system provides a good solution of map building, navigation and location in the laboratory environment. {\textcopyright} 2013 IEEE.},
annote = {cited By 1},
author = {Li, X and Wang, Q and Zhang, X},
booktitle = {Proceedings - IEEE 9th International Conference on Mobile Ad-Hoc and Sensor Networks, MSN 2013},
doi = {10.1109/MSN.2013.101},
pages = {546--549},
title = {{Application of electronic compass and vision-based camera in robot navigation and map building}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894151501{\&}doi=10.1109{\%}2FMSN.2013.101{\&}partnerID=40{\&}md5=02270f988a45013ebfdb9e62c3117bab},
year = {2013}
}
@article{Li2011,
abstract = {Based on studying the basic law of the Chinese natural language representation of path (NLRP), a visual navigation algorithm based on constrained natural language for indoor environments is designed through establishing the imagery map for mobile robot navigation. Firstly, landmarks are extracted from constrained Chinese text, relative directions and distances among the landmarks are obtained, and then those landmarks are mapped onto the imagery map. Secondly, key boot points, by which the path is divided into several segments, are extracted to realize the path planning of the mobile robot. For each segment, the matching degree of SURF (Speeded-Up Robust Feature) feature points between the referenced object's real-time pictures and sample pictures in the database is calculated, and the data of odometer are fused to ascertain the approximate location of the mobile robot. Then, based on the approximate location obtained in the previous segment, the running direction in the next segment is calculated, and the robot will run along it. The calculation and movement go analogically till the last segment. Experiment results demonstrate the feasibility, validity and robustness of the method.},
annote = {cited By 5},
author = {Li, X and Zhang, X and Dai, X},
doi = {10.3724/SP.J.1218.2011.00742},
journal = {Jiqiren/Robot},
keywords = {Chinese text; Constrained Chinese; Constrained nat,Computational linguistics; Image matching; Intell,Natural language processing systems},
number = {6},
pages = {742--749+757},
title = {{A visual navigation method of mobile robot based on constrained natural language processing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-83455201234{\&}doi=10.3724{\%}2FSP.J.1218.2011.00742{\&}partnerID=40{\&}md5=9cc83943f69e698f92ff8cbb9cf66a30},
volume = {33},
year = {2011}
}
@inproceedings{Li2007995,
abstract = {In this paper, a hierarchical indoor localization scheme is proposed to enable the use of autonomously powered ultra-low-power tags attached to the objects with unknown position. Using the UWB characteristics and the 3-tier organization (consisting of a large number of cost-effective tags, a small number of cheap and low-power hubs and a few synchronized base stations), the proposed localization scheme can provide a wide geographical coverage and precise positioning. Localization is based on the arrival time of the UWB pulses at the reference nodes with known locations. We formalize the hub placement problem as an optimization problem. Simulations investigate the performance degradation due to the nonideal hub placement and hub localization error. {\textcopyright} 2007 IEEE.},
annote = {cited By 13},
author = {Li, Z and Dehaene, W and Gielen, G},
booktitle = {ICSPC 2007 Proceedings - 2007 IEEE International Conference on Signal Processing and Communications},
doi = {10.1109/ICSPC.2007.4728489},
keywords = {Arrival time; Geographical coverages; Indoor loca,Broadband networks,Sensor nodes; Signal processing; Telecommunication},
pages = {995--998},
title = {{A 3-tier UWB-based indoor localization scheme for ultra-low-power sensor nodes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-60349127448{\&}doi=10.1109{\%}2FICSPC.2007.4728489{\&}partnerID=40{\&}md5=8d91e3b2c75e0ccd250ad26d148f32f1},
year = {2007}
}
@article{8476608,
abstract = {Obtaining accurate location information of tracked objects is the cornerstone of providing high-quality location-based services (LBSs). Recently, passive localization has become an increasingly important research theme, attracting the attention from both academic and industrial communities. However, existing Wi-Fi fingerprinting-based passive localization methods mainly focus on the indoor localization problem and require Wi-Fi detection equipment to scan wireless communications simultaneously. In this paper, we propose the concept of indoor region localization, which aims at estimating the region where an object stayed for a given time interval. Moreover, a Bayesian probabilistic model is presented to cope with this issue. The key novelty of our method lies in that it allows Wi-Fi detection equipment to behave in an asynchronous fashion, which eliminates synchronization concerns when implementing the positioning system. Specifically, it first introduces a time window for each timestamp, and then aggregates all the sensing records in the given time window to obtain an RSSI measurement vector. Afterward, a kernel function is utilized to measure the conditional probability with respect to every fingerprint, and all these probabilities are combined to obtain the posterior probabilities corresponding to different regions. Extensive experiments are conducted on both public and proprietary data sets and our method significantly outperforms all the comparing algorithms in terms of each evaluation metric.},
author = {Liang, W and Wang, Y and Wu, Z and Mao, B and Cao, J},
doi = {10.1109/JSEN.2018.2872825},
issn = {1530-437X},
journal = {IEEE Sensors Journal},
keywords = {Bayes methods;indoor navigation;radionavigation;RS},
number = {24},
pages = {10174--10182},
title = {{Indoor Region Localization With Asynchronous Sensing Data: A Bayesian Probabilistic Model}},
volume = {18},
year = {2018}
}
@inproceedings{Liao2011227,
abstract = {Cameras and surveillance systems are widely installed at streets, communities, schools, buildings and so on. In our previous results, the global positioning system (GPS) was incorporated with the visual tracking technique, called GPS-VT. A person can be located and tracking according his GPS coordinate in the outdoor environment. However, GPS-VT service is unavailable when the person walks in an indoor environment. Therefore, the purpose of this study is to provide a seamless fusion of GPS-VT service for persons from the outdoor to indoor environment. In order to achieve the above purpose, template matching, shadow removal, and collision resolution techniques are used for the tracking among multiple cameras in the indoor environment. Besides, the elapsed time of a person leaving the field-of-views (FOV) of one camera and entering the FOV of another is not a fixed value. An automatic estimation mechanism is designed and a normal distribution function is used to estimate an acceptable interval of the elapsed time. Such a mechanism is performed for any two successive cameras. Besides, a prototype was implemented to demonstrate that the GPS-VT service is extended from outdoor to indoor environment with multiple cameras. {\textcopyright} 2011 IEEE.},
annote = {cited By 4},
author = {Liao, H.-C. and Lai, C.-M.},
booktitle = {Proceedings of 2011 3rd International Conference on Awareness Science and Technology, iCAST 2011},
doi = {10.1109/ICAwST.2011.6163145},
keywords = {Automatic estimation; Collision resolution; Global,Cameras,Normal distribution; Security systems; Technology},
pages = {227--232},
title = {{Seamless fusion of GPS-VT service from outdoor to indoor cameras}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858779893{\&}doi=10.1109{\%}2FICAwST.2011.6163145{\&}partnerID=40{\&}md5=01a98e8148ca3dd17f0e44c3dbd624db},
year = {2011}
}
@inproceedings{7489526,
abstract = {This research paper proposes a single camera based depth estimation technique. The proposed technique takes images of walls in a room and detects objects of interest in a cluttered environment. Having detected different objects in a room the proposed technique calculates their areas. Based on training data and polynomial curve fitting approach the proposed technique estimates the distance of the camera from the objects. For a real world object one can determine a fixed equation which can then be used to find any random distance. The approach is efficient and can effectively be applied to any indoor navigation or motion planning algorithm. Based on the estimated distances from different objects the proposed algorithm estimates the accurate location of the camera (mounted on a robot) in a room. For detection we have used template matching technique. Algorithm compares the reference template with the objects of interest in a cluttered environment by using SURF (speeded up robust features). The proposed algorithm is tested on real world images and compared with the existing depth estimation techniques.},
author = {Liaquat, S and Khan, U S},
booktitle = {2015 Fourth International Conference on Aerospace Science and Engineering (ICASE)},
doi = {10.1109/ICASE.2015.7489526},
keywords = {cameras;feature extraction;object detection;spatia},
pages = {1--4},
title = {{Object detection and depth estimation of real world objects using single camera}},
year = {2015}
}
@article{Liarokapis200622,
abstract = {The development of Location Context tools for UMTS Mobile Information Services (LOCUS) research project aims to significantly enhance the current map-based user-interference paradigm on a mobile device through the use of virtual reality and augmented reality techniques. Based on the principles of both AR and VR, a prototype mixed reality interface has been designed to be superimposed on location aware 3D models, 3D sound, images and textual information in both indoor and outdoor environments. The research, funded by the EPSRC, discusses the registration of the geographical information with real objects in real-time, use of mixed reality for spatial visualization at decision points, and integration of visualized geographic information with other location-based services. Location Based Services (LBS) are a crucial element in the strategy to develop new revenue streams alongside voice, and this research could significantly improve the usability and functionality of these services.},
annote = {cited By 3},
author = {Liarokapis, F},
journal = {Advanced Imaging},
keywords = {Decision Making; GIS; Mathematical Models; Mobile,Decision making; Geographic information systems;,Location Based Services (LBS); Location Context to,Mobile telecommunication systems},
number = {4},
pages = {22--25},
title = {{Location-based mixed reality for mobile information services}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646496986{\&}partnerID=40{\&}md5=547e2a1ed21f1748b3293bb5f364bff9},
volume = {21},
year = {2006}
}
@inproceedings{Lieckfeldt2009338,
abstract = {Using simple and cost-effective tags, passive RFID systems offer a promising aid for identifying and localizing objects and users in indoor environments. Although systems based on radio frequencies usually suffer from multi-path interference and signal scattering, we show that the characteristics of such interference and scattering can be analyzed with passive RFID. We present and analyze measurements of received signal strength (RSS) conducted in an indoor environment using a passive bistatic RFID-System. In order to characterize the influence of human presence on RSS, measurements were conducted for different user locations and orientations in an indoor deployment area. Finally, an analytical approximation of the relation between user location and RSS is presented in accordance to our measurement results. {\textcopyright} 2009 IEEE.},
annote = {cited By 7},
author = {Lieckfeldt, D and You, J and Timmermann, D},
booktitle = {WiMob 2009 - 5th IEEE International Conference on Wireless and Mobile Computing Networking and Communication},
doi = {10.1109/WiMob.2009.64},
keywords = {Analytical approximation; Bistatic; Indoor environ,Computer science; Location; Mobile computing; Wir,Wireless networks},
pages = {338--343},
title = {{Characterizing the influence of human presence on bistatic passive RFID-system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-72849138744{\&}doi=10.1109{\%}2FWiMob.2009.64{\&}partnerID=40{\&}md5=5bbc5c6dd7b194fda53a2bd97e7932aa},
year = {2009}
}
@article{GiHyunLim:2011:OUR:2334426.2334432,
address = {Piscataway, NJ, USA},
author = {Lim, Gi Hyun and Suh, Il Hong and Suh, Hyowon},
doi = {10.1109/TSMCA.2010.2076404},
issn = {1083-4427},
journal = {Trans. Sys. Man Cyber. Part A},
number = {3},
pages = {492--509},
publisher = {IEEE Press},
title = {{Ontology-Based Unified Robot Knowledge for Service Robots in Indoor Environments}},
url = {https://doi.org/10.1109/TSMCA.2010.2076404},
volume = {41},
year = {2011}
}
@inproceedings{Lin2018,
abstract = {In this paper we present the development of an evidence-based search planner for a mobile assistive robot to autonomously search for a dynamic person in a multi-room home environment in order to provide assistance. We solve the dynamic person search problem by uniquely considering evidence of household objects along with a user spatial-temporal model to increase the probability of finding the user. Our planner utilizes a Partially Observable Markov Decision Process (POMDP) to plan optimal robot search paths in the environment as the user and evidence locations are partially observable. Extensive simulated experiments in a home environment were conducted to compare our proposed evidence-based search approach with 1) a search technique without prior user information, and 2) a search technique that only uses a user model. The results show that our proposed search technique has higher success rates for finding the user and is more robust to the dynamic behaviors of the user. Copyright {\textcopyright} 2018 ASME},
annote = {cited By 0},
author = {Lin, S and Nejat, G},
booktitle = {Proceedings of the ASME Design Engineering Technical Conference},
doi = {10.1115/DETC2018-86295},
keywords = {Assistive robots; Dynamic behaviors; Home environ,Behavioral research,Data reduction; Design; Information analysis; Mark},
title = {{Robot evidence based search for a dynamic user in an indoor environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057109618{\&}doi=10.1115{\%}2FDETC2018-86295{\&}partnerID=40{\&}md5=55805fab644bfd6480c8f070391731ba},
volume = {5B-2018},
year = {2018}
}
@article{Liu2018108,
abstract = {Given a single indoor image, this paper proposes an automatic retrieval system to estimate the best-matching 3D models with consistent style and pose. To support this system, we combine a deep CNN based object detection approach with a deformable part based alignment model. The key idea is to cast a 2D-3D alignment problem as a part-based cross-domain matching. We also provide an interactive refinement interface that allows users to browse models based on similarities and differences between shapes in user-specified regions of interest (ROIs). We demonstrate the ability of our system on numerous examples. {\textcopyright} 2017},
annote = {cited By 1},
author = {Liu, F and Wang, S and Ding, D and Yuan, Q and Yao, Z and Pan, Z and Li, H},
doi = {10.1016/j.cag.2017.07.029},
journal = {Computers and Graphics (Pergamon)},
keywords = {3 d model retrievals; 3D indoor scenes; Alignment,Alignment; Object detection; Self organizing maps,Search engines},
pages = {108--117},
title = {{Retrieving indoor objects: 2D-3D alignment using single image and interactive ROI-based refinement}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028765178{\&}doi=10.1016{\%}2Fj.cag.2017.07.029{\&}partnerID=40{\&}md5=2dc9c5011747cf9285ab670e05afee59},
volume = {70},
year = {2018}
}
@inproceedings{Liu:2014:FGA:3044805.3044863,
author = {Liu, Ji and Fujimaki, Ryohei and Ye, Jieping},
booktitle = {Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32},
pages = {I--503----I--511},
publisher = {JMLR.org},
series = {ICML'14},
title = {{Forward-backward Greedy Algorithms for General Convex Smooth Functions over a Cardinality Constraint}},
url = {http://dl.acm.org/citation.cfm?id=3044805.3044863},
year = {2014}
}
@article{Liu:2017:ISM:3140137.3140204,
address = {Secaucus, NJ, USA},
author = {Liu, Mingming and Guo, Yanwen and Wang, Jun},
doi = {10.1007/s00371-016-1348-3},
issn = {0178-2789},
journal = {Vis. Comput.},
keywords = {Calibration,Edge,Indoor image modeling,Orientation estimation},
number = {10},
pages = {1227--1240},
publisher = {Springer-Verlag New York, Inc.},
title = {{Indoor Scene Modeling from a Single Image Using Normal Inference and Edge Features}},
url = {https://doi.org/10.1007/s00371-016-1348-3},
volume = {33},
year = {2017}
}
@inproceedings{Liu2017,
abstract = {A new methodology for 3D change detection which can support effective robot sensing and navigation in a reconstructed indoor environment is presented in this paper. We register the RGB-D images acquired with an untracked camera into a globally consistent and accurate point-cloud model. This paper introduces a robust system that detects camera position for multiple RGB video frames by using both photo-metric error and feature based method. It utilizes the iterative closest point (ICP) algorithm to establish geometric constraints between the point-cloud as they become aligned. For the change detection part, a bag-of-word (DBoW) model is used to match the current frame with the previous key frames based on RGB images with Oriented FAST and Rotated BRIEF (ORB) feature. Then combine the key-frame translation and ICP to align the current point-cloud with reconstructed 3D scene to localize the robot position. Meanwhile, camera position and orientation are used to aid robot navigation. After preprocessing the data, we create an Octomap Model to detect the scene change measurements. The experimental evaluations performed to evaluate the capability of our algorithm show that the robot's location and orientation are accurately determined and provide promising results for change detection indicating all the object changes with very limited false alarm rate. {\textcopyright} 2017 SPIE.},
annote = {cited By 1},
author = {Liu, R and Asari, V K},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.2262831},
keywords = {3D reconstruction; Bag of words; Change detection,Cameras; Feature extraction; Indoor positioning sy,Robots},
title = {{3D indoor scene reconstruction and change detection for robotic sensing and navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023628924{\&}doi=10.1117{\%}2F12.2262831{\&}partnerID=40{\&}md5=d5c8e6e62737ba3ff0fe4043d87862b8},
volume = {10221},
year = {2017}
}
@inproceedings{Liu2010406,
abstract = {This paper presents a video summarization method to visualize the video object trajectories across multiple cameras in a static image for monitoring the movements of suspicious people in a building. First, we have designed an object association algorithm across multiple stationary cameras, which can be used to build the object trajectories in the building with the assistants of the predefined locations of the cameras. The object associations are based on the features of human body, such as the clothing colour, stature, shoulder breadth and so on. These features are calculated from the anthropometric dimensions of the human body from calibrated monocular video sequences. Finally, the object trajectories are illustrated in a perspective picture that overviews all floors of the building, wihich is called storyboard. Some diagrammatic elements such as arrows and texts are used to annotate the object movements. Thicker arrows represent the more rapid movements and narrower arrows represent the slower movements. The visualization results can assist the monitors to real-time observe the people's movements and easily understand the people's activities in a building. {\textcopyright} 2009 IEEE.},
annote = {cited By 2},
author = {Liu, S and Lai, S},
booktitle = {Proceedings of the 5th International Conference on Image and Graphics, ICIG 2009},
doi = {10.1109/ICIG.2009.184},
keywords = {Anthropometric dimensions; Human bodies; Indoor su,Cameras,Hosiery manufacture; Trajectories; Video cameras;},
pages = {406--411},
title = {{Schematic visualization of object trajectories across multiple cameras for indoor surveillances}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952257879{\&}doi=10.1109{\%}2FICIG.2009.184{\&}partnerID=40{\&}md5=b789c5090a16d0d67ff1e3ea52998045},
year = {2010}
}
@inproceedings{Liu:2009:SVO:1748607.1749107,
address = {Washington, DC, USA},
author = {Liu, Shaohua and Lai, Shiming},
booktitle = {Proceedings of the 2009 Fifth International Conference on Image and Graphics},
doi = {10.1109/ICIG.2009.184},
isbn = {978-0-7695-3883-9},
pages = {406--411},
publisher = {IEEE Computer Society},
series = {ICIG '09},
title = {{Schematic Visualization of Object Trajectories Across Multiple Cameras for Indoor Surveillances}},
url = {https://doi.org/10.1109/ICIG.2009.184},
year = {2009}
}
@inproceedings{4449920,
abstract = {Context-aware systems allow users to access services and multimedia data according to their current context (location, identity, preferences). We deem that applying Web 2.0 and ubiquitous Web concepts as guiding principles to design middleware infrastructure may ease the development and deployment of context-aware systems and, so, result in a wider adoption of intelligent environments. Our work combines social context-aware annotation of objects and spatial regions with sentient mobile devices in order to enable advanced context-aware data and service discovery, filtering and consumption for both indoor and outdoor environments.},
author = {Lopez-de-Ipina, D and Vazquez, J I and Abaitua, J},
booktitle = {2007 3rd IET International Conference on Intelligent Environments},
issn = {0537-9989},
keywords = {Internet;knowledge based systems;middleware;mobile},
pages = {116--123},
title = {{A context-aware mobile mash-up platform for ubiquitous web}},
year = {2007}
}
@article{Liu201419,
abstract = {A positioning algorithm based on grid-matching in space domain was proposed. By using the signal attenuation model, the matching calculation in signal domain was transformed into distance domain, and then the similarity rate was calculated. Therefore, the nearest object grid was detected. Finally, the accurate positioning result was obtained. The nonlinear spatial matching errors were reduced caused by the position of similarity. The positioning error was further reduced by learning grid matching method, which increased the positioning accuracy. Compared to RSSI-KNN (received signal strength indication-K nearest neighborhood) and RSSI-GRID algorithm, the proposed algorithm reduces the positioning error and the positioning accuracy by nearly 10{\%}, which can meet the indoor positioning.},
annote = {cited By 1},
author = {Liu, W and Xu, L and Li, Z and Deng, Z},
doi = {10.13245/j.hust.140305},
journal = {Huazhong Keji Daxue Xuebao (Ziran Kexue Ban)/Journal of Huazhong University of Science and Technology (Natural Science Edition)},
keywords = {Algorithms,Distance domain; Grid-matching; Indoor locations;,Engineering; Mathematical models},
number = {3},
pages = {19--22},
title = {{Location algorithm based on distance domain grid matching}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897142288{\&}doi=10.13245{\%}2Fj.hust.140305{\&}partnerID=40{\&}md5=925f4be519549923b425e013742c9e46},
volume = {42},
year = {2014}
}
@inproceedings{8559796,
abstract = {Location based social network services like Facebook and Twitter have supported billions of social media users to share their check-ins all over the world. The massive check-in data is regarded as a kind of novel data resource to explore human mobility. In this paper, we study the human mobility characteristics and differences presented in Sina Weibo (a Chinese equivalent of Twitter) check-in data for different groups. First, we identified different groups based on their spatial distribution characters. Then, we selected two urban resident groups and two college student groups as our study objects. The four groups are consisted by more than 12,000 Sina Weibo users who contributed over 80,000 geo-tagged Weibo messages in Wuhan city from 2015-2016. We analyzed the four groups' mobility characters and patterns through spatiotemporal statistics and calculation. The quantitative analysis methods help us to find out that:(i) the mobility differences among communities can be observed through their check-ins;(ii) human dynamics and mobilities are largely affected by the distance (iii) similar social structure directed similar behavior patterns.},
author = {Liu, Z and Yang, C},
booktitle = {2018 Ubiquitous Positioning, Indoor Navigation and Location-Based Services (UPINLBS)},
doi = {10.1109/UPINLBS.2018.8559796},
keywords = {social networking (online);mobility differences;di},
pages = {1--5},
title = {{Exploring group-level human mobility from location-based social media check-in data}},
year = {2018}
}
@article{Liu:2014:AIS:2771634.2771662,
address = {Chichester, UK},
author = {Liu, Zhenbao and Tang, Sicong and Xu, Weiwei and Bu, Shuhui and Han, Junwei and Zhou, Kun},
doi = {10.1111/cgf.12495},
issn = {0167-7055},
journal = {Comput. Graph. Forum},
keywords = {Categories and Subject Descriptors according to AC,I.3.5 [Computer Graphics]: Computational Geometry},
number = {7},
pages = {269--278},
publisher = {The Eurographs Association {\&}{\#}38; John Wiley {\&}{\#}38; Sons, Ltd.},
title = {{Automatic 3D Indoor Scene Updating with RGBD Cameras}},
url = {http://dx.doi.org/10.1111/cgf.12495},
volume = {33},
year = {2014}
}
@book{Ljubojevi2013107,
abstract = {An important issue in multimedia surveillance systems is determining the physical location of moving objects. Due to features like contactless communications, high data rate, non-line-of-sight readability, compactness and low cost, passive Radio Frequency Identification technology is very attractive for indoor localization. Technologies and techniques can be employed in combination, aimed to improve accuracy and precision of localization by heterogeneous data fusion. Object recognition, moving object localization and tracking can be successfully implemented using integration of RFID technology and digital image processing techniques. The block matching algorithm based on region of interest can be efficiently used in image processing analysis for motion segmentation and object tracking. By using regions of interest we eliminate the influence of other large moving objects and avoid unnecessary computations. In this chapter, the improvement of RFID localization using motion segmentation applied on the region of interest extracted using RFID is described. The presented solution shows significant reduction of the position estimation error and variance in comparison to the conventional passive RFID position estimation. {\textcopyright} 2013 Springer-Verlag Berlin Heidelberg. All rights are reserved.},
annote = {cited By 0},
author = {Ljubojevi{\'{c}}, M and Babi{\'{c}}, Z and Risojevi{\'{c}}, V},
booktitle = {Intelligent Multimedia Surveillance: Current Trends and Research},
doi = {10.1007/978-3-642-41512-8_6},
keywords = {Accuracy and precision; Block matching algorithms,Data fusion; Image processing; Image segmentation;,Radio frequency identification (RFID)},
pages = {107--131},
title = {{RFID localization improved by motion segmentation in multimedia surveillance systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930319356{\&}doi=10.1007{\%}2F978-3-642-41512-8{\_}6{\&}partnerID=40{\&}md5=7ecb28684595404bc70d4a8a02c6946c},
volume = {9783642415},
year = {2013}
}
@inproceedings{8120946,
abstract = {This paper presents a conceptual framework for co-design (by multidisciplinary team) Location-based Mobile Learning Applications. Four stages are identified related with this kind of applications: conceptual design, development cycle, put into practice and evaluation. This paper is focus on the first stage, the conceptual design. For this stage, relevant features are described. In particular, good practices of software engineering could be used for the design stage. As part of conceptual design, guidelines are provided to define learning content decoupled of relevant locations of physical space (indoor or outdoor). This allows to reuse both in different applications.},
author = {Lliteras, A B and Challiol, C and Gordillo, S E},
booktitle = {2017 Twelfth Latin American Conference on Learning Technologies (LACLO)},
doi = {10.1109/LACLO.2017.8120946},
keywords = {computer aided instruction;mobile learning;softwar},
pages = {1--8},
title = {{Location-based mobile learning applications: A conceptual framework for co-design}},
year = {2017}
}
@inproceedings{Lobaton2009193,
abstract = {Camera networks are widely used for tasks such as surveillance, monitoring and tracking. In order to accomplish these tasks, knowledge of localization information such as camera locations and other geometric constraints about the environment (e.g. walls, rooms, and building layout) are typically considered to be essential. However, this information is not required for tasks such as estimating the topology of camera network coverage, or coordinate-free object tracking and navigation. In this paper, we propose a simplicial representation (called CN-Complex) that can be constructed from discrete local observations, and utilize this novel representation to recover topological information of the network coverage. We prove that our representation captures the correct topological information for coverage in 2.5D layouts, and demonstrate its utility in simulations as well as an experimental setup. Our proposed approach is particularly useful in the context of ad-hoc camera networks in indoor/outdoor urban environments with distributed but limited computational power and energy. Copyright 2009 ACM.},
annote = {cited By 12},
author = {Lobaton, E J and Ahammad, P and Sastry, S},
booktitle = {2009 International Conference on Information Processing in Sensor Networks, IPSN 2009},
keywords = {Ad hoc networks; Cameras; Data processing; Sensor,Algebraic approaches; Building layout; Camera loca,Security systems},
pages = {193--204},
title = {{Algebraic approach to recovering topological information in distributed camera networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449346119{\&}partnerID=40{\&}md5=32056e8469c1b111a95f1c813cd7ccbd},
year = {2009}
}
@inproceedings{Lopez:2017:RSR:3029798.3036653,
address = {New York, NY, USA},
author = {L{\'{o}}pez, Jose Alexander and Cu{\'{e}}llar, Francisco},
booktitle = {Proceedings of the Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction},
doi = {10.1145/3029798.3036653},
isbn = {978-1-4503-4885-0},
keywords = {human robot interaction,security robot},
pages = {410},
publisher = {ACM},
series = {HRI '17},
title = {{ROBOTMAN: Security Robot for Human-robot Interaction Inside Malls}},
url = {http://doi.acm.org/10.1145/3029798.3036653},
year = {2017}
}
@article{Lopez:2005:NSA:1064517.1064539,
address = {Hingham, MA, USA},
author = {L{\'{o}}pez, Mar$\backslash$'$\backslash$ia Elena and Bergasa, Luis Miguel and Barea, Rafael and Escudero, Mar$\backslash$'$\backslash$ia Soledad},
doi = {10.1007/s10514-005-0607-3},
issn = {0929-5593},
journal = {Auton. Robots},
keywords = {Partially Observable Markov Decision Processes,assistant robots,multisensorial fusion,planning under uncertainty,probabilistic navigation},
number = {1},
pages = {67--87},
publisher = {Kluwer Academic Publishers},
title = {{A Navigation System for Assistant Robots Using Visually Augmented POMDPs}},
url = {http://dx.doi.org/10.1007/s10514-005-0607-3},
volume = {19},
year = {2005}
}
@article{Lou20051561,
abstract = {This paper aims at tracking vehicles from monocular intensity image sequences and presents an efficient and robust approach to three-dimensional (3-D) model-based vehicle tracking. Under the weak perspective assumption and the ground-plane constraint, the movements of model projection in the two-dimensional image plane can be decomposed into two motions: translation and rotation. They are the results of the corresponding movements of 3-D translation on the ground plane (GP) and rotation around the normal of the GP, which can be determined separately. A new metric based on point-to-line segment distance is proposed to evaluate the similarity between an image region and an instantiation of a 3-D vehicle model under a given pose. Based on this, we provide an efficient pose refinement method to refine the vehicle's pose parameters. An improved EKF is also proposed to track and to predict vehicle motion with a precise kinematics model. Experimental results with both indoor and outdoor data show that the algorithm obtains desirable performance even under severe occlusion and clutter. {\textcopyright} 2005 IEEE.},
annote = {cited By 92},
author = {Lou, J and Tan, T and Hu, W and Yang, H and Maybank, S J},
doi = {10.1109/TIP.2005.854495},
journal = {IEEE Transactions on Image Processing},
keywords = {Algorithms; Artificial Intelligence; Computer Sim,Algorithms; Cameras; Computer vision; Image qualit,Automated; Signal Processing,Computer-Assisted; Imaging,Computer-Assisted; Pattern Recognition,Computer-Assisted; Subtraction Technique; Video R,Model-based vision; Occlusion reasoning; Pose ref,Object recognition,Statistical; Motion; Motor Vehicles; Numerical An,Three-Dimensional; Information Storage and Retrie,algorithm; article; artificial intelligence; auto},
number = {10},
pages = {1561--1569},
title = {{3-D model-based vehicle tracking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-27744483314{\&}doi=10.1109{\%}2FTIP.2005.854495{\&}partnerID=40{\&}md5=7e49e743dc0047f06c7a2fdf2c6fe08e},
volume = {14},
year = {2005}
}
@inproceedings{Lovaszova:2016:LAM:3096345.3096453,
address = {Portugal},
author = {Lov{\'{a}}szov{\'{a}}, Gabriela and C{\'{a}}pay, Martin and Michali{\'{z}}kov{\'{a}}, Viera},
booktitle = {Proceedings of the 8th International Conference on Computer Supported Education},
doi = {10.5220/0005862303940401},
isbn = {978-989-758-179-3},
keywords = {Location-based Games.,Mobile Devices,Tablets in Education},
pages = {394--401},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
series = {CSEDU 2016},
title = {{Learning Activities Mediated by Mobile Technology: Best Practices for Informatics Education}},
url = {https://doi.org/10.5220/0005862303940401},
year = {2016}
}
@phdthesis{Low:2006:VPR:1168439,
address = {Chapel Hill, NC, USA},
annote = {AAI3207396},
author = {Low, Kok-Lim},
isbn = {0-542-54731-7},
publisher = {University of North Carolina at Chapel Hill},
title = {{View Planning for Range Acquisition of Indoor Environments}},
year = {2006}
}
@inproceedings{Lu2012438,
abstract = {Indoor spaces accommodate large numbers of spatial objects, e.g., points of interest (POIs), and moving populations. A variety of services, e.g., location-based services and security control, are relevant to indoor spaces. Such services can be improved substantially if they are capable of utilizing indoor distances. However, existing indoor space models do not account well for indoor distances. To address this shortcoming, we propose a data management infrastructure that captures indoor distance and facilitates distance-aware query processing. In particular, we propose a distance-aware indoor space model that integrates indoor distance seamlessly. To enable the use of the model as a foundation for query processing, we develop accompanying, efficient algorithms that compute indoor distances for different indoor entities like doors as well as locations. We also propose an indexing framework that accommodates indoor distances that are pre-computed using the proposed algorithms. On top of this foundation, we develop efficient algorithms for typical indoor, distance-aware queries. The results of an extensive experimental evaluation demonstrate the efficacy of the proposals. {\textcopyright} 2012 IEEE.},
annote = {cited By 38},
author = {Lu, H and Cao, X and Jensen, C S},
booktitle = {Proceedings - International Conference on Data Engineering},
doi = {10.1109/ICDE.2012.44},
keywords = {Algorithms; Information management; Location base,Experimental evaluation; Indexing framework; Indoo,Query processing},
pages = {438--449},
title = {{A foundation for efficient indoor distance-aware query processing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864211796{\&}doi=10.1109{\%}2FICDE.2012.44{\&}partnerID=40{\&}md5=7e81c79062f225e79756dc459fee012f},
year = {2012}
}
@inproceedings{Lu2016449,
abstract = {Indoor tracking data is being amassed due to the deployment of indoor positioning technologies. Analysing such data discloses useful insights that are otherwise hard to obtain. For example, by studying tracking data from an airport, we can identify the shops and restaurants that are most popular among passengers. In this paper, we study two query types for finding frequently visited Points of Interest (POIs) from symbolic indoor tracking data. The snapshot query finds those POIs that were most frequently visited at a given time point, whereas the interval query finds such POIs for a given time interval. A typical example of symbolic tracking is RFID-based tracking, where an object with an RFID tag is detected by an RFID reader when the object is in the reader's detection range. A symbolic indoor tracking system deploys a limited number of proximity detection devices, like RFID readers, at preselected locations, covering only part of the host indoor space. Consequently, symbolic tracking data is inherently uncertain and only enables the discrete capture of the trajectories of indoor moving objects in terms of coarse regions. We provide uncertainty analyses of the data in relation to the two kinds of queries. The outcomes of the analyses enable us to design processing algorithms for both query types. An experimental evaluation with both real and synthetic data suggests that the framework and algorithms enable efficient and scalable query processing. {\textcopyright} 2016, Copyright is with the authors.},
annote = {cited By 8},
author = {Lu, H and Guo, C and Yang, B and Jensen, C S},
booktitle = {Advances in Database Technology - EDBT},
doi = {10.5441/002/edbt.2016.41},
keywords = {Database systems; Query processing; Uncertainty an,Experimental evaluation; Framework and algorithms,Radio frequency identification (RFID)},
pages = {449--460},
title = {{Finding frequently visited indoor POIs using symbolic indoor tracking data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045545227{\&}doi=10.5441{\%}2F002{\%}2Fedbt.2016.41{\&}partnerID=40{\&}md5=d367d0e4e57f6354f8e1ddb136599c1b},
volume = {2016-March},
year = {2016}
}
@article{Luimula:2010:RNM:1731477.1731504,
address = {London, UK, UK},
author = {Luimula, Mika and S{\"{a}}{\"{a}}skilahti, Kirsti and Partala, Timo and Piesk{\"{a}}, Sakari and Alasp{\"{a}}{\"{a}}, Juha},
doi = {10.1007/s00779-009-0238-3},
issn = {1617-4909},
journal = {Personal Ubiquitous Comput.},
keywords = {Human factors,Identification,Mobile robots,Multisensor systems,RFID,Remote control,Robot sensing systems,User interfaces},
number = {2},
pages = {125--136},
publisher = {Springer-Verlag},
title = {{Remote Navigation of a Mobile Robot in an RFID-augmented Environment}},
url = {http://dx.doi.org/10.1007/s00779-009-0238-3},
volume = {14},
year = {2010}
}
@inproceedings{Luo:2015:RLP:2923304.2923732,
address = {Washington, DC, USA},
author = {Luo, Jiaqing and Zhou, Shijie and Cheng, Hongrong and Liao, Yongjian and Bu, Kai},
booktitle = {Proceedings of the 2015 IEEE 12th International Conference on Mobile Ad Hoc and Sensor Systems (MASS)},
doi = {10.1109/MASS.2015.34},
isbn = {978-1-4673-9101-6},
pages = {445--446},
publisher = {IEEE Computer Society},
series = {MASS '15},
title = {{A Range-Free Localization of Passive RFID Tags Using Mobile Readers}},
url = {http://dx.doi.org/10.1109/MASS.2015.34},
year = {2015}
}
@inproceedings{Luo:2015:DIC:2820716.2820718,
address = {New York, NY, USA},
author = {Luo, Jiaqing and Zhou, Shijie and Cheng, Hongrong and Liao, Yongjian and Guo, Bin},
booktitle = {Proceedings of the 1st Workshop on Context Sensing and Activity Recognition},
doi = {10.1145/2820716.2820718},
isbn = {978-1-4503-3842-4},
keywords = {smartcards},
pages = {1--6},
publisher = {ACM},
series = {CSAR '15},
title = {{The Design and Implementation of A Cost-effective RFID Indoor Localization System}},
url = {http://doi.acm.org/10.1145/2820716.2820718},
year = {2015}
}
@article{Luo2018404,
abstract = {Indoor location systems can track objects using near-field electromagnetic ranging technology (NFER). However, the ranging error can be large because the phase difference between the electronic and magnetic fields cannot be measured directly. This study proposes a method that adopts an adaptive time-delay estimation algorithm based on a normalized maximum correntropy criterion (NMCC-ATDE) instead of exploiting the phase behavior of the electromagnetic signal for near-field ranging. In the NMCC-ATDE algorithm, the input signal is normalized to mitigate any sudden increase in the input signal. As our simulation results reveal, compared to the algorithms based on maximum correntropy criterion and normalized least mean square, the NMCC-ATDE algorithm can estimate the time delay in real time with a fast convergence rate and small steady-state error. {\textcopyright} 2017 Elsevier Ltd},
annote = {cited By 2},
author = {Luo, Y and Sun, G and Zhang, X and Wang, P and Liu, T and Xu, G},
doi = {10.1016/j.compeleceng.2017.11.016},
journal = {Computers and Electrical Engineering},
keywords = {Adaptive time delay estimation; Correntropy; Elec,Indoor positioning systems; Timing circuits,Time delay},
pages = {404--414},
title = {{Adaptive time-delay estimation based on normalized maximum correntropy criterion for near-field electromagnetic ranging}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035339219{\&}doi=10.1016{\%}2Fj.compeleceng.2017.11.016{\&}partnerID=40{\&}md5=3cbf105ef43077c77af61996cd576852},
volume = {67},
year = {2018}
}
@inproceedings{Lyons2013,
abstract = {We address the problem of fusing laser ranging data from multiple mobile robots that are surveying an area as part of a robot search and rescue or area surveillance mission. We are specifically interested in the case where members of the robot team are working in close proximity to each other. The advantage of this teamwork is that it greatly speeds up the surveying process; the area can be quickly covered even when the robots use a random motion exploration approach. However, the disadvantage of the close proximity is that it is possible, and even likely, that the laser ranging data from one robot include many depth readings caused by another robot. We refer to this as mutual interference. Using a team of two Pioneer 3-AT robots with tilted SICK LMS-200 laser sensors, we evaluate several techniques for fusing the laser ranging information so as to eliminate the mutual interference. There is an extensive literature on the mapping and localization aspect of this problem. Recent work on mapping has begun to address dynamic or transient objects. Our problem differs from the dynamic map problem in that we look at one kind of transient map feature, other robots, and we know that we wish to completely eliminate the feature. We present and evaluate three different approaches to the map fusion problem: Aa robot-centric approach, based on estimating team member locations; a map-centric approach, based on inspecting local regions of the map, and a combination of both approaches. We show results for these approaches for several experiments for a two robot team operating in a confined indoor environment . {\textcopyright} 2013 SPIE.},
annote = {cited By 3},
author = {Lyons, D M and Shrestha, K and Liu, T.-M.},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.2018320},
keywords = {Algorithms; Information fusion; Navigation; Surve,Cognitive robotics; Indoor environment; Mapping an,Robots},
title = {{Fusion of ranging data from robot teams operating in confined areas}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881182266{\&}doi=10.1117{\%}2F12.2018320{\&}partnerID=40{\&}md5=1410621079b159398a83dbebdbeda57f},
volume = {8756},
year = {2013}
}
@article{Ma:2011:PFO:2025276.2025281,
address = {Thousand Oaks, CA, USA},
author = {Ma, Jeremy and Chung, Timothy H and Burdick, Joel},
doi = {10.1177/0278364911410090},
issn = {0278-3649},
journal = {Int. J. Rob. Res.},
keywords = {Range sensing,recognition,sensing and perception computer vision,visual tracking},
number = {10},
pages = {1209--1228},
publisher = {Sage Publications, Inc.},
title = {{A Probabilistic Framework for Object Search with 6-DOF Pose Estimation}},
url = {http://dx.doi.org/10.1177/0278364911410090},
volume = {30},
year = {2011}
}
@article{Ma:2018:LSS:3272127.3275035,
address = {New York, NY, USA},
author = {Ma, Rui and Patil, Akshay Gadi and Fisher, Matthew and Li, Manyi and Pirk, S{\"{o}}ren and Hua, Binh-Son and Yeung, Sai-Kit and Tong, Xin and Guibas, Leonidas and Zhang, Hao},
doi = {10.1145/3272127.3275035},
issn = {0730-0301},
journal = {ACM Trans. Graph.},
keywords = {data-driven 3D scene generation and editing,natural language interface,relational model,semantic scene graph},
number = {6},
pages = {212:1----212:16},
publisher = {ACM},
title = {{Language-driven Synthesis of 3D Scenes from Scene Databases}},
url = {http://doi.acm.org/10.1145/3272127.3275035},
volume = {37},
year = {2018}
}
@inproceedings{8292442,
abstract = {Indoor Positioning Systems should be able to locate an object or person in a dynamic environment. In this research work, we present experimental results when performing indoor positioning in a dynamic environment when using channel frequency response as the indoor location's fingerprint. Dynamic environments introduce varying channel frequency responses for a given indoor location, which makes it difficult to locate desired indoor objects. According to our experiments, we find that indoor fingerprints become uncorrelated within a 15-min window. To bridge the gap between daily fingerprints, we propose three quick remedies in updating the Channel Frequency Response (CFR) database. These updates allow indoor localization even in the presence of dynamic environmental changes (e.g., people movement, interference of other wireless signals, etc.) and are able to 100{\%} localize indoor locations separated by at least five (5) centimeters. We highlight that in the experiments, there is only one anchor node used to estimate the desired indoor location.},
author = {Magsino, E R and Ho, I W and Situ, Z},
booktitle = {2017 IEEE 28th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications (PIMRC)},
doi = {10.1109/PIMRC.2017.8292442},
issn = {2166-9589},
keywords = {frequency response;Global Positioning System;indoo},
pages = {1--6},
title = {{The effects of dynamic environment on channel frequency response-based indoor positioning}},
year = {2017}
}
@inproceedings{Mahapatra2016211,
abstract = {Research in Wireless Sensor Networks (WSNs) has revealed the location information of the sensor nodes seems to be the critical and the most important aspect, for the applications like environment monitoring, object tracking, health care etc. Estimation accuracy is needed in these kind of applications. In general, Signal strength decreases with the increase in distance. Hence the correlation that exists between the RSSI (Received Signal Strength Indication) value and distance is the key parameter for the ranging and localization of WSNs. This paper presents a model based on RSSI, which provides the distance estimation between sensor nodes in WSNs. Analysis of the model and performance evaluation is done in a real system, deployed in indoor environment using IRIS mote. Results of these evaluation would help to achieve accuracy in location estimation of WSNs. {\textcopyright} 2016 IEEE.},
annote = {cited By 9},
author = {Mahapatra, R K and Shet, N S V},
booktitle = {2016 IEEE International Conference on Distributed Computing, VLSI, Electrical Circuits and Robotics, DISCOVER 2016 - Proceedings},
doi = {10.1109/DISCOVER.2016.7806221},
keywords = {Computer circuits; Distributed computer systems; E,Distance estimation; Environment monitoring; Expe,Wireless sensor networks},
pages = {211--215},
title = {{Experimental analysis of RSSI-based distance estimation for wireless sensor networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015962124{\&}doi=10.1109{\%}2FDISCOVER.2016.7806221{\&}partnerID=40{\&}md5=21f95e4c07415b6200cc18377d2ec95c},
year = {2016}
}
@inproceedings{6707557,
abstract = {3D scene modeling for indoor environments has stirred significant interest in the last few years. The obtained photo-realistic rendering of internal structures are being used in a huge variety of civilian and military applications such as training, simulation, patrimonies conservation, localization and mapping. Whereas, building such complicated maps poses significant challenges for both computer vision and robotic communities (low lighting and textureless structures, transparent and specular surfaces, registration and fusion problems, coverage of all details, real time constraint, etc.). Recently, the Microsoft Kinect sensors, originally developed as a gaming interface, have received a great deal of attention as being able to produce high quality depth maps in real time. However, we realized that these active sensors failed completely on transparent and specular surfaces due to many technical causes. As these objects should be involved into the 3D model, we have investigated methods to inspect them without any modification of the hardware. In particular, the Structure from Motion (SFM) passive technique can be efficiently integrated to the reconstruction process to improve the detection of these surfaces. In fact, we proposed to fill the holes in the depth map provided by the Infrared (IR) kinect sensor with new values passively retrieved by the SFM technique. This helps to acquire additional huge amount of depth information in a relative short time from two consecutive RGB frames. To conserve the real time aspect of our approach we propose to select key-RGB-images instead of using all the available frames. The experiments show a strong improvement in the indoor reconstruction as well as transparent object inspection.},
author = {Majdi, A and Bakkay, M C and Zagrouba, E},
booktitle = {2013 IEEE Second International Conference on Image Information Processing (ICIIP-2013)},
doi = {10.1109/ICIIP.2013.6707557},
keywords = {image reconstruction;image retrieval;image sensors},
pages = {67--72},
title = {{3D modeling of indoor environments using Kinect sensor}},
year = {2013}
}
@article{Majdik201118,
abstract = {AMPLE is the acronym of the project called Autonomous Mapping of Polluted Environments. This paper introduces the concept of the project and presents some preliminary results of the ongoing research with the final goal of building an autonomous mobile robot that is capable of performing various tasks in unknown environments. To achieve this scope the mapping problem is an ineluctable one. This paper presents a visual mapping system which detects the same Speeded Up Robust Features (SURF) on the stereo pair images in order to obtain three dimensional point clouds at every robot location. The algorithm tracks the displacement of the identical features viewed from different positions to get back the robots positions. Also a mapping algorithm based on the laser system is presented which can detect the dynamic objects that are present in the robots field. The results of an indoor office environment experiments are shown.},
annote = {cited By 1},
author = {Majdik, A L and Szoke, I and Popa, M and Tamas, L and Lazea, G},
journal = {Control Engineering and Applied Informatics},
number = {1},
pages = {18--24},
title = {{Mapping techniques for AMPLE, an autonomous security mobile robot}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957942178{\&}partnerID=40{\&}md5=b58a877e0b10a943377aa4e033d5350d},
volume = {13},
year = {2011}
}
@inproceedings{Majdik2010360,
abstract = {We presents some preliminary results of the ongoing research with the final goal of building an autonomous mobile robot. To achieve this scope the mapping problem is an ineluctable one. This paper presents a visual mapping system which detects the same Speeded Up Robust Features (SURF) on the stereo pair images in order to obtain three dimensional point clouds at every robot location. The algorithm tracks the displacement of the identical features viewed from different positions to get back the robots positions. The Iterative Closest Point (ICP) algorithm is used to register the obtained landmarks in the feature based map of the entire environment. Also a mapping algorithm based on the laser system is presented which can detect the dynamic objects that are present in the robots field. The results of an indoor office environment experiments are shown.},
annote = {cited By 2},
author = {Majdik, A L and Szoke, I and Tamas, L and Popa, M and Lazea, Gh.},
booktitle = {2010 IEEE International Conference on Automation, Quality and Testing, Robotics, AQTR 2010 - Proceedings},
doi = {10.1109/AQTR.2010.5520858},
keywords = {Algorithms; Conformal mapping; Mobile robots; Nav,Autonomous Mobile Robot; Dynamic objects; Feature-,Robotics},
pages = {360--365},
title = {{Laser and vision based map building techniques for mobile robot navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77958588580{\&}doi=10.1109{\%}2FAQTR.2010.5520858{\&}partnerID=40{\&}md5=6c7fdf7024aec308bc62f7a0d06e6860},
volume = {1},
year = {2010}
}
@article{Malashin2018251,
abstract = {Outlier elimination is a crucial stage in keypoints-based methods, especially in extreme conditions. In this chapter, a fast and robust Core Structural Verification Algorithm (CSVA) for a variety of applications and feature extraction methods is developed. The proposed algorithm pipeline involves many-to-one matches' exclusion, the improved Hough clustering of keypoint matches, and cluster verification procedure. The Hough clustering is improved through an accurate incorporation of translation parameters of similarity transform and partially ignoring the boundary impact using two displaced accumulators. The cluster verification procedure involves the use of modified RANSAC. It is also shown that the use of the nearest neighbour ratio may eliminate too many inliers, when two images are matched (especially in extreme conditions), and the preferable method is a simple many-to-one matches exclusion. The theory and experiment prove the propriety of the suggested parameters, algorithms, and modifications. The developed cluster analysis algorithms are robust and computationally efficient at the same time. These algorithms use some specific information (rigidity of objects in a scene), consume low volume memory and only 3ms in average on a standard Intel i7 processor for verification of 1,000 matches (i.e. magnitudes less than the time needed to generate those matches). The CSVA has been successfully applied to practical tasks with minor adaptation, such as the matching of 3D indoor scenes, retrieval of images of 3D scenes based on the concept of Bag of Words (BoWs), and matching of aerial and cosmic photographs with strong appearance changes caused by season, day-time, and viewpoint variation. Eliminating a huge number of outliers using geometrical constraints allowed to reach the reliability and accuracy in all solutions. {\textcopyright} 2018, Springer International Publishing AG.},
annote = {cited By 0},
author = {Malashin, R O},
doi = {10.1007/978-3-319-67516-9_9},
journal = {Intelligent Systems Reference Library},
pages = {251--286},
title = {{Core algorithm for structural verification of keypoint matches}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032580759{\&}doi=10.1007{\%}2F978-3-319-67516-9{\_}9{\&}partnerID=40{\&}md5=563d3d42ac22ef384e99a17797f255fd},
volume = {135},
year = {2018}
}
@inproceedings{799143,
abstract = {New-generation computational software is the emerging and enabling technology that is revolutionizing the delivery of education and the analysis of results to yield information. This allows for the dynamic and interactive analytical processing of both archival and current experimental data. The design and usability of a database-driven computational system that demonstrates the qualitative analysis of the dynamic balance of thermoregulatory processes is discussed. Incorporated within the software are educational modules that describe the effect of exercise on body temperature and heart rate, the effects of the environment on body temperature, methods of prevention of heat illness and first-aid procedures to be utilized in the event of a medical emergency. These modules are linked to clinical and experimental research databases. A user-friendly interface allows both non-technical users and scientists to retrieve information of interest easily. Simple examples are presented which demonstrate the utility of the interface. These include normal (indoor) body temperature, body temperature while hiking in a mountainous region and partial results from a study that characterized the skin temperature and heart rate response during bicycle ergometry. Temperature was measured by thermistors from 13 body segments. The data was collected and compiled into a relational database. Several algorithms, some of which utilize artificial intelligence objects incorporated within the database, analyze the data and yield results based on user preferences.},
author = {Malkinson, T J},
booktitle = {IPCC 99. Communication Jazz: Improvising the New International Communication Culture. Proceedings 1999 IEEE International Professional Communication Conference (Cat. No.99CH37023)},
doi = {10.1109/IPCC.1999.799143},
keywords = {biothermics;biomedical measurement;relational data},
pages = {325--334},
title = {{A database-driven interactive computational system for the qualitative analysis of body temperature}},
year = {1999}
}
@article{Maneerat2016,
abstract = {One of the challenging problems for indoor wireless multifloor positioning systems is the presence of reference node (RN) failures, which cause the values of received signal strength (RSS) to be missed during the online positioning phase of the location fingerprinting technique. This leads to performance degradation in terms of floor accuracy, which in turn affects other localization procedures. This paper presents a robust floor determination algorithm called Robust Mean of Sum-RSS (RMoS), which can accurately determine the floor on which mobile objects are located and can work under either the fault-free scenario or the RN-failure scenarios. The proposed fault tolerance floor algorithm is based on the mean of the summation of the strongest RSSs obtained from the IEEE 802.15.4 Wireless Sensor Networks (WSNs) during the online phase. The performance of the proposed algorithm is compared with those of different floor determination algorithms in literature. The experimental results show that the proposed robust floor determination algorithm outperformed the other floor algorithms and can achieve the highest percentage of floor determination accuracy in all scenarios tested. Specifically, the proposed algorithm can achieve greater than 95{\%} correct floor determination under the scenario in which 40{\%} of RNs failed. {\textcopyright} Copyright 2016 Kriangkrai Maneerat et al.},
annote = {cited By 4},
author = {Maneerat, K and Kaemarungsi, K and Prommak, C},
doi = {10.1155/2016/4961565},
journal = {Mobile Information Systems},
keywords = {Determination algorithm; Localization procedure;,Fault tolerance; Indoor positioning systems; Onlin,Floors},
title = {{Robust Floor Determination Algorithm for Indoor Wireless Localization Systems under Reference Node Failure}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994236263{\&}doi=10.1155{\%}2F2016{\%}2F4961565{\&}partnerID=40{\&}md5=676528807241b5490399275880842405},
volume = {2016},
year = {2016}
}
@article{Maneerat2019,
abstract = {Most existing wireless indoor positioning systems have only success performance requirements in normal operating situations whereby all wireless equipment works properly. There remains a lack of system reliability that can support emergency situations when there are some reference node failures, such as in earthquake and fire scenarios. Additionally, most systems do not incorporate environmental information such as temperature and relative humidity level into the process of determining the location of objects inside the building. To address these gaps, we propose a novel integrated framework for wireless indoor positioning systems based on a location fingerprinting technique which is called the Robust and low Complexity indoor positioning systems framework (RoC framework). Our proposed integrated framework consists of two essential indoor positioning processes: The system design process and the localization process. The RoC framework aims to achieve robustness in the system design structure and reliability of the target location during the online estimation phase either under a normal situation or when some reference nodes (RNs) have failed. The availability of low-cost temperature and relative humidity sensors can provide additional information for the location fingerprinting technique and thereby reduce location estimation complexity by including this additional information. Experimental results and comparative performance evaluation revealed that the RoC framework can achieve robustness in terms of the system design structure, whereby it was able to provide the highest positioning performance in either fault-free or RN-failure scenarios. Moreover, in the online estimation phase, the proposed framework can provide the highest reliability of the target location under the RN-failure scenarios and also yields the lowest computational complexity in online searching compared to other techniques. Specifically, when compared to the traditional weighted k-nearest neighbor techniques (WKNN) under the 30{\%} RN-failure scenario at Building B, the proposed RoC framework shows 74.1{\%} better accuracy performance and yields 55.1{\%} lower computational time than the WKNN. {\textcopyright} 2019 Kriangkrai Maneerat and Kamol Kaemarungsi.},
annote = {cited By 0},
author = {Maneerat, K and Kaemarungsi, K and Yim, J},
doi = {10.1155/2019/5089626},
journal = {Mobile Information Systems},
keywords = {Comparative performance; Environmental informatio,Indoor positioning systems,Location; Motion compensation; Nearest neighbor se},
title = {{RoC: Robust and low-complexity wireless indoor positioning systems for multifloor buildings using location fingerprinting techniques}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062323855{\&}doi=10.1155{\%}2F2019{\%}2F5089626{\&}partnerID=40{\&}md5=7a681e6c49a824d643e5d9f881aa125c},
volume = {2019},
year = {2019}
}
@inproceedings{Maneerat:2016:FDA:3015166.3015200,
address = {New York, NY, USA},
author = {Maneerat, Kriangkrai and Prommak, Chutima},
booktitle = {Proceedings of the 8th International Conference on Signal Processing Systems},
doi = {10.1145/3015166.3015200},
isbn = {978-1-4503-4790-7},
keywords = {fault tolerance floor algorithm,floor determination,multi-floor building,robust systems},
pages = {203--207},
publisher = {ACM},
series = {ICSPS 2016},
title = {{Floor Determination Algorithm with Node Failure Consideration for Indoor Positioning Systems}},
url = {http://doi.acm.org/10.1145/3015166.3015200},
year = {2016}
}
@inproceedings{Mantoro201198,
abstract = {Location-aware personal computing application can work accurately by estimating user location using IEEE 802.11 (Wi-Fi) signals in indoor environment. Nowadays, Wi-Fi is more and more widely available and installed on most mobile devices. Unfortunately, the Wi-Fi's signal fluctuates greatly up to 33{\%}, some of the causes are reflection, refraction, temperature, humidity, the dynamic environment. These make user location not in good accuracy to be estimated. In this paper we propose the use of Particle Filter to improve user location estimation which involves the modeling of non-linear and non-Gaussian systems. To make the estimation accurate, the real time data of multi-observer Wi-Fi signals is used. The loss of diversity and parameter chosen in order to reduce the ambiguity is observed in tracking user location. We improve the Particle Filter Algorithm by giving target/reference points and by reducing the computational complexity. This paper shows that the estimation of the location from real-time data is close to the real tracking object. {\textcopyright} 2011 IEEE.},
annote = {cited By 0},
author = {Mantoro, T and Ayu, M A and Usino, W and Raman, S H and {Md. Latiff}, N H},
booktitle = {IEEE Region 10 Annual International Conference, Proceedings/TENCON},
doi = {10.1109/TENCON.2011.6129071},
keywords = {Computing applications; Dynamic environments; IEEE,Estimation,Global system for mobile communications; Mobile d},
pages = {98--102},
title = {{Multi-observers of particle filter approach for estimating indoor mobile user location}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856846027{\&}doi=10.1109{\%}2FTENCON.2011.6129071{\&}partnerID=40{\&}md5=d2284b3bccb603c0a64f882edd2dd7df},
year = {2011}
}
@inproceedings{Manzoor2011,
abstract = {Amongst various application usages of Radio Frequency Identification (RFID) Technology, Indoor localization or positioning has gained much importance and value over the past few years. Different algorithms and hardware have been developed with active research still in place. Research towards localization of objects and personnel specifically using passive RFID technology has immensely reduced the overall solution cost, while effectively increasing positioning accuracy. In this paper, we present a passive RFID-based indoor localization algorithm for the Buildings and Constructions Industry. In complex building designs, such as multi-storey car parks or high-rise hospitals, it is often required to locate a particular car or medical personnel at least at a room level accuracy in case of emergencies. In the methodology presented, passive RFID tags with unknown locations are tracked and identified using a number of similar tags with known positions. This approach offers the advantage to have less number of expensive RFID readers to locate unknown tags. Instead, low cost passive RFID tags collaborate together to find the unknown tags' locations. The distance and positions of the known tags along with mathematical techniques and computations form the basis of our algorithm to compute the final position of unknown tags. The experimental results are acquired by considering a simulated implementation in a 10m10m room using two UHF RFID readers. A number of simulation results show an average linear error in positioning of 1.32m from reader 1 and that of 3.14m from reader 2. {\textcopyright} 2011 IEEE.},
annote = {cited By 5},
author = {Manzoor, F and Menzel, K},
booktitle = {2011 30th URSI General Assembly and Scientific Symposium, URSIGASS 2011},
doi = {10.1109/URSIGASS.2011.6050581},
keywords = {Algorithms; Parking; Parks; Radio navigation,Complex buildings; Indoor localization; Localisati,Radio frequency identification (RFID)},
title = {{Indoor localisation for complex building designs using passive RFID technology}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-81255144612{\&}doi=10.1109{\%}2FURSIGASS.2011.6050581{\&}partnerID=40{\&}md5=f130b574d077d713850fba439f2cdd13},
year = {2011}
}
@inproceedings{Mariette:2006:NSL:2127271.2127288,
address = {Berlin, Heidelberg},
author = {Mariette, Nick},
booktitle = {Proceedings of the 16th International Conference on Advances in Artificial Reality and Tele-Existence},
doi = {10.1007/11941354_15},
isbn = {3-540-49776-5, 978-3-540-49776-9},
pages = {132--142},
publisher = {Springer-Verlag},
series = {ICAT'06},
title = {{A Novel Sound Localization Experiment for Mobile Audio Augmented Reality Applications}},
url = {http://dx.doi.org/10.1007/11941354{\_}15},
year = {2006}
}
@article{Marin-Restrepo20156206,
abstract = {Architecture and Acoustic are intimately related, been sound an extremely important part of the human natural environment. Sounds give specific qualities to spaces establishing whether or not a hearing condition is pleasant or annoying to those who inhabit them, and may or may not favor oral communication, a fundamental activity in human interaction. A pleasant sound may improve human wellbeing, while a noise can be a great obstacle to a person's comfort, creating discomfort, concentration issues and health problems. The role of architecture is clear, since the form and materiality of a space, change its acoustic conditions. The use of space and the activity to be developed, as such, determine the acoustic requirements. Within these, clarity of message delivered is critical in an indoor environment and it's evaluated through a parameter called intelligibility. The overall object of this paper is to determine whether or not the intelligibility of a space is modify by the way it is occupied. For the case study, an environment with high demands on intelligibility was selected: a preschool classroom with children age 3 to 5 years old, where acoustic requirements are determined by two factors. The first is the very condition of an educational environment, whose primary function is the learning process, for which communication is essential and regarding the field of acoustics concerns, the clarity of the message transmitted orally. The second factor is related to a group of users who have physical characteristics and spatial requirements that must be met from an architectural design point of view. An additional aspect to consider is that the use of space differs from a traditional classroom dynamics, since children that age, appropriate and modify their spatial occupation in several ways. The evaluated space was a square shaped classroom made of a brick based building system, which is a proper representation of the building systems used in traditional preschool educational spaces in the city of Medell{\'{i}}n, where the study was conducted. The methodology that was used in this study, focused on evaluating the intelligibility of the space, by both, theoretical calculations and field tests, with measurements and analysis processes that were adjusted to the physical conditions of children, such as the equipment heights and the representation of the phenomenon, besides considering three groupings identified as the most common in kindergartens classrooms: roundtable, backs against the wall and distributed in small groups. The results indicated that the quality of intelligibility in the preschool classroom, in fact, varies according to the type of use for each way of grouping. It was also concluded, that the evaluated types of grouping in the preschool classroom, create different areas with varying intelligibility, allowing to identify were it is necessary to make reinforcements on surface finishes within the classrooms, and to identify places that are optimal location for teachers. {\textcopyright} 2015 The Authors},
annote = {cited By 0},
author = {Marin-Restrepo, L and Morales-Maya, C and Guerrero-Teran, G and Garc{\'{i}}a-Cardona, A and Waldron-Toro, J},
doi = {10.1016/j.promfg.2015.07.939},
journal = {Procedia Manufacturing},
pages = {6206--6213},
title = {{Intellibility Assessment in a Square Shaped Preschool Classroom According to the Grouping of Children of 3 to 5 Year of Age}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009944233{\&}doi=10.1016{\%}2Fj.promfg.2015.07.939{\&}partnerID=40{\&}md5=f5dc7bf73c93d6bc2528af18f0542798},
volume = {3},
year = {2015}
}
@inproceedings{5759270,
abstract = {Indoor RTLS (Real Time Location Systems) are the foundations of promising context-aware and ambient intelligent services. In this work the feasibility of applying Active RFID and neural networks to develop a RTLS service is discussed. In most of the Active RFID systems available on the market, the Readers can measure the Received Signal Strengh (RSS) from a beacon transmitted from a Active tag and send the data gathered to a location server. The RSS measurements can be processed to infer the position of a tag by means of a positioning algorithm. In this research work we discuss and show how to use RSS measurements from the Readers to calculate the tag position by means of a neural network, based on a Multilayer Perceptron which is trained and tested with a radiomap and learns to compute the tags position. By means of simulation, we study the proper MLP architecture and the mean error positioning estimation and precision that is achieved depending on the number of Readers. With 8 Readers deployed in an indoor area of 576 m(exp 2) we get an error less than 1.75 meters in the 75{\%} of the target area.},
author = {{Martinez Sala}, A S and {Guzman Quiros}, R and {Egea Lopez}, E},
booktitle = {European Workshop on Smart Objects: Systems, Technologies and Applications},
keywords = {Computational modeling;Training;Pattern matching;R},
pages = {1--9},
title = {{Using neural networks and Active RFID for indoor location services}},
year = {2010}
}
@inproceedings{Mast:2013:PFO:2688292.2688305,
address = {New York, NY, USA},
author = {Mast, Vivien and Wolter, Diedrich},
booktitle = {Proceedings of the 11th International Conference on Spatial Information Theory - Volume 8116},
doi = {10.1007/978-3-319-01790-7_11},
isbn = {978-3-319-01789-1},
pages = {185--204},
publisher = {Springer-Verlag New York, Inc.},
series = {COSIT 2013},
title = {{A Probabilistic Framework for Object Descriptions in Indoor Route Instructions}},
url = {http://dx.doi.org/10.1007/978-3-319-01790-7{\_}11},
year = {2013}
}
@article{Matas1993197,
abstract = {A novel approach to junction detection using an explicit line finder model and contextual rules is presented. Contextual rules expressing properties of 3D-images (surface orientation discontinuities) limit the number of line intersections interpreted as junctions. A probabilistic relaxation labelling scheme is used to combine the a priori world knowledge represented by contextual rules and the information contained in observed lines. Junctions corresponding to a vertex (V-junctions) and an occlusion (T-junction) of 3D objects are detected and stored in a junciton graph. The information in the junction graph is used to extract higher level features. Results of the most promising method, the polyhedral object face recovery, are briefly discussed. The performance of the junction detection process is demonstrated on images from indoor, outdoor, and industrial environments. {\textcopyright} 1993.},
annote = {cited By 9},
author = {Matas, J and Kittler, J},
doi = {10.1016/0262-8856(93)90036-G},
journal = {Image and Vision Computing},
keywords = {Computer graphics; Computer simulation; Error dete,Computer vision,Contextual rules; Explicit line finder model; Jun},
number = {4},
pages = {197--202},
title = {{Junction detection using probabilistic relaxation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027600040{\&}doi=10.1016{\%}2F0262-8856{\%}2893{\%}2990036-G{\&}partnerID=40{\&}md5=8c156502f45576c8392a432d97092abf},
volume = {11},
year = {1993}
}
@book{Meawad2013245,
abstract = {Handheld Augmented reality (AR) is the ability of smartphones to overlay digital information on a real view (video stream) of the world using built-in sensors such as, GPS, Compass and Accelerometer. With the use of geo-tagging and location based services, information is automatically filtered whenever users point their devices to places or objects of interest around them allowing them to browse the world. Current world browsers compromise the augmented reality experience due to poor support of contextual content, flow and interaction. This chapter discusses the principles underpinning the design of a solution for an indoor-outdoor world browser platform. The chapter presents the results of qualitative evaluations that were conducted on existing commercial world browsers and the design ideas of the proposed solutions. The main elements of a successful world browsing experience are highlighted as a guide for augmented reality designers. {\textcopyright} 2014 by IGI Global. All rights reserved.},
annote = {cited By 1},
author = {Meawad, F and Ahmed, G},
booktitle = {Research and Design Innovations for Mobile User Experience},
doi = {10.4018/978-1-4666-4446-5.ch013},
keywords = {Augmented reality applications; Built-in sensors;,Augmented reality; Location based services; Video,Information filtering},
pages = {245--262},
title = {{Designing browser-style augmented reality applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944930333{\&}doi=10.4018{\%}2F978-1-4666-4446-5.ch013{\&}partnerID=40{\&}md5=ae21aa67979bfc73365c984abdb1ac64},
year = {2013}
}
@article{Medina2013341,
abstract = {In this paper, we present a semantic map model in order to represent multimedia environments using mobile devices. Our approach makes it possible defining indoor maps and locating the objects of interest. This model is based on an Ontology, which defines both semantic qualities and graphic forms of the objects that exist in the multimedia environment (rooms, doors, cameras,.). The semantic of the maps enables to query and to reason the map content automatically. For example, in this work, we solve the indoor routing adding a heuristic that exploits the topology of the interior spaces, which has been evaluated by obtaining a significant improvement in indoor spaces. In addition, the proposed Ontology includes the location and the remote services of the multimedia resources, such as ambient cameras and microphones. Thus, users can access in real time to multimedia resources through the maps displayed on mobile devices. The mobile applications have been developed, tested and measured both in light devices and hand-held computers. {\textcopyright} 2011 Springer Science+Business Media, LLC.},
annote = {cited By 1},
author = {Medina, J and {Ruiz Lozano}, M D and Delgado, M and Vila, A},
doi = {10.1007/s11042-011-0924-9},
journal = {Multimedia Tools and Applications},
keywords = {Cameras; Hand held computers; Mobile devices; Mul,Indoor space; Multimedia resources; Real-Time; Rou,Multimedia systems},
number = {2},
pages = {341--362},
title = {{Multimedia access to mobile environments using indoor semantic maps: Applications for light devices and hand-held computers}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883143292{\&}doi=10.1007{\%}2Fs11042-011-0924-9{\&}partnerID=40{\&}md5=e2333a656971e894a782916806db9c90},
volume = {67},
year = {2013}
}
@article{Medina:2013:MAM:2556720.2556726,
address = {Hingham, MA, USA},
author = {Medina, Javier and {Ruiz Lozano}, Maria Dolores and Delgado, Miguel and Vila, Amparo},
doi = {10.1007/s11042-011-0924-9},
issn = {1380-7501},
journal = {Multimedia Tools Appl.},
keywords = {Indoor space,Mobile devices,Multimedia resources,Real-Time,Routing,Semantic maps},
number = {2},
pages = {341--362},
publisher = {Kluwer Academic Publishers},
title = {{Multimedia Access to Mobile Environments Using Indoor Semantic Maps}},
url = {http://dx.doi.org/10.1007/s11042-011-0924-9},
volume = {67},
year = {2013}
}
@inproceedings{Meger20114885,
abstract = {This paper presents a method for multi-view 3D robotic object recognition targeted for cluttered indoor scenes. We explicitly model occlusions that cause failures in visual detectors by learning a generative appearance-occlusion model from a training set containing annotated 3D objects, images and point clouds. A Bayesian 3D object likelihood incorporates visual information from many views as well as geometric priors for object size and position. An iterative, sampling-based inference technique determines object locations based on the model. We also contribute a novel robot-collected data set with images and point clouds from multiple views of 60 scenes, with over 600 manually annotated 3D objects accounting for over ten thousand bounding boxes. This data has been released to the community. Our results show that our system is able to robustly recognize objects in realistic scenes, significantly improving recognition performance in clutter. {\textcopyright} 2011 IEEE.},
annote = {cited By 3},
author = {Meger, D and Little, J J},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2011.6048676},
keywords = {3D object; Bounding box; Data sets; Inference tech,Clouds; Clutter (information theory); Content bas,Three dimensional},
pages = {4885--4892},
title = {{Mobile 3D object detection in clutter}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84455192600{\&}doi=10.1109{\%}2FIROS.2011.6048676{\&}partnerID=40{\&}md5=1ef82b272a1f0b6feaafc7b04c9a4965},
year = {2011}
}
@article{Meghdadi20132119,
abstract = {We propose a novel video visual analytics system for interactive exploration of surveillance video data. Our approach consists of providing analysts with various views of information related to moving objects in a video. To do this we first extract each object's movement path. We visualize each movement by (a) creating a single action shot image (a still image that coalesces multiple frames), (b) plotting its trajectory in a space-time cube and (c) displaying an overall timeline view of all the movements. The action shots provide a still view of the moving object while the path view presents movement properties such as speed and location. We also provide tools for spatial and temporal filtering based on regions of interest. This allows analysts to filter out large amounts of movement activities while the action shot representation summarizes the content of each movement. We incorporated this multi-part visual representation of moving objects in sViSIT, a tool to facilitate browsing through the video content by interactive querying and retrieval of data. Based on our interaction with security personnel who routinely interact with surveillance video data, we identified some of the most common tasks performed. This resulted in designing a user study to measure time-to-completion of the various tasks. These generally required searching for specific events of interest (targets) in videos. Fourteen different tasks were designed and a total of 120 min of surveillance video were recorded (indoor and outdoor locations recording movements of people and vehicles). The time-to-completion of these tasks were compared against a manual fast forward video browsing guided with movement detection. We demonstrate how our system can facilitate lengthy video exploration and significantly reduce browsing time to find events of interest. Reports from expert users identify positive aspects of our approach which we summarize in our recommendations for future video visual analytics systems. {\textcopyright} 2013 IEEE.},
annote = {cited By 22},
author = {Meghdadi, A H and Irani, P},
doi = {10.1109/TVCG.2013.168},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Algorithms; Artificial Intelligence; Computer Gra,Automated; Photography; Reproducibility of Result,Computer-Assisted; Pattern Recognition,Monitoring; Tools; Video recording; Visualization,Security systems,Surveillance video; Video browsing; Video summariz,algorithm; artificial intelligence; automated pat},
number = {12},
pages = {2119--2128},
title = {{Interactive exploration of surveillance video through action shot summarization and trajectory visualization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886643615{\&}doi=10.1109{\%}2FTVCG.2013.168{\&}partnerID=40{\&}md5=281a0d5fc212094a4901f9dfa4fff72b},
volume = {19},
year = {2013}
}
@article{Mehta:2016:SRA:2926204.2926211,
address = {Chichester, UK},
author = {Mehta, Mahima and Rane, Nirbhay and Karandikar, Abhay and Imran, Muhammad Ali and Evans, Barry G},
doi = {10.1002/wcm.2518},
issn = {1530-8669},
journal = {Wirel. Commun. Mob. Comput.},
keywords = {OFDMA,co-layer interference,femtocell,macrocell,resource allocation},
number = {3},
pages = {330--342},
publisher = {John Wiley and Sons Ltd.},
title = {{A Self-organized Resource Allocation Scheme for Heterogeneous Macro-femto Networks}},
url = {http://dx.doi.org/10.1002/wcm.2518},
volume = {16},
year = {2016}
}
@article{Melo2016195,
abstract = {Nowadays, it is clear that location systems are increasingly present in people's lives. In general people often spend 8090{\%} of their time in indoor environments, which include shopping malls, libraries, airports, universities, schools, offices, factories, hospitals, among others. In these environments, GPS does not work properly, causing inaccurate positioning. Currently, when performing the location of people or objects in indoor environments, no single technology can reproduce the same results achieved by the GPS for outdoor environments. One of the main reasons for this is the high complexity of indoor environments where, unlike outdoor spaces, there is a series of obstacles such as walls, equipment and even people. Thus, it is necessary that the solutions proposed to solve the problem of location in indoor environments take into account the complexity of these environments. In this paper, we propose an adaptable platform for indoor location, which allows the use and combination of different technologies, techniques and methods in this context. {\textcopyright} Springer International Publishing Switzerland 2016.},
annote = {cited By 0},
author = {Melo, M and Aquino, G and Morais, I},
doi = {10.1007/978-3-319-42108-7_15},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Artificial intelligence; Computer science; Compute,High complexity; Indoor environment; Indoor locat,Location},
pages = {195--206},
title = {{Indoor location: An adaptable platform}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978832753{\&}doi=10.1007{\%}2F978-3-319-42108-7{\_}15{\&}partnerID=40{\&}md5=011f6d6c2d1fb3a11a084a8f8676bc7c},
volume = {9787},
year = {2016}
}
@inproceedings{Merz2008,
abstract = {In this paper, an experimental platform for indoor location and tracking using ultra wideband (UWB) signals is presented. The platform has been developed entirely using standard electronic components that are commercially available. As principal goal, the experimental platform should allow a rapid performance evaluation for various system architectures and signal processing algorithms. Hence, the platform has to be as versatile as possible while remaining optimized for accurate location estimation. To meet these targets, the UWB receivers are implemented using a fast analog to digital converter (ADC) and a field programmable gate array (FPGA). The ADC acquires directly the received radio frequency signal. The FPGA can be programmed to perform the required signal processing in real time. First results from the measurement of the time of arrivals are available and are presented. During the development of the experimental platform, the following application scenario has been assumed: An object or a person equipped with an active tag should be located or tracked in an indoor environment. It is hence required, that the system provides accurate position information even for a multipath propagation channel. On the other hand, the communication range is limited to some tens of meters and the maximum velocity of the tag is low. For a practical system, the tag should have low power consumption and small size. As the tags do not estimate the positions themselves in this scenario, they do currently not contain a radio receiver. In consequence, they are not using any channel access method, which limits either the number of active tags in one cell or the individual update rate. However, due to the short duration of one transmitted frame (150 $\mu$s), the probability that a collision occurs is small enough for many applications. As an example, 100 active tags in one cell and a position update each minute, the probability of collision is only 2.5 {\textperiodcentered} 10-4. One frame to be transmitted consists of 16 pulses with an average delay between them of 10 $\mu$s. The delays between consecutive pulses can be altered by some nanoseconds to generate a pulse position modulated signal which is used to unambiguously identify the tag. The generated signal covers a -10 dB bandwidth of about 750 MHz. The frame is emitted using a wideband antenna and propagated through the indoor propagation channel. Four synchronized UWB receivers at known positions capture the received signal. After amplification, the ADC08D1500 from National Semiconductor is used to sample the signal with up to 3 GS/s and convert it to a stream of 8 bit digital data. The digital data is processed in real time using an EP2C70 FPGA from Altera. For the indoor location demonstrator, the FPGA stores a timestamp for the time of arrival of the frame and identifies the tag. The timestamps from the four UWB receivers are then collected on a standard PC. Based on the timestamps, the time difference of arrival (TDOA) of the frame between two receivers is calculated. In a first experience, the emitter remained at a given position and PC stored the TDOAs during 15 min while three people were working and moving around in the laboratory. The acquired data show a nearly Gaussian probability density function for the TDOA estimation with a standard deviation of 500 ps. This corresponds to a 95{\%} probability that the resulting distance estimation is not more than 30 cm off compared to the average of the estimated distances. The measurements for the accuracy of the TDOA estimation and the extension to a two-dimensional location system are currently ongoing. The final results will be provided in the final paper.},
annote = {cited By 10},
author = {Merz, R and Chastellain, F and Botteron, C and Blatter, A and Farine, P.-A.},
booktitle = {ENC-GNSS 2008 - European Navigation Conference},
keywords = {Analog to digital conversion; Bandwidth; Communica,Analog to digital converters; Gaussian probabilit,Signal receivers},
title = {{An experimental platform for an indoor location and tracking system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924191433{\&}partnerID=40{\&}md5=9db3b0f381e82fdf0d06d6765b476d6e},
year = {2008}
}
@inproceedings{Mighali:2015:IIS:2740908.2744711,
address = {New York, NY, USA},
author = {Mighali, Vincenzo and {Del Fiore}, Giuseppe and Patrono, Luigi and Mainetti, Luca and Alletto, Stefano and Serra, Giuseppe and Cucchiara, Rita},
booktitle = {Proceedings of the 24th International Conference on World Wide Web},
doi = {10.1145/2740908.2744711},
isbn = {978-1-4503-3473-0},
keywords = {android,artwork recognition,cloud,embedded systems,iot architecture,localization,smart museum},
pages = {547--550},
publisher = {ACM},
series = {WWW '15 Companion},
title = {{Innovative IoT-aware Services for a Smart Museum}},
url = {http://doi.acm.org/10.1145/2740908.2744711},
year = {2015}
}
@inproceedings{Miliner2009,
abstract = {This paper describes a system for three dimensional indoor and outdoor localization of animals using a sequential Monte-Carlo-Method. A Kaiman based particle filter is used to improve the measurement quality by incorporating the dynamics of the target object. The positioning method was integrated into a system for animal behavior analysis which provides extensive features to identify habitual residence and movement patterns of the animals. {\textcopyright} 2009 IEEE.},
annote = {cited By 2},
author = {Miliner, H and Ebelt, R and Hoffmannt, G and Vossiek, M},
booktitle = {IEEE MTT-S International Microwave Workshop Series on Wireless Sensing, Local Positioning and RFID, Proceedings, IMWS 2009 - Croatia},
doi = {10.1109/IMWS2.2009.5307890},
keywords = {3D localization; Animal behavior; Behavior analysi,Animals; Microwaves; Three dimensional,Monte Carlo methods},
title = {{Wireless 3D localization of animals for trait and behavior analysis in indoor and outdoor areas}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-73649137884{\&}doi=10.1109{\%}2FIMWS2.2009.5307890{\&}partnerID=40{\&}md5=2144c396668a1014e374a7a61919b98b},
year = {2009}
}
@article{Minami2004347,
abstract = {Obtaining indoor location information is one of the essential technologies for enriching various ubiquitous computing applications. Although many indoor location systems have been proposed until now, wide-area deployments in everyday environments are still extremely rare. To deploy indoor locating systems beyond laboratory use, we believe that the initial configuration cost of the system should be reduced. This paper describes a fully distributed ultrasonic positioning system which enables us to locate various indoor objects with lower initial configuration cost. {\textcopyright} Springer-Verlag 2004.},
annote = {cited By 73},
author = {Minami, M and Fukuju, Y and Hirasawa, K and Yokoyama, S and Mizumachi, M and Morikawa, H and Aoyama, T},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {347--365},
title = {{Dolphin: A practical approach for implementing a fully distributed indoor ultrasonic positioning system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-35048865764{\&}partnerID=40{\&}md5=8498480a75d59d7598259c87e65b7a6a},
volume = {3205},
year = {2004}
}
@article{Mindru:2004:MIR:1005418.1005420,
address = {New York, NY, USA},
author = {Mindru, Florica and Tuytelaars, Tinne and {Van Gool}, Luc and Moons, Theo},
doi = {10.1016/j.cviu.2003.10.011},
issn = {1077-3142},
journal = {Comput. Vis. Image Underst.},
keywords = {color,illumination changes,moment invariants,recognition,viewpoint changes},
number = {1-3},
pages = {3--27},
publisher = {Elsevier Science Inc.},
title = {{Moment Invariants for Recognition Under Changing Viewpoint and Illumination}},
url = {http://dx.doi.org/10.1016/j.cviu.2003.10.011},
volume = {94},
year = {2004}
}
@article{7339420,
abstract = {In this paper, we present a comprehensive channel modeling and characterization study for visible light communications. Our study is based on ray tracing, which allows for an accurate description of the interaction of rays emitted from the lighting source within a specified confined space. Contrary to existing works, which are mainly limited to ideal Lambertian sources and purely diffuse reflections, our approach is capable of obtaining channel impulse responses (CIRs) for any nonideal sources, as well as specular and mixed specular-diffuse reflections. Furthermore, we can precisely reflect the presence of objects (e.g., furniture) and wavelength-dependent reflection characteristics of surface materials (e.g., ceilings, floor, walls, and furniture) in a channel study. As case studies, we consider a number of indoor environments with various dimensions and different surface materials, i.e., plaster, gloss paint, wood, aluminum metal, and glass. We further consider various scenarios with different transmitter specifications (i.e., single versus multiple transmitters and array type) and receiver specifications (i.e., location and rotation). For each environment, we obtain CIRs and present a channel characterization study where channel parameters, such as channel DC gain, root mean square (RMS) delay spread, coherence bandwidth, and mean excess delay, are obtained. We also make one-to-one comparisons between infrared and visible-light CIRs for the same environments to emphasize the differences between two optical bands.},
author = {Miramirkhani, F and Uysal, M},
doi = {10.1109/JPHOT.2015.2504238},
issn = {1943-0655},
journal = {IEEE Photonics Journal},
keywords = {free-space optical communication;indoor environmen},
number = {6},
pages = {1--16},
title = {{Channel Modeling and Characterization for Visible Light Communications}},
volume = {7},
year = {2015}
}
@inproceedings{Miramirkhani2015,
abstract = {In this paper, we investigate channel modeling for visible light communications (VLC) using non-sequential ray tracing simulation tools. We create three dimensional realistic simulation environments to depict indoor scenarios specifying the geometry of the environment, the objects inside, the reflection characteristics of the surface materials as well as the characteristics of the transmitter and receivers, i.e., LED sources and photodioes. Through ray tracing simulations, we compute the received optical power and the delay of direct/indirect rays which are then used to obtain the channel impulse response (CIR). Following this methodology, we present CIRs for a number of indoor environments including empty/furnished rectangular rooms with different sizes and wall/object materials (e.g., plaster, gloss paint, wood, aluminum metal, glass) assuming deployment of both single and multiple LED transmitters. We further quantify multipath channel parameters such as delay spread and channel DC gain for each configuration and provide insights into the effects of indoor environment parameters (e.g., size, wall/object materials, etc.), transmitter/receiver specifications (e.g., single vs. multiple transmitters, location, rotation etc.) on the channel.},
annote = {cited By 16},
author = {Miramirkhani, F and Uysal, M and Panayirci, E},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.2077565},
keywords = {Broadband networks; Communication channels (inform,Channel impulse response; Channel model; Indoor e,Ray tracing},
title = {{Novel channel models for visible light communications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923872673{\&}doi=10.1117{\%}2F12.2077565{\&}partnerID=40{\&}md5=c612327b104adf7fdeda76f7397cf527},
volume = {9387},
year = {2015}
}
@inproceedings{Misra:2009:AON:1644038.1644102,
address = {New York, NY, USA},
author = {Misra, Prasant and Jha, Sanjay and Ostry, Diet},
booktitle = {Proceedings of the 7th ACM Conference on Embedded Networked Sensor Systems},
doi = {10.1145/1644038.1644102},
isbn = {978-1-60558-519-2},
keywords = {chirp spread spectrum,omni-directional receiver},
pages = {361--362},
publisher = {ACM},
series = {SenSys '09},
title = {{Analysis of an Omni-directional Narrowband Ultrasonic Receiver and CSS-based Broadband Transmission}},
url = {http://doi.acm.org/10.1145/1644038.1644102},
year = {2009}
}
@inproceedings{Mitra200495,
abstract = {A COTS-based design for a monostatic position-adaptive radar concept is presented. The development and design effort is focused on a test experiment where a onboard radar-based instrumentation system allows a mini-UAV helicopter to hover back and forth in front of two large (side-by-side) "building-type" structures. Under this concept, the "smart" or "robotic" mini-UAV helicopter "position-adaptively" converges to a location between the two "building-type" structures in order to interrogate an object-of-interest that may be located between these "building-type" structures. Design issues with regard to major sub-systems and interfaces between these sub-systems are discussed. Applications for this type of system include intelligence gathering from indoor and outdoor urban environments and underground facilities via deployment a tier of position-adaptive mini-UAV's.},
annote = {cited By 0},
author = {Mitra, A K and Pasala, K M},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.541063},
keywords = {Attenuation; Design; Helicopters; Radar target re,Broadband antenna design; Mini-UAV helicopter; Pos,Radar systems},
pages = {95--101},
title = {{Low-cost position-adaptive UAV radar design with state-of-the-art COTS technology}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-8844236998{\&}doi=10.1117{\%}2F12.541063{\&}partnerID=40{\&}md5=ed48f169ac3ff5933be3cbdaa68a2ad8},
volume = {5410},
year = {2004}
}
@inproceedings{Miyaki2007275,
abstract = {In a widely distributed camera network environment, object tracking is a important function for a surveillance application. This paper describes an object tracking scheme using sensor fusion approach which is composed of visual information from cameras and location information based on Wi-Fi location estimation system. Estimated location information is calculated by a set of received signal strength values of beacon packets from Wi-Fi access points (APs) around the targets. Different from the conventional approaches which use another kind of sensors (e.g., global positioning system (GPS), pressure sensors on the floors, laser-range scanners, etc.), our approach can cover wider areas both indoor and outdoor with lower cost. Particle filter is applied to combine those two different kinds of sensory input to achieve tracking the target in a stable performance. Wi-Fi observation model is involved in a conventional visual particle filtering scheme to evaluate importance weights of each particle. In this paper, we present experimental results applied to outdoor surveillance camera environment. {\textcopyright}2007 IEEE.},
annote = {cited By 8},
author = {Miyaki, T and Yamasaki, T and Aizawa, K},
booktitle = {2007 1st ACM/IEEE International Conference on Distributed Smart Cameras, ICDSC},
doi = {10.1109/ICDSC.2007.4357534},
keywords = {Access points (APs); Camera networks; Distributed,Cameras; Detectors; Estimation; Fusion reactions;,Security systems},
pages = {275--282},
title = {{Multi-sensor fusion tracking using visual information and Wi-Fi location estimation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-47349107103{\&}doi=10.1109{\%}2FICDSC.2007.4357534{\&}partnerID=40{\&}md5=1f55cdfb962093364760cf0942b7792f},
year = {2007}
}
@inproceedings{Miyaki20071762,
abstract = {Object tracking with multiple cameras is a fundamental problem in wide-area surveillance application, but it has difficulties to achieve accurate and stable performance because of disjoint shot areas or initial object identification problems. We propose a novel object tracking method which jointly uses estimated location information of the target derived from a set of Wi-Fi signal strength values with video images from cameras. Apart from sensor fusion techniques proposed in the past which use another kind of sensors (eg., Global Positioning System (GPS), pressure sensors on the floors to detect foot steps, laser-range scanners, etc), our approach can cover wide-areas both indoor and outdoor in low cost because of propagation characteristics of Wi-Fi signals. Particle filtering is applied to achieve tracking the target from video images, with this Wi-Fi location estimation. This paper describes system architectures and the experimental results of the pedestrian tracking technique with Wi-Fi location estimation. {\textcopyright} 2007 IEEE.},
annote = {cited By 5},
author = {Miyaki, T and Yamasaki, T and Aizawa, K},
booktitle = {Proceedings of the 2007 IEEE International Conference on Multimedia and Expo, ICME 2007},
keywords = {Applied (CO); Camera networks; Experimental resul,Cameras; Data fusion; Detectors; Estimation; Exhib,Target tracking},
pages = {1762--1765},
title = {{Visual tracking of pedestrians jointly using WI-FI location system on distributed camera network}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-46449090352{\&}partnerID=40{\&}md5=2861b8ba297bf68de02857ed45a14028},
year = {2007}
}
@article{Mohammadi:2014:UWI:2582787.2582809,
address = {Hingham, MA, USA},
author = {Mohammadi, Zakaria and Saadane, Rachid and Aboutajdine, Driss},
doi = {10.1007/s11277-013-1304-8},
issn = {0929-6212},
journal = {Wirel. Pers. Commun.},
keywords = {Generalized Gamma distribution,Power delay profile,Propagation channel,Shadow fading,Ultra Wideband},
number = {2},
pages = {529--544},
publisher = {Kluwer Academic Publishers},
title = {{On Ultra Wideband Indoor Channel Modeling Based on Generalized Gamma Distribution}},
url = {http://dx.doi.org/10.1007/s11277-013-1304-8},
volume = {74},
year = {2014}
}
@inproceedings{Mohammadmoradi:2018:UPL:3289100.3289120,
address = {New York, NY, USA},
author = {Mohammadmoradi, Hessam and Heydariaan, Milad and Gnawali, Omprakash},
booktitle = {Proceedings of the 2Nd International Conference on Smart Digital Environment},
doi = {10.1145/3289100.3289120},
isbn = {978-1-4503-6507-9},
keywords = {Indoor Localization,Physical Layer Configuration,UWB},
pages = {119--126},
publisher = {ACM},
series = {ICSDE'18},
title = {{UWB Physical Layer Adaptation for Best Ranging Performance Within Application Constraints}},
url = {http://doi.acm.org/10.1145/3289100.3289120},
year = {2018}
}
@article{Mohammed2016157,
abstract = {An active camera tracking system (ACTS) is comprised of a camera that can rotate automatically toward an object of interest so the object remains within the camera's field of view. To rotate the camera toward an object, the camera needs to detect the object's location. Detecting an object's location can be achieved using image processing techniques. However, conventional image processing techniques require expensive calculations in addition to expensive hardware, which in turn limits the video frame processing speed. In this paper, we propose an effective ACTS to monitor and track objects automatically with high accuracy. The proposed approach automatically initializes the object to be tracked using an absolute difference motion detection technique. To track the object correctly, the minimum output sum of squared error (MOSSE) adaptive correlation tracker is applied to provide an accurate and fast visual tracking. We also implemented an accurate scale estimation for the visual tracking technique that detects the scale changes of the object. Additionally, the proposed ACTS uses a closed loop controller to control the pan-tilt speed of the system. By combining these techniques, the proposed ACTS can provide accurate tracking with smooth rotation. {\textcopyright} 2016 SERSC.},
annote = {cited By 0},
author = {Mohammed, Y I and Rhee, J M},
doi = {10.14257/ijsh.2016.10.10.15},
journal = {International Journal of Smart Home},
keywords = {Absolute difference; Active camera; Closed loop c,Cameras; Image processing; Motion analysis; Tracki,Object detection},
number = {10},
pages = {157--165},
title = {{IACTS: A novel indoor active camera tracking system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002719200{\&}doi=10.14257{\%}2Fijsh.2016.10.10.15{\&}partnerID=40{\&}md5=f53e50f961b18f2280a21eb5d5ddf34b},
volume = {10},
year = {2016}
}
@article{Mohareri2013,
abstract = {In this paper, we present a vision-based localization system using mobile augmented reality (MAR) and mobile audio augmented reality (MAAR) techniques, applicable to both humans and humanoid robots navigation in indoor environments. In the first stage, we propose a system that recognizes the location of a user from the image sequence of an indoor environment using its onboard camera. The location information is added to the user's view in the form of 3D objects and audio sounds with location information and navigation instruction content via augmented reality (AR). The location is recognized by using the prior knowledge about the layout of the environment and the location of the AR markers. The image sequence can be obtained using a smart phone's camera and the marker detection, 3D object placement and audio augmentation will be performed by the phone's operating processor and graphical/audio modules. Using this system will majorly reduce the hardware complexity of such navigation systems, as it replaces a system consisting of a mobile PC, wireless camera, head-mounted displays (HMD) and a remote PC with a smart phone with camera. In the second stage, the same algorithm is employed as a novel vision-based autonomous humanoid robot localization and navigation approach. The proposed technique is implemented on a humanoid robot NAO and improves the robot's navigation and localization performance previously done using an extended Kalman filter (EKF) by presenting location-based information to the robot through different AR markers placed in the robot environment. {\textcopyright} 2013 World Scientific Publishing Company.},
annote = {cited By 6},
author = {Mohareri, O and Rad, A B},
doi = {10.1142/S0219843613500199},
journal = {International Journal of Humanoid Robotics},
keywords = {Anthropomorphic robots; Audio acoustics; Augmente,Audio augmented reality; Autonomous humanoid robot,Cellular telephone systems},
number = {3},
title = {{A vision-based location positioning system via augmented reality: An application in humanoid robot navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885109607{\&}doi=10.1142{\%}2FS0219843613500199{\&}partnerID=40{\&}md5=52993b0b69f16e9ad81a2451758f9c13},
volume = {10},
year = {2013}
}
@article{Mohedano2008785,
abstract = {Visual surveillance and monitoring of indoor environments using multiple cameras has become a field of great activity in computer vision. Usual 3D tracking and positioning systems rely on several independent 2D tracking modules applied over individual camera streams, fused using geometrical relationships across cameras. As 2D tracking systems suffer inherent difficulties due to point of view limitations (perceptually similar foreground and background regions causing fragmentation of moving objects, occlusions), 3D tracking based on partially erroneous 2D tracks are likely to fail when handling multiple-people interaction. To overcome this problem, this paper proposes a Bayesian framework for combining 2D low-level cues from multiple cameras directly into the 3D world through 3D Particle Filters. This method allows to estimate the probability of a certain volume being occupied by a moving object, and thus to segment and track multiple people across the monitored area. The proposed method is developed on the basis of simple, binary 2D moving region segmentation on each camera, considered as different state observations. In addition, the method is proved well suited for integrating additional 2D low-level cues to increase system robustness to occlusions: in this line, a na{\"{i}}ve color-based (HSI) appearance model has been integrated, resulting in clear performance improvements when dealing with complex scenarios. {\textcopyright} 2008 Springer Berlin Heidelberg.},
annote = {cited By 2},
author = {Mohedano, R and Garc{\'{i}}a, N and Salgado, L and Jaureguizar, F},
doi = {10.1007/978-3-540-88458-3-71},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {2d tracking; 2D tracks; 3d tracking; Appearance m,Air filters; Cameras; Computer vision; Face recogn,Three dimensional},
pages = {785--795},
title = {{3D tracking using multi-view based particle filters}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-57049098605{\&}doi=10.1007{\%}2F978-3-540-88458-3-71{\&}partnerID=40{\&}md5=030cbbc7b7b1ef33e839c02123ffc09a},
volume = {5259 LNCS},
year = {2008}
}
@article{Mokatren:2018:EPM:3178898.3179317,
address = {Amsterdam, The Netherlands, The Netherlands},
author = {Mokatren, Moayad and Kuflik, Tsvi and Shimshoni, Ilan},
doi = {10.1016/j.future.2017.07.007},
issn = {0167-739X},
journal = {Future Gener. Comput. Syst.},
keywords = {Mobile eye tracking,Museum visitors guide},
number = {C},
pages = {528--541},
publisher = {Elsevier Science Publishers B. V.},
title = {{Exploring the Potential of a Mobile Eye Tracker As an Intuitive Indoor Pointing Device}},
url = {https://doi.org/10.1016/j.future.2017.07.007},
volume = {81},
year = {2018}
}
@inproceedings{Molnr2013503,
abstract = {MS Kinect, a motion sensor, developed as a game console for the XBOX360, is a Flash-LiDAR-type sensor. Earlier investigations have confirmed that good accuracy can be achieved with that inexpensive device. As the returned depth image is coarsely quantized and the spacing of the points is growing with the object distance, the accuracy degrades at larger object distances. If the measured object morphology is known, this effect can be compensated, and, consequently, consistent accuracy can be maintained over the entire range. In positioning applications, targets, such as spheres, are frequently used, and thus, target fitting methods can result in highly accurate target-sensor distance estimation. If multiple targets are detectable in a sequence of depth images, the sensor locations can be determined by resection. The paper provides a performance evaluation of the method applied to,indoor platform positioning and mapping. Copyright {\textcopyright} (2013) by the American Society for Photogrammetry {\&} Remote Sensing.},
annote = {cited By 1},
author = {Moln{\'{a}}r, B and Toth, C},
booktitle = {American Society for Photogrammetry and Remote Sensing Annual Conference, ASPRS 2013},
keywords = {Distance estimation; Flash LIDAR; Highly accurate;,Optical radar; Photogrammetry; Remote sensing,Spheres},
pages = {503--511},
title = {{Spherical target based trajectory recovery from kinect depth imagery}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887867128{\&}partnerID=40{\&}md5=d138a15f5a04aeda723083cee586eb19},
year = {2013}
}
@inproceedings{Montanari:2015:MIS:2801694.2801706,
address = {New York, NY, USA},
author = {Montanari, Alessandro},
booktitle = {Proceedings of the 2015 Workshop on Wireless of the Students, by the Students, {\&}{\#}38; for the Students},
doi = {10.1145/2801694.2801706},
isbn = {978-1-4503-3701-4},
keywords = {mobile sensing,real-time feedback,social interactions,wearables},
pages = {7--9},
publisher = {ACM},
series = {S3 '15},
title = {{Multimodal Indoor Social Interaction Sensing and Real-time Feedback for Behavioural Intervention}},
url = {http://doi.acm.org/10.1145/2801694.2801706},
year = {2015}
}
@inproceedings{Montaser2013618,
abstract = {This paper presents an experimental study conducted to facilitate the use of RFID on construction job sites. The study focuses on deployment settings to provide data acquisition with higher accuracy for indoor location sensing. It provides extension to the state-of-the-art in this field as it addresses the impact of metal media proximity to RFID tags, the reasonable duration for data capturing, number of RFID tags employed and the distance between them. Low cost passive RFID tags were used in the experiments where each tag is used as a reference point with a known location. Five hundred and forty (514) experiments were conducted in lab environment using a 3m by 3m test bed that is dynamically rearranged to generate 15 test beds and a total of 67713 data sets were collected and analyzed. The collected data were captured from nine locations for each test bed at four time intervals. Received Signal Strength Indicator (RSSI) was used as the main attribute for signal measurement to process the captured data. Results of the data analysis performed are studied under four main categories: duration, number of tags, locations of tags and metal interference. The best duration was found to be the 15 second in the test bed with the least number of tags; as the short amount of time to capture data did not allow creation of a lot of interference among the emitted signals. Within each test bed, errors occurred most at points where the received signals were not well distributed in a 360 degree vicinity of the data capturing point. It means that the center point of each test bed resulted in lowest errors and the points located on the extremities led to the highest errors. Finally, metal objects were found to have major impact on the accuracy of the captured data; to the level where reliable values for errors could not be calculated in the test beds attached to metal objects. In summary, the results of the experimental study and related findings are expected to provide guidelines to the users of RFID technology for localization in building construction.},
annote = {cited By 2},
author = {Montaser, A and Azram, R and Moselhi, O},
booktitle = {ISARC 2013 - 30th International Symposium on Automation and Robotics in Construction and Mining, Held in Conjunction with the 23rd World Mining Congress},
keywords = {Deployment settings; Experimental study; Indoor lo,Equipment testing,Errors; Experiments; Metals; Radio frequency iden},
pages = {618--625},
title = {{Experimental study for efficient use of RFID in construction}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893555281{\&}partnerID=40{\&}md5=627463c86e29f569ed1bb65ed553d949},
year = {2013}
}
@article{7518770,
abstract = {Indoor positioning methods using location-sensitive features of available wireless signals can achieve high accuracy. In particular, many state-of-the-art methods exploit quite unique sets of location-dependent received signal strength (RSS) measurements from multiple wireless local area network (WLAN) access points (APs), also called as wireless fingerprints. However, reception of signals from WLAN APs is not often stable, and RSS measurements tend to be unavailable due to WLAN card or AP transient effects, limited sensitivity of WLAN cards, and fluctuating attenuation and reflection of signals due to a multipath environment, structural changes and moving objects. In certain hostile scenarios, bogus APs may be installed to disorient WLAN localisation algorithms. In this study, two approaches are proposed to mitigate the impact of faulty signal strength measurements. Performance figures are provided for both simulated and empirical environments in order to support conclusions.},
author = {Morales, J and Akopian, D and Agaian, S},
doi = {10.1049/iet-rsn.2015.0479},
issn = {1751-8784},
journal = {IET Radar, Sonar Navigation},
keywords = {indoor navigation;indoor radio;mobility management},
number = {7},
pages = {1220--1227},
title = {{Mitigating anomalous measurements for indoor wireless local area network positioning}},
volume = {10},
year = {2016}
}
@article{Moreno-Cano:2013:ILS:2532880.2533184,
address = {Amsterdam, The Netherlands, The Netherlands},
author = {Moreno-Cano, M V and Zamora-Izquierdo, M A and Santa, Jos{\'{e}} and Skarmeta, Antonio F},
doi = {10.1016/j.neucom.2013.01.045},
issn = {0925-2312},
journal = {Neurocomput.},
keywords = {Artificial neural networks,Indoor positioning,Particle filter,RFID,Smart building},
pages = {116--125},
publisher = {Elsevier Science Publishers B. V.},
title = {{An Indoor Localization System Based on Artificial Neural Networks and Particle Filters Applied to Intelligent Buildings}},
url = {http://dx.doi.org/10.1016/j.neucom.2013.01.045},
volume = {122},
year = {2013}
}
@inproceedings{Moreno2014791,
abstract = {This work proposes a distributed access control mechanism based on location data and its application in the context of smart buildings. Our approach includes an access control engine embedded into smart objects, which are responsible to make authorization decisions by considering both user location data and access credentials. User location data are estimated using magnetic field data measured and sent by users through their personal phone. The proposed location-aware access control mechanism does not require any additional hardware or intermediate entities, providing the benefits of a decentralized and flexible solution for indoor environments. From the results obtained, we can consider our proposal as an appropriate solution in order to tackle the challenging security requirements of typical pervasive environments. {\textcopyright} 2014 IEEE.},
annote = {cited By 12},
author = {Moreno, M V and Hernandez, J L and Skarmeta, A F},
booktitle = {Proceedings - 2014 IEEE 28th International Conference on Advanced Information Networking and Applications Workshops, IEEE WAINA 2014},
doi = {10.1109/WAINA.2014.160},
keywords = {Access control,Access control mechanism; Authorization decision;},
pages = {791--796},
title = {{A new location-aware authorization mechanism for indoor environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904490442{\&}doi=10.1109{\%}2FWAINA.2014.160{\&}partnerID=40{\&}md5=c94721fc56e681a0aa15863c4b2a5a67},
year = {2014}
}
@article{5876205,
abstract = {In this article, we investigate how autonomous robots can exploit the high quality information already available from the WWW concerning 3-D models of office furniture. Apart from the hobbyist effort in Google 3-D Warehouse, many companies providing office furnishings already have the models for considerable portions of the objects found in our workplaces and homes. In particular, we present an approach that allows a robot to learn generic models of typical office furniture using examples found in the Web. These generic models are then used by the robot to locate and categorize unknown furniture in real indoor environments.},
author = {Mozos, O M and Marton, Z and Beetz, M},
doi = {10.1109/MRA.2011.940996},
issn = {1070-9932},
journal = {IEEE Robotics Automation Magazine},
keywords = {control engineering computing;furniture;Internet;m},
number = {2},
pages = {22--32},
title = {{Furniture Models Learned from the WWW}},
volume = {18},
year = {2011}
}
@inproceedings{Murata201413,
abstract = {This paper describes new concepts and techniques for an indoor positioning system that uses near-ultrasonic sound from a smartphone. The indoor positioning system can be used in many practical applications, for example, in detecting the location of moving objects, such as a person or a wheelchair, and navigation within a wide indoor area. Indoor positioning systems seem to require a higher positioning accuracy compared with systems for use in outdoor areas. The authors have previously proposed a solution for indoor positioning using ultrasonic sensors. However, these suffer from a shortcoming in that users have to possess a special ultrasonic transmitter. The system proposed here does not need such a transmitter, because a smartphone is used as the sound source. Smartphones are already widely used, so the proposed system seems to be easy to introduce for practical use. The sound transmitted from the smartphone has been investigated and confirmed, as has the validity of the developed receiving unit which makes use of the timer count values of a microcomputer, which gives an indication of the timing of the detection of sound from the smartphone. Positioning tests for static and moving objects have been carried out in both quiet and noisy environments. It has been verified that the positioning accuracy is sufficient for navigation for visually impaired persons and for other applications. {\textcopyright} 2014 IEEE.},
annote = {cited By 10},
author = {Murata, S and Yara, C and Kaneta, K and Ioroi, S and Tanaka, H},
booktitle = {Proceedings - 2014 8th International Conference on Next Generation Mobile Applications, Services and Technologies, NGMAST 2014},
doi = {10.1109/NGMAST.2014.17},
keywords = {Indoor positioning systems,Indoor positioning; Moving objects; Noisy environ,Signal encoding; Smartphones; Transmitters; Ultras},
pages = {13--18},
title = {{Accurate indoor positioning system using near-ultrasonic sound from a smartphone}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921064630{\&}doi=10.1109{\%}2FNGMAST.2014.17{\&}partnerID=40{\&}md5=5b7552208ee1d1be8aa8ea33ec3d58dc},
year = {2014}
}
@phdthesis{Mysorewala:2008:SRL:1467901,
address = {Arlington, TX, USA},
annote = {AAI3307247},
author = {Mysorewala, Muhammad Faizan},
isbn = {978-0-549-55682-4},
publisher = {University of Texas at Arlington},
title = {{Simultaneous Robot Localization and Mapping of Parameterized Spatio-temporal Fields Using Multi-scale Adaptive Sampling}},
year = {2008}
}
@article{Nagarajan:2004:CAV:1273050.1273052,
address = {Amsterdam, The Netherlands, The Netherlands},
author = {Nagarajan, R and Yaacob, Sazali and Sainarayanan, G},
issn = {1069-2509},
journal = {Integr. Comput.-Aided Eng.},
number = {1},
pages = {15--24},
publisher = {IOS Press},
title = {{Computer Aided Vision Assistance for Human Blind}},
url = {http://dl.acm.org/citation.cfm?id=1273050.1273052},
volume = {11},
year = {2004}
}
@inproceedings{Naik2012251,
abstract = {Geolocation is the identification of the geographic location of any object or device. Indoor Geolocation can be seen as an alternative for Global Positioning System as, GPS fails in an indoor area. As an emerging technology there are two main classes of infrastructure based on which these systems are built. There are basic challenges which these systems have to face and they include the signaling systems, cost of deployment, and accuracy of prediction, pattern recognition and use of signature databases. The use of appropriate methods with proper estimation values gives better accuracy. There are various methods depending on which these systems are implemented. Indoor Geolocation has various techniques to determine the position of the object. This paper has a comparative study of the two main techniques of RSSI. Also a design for one of the applications of Indoor Geolocation i.e. a system that can be implemented for a medical store has been proposed. The basic aim is to find the RSSI value based on which the mobile station can be located. The RSSI values can be modified for any changes in the environment. An algorithm that combines the best features of the calibration procedures, fingerprinting techniques and pattern recognition helps to implement the system with best accuracy in results. For different applications, the values the various methods of determination can be selected as per requirements. {\textcopyright} 2012 IEEE.},
annote = {cited By 4},
author = {Naik, G A and Khedekar, M P and Krishnamoorthy, M and Patil, S D and Deshmukh, R N},
booktitle = {2012 National Conference on Computing and Communication Systems, NCCCS 2012 - Proceeding},
doi = {10.1109/NCCCS.2012.6413008},
keywords = {Calibration procedure; Comparative studies; Emergi,Calibration; Communication systems; Pattern recog,Global positioning system},
pages = {251--255},
title = {{Comparison of RSSI techniques in wireless indoor geolocation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874240302{\&}doi=10.1109{\%}2FNCCCS.2012.6413008{\&}partnerID=40{\&}md5=08912e43df77dc99cd69d485009c17ad},
year = {2012}
}
@article{Nair2019128,
abstract = {Blind {\&} visually impaired (BVI) individuals and those with Autism Spectrum Disorder (ASD) each face unique challenges in navigating unfamiliar indoor environments. In this paper, we propose an indoor positioning and navigation system that guides a user from point A to point B indoors with high accuracy while augmenting their situational awareness. This system has three major components: location recognition (a hybrid indoor localization app that uses Bluetooth Low Energy beacons and Google Tango to provide high accuracy), object recognition (a body-mounted camera to provide the user momentary situational awareness of objects and people), and semantic recognition (map-based annotations to alert the user of static environmental characteristics). This system also features personalized interfaces built upon the unique experiences that both BVI and ASD individuals have in indoor wayfinding and tailors its multimodal feedback to their needs. Here, the technical approach and implementation of this system are discussed, and the results of human subject tests with both BVI and ASD individuals are presented. In addition, we discuss and show the system's user-centric interface and present points for future work and expansion. {\textcopyright} Springer Nature Switzerland AG 2019.},
annote = {cited By 1},
author = {Nair, V and Budhai, M and Olmschenk, G and Seiple, W H and Zhu, Z},
doi = {10.1007/978-3-030-11024-6_9},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Autism spectrum disorders; Bluetooth low energies,Bluetooth; Computer vision; Navigation systems; Ob,Indoor positioning systems},
pages = {128--143},
title = {{ASSIST: Personalized indoor navigation via multimodal sensors and high-level semantic information}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061754935{\&}doi=10.1007{\%}2F978-3-030-11024-6{\_}9{\&}partnerID=40{\&}md5=dc13ff5651655f7daab7848f03bab207},
volume = {11134 LNCS},
year = {2019}
}
@inproceedings{6071950,
abstract = {In this paper, a scalable middleware for supporting location aware applications, MapUme is presented. Scalability feature will enable development of a broad range localisation systems from small size to a large number of localised objects. Distributed data processing supports the scalability requirement by distributing data processing load into several computing machines. The distributed data processing is implemented using service oriented architecture which fits well with the scalability requirement. This feature promotes scalability since a main server may forward requests to multiple service instances without the knowledge of the service client. The middleware offers also extensibility of its components taking advantage of component based software development approach used.},
author = {Najib, W and Klepal, M and Wibowo, S B},
booktitle = {2011 International Conference on Indoor Positioning and Indoor Navigation},
doi = {10.1109/IPIN.2011.6071950},
keywords = {middleware;mobile computing;object-oriented progra},
pages = {1--6},
title = {{MapUme: Scalable middleware for location aware computing applications}},
year = {2011}
}
@inproceedings{Nakamura2007187,
abstract = {This paper presents a method for estimating an object's two-dimensional (2D) position and orientation based on topological information collected using infrared tags without any special location sensors or direction sensors. Estimating a user's and articles' location, irrespective of circumstances, is an important issue for context-aware systems. Users are present in a location with some purpose or intention. Therefore, a user's position and orientation clearly reflect their context. Especially, orientation information can reflect a more detailed context than that obtained merely according to location: people standing face-to-face or back-to-back would have vastly different contexts. The analyses explained in this paper particularly examine an object's orientation and describe a new method for estimating an object's position and orientation in an indoor, real-world environment. Using a simulation and an implemented prototype system, the experimental results demonstrate the feasibility of our topological estimation method.},
annote = {cited By 7},
author = {Nakamura, Y and Namimatsu, Y and Miyazaki, N and Matsuo, Y and Nishimura, T},
booktitle = {4th International Conference on Networked Sensing Systems, INSS},
doi = {10.1109/INSS.2007.4297418},
keywords = {Context-aware systems; Direction sensors; Estimat,Detectors; Mobile telecommunication systems; Senso,Estimation},
pages = {187--195},
title = {{A method for estimating position and orientation with a topological approach using multiple infrared tags}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-47149111794{\&}doi=10.1109{\%}2FINSS.2007.4297418{\&}partnerID=40{\&}md5=1e769df45c2ed00acd11e1b4c94d2a9f},
year = {2007}
}
@inproceedings{Nakamura2013658,
abstract = {In this paper, we propose a support system for daily living activities based on a user's behavior log in an indoor environment. Generally speaking, daily living activities hardly remain in our memory, so that, determining the order and priority of daily tasks can be difficult. There are studies supporting daily chores based on a behavior log and aiming to improve the work efficiency by using a memory aid. However, most of the existing studies require pre-installation of costly devices such as cameras and sensors, and are limited to supporting a particular task or purpose. There have been proposed many methods based on Augmented Reality (AR) which annotate captured images of the real world with texts, but text-based information may frustrate users. More intuitive user interfaces are required. In this paper, we first propose a user's behavior log management technique which associates each activity log with an object/location in the target indoor space. Then, we propose a method for reproducing AR-based visual effects on the object/location determined based on the log; the method naturally navigates the user to carrying out the intended task. We have implemented a prototype of the proposed method and have conducted subjective surveys to evaluate the effectiveness of the proposed visual effects. We thereby, confirmed that the proposed visual effects can make users more intuitively aware of the intended task than the text-based annotation method. {\textcopyright} 2013 IEEE.},
annote = {cited By 2},
author = {Nakamura, Y and Yamamoto, S and Tamai, M and Yasumoto, K},
booktitle = {2013 IEEE International Conference on Pervasive Computing and Communications Workshops, PerCom Workshops 2013},
doi = {10.1109/PerComW.2013.6529575},
keywords = {Annotation methods; Daily living activities; Indoo,Augmented reality; Ubiquitous computing; User int,Behavioral research},
pages = {658--663},
title = {{Supporting daily living activities using behavior logs and Augmented Reality}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881521519{\&}doi=10.1109{\%}2FPerComW.2013.6529575{\&}partnerID=40{\&}md5=8f528219f8588c143cc92ca56fba4b62},
year = {2013}
}
@inproceedings{Nallagalva:2015:IEP:2835596.2835597,
address = {New York, NY, USA},
author = {Nallagalva, Ashok and Sarda, Nandlal L and Bhushan, Alka},
booktitle = {Proceedings of the 1st ACM SIGSPATIAL International Workshop on the Use of GIS in Emergency Management},
doi = {10.1145/2835596.2835597},
isbn = {978-1-4503-3970-4},
keywords = {indoor evacuation planning,indoor network,routing and scheduling},
pages = {3:1----3:6},
publisher = {ACM},
series = {EM-GIS '15},
title = {{Indoor Evacuation Planning Using a Limited Number of Sensors}},
url = {http://doi.acm.org/10.1145/2835596.2835597},
year = {2015}
}
@article{Navarro2015,
abstract = {Radio Frequency Identification (RFID) is a solution for automated inventory and object detection applications. However, if RFID tags are attached to metal objects, detection errors may occur due to Foucault currents and interferences caused by multiple simultaneous reflections. Errors may increase if metal objects are moving. The paper presents a novel algorithm using RFID low-level reader variables, such as RSSI (Received Signal Strength Indicator), phase angle, and Doppler shift, to detect and trace metal objects. The algorithm was designed to identify if a tag is static or moving and, in the latter case, to compute its speed and direction. The algorithm differs from previous approaches since it uses a simple setup with one commercial portal reader coupled with one single element antenna. Experiments employed one tag located on one metal moving object and 12 static interferer tags, in both outdoor and indoor locations. Results show that the algorithm identifies static tags with no errors. For moving tags, the algorithm shows a maximum 12{\%} error. The algorithm correctly estimates direction and computes object speed. Test conditions emulate fork lift speeds when carrying objects in an industrial warehouse. {\textcopyright} 2015 Wendy Navarro et al.},
annote = {cited By 0},
author = {Navarro, W and Velez, J C and Schettini, N and Calle, M},
doi = {10.1155/2015/409617},
journal = {International Journal of Distributed Sensor Networks},
keywords = {Algorithms,Carrying objects; Detection error; Indoor locatio,Errors; Metals; Object detection; Radio frequency},
title = {{A Novel Multivariable Algorithm for Detecting and Tracing Metal Mobile Objects Employing a Simple RFID Setup}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949256721{\&}doi=10.1155{\%}2F2015{\%}2F409617{\&}partnerID=40{\&}md5=572ae1ee5b0df86a265e284753361851},
volume = {2015},
year = {2015}
}
@article{Navarro:2016:NMA:2810710.2929781,
address = {London, UK, United Kingdom},
author = {Navarro, Wendy and Velez, Juan C and Schettini, Norelli and Calle, Maria},
doi = {10.1155/2015/409617},
issn = {1550-1329},
journal = {Int. J. Distrib. Sen. Netw.},
pages = {224:224----224:224},
publisher = {Hindawi Limited},
title = {{A Novel Multivariable Algorithm for Detecting and Tracing Metal Mobile Objects Employing a Simple RFID Setup}},
url = {https://doi.org/10.1155/2015/409617},
volume = {2015},
year = {2016}
}
@article{Naz20187557,
abstract = {A novel indoor positioning algorithm with improved location accuracy is proposed for visible light communication system. The novelty of the positioning algorithm lies in a hybrid approach of making use of both frequency and variable phase of the transmitted signal. The algorithm has the capability of estimating the position of an object with localization error in millimeters when the signal passes through an optical channel. The LEDs are modulated at very high frequencies. The simulation results demonstrate that the positioning error is reasonably reduced compared with other existing approaches (algorithms). Unlike existing work, the current work also evaluates the performance of the positioning algorithm in the presence of different noise distributions and shows that 1-2 cm positioning accuracy can be achieved in the presence of the noise. Finally, multiple potential applications are discussed in which the proposed positioning scheme can be deployed. {\textcopyright} 2013 IEEE.},
annote = {cited By 9},
author = {Naz, A and Asif, H M and Umer, T and Kim, B.-S.},
doi = {10.1109/ACCESS.2018.2796623},
journal = {IEEE Access},
keywords = {Frequency division multiplexing; Frequency modulat,Indoor positioning; Localization errors; Optical,Light},
pages = {7557--7564},
title = {{PDOA Based Indoor Positioning Using Visible Light Communication}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041414149{\&}doi=10.1109{\%}2FACCESS.2018.2796623{\&}partnerID=40{\&}md5=6f1f7c4f380cd1ba86e01fdbc2b0fd23},
volume = {6},
year = {2018}
}
@inproceedings{Neto:2018:DRU:3213299.3213305,
address = {New York, NY, USA},
author = {Neto, Jo{\~{a}}o B Pinto and Mitton, Nathalie and Campista, Miguel Elias M and Costa, Lu$\backslash$'$\backslash$is Henrique M K},
booktitle = {Proceedings of the 4th ACM MobiHoc Workshop on Experiences with the Design and Implementation of Smart Objects},
doi = {10.1145/3213299.3213305},
isbn = {978-1-4503-5857-6},
keywords = {connected vehicles,dead-reckoning,robot,time series},
pages = {6:1----6:6},
publisher = {ACM},
series = {SMARTOBJECTS '18},
title = {{Dead Reckoning Using Time Series Regression Models}},
url = {http://doi.acm.org/10.1145/3213299.3213305},
year = {2018}
}
@inproceedings{Neufeld:2008:AGN:1402383.1402395,
address = {Richland, SC},
author = {Neufeld, James and Sokolsky, Michael and Roberts, Jason and Milstein, Adam and Walsh, Stephen and Bowling, Michael},
booktitle = {Proceedings of the 7th International Joint Conference on Autonomous Agents and Multiagent Systems - Volume 1},
isbn = {978-0-9817381-0-9},
keywords = {geocaching,outdoor navigation,robotics},
pages = {47--54},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
series = {AAMAS '08},
title = {{Autonomous Geocaching: Navigation and Goal Finding in Outdoor Domains}},
url = {http://dl.acm.org/citation.cfm?id=1402383.1402395},
year = {2008}
}
@inproceedings{Ng2011324,
abstract = {Radio frequency identification (RFID) technology has a wide range of industrial applications because of its low cost. In this paper, RFID is used for indoor object positioning system and we focus on the scenario of goods allocation in a warehouse. An Radial Basis Function Neural Network (RBFNN) is trained via a minimization of the Localized Generalization Error (L-GEM) to learn the object location based on received RFID signals from multiple RFID readers. Goods are stacked in 3-Dimensional ways in a warehouse, the RBFNN outputs 3-D vectors as the predicted locations of target goods. The proposed method is robust to uncertainty and changes in environment. Using MATLAB simulations, the experimental result shows that the proposed method yields an efficient indoor positioning. {\textcopyright} 2011 IEEE.},
annote = {cited By 2},
author = {Ng, W W Y and Lin, L and Chan, P P K and Yeung, D S},
booktitle = {Proceedings - International Conference on Machine Learning and Cybernetics},
doi = {10.1109/ICMLC.2011.6016745},
keywords = {3-dimensional; Indoor positioning; L-GEM; Localize,Cryptography; Cybernetics; Industrial application,Radio frequency identification (RFID)},
pages = {324--329},
title = {{3D goods allocation in warehouse with L-GEM based 3-D RFID positioning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80155132318{\&}doi=10.1109{\%}2FICMLC.2011.6016745{\&}partnerID=40{\&}md5=966d19f61385417320ede2bba6ae9e08},
volume = {1},
year = {2011}
}
@inproceedings{6416658,
abstract = {Obstacle detection is a fundamental issue of robot navigation and there have been several proposed methods for this problem. In this paper, we propose a new approach to find out obstacles on Depth Camera streams. The proposed approach consists of three stages. First, preprocessing stage is for noise removal. Second, different depths in a frame are clustered based on the Interval Type-2 Fuzzy Subtractive Clustering algorithm. Third, the objects of interest are detected from the obtained clusters. Beside that, it gives an improvement in the Interval Type-2 Fuzzy Subtractive Clustering algorithm to reduce the time consuming. In theory, it is at least 3700 times better than the original one, and approximate 980100 in practice on our depth frames. The results conducted on frames demonstrate that the distance from the camera to objects retrieved is exact enough for indoor robot navigation problems.},
author = {Nguyen, M U and Ngo, L T and Dao, T T},
booktitle = {2012 12th International Conference on Intelligent Systems Design and Applications (ISDA)},
doi = {10.1109/ISDA.2012.6416658},
issn = {2164-7143},
keywords = {cameras;collision avoidance;fuzzy set theory;image},
month = {nov},
pages = {903--908},
title = {{Improved Interval Type-2 Fuzzy Subtractive Clustering for obstacle detection of robot vision from stream of Depth Camera}},
year = {2012}
}
@article{Nguyen:2014:ITF:2595356.2595359,
address = {Amsterdam, The Netherlands, The Netherlands},
author = {Nguyen, Mau Uyen and Ngo, Long Thanh and Dao, Thanh Tinh},
doi = {10.3233/HIS-130186},
issn = {1448-5869},
journal = {Int. J. Hybrid Intell. Syst.},
keywords = {Depth Camera,Obstacle Detection,Robot Navigation,Subtractive Clustering,Type-2 Fuzzy Sets},
number = {2},
pages = {97--107},
publisher = {IOS Press},
title = {{An Interval Type-2 Fuzzy Subtractive Clustering Approach to Obstacle Detection of Robot Vision Using RGB-D Camera}},
url = {http://dx.doi.org/10.3233/HIS-130186},
volume = {11},
year = {2014}
}
@article{Nguyen2015716,
abstract = {This paper describes a Visual SLAM system developed on a mobile robot in order to support localization services to visually impaired people. The proposed system aims to provide services in small or mid-scale environments such as inside a building or campus of school where conventional positioning data such as GPS, WIFI signals are often not available. Toward this end, we adapt and improve existing vision-based techniques in order to handle issues in the indoor environments. We firstly design an image acquisition system to collect visual data. On one hand, a robust visual odometry method is adjusted to precisely create the routes in the environment. On the other hand, we utilize the Fast-Appearance Based Mapping algorithm that is may be the most successful for matching places in large scenarios. In order to better estimate robot's location, we utilize a Kalman Filter that combines the matching results of current observation and the estimation of robot states based on its kinematic model. The experimental results confirmed that the proposed system is feasible to navigate the visually impaired people in the indoor environments. {\textcopyright} Springer International Publishing Switzerland 2015.},
annote = {cited By 9},
author = {Nguyen, Q.-H. and Vu, H and Tran, T.-H. and {Van Hamme}, D and Veelaert, P and Philips, W and Nguyen, Q.-H.},
doi = {10.1007/978-3-319-16199-0_50},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Computer vision,Conformal mapping; Image acquisition; Image matchi,Image acquisition systems; Indoor environment; Lo},
pages = {716--729},
title = {{A visual SLAM system on mobile robot supporting localization services to visually impaired people}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928813947{\&}doi=10.1007{\%}2F978-3-319-16199-0{\_}50{\&}partnerID=40{\&}md5=80535da8dca1fc2ce3fba5ca5fd53bf3},
volume = {8927},
year = {2015}
}
@inproceedings{6409751,
abstract = {Radio Frequency Identification (RFID) can not only be used to identify objects, but also to localize them. If Received Signal Strength Indicator (RSSI) values are converted into distances, a Constrained Unscented Kaiman Filter (CUKF) can estimate an object's position via these measurements. In case of unknown or varying measurement noise a Fuzzy-Adaptive version of the filter (FACUKF) leads to an increase in location accuracy and filter consistency.},
author = {Nick, T and G{\"{o}}tze, J and John, W},
booktitle = {2012 Ubiquitous Positioning, Indoor Navigation, and Location Based Service (UPINLBS)},
doi = {10.1109/UPINLBS.2012.6409751},
keywords = {adaptive filters;nonlinear filters;radiofrequency},
pages = {1--7},
title = {{Fuzzy-Adaptive Kaiman Filter for RFID localization}},
year = {2012}
}
@inproceedings{Nikparvar2014215,
abstract = {Addressing and geolocation for indoor environments are important fields of research in the recent years. The problem of finding location of objects in indoor spaces is proposed to solve in two ways. The first, is to assign coordinates to objects and second is to divide space into cells and detect the presence or absence of objects in each cell to track them. In this paper the second approach is discussed by using Radio Frequency Identification technology to identify and track high value objects in jewellery retail industry. In Ubiquitous Sensor Networks, the reactivity or proactivity of the environment are important issues. Reactive environments wait for a request to response to it. Instead, in proactive spaces, the environment acts in advance to deal with an expected action. In this research, a geo-sensor network containing RFID readers, tags, and antennas which continuously exchange radio frequency signal streams is proposed to manage and monitor jewellery galleries ubiquitously. The system is also equipped with a GIS representation which provides a more user-friendly system to manage a jewellery gallery.},
annote = {cited By 1},
author = {Nikparvar, B and Sadeghi-Niaraki, A and Azari, P},
booktitle = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
doi = {10.5194/isprsarchives-XL-2-W3-215-2014},
keywords = {Geographic information systems; Radio frequency id,Geolocations; Indoor environment; Indoor geolocat,Ubiquitous computing},
number = {2W3},
pages = {215--218},
title = {{Ubiquitous indoor geolocation: A case study of jewellery management system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924177318{\&}doi=10.5194{\%}2Fisprsarchives-XL-2-W3-215-2014{\&}partnerID=40{\&}md5=bdd59f2d6c0b3065de100ca7f6dfb030},
volume = {40},
year = {2014}
}
@article{Nithya2015727,
abstract = {Human cognition based perception, map building and pursue the goal through their environment bestow more autonomy for mobile robots. The proposed system assists mobile robot to determine the factors of path planning for indoor environment with the focus on straight lines before starting its navigation. The system imitates the human's visual perception process, intentions and thought. First, it detects the partially occluded target object using Optimal Curve Segment (OCS) method which reconstructs the occluded object portion of shape by object shape models and achieves nearly 0.80 of similarity between the reconstructed partially occluded objects and complete object shape by reducing the already existing dissimilarity rate by 50 {\%}. The conical cognitive map for a straight line focus estimate of the target object location, decides the distance value of forward movement before preceding its navigation and angle of deviation of turning direction like left and right movements of the human eye. Vision guided cognitive maps replace the range finding sensors for distance estimation in mobile robots. It reduces the unwanted grid cell search in 2D-metric map of the environment. This proposed system gives better results in the detection of partially occluded target object and path planning for collision free indoor environment. {\textcopyright} Springer International Publishing Switzerland 2015.},
annote = {cited By 1},
author = {Nithya, N and {Tamil Selvi}, D},
doi = {10.1007/978-3-319-08422-0_104},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Cognitive maps; Cognitive vision; Contour reconst,Cognitive systems; Eye movements; Motion planning;,Mobile robots},
pages = {727--732},
title = {{Human Cognition and Vision Based Earlier Path Determination System for Indoor Mobile Robot Path Planning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906544889{\&}doi=10.1007{\%}2F978-3-319-08422-0{\_}104{\&}partnerID=40{\&}md5=4036c57540566069da60b0835bca5e90},
volume = {1089},
year = {2015}
}
@inproceedings{6626055,
abstract = {This paper introduces an automatic method of extracting accessible information from CityGMLLoD4 files. The proposed solution could generate accessible rectangles from supplied files, and then use these rectangles and their spatial relationships to produce their intersection partsand nodes. Thus, we can use these accessible objects to meet the path finding demand of navigation and evacuation simulation. Furthermore, the stored accessible navigation rectangles could be utilized to meet dynamic routing demand, whichcould affect the navigation environment, in the future work.},
author = {Niu, L and Song, Y},
booktitle = {2013 21st International Conference on Geoinformatics},
doi = {10.1109/Geoinformatics.2013.6626055},
issn = {2161-024X},
keywords = {building management systems;computerised navigatio},
pages = {1--6},
title = {{An automatic solution of accessible information extraction from CityGMLLoD4 files}},
year = {2013}
}
@article{Niu20181416,
abstract = {The location-based service requires fast query, insertion and deletion operations for research objects, and this demand is augmented for the indoor evacuation fields. Thus, introducing spatial index to tackle the operation efficiency problem is strongly demanded for indoor related scenes, and this method is sounding for indoor spatial objects. Nevertheless, this solution always meets a performance bottleneck. And this performance bottleneck of spatial index pervasively exists in the current compact indoor application scenes. To mitigate this problem, this paper tries to combine the R* tree index with the Hilbert curve, and proposes an innovative Hilbert curve based index. The succeeding experiment is designed to compare the performance of proposed index with the classic R* index. The test result shows the new index has successfully alleviated the execution efficiency for multi-type spatial operations, especially on critic indicators of spatial index performance. {\textcopyright} 2018, Research and Development Office of Wuhan University. All right reserved.},
annote = {cited By 0},
author = {Niu, L and Song, Y and Zhang, H and Hou, S},
doi = {10.13203/j.whugis20160352},
journal = {Wuhan Daxue Xuebao (Xinxi Kexue Ban)/Geomatics and Information Science of Wuhan University},
keywords = {Efficiency; Forestry; Telecommunication services,Evacuation; Hilbert curve; Indoor applications; I,Location based services,comparative study; experimental study; hazard man},
number = {9},
pages = {1416--1421},
title = {{A Hilbert-Curve-Based R* Tree Index Optimized for Indoor Evacuation [HilbertR*]}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057056614{\&}doi=10.13203{\%}2Fj.whugis20160352{\&}partnerID=40{\&}md5=d84d73149bafabe6fcca1f19d8e7adbf},
volume = {43},
year = {2018}
}
@inproceedings{Niu:2014:CCD:2663713.2664423,
address = {New York, NY, USA},
author = {Niu, Long and Matsumoto, Shinsuke and Saiki, Sachio and Nakamura, Masahide},
booktitle = {Proceedings of the 4th International Workshop on Location and the Web},
doi = {10.1145/2663713.2664423},
isbn = {978-1-4503-1459-6},
keywords = {API,data modeling,indoor location query service,indoor positioning system,location information,location-aware service},
pages = {25--32},
publisher = {ACM},
series = {LocWeb '14},
title = {{Considering Common Data Model for Indoor Location-aware Services}},
url = {http://doi.acm.org/10.1145/2663713.2664423},
year = {2014}
}
@inproceedings{Noh200813,
abstract = {Localization has been an important issue along with the development of context-aware systems applicable to dynamic mobile environment. ZigBee is very cheap and less power consuming wireless techniques comparing to other types such as RFID, infrared and ultrasound. Thus this paper compares conventional techniques for predicting mobile object's location by combining estimates drawn from Received Signal Strength (RSS) using ZigBee modules. We classify these mechanisms into two categories; map-based localization techniques, referring to database of predefined locations and their RSSI data; and distance-based localization using Markov Chain inference. Our results show the relationship between RSSI and distance in indoor ZigBee environment and compare localization accuracy of those two techniques. We conclude that map-based localization is not suitable for flexible changes in indoors because of its predefined condition setup and lower accuracy comparing to distance-based Markov Chain inference localization system. {\textcopyright} 2008 IEEE.},
annote = {cited By 46},
author = {Noh, A.S.-I. and Lee, W J and Ye, J Y},
booktitle = {Proc. 9th ACIS Int. Conf. Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing, SNPD 2008 and 2nd Int. Workshop on Advanced Internet Technology and Applications},
doi = {10.1109/SNPD.2008.125},
keywords = {Artificial intelligence; Demodulation; Internet; L,Context-aware; Conventional techniques; Indoor lo,Wireless networks},
pages = {13--18},
title = {{Comparison of the mechanisms of the ZigBee's indoor localization algorithm}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-57749192069{\&}doi=10.1109{\%}2FSNPD.2008.125{\&}partnerID=40{\&}md5=88b251e7137334f1af608f19e14ca93f},
year = {2008}
}
@inproceedings{Noreikis2018578,
abstract = {Visual crowdsourcing (VCS) offers an inexpensive method to collect visual data for implementing tasks, such as 3D mapping and place detection, thanks to the prevalence of smartphone cameras. However, without proper guidance, participants may not always collect data from desired locations with a required Quality-of-Information (QoI). This often causes either a lack of data in certain areas, or extra overheads for processing unnecessary redundancy. In this work, we propose SnapTask, a participatory VCS system that aims at creating complete indoor maps by guiding participants to efficiently collect visual data of high QoI. It applies Structure-from-Motion (SfM) techniques to reconstruct 3D models of indoor environments, which are then converted into indoor maps. To increase coverage with minimal redundancy, SnapTask determines locations for the next data collection tasks by analyzing the coverage of the generated 3D model and the camera views of the collected images. In addition, it overcomes the limitations of SfM techniques by utilizing crowdsourced annotations to reconstruct featureless surfaces (e.g. glass walls) in the 3D model. According to a field test in a library, the indoor map generated by SnapTask successfully reconstructs 100{\%} of the library walls and 98.12{\%} of objects and traversal areas within the library. With the same amount of input data our design of guided data collection increases the map coverage by 20.72{\%} and 34.45{\%}, respectively, compared with unguided participatory and opportunistic VCS. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Noreikis, M and Xiao, Y and Hu, J and Chen, Y},
booktitle = {Proceedings - International Conference on Distributed Computing Systems},
doi = {10.1109/ICDCS.2018.00063},
keywords = {3-d modeling; Data collection; Indoor environment,Cameras; Crowdsourcing; Distributed computer syste,Data acquisition},
pages = {578--588},
title = {{SnapTask: Towards efficient visual crowdsourcing for indoor mapping}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050965679{\&}doi=10.1109{\%}2FICDCS.2018.00063{\&}partnerID=40{\&}md5=5b09918f00453019e1c410567a4d2751},
volume = {2018-July},
year = {2018}
}
@inproceedings{Nugroho201853,
abstract = {In this paper, we propose an enhancement of color-based particle filter algorithm with oriented FAST and rotated BRIEF (ORB) feature detector (ORBPF). By carefully defining the size and position of the search window, ORB will generate interesting key-point close to the object being tracked. The location of matched key-point with high color similarity is then selected to replace the particles from the original filter. This matched key-point can be used to manage the particle spread and minimize the disadvantages of a random selection of the particle set such as degeneracy and sample impoverishment problem. The number of particles can be significantly reduced by using this method while maintaining the accuracy of the tracker. We test our tracker on numerous video sequences and using real-time video input from CCD camera in an indoor and outdoor application that involves some challenging situations including variations in illumination, scale, rotation, and occlusions. From the experiment, we show that our tracker performs more efficiently than standard color-based particle filter without ORB feature detector (CPF). {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Nugroho, T H and Mangkusasmito, F and Trilaksono, B R and Indriyanto, T and Yulianti, L},
booktitle = {2018 International Conference on Signals and Systems, ICSigSys 2018 - Proceedings},
doi = {10.1109/ICSIGSYS.2018.8373567},
keywords = {CCD cameras; Color; Fire fighting equipment; Match,Color similarity; Oriented fast and rotated brief,Feature extraction},
pages = {53--58},
title = {{Enhancing color-based particle filter algorithm with ORB feature for real-time video tracking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049314822{\&}doi=10.1109{\%}2FICSIGSYS.2018.8373567{\&}partnerID=40{\&}md5=94aa925b8852c679a267018e73d420b6},
year = {2018}
}
@article{Odobez1996101,
abstract = {Analysing the dynamic content of a scene observed by a mobile camera often requires the segmentation of each image of the sequence into region entities of apparent homogeneous motion. To each region is associated a 2D polynomial model (e.g., an affine one) able to describe at each location the underlying 2D true motion with a predefined precision $\eta$. Thanks to the use of a multiresolution robust estimator [1] to compute the motion models, the determination of the boundaries between the different regions, which is stated as a statistical regularization based on multiscale Markov Random Field (MRF) models, can be achieved in one pass only. This avoids the time consuming iterations between motion estimation and boundary identification that are encountered in almost all other motion-segmentation schemes (for instance [2, 3, 4]). We explicitly detect areas where the error between the underlying motion and the one given by the estimated models is not whithin the precision $\eta$. This allows us to handle the appearance of new objects in the scene. We have performed numerous experiments with real indoor and outdoor image sequences which demonstrate the efficiency of the method. {\textcopyright} Springer-Verlag Berlin Heidelberg 1996.},
annote = {cited By 1},
author = {Odobez, J.-M. and Bouthemy, P},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Boundary identification; Dynamic content; Dynamic,Computer vision; Image analysis; Image processing;,Motion analysis},
pages = {101--110},
title = {{Direct model-based image motion segmentation for dynamic scene analysis}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950000155{\&}partnerID=40{\&}md5=178cfe0e5cca006b82d36bf83838aaf5},
volume = {1035},
year = {1996}
}
@article{Oldham2015275,
abstract = {There is little evidence of thorough experimental research having been performed for the investigation of optimum computer vision algorithms suitable for table tennis umpire support systems and player performance analysis. The only practical way of evaluating and comparing such algorithms is to gather source video data from repeatable experiments in controlled conditions and pass multiple sequences through the same validated algorithms, techniques and processes. This paper presents a digest of software engineering issues, considerations and challenges observed as a direct result of performing over 250 experiments with computer vision and table tennis. Results demonstrate that variations in camera configuration have a direct impact on the success of a selected algorithm and that a comparison of algorithms against the source video data must be made for confirmation. Finally, determination of the location of the ball itself varies between algorithms and a parallel, non-obtrusive technology is required to provide baseline data. {\textcopyright} Springer International Publishing Switzerland 2015.},
annote = {cited By 1},
author = {Oldham, K M and {Wai Hing Chung}, P and Edirisinghe, E A and Halkon, B J},
doi = {10.1007/978-3-319-13153-5_27},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Algorithms,Artificial intelligence; Computer vision; Error de,Ball; Camera configuration; Comparison; Computer},
pages = {275--284},
title = {{Experiments in the application of computer vision for ball and event identification in indoor sports}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84914820384{\&}doi=10.1007{\%}2F978-3-319-13153-5{\_}27{\&}partnerID=40{\&}md5=094e07dd13110a3986468c592ecec01c},
volume = {331},
year = {2015}
}
@inproceedings{Omi20173147,
abstract = {Object tracking from camera images is a key technique in the field of computer vision. Because the most representative application of this technique is security or surveillance, objects such as pedestrians or vehicles in public spaces are considered as tracking targets. However, it is also useful to track objects such as daily items found in indoor living spaces, including offices, private rooms, and other locations, when they go missing or need to be located. However, it is not known in advance which part of the living space can move as a single object to be tracked. Moreover, because objects in a living space do not move by themselves but are moved by human hands, the bodies of objects in motion are usually occluded by the hands for a relatively long period of time, and drastic changes in the position and appearance of the objects may occur after a long-term occlusion. In this article, we propose an approach to finding the correspondence between objects observed before and after their occlusion for object tracking purposes by detecting the grasp and release of such objects by the same hand. Segmentation of the body of each object is also realized through the detection of its grasp and release. {\textcopyright} 2017 IEEE.},
annote = {cited By 1},
author = {Omi, T and Kakusho, K and Iiyama, M and Nishiguchi, S},
booktitle = {2017 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2017},
doi = {10.1109/SMC.2017.8123111},
keywords = {Automobile bodies; Cybernetics; Image processing;,Camera images; Grasping; Human hands; Living spac,Object detection},
pages = {3147--3152},
title = {{Segmentation and tracking of object when grasped and moved within living spaces}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044222092{\&}doi=10.1109{\%}2FSMC.2017.8123111{\&}partnerID=40{\&}md5=8a9a7524de580ea16f620bca83751c20},
volume = {2017-Janua},
year = {2017}
}
@inproceedings{Orozco-Ochoa2012338,
abstract = {The location of objects and people by the use of Global Positioning System (GPS) or Global System for Mobile Communications (GSM) network is increasingly used to provide location-based services. These technologies work well outdoors and when the required accuracy is not very high, up to 10 meters. This paper describes an algorithm for monitoring elderly people at home, by continuously taking its position, which uses the RSS information exchanged between Bluetooth devices, Weibull distributions and Bayesian classifiers. This algorithm has been validated in a real environment, an area of 13  12 meters, with several rooms and corridors, where zones of approximately 6 square meters have been delimited. Our algorithm achieved a rate of correct detections of 91.875{\%}.},
annote = {cited By 0},
author = {Orozco-Ochoa, S and Vila-Sobrino, X A and G{\'{o}}mez-Conde, I and Lado, M J},
booktitle = {BIOSIGNALS 2012 - Proceedings of the International Conference on Bio-Inspired Systems and Signal Processing},
keywords = {Algorithms,Bayes; Bayesian classifier; Bluetooth device; Elde,Bluetooth; Global positioning system; Global syst},
pages = {338--341},
title = {{AN indoor localization algorithm based in weibull distribution and Bayesian classifier}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861996009{\&}partnerID=40{\&}md5=493198048ef649e211525a3633f173f3},
year = {2012}
}
@inproceedings{zyurt20123516,
abstract = {Precise localization of mobile robots is critical issue in military, industrial and show business applications. In the literature, several localization techniques has been proposed, in which reader is carried by the mobile object. But in this study a passive Radio Frequency Identification (RFID) tag is attached to mobile robot and the reader antennas being dispersed around the environment. This novelty protects the mobile robot from an increase of weight and results in saving in battery consumption. Also by this way, an increase in mobile object requires a mere increase in low cost passive RFID tags in the navigation system. We have applied a signal pattern matching algorithm, Weighted Centroid Localization (WCL) and Selective Adaptive Weighted Localization (SAWCL) algorithms to locate the tag via Received Signal Strength Indicator (RSSI) and we compare the results. In this study a pilot application is implemented and a prototype is developed to show the proof of concept of the system. {\textcopyright} 2012 IEEE.},
annote = {cited By 1},
author = {{\"{O}}zyurt, E and Aydin, E and Yapici, A C},
booktitle = {Proceedings of 6th European Conference on Antennas and Propagation, EuCAP 2012},
doi = {10.1109/EuCAP.2012.6206440},
keywords = {Algorithms; Military applications; Mobile phones;,Antennas,Battery consumption; Business applications; Critic},
pages = {3516--3519},
title = {{Indoor location finding algorithms for mobile robots carrying passive RFID tags}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862878961{\&}doi=10.1109{\%}2FEuCAP.2012.6206440{\&}partnerID=40{\&}md5=c5a9820deb16d87e6c8782264962d13c},
year = {2012}
}
@phdthesis{Paek:2000:SRN:932018,
address = {New York, NY, USA},
annote = {AAI0801746},
author = {Paek, Seungyup},
publisher = {Columbia University},
title = {{Storage and Retrieval of Networked Visual Information}},
year = {2000}
}
@book{Palanisamy2015227,
abstract = {An indoor positioning system is a network of devices used to wirelessly locate objects or people inside a building. When it comes to the widespread adoption of indoor positioning and navigation tools among users, technology is not often a barrier, as recent advancements in positioning technologies have produced a number of low-cost accurate embedded positioning devices. However, privacy concerns remain the major consumer pushback for a wider acceptance of such services among users. An indoor navigation service enables smartphone users to navigate indoors and share indoor location-based information. It thus generates a huge amount of potentially sensitive information, including the activities of smartphone users' movements, information searched by them, and the content they share with their neighboring peers. Even though it is believed that smartphone users are aware that such positioning services are tracking their mobile activities, a large fraction of the smartphone user populations are concerned about their location and other sensitive data generated through such services. Overcoming these concerns is a top priority for both service vendors who provide indoor location technologies to retailers and mobile consumers who are conscious of their privacy when they navigate indoors. In this chapter, we introduce the privacy risks and threats related to indoor positioning systems and the state-of-the-art countermeasures to protect against them. We also discuss the new challenges in developing privacy-enabling indoor positioning and navigation tools and their merits and demerits. {\textcopyright} 2015 by Taylor {\&} Francis Group, LLC.},
annote = {cited By 0},
author = {Palanisamy, B and Joshi, J},
booktitle = {Indoor Wayfinding and Navigation},
doi = {10.1201/b18220},
keywords = {In-door navigations; Indoor locations; Indoor pos,Indoor positioning systems,Location; Location based services; Navigation; Pop},
pages = {227--243},
title = {{Protecting privacy in indoor positioning systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053955189{\&}doi=10.1201{\%}2Fb18220{\&}partnerID=40{\&}md5=b2c1b0909a10fa70b898a6574db4ad78},
year = {2015}
}
@inproceedings{Paletta:2005:CSA:1099539.1100001,
address = {Washington, DC, USA},
author = {Paletta, Lucas and Fritz, Gerald and Seifert, Christin},
booktitle = {Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops - Volume 03},
doi = {10.1109/CVPR.2005.429},
isbn = {0-7695-2372-2-3},
pages = {94----},
publisher = {IEEE Computer Society},
series = {CVPR '05},
title = {{Cascaded Sequential Attention for Object Recognition with Informative Local Descriptors and Q-learning of Grouping Strategies}},
url = {https://doi.org/10.1109/CVPR.2005.429},
year = {2005}
}
@inproceedings{Pannuto2018242,
abstract = {Ultra wideband technology has shown great promise for providing high-quality location estimation, even in complex indoor multipath environments, but existing ultra wideband systems require tens to hundreds of milliwatts during operation. Backscatter communication has demonstrated the viability of astonishingly low-power tags, but has thus far been restricted to narrowband systems with low localization resolution. The challenge to combining these complimentary technologies is that they share a compounding limitation, constrained transmit power. Regulations limit ultra wideband transmissions to just -41.3 dBm/MHz, and a backscatter device can only reflect the power it receives. The solution is long-term integration of this limited power, lifting the initially imperceptible signal out of the noise. This integration only works while the target is stationary. However, stationary describes the vast majority of objects, especially lost ones. With this insight, we design Slocalization, a sub-microwatt, decimeter-accurate localization system that opens a new tradeoff space in localization systems and realizes an energy, size, and cost point that invites the localization of every thing. To evaluate this concept, we implement an energy-harvesting Slocalization tag and find that Slocalization can recover ultra wideband backscatter in under fifteen minutes across thirty meters of space and localize tags with a mean 3D Euclidean error of only 30 cm. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Pannuto, P and Kempke, B and Dutta, P},
booktitle = {Proceedings - 17th ACM/IEEE International Conference on Information Processing in Sensor Networks, IPSN 2018},
doi = {10.1109/IPSN.2018.00052},
keywords = {Backscattering; Broadband networks; Communication,Ultra-wideband (UWB),localization; Location estimation; Long-term inte},
pages = {242--253},
title = {{Slocalization: Sub-$\mu$W Ultra Wideband Backscatter Localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056262606{\&}doi=10.1109{\%}2FIPSN.2018.00052{\&}partnerID=40{\&}md5=8bfd6b86186adebadeb5e52ffadd08a9},
year = {2018}
}
@inproceedings{Panta20181,
abstract = {Location sensors and Closed-circuit Television (CCTV) cameras are widely used for the surveillance of people, objects and areas. These devices (sensors, CCTV cameras, etc.) generate a large amount of heterogeneous data, making their analysis and management difficult and very time-consuming. In the context of video-surveillance, automatic extraction of the relevant information among the mass of multi-sources information produced by these systems could significantly reduce the investigation time and facilitate their analysis. In this paper, we propose an approach that combines data from Indoor Location Sensors and metadata from CCTV cameras to automatically retrieve relevant video segments during research of evidence accident or crime events in indoor environments. The proposed method consists in i) the reconstruction of the mobile device trajectories from indoor location sensors and ii) the identification of the CCTV cameras intersecting the reconstructed trajectories. To ensure industrial transferability, indoor location sensors data were embedded in a generic model of CCTV cameras metadata that instantiates the standard ISO 22311 (relative to digital video-surveillance contents). We provide an experimental evaluation demonstrating the utility of our approach in a real-world case. Results show that our method helps the CCTV operators to effectively retrieve the relevant video and drastically reduce the time of analysis. {\textcopyright} 2018 IEEE.},
annote = {cited By 1},
author = {Panta, F J and Roman-Jimenez, G and Sedes, F},
booktitle = {Proceedings - International Conference on Research Challenges in Information Science},
doi = {10.1109/RCIS.2018.8406677},
keywords = {Automatic extraction; Automatic filtering; Closed,Computer graphics; Location; Metadata; Mobile devi,Security systems},
pages = {1--9},
title = {{Modeling metadata of CCTV systems and Indoor Location Sensors for automatic filtering of relevant video content}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050877253{\&}doi=10.1109{\%}2FRCIS.2018.8406677{\&}partnerID=40{\&}md5=ae4645732b5769858562d6e568b70898},
volume = {2018-May},
year = {2018}
}
@inproceedings{Papon2015774,
abstract = {In this work we address the problem of indoor scene understanding from RGB-D images. Specifically, we propose to find instances of common furniture classes, their spatial extent, and their pose with respect to generalized class models. To accomplish this, we use a deep, wide, multi-output convolutional neural network (CNN) that predicts class, pose, and location of possible objects simultaneously. To overcome the lack of large annotated RGB-D training sets (especially those with pose), we use an on-the-fly rendering pipeline that generates realistic cluttered room scenes in parallel to training. We then perform transfer learning on the relatively small amount of publicly available annotated RGB-D data, and find that our model is able to successfully annotate even highly challenging real scenes. Importantly, our trained network is able to understand noisy and sparse observations of highly cluttered scenes with a remarkable degree of accuracy, inferring class and pose from a very limited set of cues. Additionally, our neural network is only moderately deep and computes class, pose and position in tandem, so the overall run-time is significantly faster than existing methods, estimating all output parameters simultaneously in parallel. {\textcopyright} 2015 IEEE.},
annote = {cited By 16},
author = {Papon, J and Schoeler, M},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2015.95},
keywords = {Cluttered scenes; Convolutional neural network; D,Computer vision,Embedded systems; Neural networks; Semantics},
pages = {774--782},
title = {{Semantic pose using deep networks trained on synthetic RGB-D}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973925898{\&}doi=10.1109{\%}2FICCV.2015.95{\&}partnerID=40{\&}md5=b23d8ea3af54412cff68eaf37d81d837},
volume = {2015 Inter},
year = {2015}
}
@article{Park20111124,
abstract = {Information summarization and retrieval are significant research topics associated with recent advancements in sensor devices, data compression and storage techniques, and high-speed internet. As a result of these advances, it is possible for people to collect huge life-logs. Video is one of the most important life information sources. This paper describes a method of summarizing video life-logs in an office environment with a multi-camera system. Previously, multi-camera systems have been used to track moving objects or to cover a wide area. This paper focuses on capturing diverse views of each office event using a multi-camera system with several cameras observing the same area. The summarization process includes camera view selection and event sequence summarization. View selection produces a single event sequence from multiple event sequences by selecting an optimal view at each time, for which domain knowledge based on the elements of the office environment and rules from questionnaire surveys have been used. Summarization creates a summary sequence from whole sequences by using a fuzzy rule-based system to approximate human decision making. The user-entered degrees of interest in objects, persons, and events are used for a personalized summarization. We confirmed experimentally that the proposed method provides promising results. {\textcopyright} 2011 Elsevier B.V. All rights reserved.},
annote = {cited By 14},
author = {Park, H.-S. and Cho, S.-B.},
doi = {10.1016/j.is.2011.04.005},
journal = {Information Systems},
keywords = {Cameras; Data compression; Decision making; Fuzzy,Domain knowledge; Fuzzy rule-based systems; Lifelo,Search engines},
number = {8},
pages = {1124--1134},
title = {{A personalized summarization of video life-logs from an indoor multi-camera system using a fuzzy rule-based system with domain knowledge}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051549174{\&}doi=10.1016{\%}2Fj.is.2011.04.005{\&}partnerID=40{\&}md5=642b294eca5ff0ba4a45e6e57b9ea233},
volume = {36},
year = {2011}
}
@inproceedings{Park2010155,
abstract = {Since September 11, 2001, geospatial researchers have been interested in utilizing GIScience technologies to solve geographical questions in micro-scale space in built-environments such as indoor space within a building. The indoor space should be dealt with differently from outdoor space in order to provide integrated and seamless location-based services (Li, 2009). The indoor LBS applications provided in multi-level structures such as buildings require a fundamental geo-spatial functionality to define spatial relationships among 3D entities to describe how individual spatial units interact. Because the 3D query operations are much complex geometric computational problems, this study proposes an alternative method to define the spatial neighborhoods among the 3D objects based on network-based topological representations for analyzing spatial relationships in indoor space.},
annote = {cited By 0},
author = {Park, I and Lee, J},
booktitle = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
keywords = {Complex networks; Geographic information systems;,Computational problem; Multi-level structures; Sh,Three dimensional; Topology},
number = {4 PART W15},
pages = {155--158},
title = {{Defining spatial neighborhoods for 3D topological analysis in indoor space}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881604033{\&}partnerID=40{\&}md5=aa748921ccc5852985981085a22d6add},
volume = {38},
year = {2010}
}
@article{Park2009619,
abstract = {This paper presents methods of localization of mobile systems using recent Radio Frequency Identification (RFID) technology. We consider an indoor environment where RFID tags are implanted along the wall or in objects in the room. If the absolute position and orientation of a tag are read by an RF reader, a mobile system can estimate its location using the information saved in the tags. A reader-tag model is obtained through experiments in order to derive relative positions and orientations between an antenna and an RFID tag. To estimate the location, we propose two estimation methods. One uses a single RFID tag and the other uses multi-RFID tags. Experimental results show that the proposed methods can provide good performance for mobile system localization in an indoor environment. {\textcopyright} 2009 World Scientific Publishing Company.},
annote = {cited By 1},
author = {Park, J H and Ji, Y.-K.},
doi = {10.1142/S0129183109013844},
journal = {International Journal of Modern Physics C},
number = {4},
pages = {619--632},
title = {{Location estimation of mobile systems using passive RFID tags in an indoor environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-67649389565{\&}doi=10.1142{\%}2FS0129183109013844{\&}partnerID=40{\&}md5=744fe81075c2704b27a821e79b478a96},
volume = {20},
year = {2009}
}
@inproceedings{Park2006353,
abstract = {This paper presents methods of robot localization using recent Radio Frequency Identification technology. We consider an indoor environment where RFID (radio frequency identification) tags are implanted along the wall or in objects in the room. If the absolute position and orientation of a tag are read by an RF reader, a robot can estimate its location using the information saved in the tags. A reader-tag model is obtained through experiments in order to derive relative positions and orientations between a robot and an RFID tag. To estimate the location of robot, we propose two estimation methods. One uses a single RFID tag and the other uses multi-RFID tags. Experimental results show that the proposed methods can provide good performance for mobile-robot localization.},
annote = {cited By 0},
author = {Park, J H and Ji, Y.-K.},
booktitle = {WMSCI 2006 - The 10th World Multi-Conference on Systemics, Cybernetics and Informatics, Jointly with the 12th International Conference on Information Systems Analysis and Synthesis, ISAS 2006 - Proc.},
keywords = {Absolute position; Estimation methods; Indoor envi,Cybernetics; Estimation; Information science; Inf,Radio frequency identification (RFID)},
pages = {353--358},
title = {{Estimation of a robot location using passive RFID tags in an indoor environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867282052{\&}partnerID=40{\&}md5=fa361b18d912bbe9415377c4985bfb0e},
volume = {2},
year = {2006}
}
@article{7849219,
abstract = {A positioning system based on visible light communication (VLC) utilizes illuminating indoor lights to identify the location of objects. The complexity and the cost of VLC are largely affected by limited bandwidths on optical emitters and detectors. In this paper, we present an optical signaling and multiplexing technique, which employs Hadamard matrices to implement a multiple-input multiple-output (MIMO) system. Fundamental conditions to create nonnegative optical signals and brightness control are defined in conjunction with multiplexing different sources and receiving messages. By using two design methods n-1 and M constructions, Hadamard matrices can be used to implement MIMO VLC without considering bandwidth limits for emitters or receivers. Eventually, the presented model and the method generalize multiplexing techniques with orthogonality from a view of orthogonal matrices. Experiments show that the proposed positioning system has 0.02-m standard errors of identification due to the noise component in a slow optical receiver.},
author = {Park, J K and Woo, T and Kim, M and Kim, J T},
doi = {10.1109/JPHOT.2017.2667038},
issn = {1943-0655},
journal = {IEEE Photonics Journal},
keywords = {free-space optical communication;Hadamard matrices},
number = {2},
pages = {1--10},
title = {{Hadamard Matrix Design for a Low-Cost Indoor Positioning System in Visible Light Communication}},
volume = {9},
year = {2017}
}
@inproceedings{Park20064251,
abstract = {This paper considers a new positioning sensor using position sensitive detector (PSD) under indoor environments. The system consists of PSD module which is attached on the ceiling and infrared (IR) projector modules attached on the interested object, and all modules are connected by wireless communication. In this system, the PSD module detects and determines location of the IR projector module with its light source, and the IR projector module receives its own location information from the PSD module. In particular, the developed system is implemented on the embedded system and it is small, simple, inexpensive and robust localization system. We applied this system to mobile robot navigation on indoor environment, and the experimental results shows the effectiveness of this system. {\textcopyright} 2006 ICASE.},
annote = {cited By 6},
author = {Park, J.-H. and Won, D.-H. and Park, K.-Y. and Baeg, S.-H. and Baeg, M.-H.},
booktitle = {2006 SICE-ICASE International Joint Conference},
doi = {10.1109/SICE.2006.314831},
keywords = {Localization; PSD module; Robot navigation,Mobile robots,Navigation systems; Optical projectors; Position},
pages = {4251--4255},
title = {{Development of a real time locating system using PSD under indoor environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250717462{\&}doi=10.1109{\%}2FSICE.2006.314831{\&}partnerID=40{\&}md5=57517999f4843be7020daba9e3eae3ee},
year = {2006}
}
@inproceedings{Park201894,
abstract = {This paper presents an efficient algorithm for measuring ranges between multiple UWB (Ultra Wide Band) transceivers. UWB device provides TOF (Time Of Flight) information of communication packet that can be converted to distance. For this reason, it is considered as a potential tool for estimating position of an object in indoor environment where GPS cannot be used. As a general method, range data between two UWB transceivers is computed with the time for round trip of communication packet because they have different time references respectively. However, it becomes a time consuming process in case of ranging between multiple transceivers. The proposed method solves the problem and saves processing time by employing broadcast in communication protocol from tag to multiple anchors. In addition, it is applied to a mobile robot system to estimate the location of moving target to follow. {\textcopyright} 2018 Newswood Limited. All rights reserved.},
annote = {cited By 0},
author = {Park, O S and Lee, J H and Okamoto, S},
booktitle = {Lecture Notes in Engineering and Computer Science},
keywords = {Communication modules; Communication packets; Ind,Mobile robots; Radio transceivers; Target tracking,Ultra-wideband (UWB)},
pages = {94--99},
title = {{Position estimation method using multiple UWB radio communication modules and its application to mobile robot}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058681731{\&}partnerID=40{\&}md5=ba1022a584d75417b019a73d72aaff93},
volume = {1},
year = {2018}
}
@inproceedings{Park20062681,
abstract = {We present a new method for indoor environment global localization with object recognition and stereo camera. For environment modeling, we use 3D object position and depth information of the stereo camera. The 3D object position is computed with the depth of the local invariant features. Furthermore, only the depth information at horizontal centerline in image is used, where optical axis passes through. The depth information is similar to the data of the laser range finder. Therefore, we can build a hybrid local map which is composed of indoor environment metric map and object location map. Also, based on such nodes, sensing data and object recognition, we suggest a method for estimating the coarse pose and refined pose of a mobile robot. The coarse pose is obtained by means of object recognition and SVD based least-squares fitting. Based on the coarse pose, the refined pose is estimated with particle filtering algorithm. One contribution of this method is that it can avoid the local minima problem which might be occurred in a geometrically non-distinctive place with scan matching based global localization method. With basic real environment, we show the proposed method can be an effective vision-based global localization algorithm. {\textcopyright} 2006 ICASE.},
annote = {cited By 10},
author = {Park, S and Kim, K and Park, S.-K. and Park, M},
booktitle = {2006 SICE-ICASE International Joint Conference},
doi = {10.1109/SICE.2006.315054},
keywords = {Cameras; Feature extraction; Mobile robots; Objec,Global localization; Local invariant features; Ste,Stereo vision},
pages = {2681--2686},
title = {{Object entity-based global localization in indoor environment with stereo camera}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250719342{\&}doi=10.1109{\%}2FSICE.2006.315054{\&}partnerID=40{\&}md5=c123ed7e58ebb4bbf5ec59fe9cb2144d},
year = {2006}
}
@article{Park20094174,
abstract = {This paper presents a novel vision-based global localization that uses hybrid maps of objects and spatial layouts. We model indoor environments with a stereo camera using the following visual cues: local invariant features for object recognition and their 3D positions for object pose estimation. We also use the depth information at the horizontal centerline of image where the optical axis passes through, which is similar to the data from a 2D laser range finder. This allows us to build our topological node that is composed of a horizontal depth map and an object location map. The horizontal depth map describes the explicit spatial layout of each local space and provides metric information to compute the spatial relationships between adjacent spaces, while the object location map contains the pose information of objects found in each local space and the visual features for object recognition. Based on this map representation, we suggest a coarse-to-fine strategy for global localization. The coarse pose is estimated by means of object recognition and SVD-based point cloud fitting, and then is refined by stochastic scan matching. Experimental results show that our approaches can be used for an effective vision-based map representation as well as for global localization methods. {\textcopyright} 2009.},
annote = {cited By 28},
author = {Park, S and Kim, S and Park, M and Park, S.-K.},
doi = {10.1016/j.ins.2009.06.030},
journal = {Information Sciences},
keywords = {3D positions; Centerlines; Coarse-to-fine strategy,Mobile robots; Special effects; Stereo vision; Th,Object recognition},
number = {24},
pages = {4174--4198},
title = {{Vision-based global localization for mobile robots with hybrid maps of objects and spatial layouts}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349739574{\&}doi=10.1016{\%}2Fj.ins.2009.06.030{\&}partnerID=40{\&}md5=7b8f0dd10da1554fc5ea72448a42b25a},
volume = {179},
year = {2009}
}
@article{Passarinho2015307,
abstract = {This paper proposes a framework to track a face in multi-view uncontrolled color video sequences. The method combines Gabor responses with missing observation Kalman filter to track the face. Using this approach, it is not necessary to estimate face positions even if the detection stage fails, because the missing observation Kalman filter is able to predict the face location in the next frame of the video sequence. Literature shows that tracking approach needs a face observation, returning to initial step. This work uses a preprocessing stage that actively treats the color constancy problem. This algorithm is applied directly to non-normalized RGB space, not demanding any color space transformation. Another contribution is the identification of a range for dark skin tones, not yet identified in uncontrolled color videos. Skin-tone pixel identification reduces the number of candidates to be a face region in the image and ensures that the image region is a human face. Using skin searching region the method can predict the object motion more accurately than one that performs face searching in the whole image. The proposed framework presented encouraging results for both indoor and outdoor unconstrained test videos, considering multi-view scenes containing partial occlusion and non-uniform illumination. Moreover, its capability to recover the face location not detected in a previous frame decreases the whole runtime, making it a very attractive one. {\textcopyright} 2003-2012 IEEE.},
annote = {cited By 2},
author = {Passarinho, C J P and Salles, E O T and Filho, M S},
doi = {10.1109/TLA.2015.7040663},
journal = {IEEE Latin America Transactions},
keywords = {Color,Color computer graphics; Color image processing; F,Color space transformation; Color video; Color vi},
number = {1},
pages = {307--314},
title = {{Face tracking in unconstrained color videos with the recovery of the location of lost faces}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923233809{\&}doi=10.1109{\%}2FTLA.2015.7040663{\&}partnerID=40{\&}md5=6d532f693e65bac3031187f3fcf12c34},
volume = {13},
year = {2015}
}
@inproceedings{Passarinho20111,
abstract = {This paper proposes a framework to track faces in color video sequences. The Adaptive Support Vector Tracker (ASVT) combines face detection with target tracking through using an adaptive filter in unconstrained videos. The adjacent locations of the target point are predicted in a search window reducing the number of image regions that are candidates for faces. Thus, the method can predict the object motion more accurately. The architecture is distinguished by the good results for both indoor and outdoor unconstrained videos, for scenes containing scale variation, partial occlusion, bad illumination and complex background. Brightness compensation is applied to improve the detection of faces in videos. {\textcopyright} 2011 IEEE.},
annote = {cited By 2},
author = {Passarinho, C J P and Salles, E O T and Filho, M S},
booktitle = {2011 ISSNIP Biosignals and Biorobotics Conference: Biosignals and Robotics for Better and Safer Living, BRC 2011},
doi = {10.1109/BRC.2011.5740684},
keywords = {Adaptive filters; Color image processing; Robotic,Adaptive support; Brightness compensation; Color v,Face recognition},
pages = {1--6},
title = {{Face detection based on Adaptive Support Vector Tracker}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955966168{\&}doi=10.1109{\%}2FBRC.2011.5740684{\&}partnerID=40{\&}md5=a58bee0011bcdd0890fb9745da452d91},
year = {2011}
}
@inproceedings{Patel:2010:SUU:2166616.2166635,
address = {Berlin, Heidelberg},
author = {Patel, Shwetak N and Kientz, Julie A and Gupta, Sidhant},
booktitle = {Proceedings of the 8th International Conference on Pervasive Computing},
doi = {10.1007/978-3-642-12654-3_14},
isbn = {3-642-12653-7, 978-3-642-12653-6},
keywords = {PowerLine positioning,accessibility,end-user deployable,indoor location sensing,location,user study,wheelchair users},
pages = {228--245},
publisher = {Springer-Verlag},
series = {Pervasive'10},
title = {{Studying the Use and Utility of an Indoor Location Tracking System for Non-experts}},
url = {http://dx.doi.org/10.1007/978-3-642-12654-3{\_}14},
year = {2010}
}
@inproceedings{Patra20181,
abstract = {Object localization is at the core of several context-Aware applications envisioned for the Internet of Things. However, the present localization approaches are often too expensive, or are limited by indoor layouts and noise. In recent years, radio tomographic imaging (RTI) has generated great interest as a device-free localization approach. While several RTI algorithms have been proposed in the literature, their robustness and comparative performance in indoor environments, with real-world impairments, has not yet been experimentally studied. In this paper, we compare the performance of three state-of-The-Art RTI algorithms and analyze the impact of different environmental conditions and algorithm parameters on the localization accuracy. Our experimental results show that multipath propagation is the main limiting factor for indoor localization using RTI: our measurements over a diverse set of indoor locations exhibit a 90th percentile localization error of between 0.8 m and 2.85 m. Additionally, our experiments reveal that co-channel interference and external human mobility further degrade the accuracy by 5{\%}-20{\%}. Furthermore, we show that while some improvements are achieved through modifications in network configuration and the fundamental RTI algorithm, these changes (such as increased node density and multi-channel RTI) are not feasible for cost-effective deployments. {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Patra, A and Wittig, S and Voicu, A and Simic, L and Petrova, M},
booktitle = {2017 IEEE Global Communications Conference, GLOBECOM 2017 - Proceedings},
doi = {10.1109/GLOCOM.2017.8253938},
keywords = {Algorithm parameters; Comparative performance; Co,Communication channels (information theory); Cost,Indoor positioning systems},
pages = {1--7},
title = {{Experimental evaluation of radio tomographic imaging algorithms for indoor localization with Wi-Fi}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046346978{\&}doi=10.1109{\%}2FGLOCOM.2017.8253938{\&}partnerID=40{\&}md5=99219a31afda2684d16a45cca61b20df},
volume = {2018-Janua},
year = {2018}
}
@inproceedings{5363110,
abstract = {As the number of older Americans increases and many decide to stay in their homes, the need for assistive technologies grows. One such technology is an intelligent system of surveillance cameras. While these systems can provide many services, we attempted to limit ourselves to the evaluation of systems that use cameras to track the locations of objects that may be lost or misplaced within a home. We provide a comparison of the systems that are currently in operation or are being developed and suggest areas where enhancements may produce systems that are more effective. Because few systems exist for the sole purpose of tracking objects in a home, we also evaluate systems that are designed to use multiple cameras to perform general surveillance. We go on to show where some principles of these system can be adapted to improve the performance in the task of tracking objects within a home.},
author = {Patrick, R and Bourbakis, N},
booktitle = {2009 21st IEEE International Conference on Tools with Artificial Intelligence},
doi = {10.1109/ICTAI.2009.93},
issn = {1082-3409},
keywords = {home computing;tracking;video cameras;video survei},
month = {nov},
pages = {248--252},
title = {{Surveillance Systems for Smart Homes: A Comparative Survey}},
year = {2009}
}
@inproceedings{Patten20186297,
abstract = {Robots operating in human environments are often required to recognise, grasp and manipulate objects. Identifying the locations of objects amongst their complex surroundings is therefore an important capability. However, when environments are unstructured and cluttered, as is typical for indoor human environments, reliable and accurate object segmentation is not always possible because the scene representation is often incomplete or ambiguous. We overcome the limitations of static object segmentation by enabling a robot to directly interact with the scene with non-prehensile actions. Our method does not rely on object models to infer object existence. Rather, interaction induces scene motion and this provides an additional clue for associating observed parts to the same object. We use a probabilistic segmentation framework in order to identify segmentation uncertainty. This uncertainty is then used to guide a robot while it manipulates the scene. Our probabilistic segmentation approach recursively updates the segmentation given the motion cues and the segmentation is monitored during interaction, thus providing online feedback. Experiments performed with RGB-D data show that the additional source of information from motion enables more certain object segmentation that was otherwise ambiguous. We then show that our interaction approach based on segmentation uncertainty maintains higher quality segmentation than competing methods with increasing clutter. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Patten, T and Zillich, M and Vincze, M},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2018.8593918},
keywords = {Action selection; Human environment; Interactive,Clutter (information theory); Radar clutter,Intelligent robots},
pages = {6297--6304},
title = {{Action Selection for Interactive Object Segmentation in Clutter}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062971909{\&}doi=10.1109{\%}2FIROS.2018.8593918{\&}partnerID=40{\&}md5=66506458219fcf98d9c5b2e350e55f09},
year = {2018}
}
@article{Pecchioli2011287,
abstract = {Managing heterogeneous information related to Cultural Heritage sites and artifacts is still a complex task. In latest years, there has been a significant trend towards the massive digitization of this data, as this allows more efficient and reliable storage and management processes. Furthermore, the relationship between conservation managers, who are often unfamiliar with current documentation techniques, and information providers, who tend to be highly technical practitioners without expertise in cultural heritage, is not easy to handle. Moreover, in Cultural Heritage objects often have a strong 3D component, and cannot be easily represented with conventional data management frameworks like Geographic Information System (GIS). The use of a 3D framework may allow a closer adherence to the real world, as it respects the spatial relationships among various parts. A novel method to access spatial information through the interactive navigation of a synthetic 3D model, reproducing the main features of a corresponding real environment, is proposed in this paper. The result of this work is a system called ISEE. An innovative aspect of the ISEE approach is represented by our definition of spatial relevance of information. The information is ranked with a novel measure of relevance that depends on the position/orientation in the 3D space, and allows for an intuitive interface. The basic idea of ISEE is to allow retrieving information by just looking around in a 3D environment, as moving and looking at the world is the main modality we use to gather information from it. Users explore in intuitive way a 3D environment and access the related information, kept in its spatial context. Information are accessed through "extended zones", i.e. portions of the 3D environment not having direct reference to specific elements, rather to the distribution of information and to the current user location. The use of extended zones gives to the proposed ranking algorithm a superior performance than rankings methods based on distance. Indeed the ISEE ranking matches the intuitive expectation of the users, as was verified with a formal usability test. The system has been applied to case studies related both to outdoor and indoor environments, showing its potential also as a smart guide with the use of augmented reality technologies. In order to enable access to a larger audience, sample applications using this method are based on Web technologies and do not require special training to be used. At the end of the paper are presented the results of an evaluation test, which provided useful suggestion to improve the system usability and performances. {\textcopyright} 2010 Elsevier Masson SAS.},
annote = {cited By 19},
author = {Pecchioli, L and Carrozzino, M and Mohamed, F and Bergamasco, M and Kolbe, T H},
doi = {10.1016/j.culher.2010.11.001},
journal = {Journal of Cultural Heritage},
number = {3},
pages = {287--294},
title = {{ISEE: Information access through the navigation of a 3D interactive environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960909048{\&}doi=10.1016{\%}2Fj.culher.2010.11.001{\&}partnerID=40{\&}md5=4a1db94979664634bc19e0a5a047acfe},
volume = {12},
year = {2011}
}
@inproceedings{Peixoto200098,
abstract = {In this paper we describe an indoor surveillance system who enables the control of a binocular active vision system by a remote operator wearing a head mounted display. Visual feedback to the head mounted display is obtained using the images captured by the active vision system. To maximize the 3D perception of the operator the system is able to adjust the vergence angle of the active vision system in order to maintain fixation on the objects in the center of the image. A wide-angle lens static camera located on the surveillance area is also used to enable the detection and tracking of intruders. In case of an intrusion a map with the location of the detected targets is displayed on top of the images being shown on the head mounted display. This information allows the remote operator to redirect his attention to where the target is. {\textcopyright} 2000 IEEE.},
annote = {cited By 1},
author = {Peixoto, P and Gon{\c{c}}alves, J and Antunes, H and Batista, J and Ara{\'{u}}jo, H},
booktitle = {Proceedings - International Conference on Pattern Recognition},
keywords = {Active vision system; Detection and tracking; Hea,Helmet mounted displays; Monitoring; Security syst,Pattern recognition systems},
number = {4},
pages = {98--101},
title = {{A surveillance system integrating visual telepresence}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-4944227894{\&}partnerID=40{\&}md5=b910ec023cd8825fa15c192e49424cbb},
volume = {15},
year = {2000}
}
@article{Peczyski2011183,
abstract = {The aim of the presented work was the development of a tracking algorithm for a single camera in a 3D scene with known objects. The input of the algorithm is a sequence of images, and the main assumption was the apriori knowledge of relative location of model objects-colourful boxes. The scene model was used to obtain a precise estimation of the camera's position. The algorithm consists of two steps: matching of model image feature points and then fitting of the model image to the actual scene image. The results of the presented study were used to estimate the motion of a stereo camera setup in the indoor scene, allowing for verification of the model-free navigation algorithm. {\textcopyright} 2011 Springer-Verlag Berlin Heidelberg.},
annote = {cited By 1},
author = {Pe{\l}czy{\'{n}}ski, P},
doi = {10.1007/978-3-642-23154-4_21},
journal = {Advances in Intelligent and Soft Computing},
keywords = {3D scenes; Apriori knowledge; Camera positions; Mo,Algorithms; Cameras; Estimation; Image matching;,Three dimensional},
pages = {183--190},
title = {{Model based estimation of camera position in 3D scene}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052844585{\&}doi=10.1007{\%}2F978-3-642-23154-4{\_}21{\&}partnerID=40{\&}md5=2b232a3d29d84895bbf03cfa6d73dfdb},
volume = {102},
year = {2011}
}
@inproceedings{Peng2014154,
abstract = {Wearable technologies have attracted considerable attention in mobile computing. This paper proposes a system for localization on wearable devices, such as the smart glasses. The existing approaches to localization, such as AoA, ToA, TDoA, GPS, and RF-based solutions, rely on auxiliary signals at set distances. This limitation constrains the availability of LBS when a mobile device is unable to receive the auxiliary signals. For example, GPS is not available in indoor environments. This paper proposes a system for 'self-contained' localization, which refers to the capability of a device to determine its location without having to rely on auxiliary signals, and demonstrates the feasibility of using inertial measurement unit (IMU) and visual sensors in a smart phone to achieve this goal. Based on a concept called inertial sensor-assisted localization (ISAL), IMU sensors are triggered by user motions and visual cues are taken from existing objects. Using augmented reality (AR) techniques, objects captured by the smart phone camera are 'tagged' manually or automatically by image processing tools. The angles of these objects relative to the user are then measured by IMU sensors. Based on these angles, we then develop an angulation algorithm to determine the location of the user. {\textcopyright} 2014 IEEE.},
annote = {cited By 0},
author = {Peng, H.-H. and Lo, C.-C. and Lin, T.-C. and Tseng, Y.-C.},
booktitle = {Proceedings - IEEE 7th International Conference on Service-Oriented Computing and Applications, SOCA 2014},
doi = {10.1109/SOCA.2014.21},
keywords = {Augmented reality; Distributed computer systems; I,Auxiliary signals; Image processing tools; Indoor,Location based services},
pages = {154--160},
title = {{Self-contained localization without auxiliary signals on smart devices}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84920518903{\&}doi=10.1109{\%}2FSOCA.2014.21{\&}partnerID=40{\&}md5=622cdd7a988382d6822e7104b13de541},
year = {2014}
}
@inproceedings{Pepe201643,
abstract = {The paper presents a system designed for micro-aerial-vehicles capable of autonomously explore an indoor environment, detect objects in the environment and build a map of the environment structure with reference to objects locations within the map. The found objects are saved in an internal database containing all previously recognized objects. The system allows fast exploration time and it is characterized by lightweight computation algorithms for the localization, map building and navigation components. The environment map is built as a set of 2D feature map layers where each layer corresponds to an environment floor. For each framework component a simulated testing scenario is presented to evaluate the capabilities of the designed algorithms. The introduced system is efficient from the computational cost point of view and allows fast exploration time that is critical for battery powered systems. {\textcopyright} 2015 IEEE.},
annote = {cited By 3},
author = {Pepe, G and Satler, M and Tripicchio, P},
booktitle = {2015 Workshop on Research, Education and Development of Unmanned Aerial Systems, RED-UAS 2015},
doi = {10.1109/RED-UAS.2015.7440989},
keywords = {Algorithms; Unmanned aerial vehicles (UAV),Autonomous exploration; Battery-powered systems;,Micro air vehicle (MAV)},
pages = {43--52},
title = {{Autonomous exploration of indoor environments with a micro-aerial vehicle}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965137534{\&}doi=10.1109{\%}2FRED-UAS.2015.7440989{\&}partnerID=40{\&}md5=ddd61ef22eafd7ffea1061687c0f87be},
year = {2016}
}
@inproceedings{Percivall:2012:CII:2345316.2345321,
address = {New York, NY, USA},
author = {Percivall, George},
booktitle = {Proceedings of the 3rd International Conference on Computing for Geospatial Research and Applications},
doi = {10.1145/2345316.2345321},
isbn = {978-1-4503-1113-7},
pages = {4:1----4:1},
publisher = {ACM},
series = {COM.Geo '12},
title = {{Connecting Islands in the Internet of Things}},
url = {http://doi.acm.org/10.1145/2345316.2345321},
year = {2012}
}
@inproceedings{Percivall:2011:EGI:1999320.1999387,
address = {New York, NY, USA},
author = {Percivall, George and Alameh, Nadine},
booktitle = {Proceedings of the 2Nd International Conference on Computing for Geospatial Research {\&} Applications},
doi = {10.1145/1999320.1999387},
isbn = {978-1-4503-0681-2},
pages = {64:1----64:1},
publisher = {ACM},
series = {COM.Geo '11},
title = {{Expanding GeoWeb to an Internet of Things}},
url = {http://doi.acm.org/10.1145/1999320.1999387},
year = {2011}
}
@inproceedings{Pers:2012:DMI:2408851.2408943,
address = {Washington, DC, USA},
author = {Pers, Janez and Kenk, Vildana Sulic and Mandeljc, Rok and Kristan, Matej and Kovacic, Stanislav},
booktitle = {Proceedings of the 2012 IEEE Ninth International Conference on Advanced Video and Signal-Based Surveillance},
doi = {10.1109/AVSS.2012.33},
isbn = {978-0-7695-4797-8},
keywords = {dataset,multi-camera,person reidentification,surveillance},
pages = {64--69},
publisher = {IEEE Computer Society},
series = {AVSS '12},
title = {{Dana36: A Multi-camera Image Dataset for Object Identification in Surveillance Scenarios}},
url = {http://dx.doi.org/10.1109/AVSS.2012.33},
year = {2012}
}
@inproceedings{4269870,
abstract = {In human-robot communication it is often important to relate robot sensor readings to concepts used by humans. We believe that access to semantic maps will make it possible for robots to better communicate information to a human operator and vice versa. The main contribution of this paper is a method that fuses data from different sensor modalities, range sensors and vision sensors are considered, to create a probabilistic semantic map of an outdoor environment. The method combines a learned virtual sensor (understood as one or several physical sensors with a dedicated signal processing unit for recognition of real world concepts) for building detection with a standard occupancy map. The virtual sensor is applied on a mobile robot, combining classifications of sub-images from a panoramic view with spatial information (location and orientation of the robot) giving the likely locations of buildings. This information is combined with an occupancy map to calculate a probabilistic semantic map. Our experiments with an outdoor mobile robot show that the method produces semantic maps with correct labeling and an evident distinction between 'building' objects from 'nature' objects.},
author = {Persson, M and Duckett, T and Valgren, C and Lilienthal, A},
booktitle = {2007 International Symposium on Computational Intelligence in Robotics and Automation},
doi = {10.1109/CIRA.2007.382870},
keywords = {building;image sensors;man-machine systems;mobile},
pages = {236--242},
title = {{Probabilistic Semantic Mapping with a Virtual Sensor for Building/Nature detection}},
year = {2007}
}
@article{Pestana2013131,
abstract = {The SECAIR project provides an event-driven architecture for dealing with spatio-temporal requirements. It adopts a multi-sensor data fusion process to handle with event streams emitting continuously location based data regarding a vast number of different business objects. It is therefore well-suited for business activity monitoring, supporting managers at analysing and processing complex event streams in real-time. A prototype applied to the surveillance of situation awareness requirements for airport environments is presented, in particular to monitor ground movements in very congested areas for indoor and outdoor areas. Outputs are presented using an advanced Graphical-User Interface, addressing a collaborative environment for airport stakeholders to manage ground handling operational procedures more efficiently and in compliance with airport business rules. {\textcopyright} 2013 ICST Institute for Computer Science, Social Informatics and Telecommunications Engineering.},
annote = {cited By 1},
author = {Pestana, G and Metter, J and Reis, P},
doi = {10.1007/978-3-642-36642-0_13},
journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering},
keywords = {Airport environment; Business Activity Monitoring;,Airport security,Airports; Digital storage; User interfaces},
pages = {131--140},
title = {{A spatio-temporal surveillance approach for business activity monitoring}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874815033{\&}doi=10.1007{\%}2F978-3-642-36642-0{\_}13{\&}partnerID=40{\&}md5=ebc27520e2e0326ccb5d00eb51745209},
volume = {109 LNICST},
year = {2013}
}
@article{PetersII1996271,
abstract = {This paper describes a hardware/software system that successfully detects certain stationary objects in an indoor scene. The system uses a four degree of freedom (4 DOF) pan-tilt-verge stereo camera head (built in-house) coupled with an inexpensive hardware image processor. A log-polar (LP) image mapping facilitates the detection of floor-wall-ceiling boundaries. The mapping also substantially reduces the data bandwidth of the input imagery by transforming a video resolution image into 64  64 pixel multiresolution image. A model matching algorithm detects the wanted object in the LP domain. If the object is in the low-resolution periphery of the LP image, the camera must be moved to center the high-resolution fovea on the object where stereo-from-vergeance can be used to calculate the distance to the object.},
annote = {cited By 4},
author = {{Peters II}, R A and Bishay, M},
doi = {10.1016/0921-8890(96)00009-7},
journal = {Robotics and Autonomous Systems},
keywords = {Algorithms; Cameras; Computer hardware; Computer s,Data bandwidth; Hardware image processor; Log pol,Mobile robots},
number = {1-2},
pages = {271--281},
title = {{Centering peripheral features in an indoor environment using a binocular log-polar 4 DOF camera head}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030195046{\&}doi=10.1016{\%}2F0921-8890{\%}2896{\%}2900009-7{\&}partnerID=40{\&}md5=41e059f20ca255e9b1e4e5f0596701a6},
volume = {18},
year = {1996}
}
@inproceedings{Petraitis2017166,
abstract = {Object and scene recognition solutions have a wide application field from entertainment apps, and medical tools to security systems. In this paper, scene recognition methods and applications are analysed, and the Bag of Words (BoW), a local image feature based scene classification model is implemented. In the BoW model every picture is encoded by a bag of visual features, which shows the quantities of different visual features of an image, but disregards any spatial information. Five different feature detectors and two feature descriptors were analyzed and two best approaches were experimentally chosen as being most effective classifying images into eight outdoor categories: forced feature detection with a grid and description using SIFT descriptor, and feature detection with SURF and description with U-SURF. Support vector machines were used for classification. We also have found that for the task of scene recognition not just the distinct features which are found by common feature detectors are important, but also the features that are uninteresting for them. Indoor scenes were experimentally classified into five categories and worse results were achieved. This shows that indoor scene classification is a much harder task and a model which does not take into account any mid-level scene information like objects of the scene is not sufficient for the task. A computer application was written in order to demonstrate the algorithm, which allows training new classifiers with different parameters and using the trained classifiers to predict the classes of new images. {\textcopyright} 2017 by SCITEPRESS - Science and Technology Publications, Lda.},
annote = {cited By 2},
author = {Petraitis, T and Maskeliunas, R and Dama{\v{s}}evi{\v{c}}ius, R and Po{\l}ap, D and Wo{\'{z}}niak, M and Gabryel, M},
booktitle = {IJCCI 2017 - Proceedings of the 9th International Joint Conference on Computational Intelligence},
keywords = {Artificial intelligence; Classification (of inform,Bag of words; Environment recognition; Local imag,Feature extraction},
pages = {166--176},
title = {{Environment recognition based on images using bag-of-words}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051246045{\&}partnerID=40{\&}md5=9ee646b210981ab761bb536f6afbf2e1},
year = {2017}
}
@inproceedings{Peursum200582,
abstract = {Traditional methods of object recognition are reliant on shape and so are very difficult to apply in cluttered, wideangle and low-detail views such as surveillance scenes. To address this, a method of indirect object recognition is proposed, where human activity is used to infer both the location and identity of objects. No shape analysis is necessary. The concept is dubbed 'interaction signatures', since the premise is that a human will interact with objects in ways characteristic of the function of that object - for example, a person sits in a chair and drinks from a cup. The human-centred approach means that recognition is possible in low-detail views and is largely invariant to the shape of objects within the same functional class. This paper implements a Bayesian network for classifying region patches with object labels, building upon our previous work in automatically segmenting and recognising a human's interactions with the objects. Experiments show that interaction signatures can successfully find and label objects in low-detail views and are equally effective at recognising test objects that differ markedly in appearance from the training objects. {\textcopyright} 2005 IEEE.},
annote = {cited By 47},
author = {Peursum, P and West, G and Venkatesh, S},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2005.57},
keywords = {Bayesian network; Human-centred approach; Image re,Clutter (information theory); Computer vision; Hu,Object recognition},
pages = {82--89},
title = {{Combining image regions and human activity for indirect object recognition in indoor wide-angle views}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745944241{\&}doi=10.1109{\%}2FICCV.2005.57{\&}partnerID=40{\&}md5=7a4df0507910f967a8302effb5d08e68},
volume = {I},
year = {2005}
}
@article{Pintore2016130,
abstract = {We present a technology to capture, reconstruct and explore multi-room indoor structures, starting from panorama images generated with the aid of commodity mobile devices. Our approach is motivated by the need for fast and effective systems to simplify indoor data acquisition, as required in many real-world cases where mapping the structure is more important than capturing 3D details, such as the design of smart houses or in the security domain.We combine and extend state-of-the-art results to obtain indoor models scaled to their real-world metric dimension, making them available for online exploration. Moreover, since our target is to assist end-users not necessarily skilled in virtual reality and 3D objects interaction, we introduce a client-server image-based navigation system, exploiting this simplified indoor structure to support a low-degree-of-freedom user interface. We tested our approach in several indoor environments and carried out a preliminary user study to assess the usability of the system by people without a specific technical background. {\textcopyright} Springer International Publishing Switzerland 2016.},
annote = {cited By 4},
author = {Pintore, G and Ganovelli, F and Gobbetti, E and Scopigno, R},
doi = {10.1007/978-3-319-48881-3_10},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Computer vision,Data acquisition; Degrees of freedom (mechanics);,Mobile systems; Safety and securities; Scene reco},
pages = {130--145},
title = {{Mobile mapping and visualization of indoor structures to simplify scene understanding and location awareness}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84996772778{\&}doi=10.1007{\%}2F978-3-319-48881-3{\_}10{\&}partnerID=40{\&}md5=6d2ec018622f6f5309ef34bf62b29c60},
volume = {9914 LNCS},
year = {2016}
}
@article{Pirkl2013128,
abstract = {Building the basic concept of a low cost, robust, indoor positioning system based on magnetic resonant coupling that we have presented in previous work we describe our entry into the EVAAL indoor location competition. The basic physical principle behind the system makes it extremely robust as the signals are hardly influenced by the human body or objects in the environment (except massive metal objects which however have mostly local influence only). Going beyond previous work we provide a detailed description of the processing architecture, show how the system can be set up on the basis of the floor-plan alone (no location specific training or measurements needed), present the software tools that can be used for system setup and application and evaluate floor plan based setup looking specifically into the influence of multiple people and changes in furniture configuration. {\textcopyright} Springer-Verlag Berlin Heidelberg 2013.},
annote = {cited By 5},
author = {Pirkl, G and Lukowicz, P},
doi = {10.1007/978-3-642-41043-7_12},
journal = {Communications in Computer and Information Science},
keywords = {Biomagnetism,Competition; Floors; Magnetic couplings; Software,Indoor localization; Indoor locations; Indoor pos},
pages = {128--140},
title = {{Indoor Localization Based on Resonant Oscillating Magnetic Fields for AAL Applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904605296{\&}doi=10.1007{\%}2F978-3-642-41043-7{\_}12{\&}partnerID=40{\&}md5=7ebd5938b1fe0d7e55dd74a9d05bced5},
volume = {386 CCIS},
year = {2013}
}
@inproceedings{Pirri:2004:IEC:3029848.3029858,
author = {Pirri, Fiora},
booktitle = {Proceedings of the Ninth International Conference on Principles of Knowledge Representation and Reasoning},
isbn = {1-57735-199-1},
pages = {73--83},
publisher = {AAAI Press},
series = {KR'04},
title = {{Indoor Environment Classification and Perceptual Matching}},
url = {http://dl.acm.org/citation.cfm?id=3029848.3029858},
year = {2004}
}
@inproceedings{6487191,
abstract = {The growth in location based services (LBS) and fast advancement in communication services has significantly increased the researchers interest in an area of the location determination. In the context-aware computing, one of the key competences is location determination. The accuracy has vital significance for localization estimation. The indoor environment requires higher degree of accuracy in comparison to the outdoor environment. The indoor environment is effected by reflection, refraction, diffraction and shadowing form obstacles by presenting difficult path to travel for RF signal. This fading and multipath propagation in radio frequency (RF) signal is because of different reasons like furniture, walls, the wired and wireless communication devices causing interference. These all problems are challenging and therefore motivate to develop an accurate indoor location estimation based on device-free location system. This research work focus to design an accurate indoor localization system for tracking the location of objects/human in indoor environment without use of any device attached.},
author = {Pirzada, N and Nayarr, M Y and Subharr, F and Hassan, M F},
booktitle = {2012 IEEE International Conference on Control System, Computing and Engineering},
doi = {10.1109/ICCSCE.2012.6487191},
keywords = {localization;location estimation technique;device-},
month = {nov},
pages = {466--472},
title = {{Design of an indoor localization system using device-free localization technique}},
year = {2012}
}
@inproceedings{Poleg:2014:TSE:2679600.2680274,
address = {Washington, DC, USA},
author = {Poleg, Yair and Arora, Chetan and Peleg, Shmuel},
booktitle = {Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2014.325},
isbn = {978-1-4799-5118-5},
pages = {2537--2544},
publisher = {IEEE Computer Society},
series = {CVPR '14},
title = {{Temporal Segmentation of Egocentric Videos}},
url = {https://doi.org/10.1109/CVPR.2014.325},
year = {2014}
}
@article{Pontikakos2006273,
abstract = {Location awareness describes applications in computing and telecommunications, which alter their behaviour in dependence on the location of an entity, such as the user of an application, a person the user of the application wants to communicate with, or an object capable of changing a location. Such location presents a major category of context and it is derived by various methods of positioning. Over the past two decades, positioning has been a driving factor in the development of ubiquitous computing applications demanding such location information. Many devices and techniques have been developed; however, very few of them are actually used commercially. This is because the precision is limited to specific applications, and the availability limited to the provider of specific services. Obviously, to support efficient and effective development and deployment of innovative Location-Based Services (LBSs), namely, services able to deliver personalized location-aware content to subscribers on the basis of their positioning capability of the wireless infrastructure, a flexible middleware should be build as the enabling infrastructure. This work examines various systems of LBSs focusing on their architecture characteristics and the different governing platforms and technologies on which they are based. The goal is to contribute towards the development of an architecture that combines numerous individual positioning technologies to obtain more precise and more reliable results according to the various needs of the whole range of LBSs. The general concepts of these system are discussed by presenting a first level of classification which depends on the positioning infrastructure namely, indoor, satellite or network-based configuration. Several specific LBS architectures are categorized by means of the various characteristics regarding the design and functionality of each one. Position is combined with spatial information so as to integrate a system of LBSs with Geographical Information Systems (GIS) or other location dependent information. Finally, to increase interoperability among the various systems and technologies, standardization and homogenization is also taken under consideration. {\textcopyright} Dynamic Publishers, Inc.},
annote = {cited By 0},
author = {Pontikakos, C and Sambrakos, M and Glezakos, T and Tsiligiridis, T},
journal = {Neural, Parallel and Scientific Computations},
number = {2-3},
pages = {273--290},
title = {{Location-based services: A framework for an architecture design}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34249291634{\&}partnerID=40{\&}md5=c0a7c0f33a68feed0f594783fea2f54b},
volume = {14},
year = {2006}
}
@inproceedings{8406705,
abstract = {The analog to digital migration of the broadcasting technologies allows broadcasters to offer interactive services with an advanced level of personalization. Within this context, the possibility to deliver commercial content to more devices into the same domestic environment is very interesting for both consumers and service providers. Several compatibility studies have identified the joint use of detection techniques (i.e., spectrum sensing) and geo-location databases as a reliable way to enable harmless communications in the free channels in each territorial area, the so called TV White Spaces (TVWS). Based on these assumptions we developed a novel cooperative system based on an Internet of Things (IoT) architecture able to involve all sensing-enabled objects in a distributed sensing procedure. In this work, we involve all IoT-enabled objects in a twofold procedure, using both spectrum sensing and Quality of Service (QoS) data delivered by the objects.},
author = {Popescu, V and Fadda, M and Nitti, M},
booktitle = {2018 Baltic URSI Symposium (URSI)},
doi = {10.23919/URSI.2018.8406705},
keywords = {cooperative communication;indoor communication;Int},
pages = {69--70},
title = {{QoS feedback mechanism for a cooperative indoor D2D system}},
year = {2018}
}
@article{Porto:2014:LIP:2943802.2944058,
address = {Amsterdam, The Netherlands, The Netherlands},
author = {Porto, S M C and Arcidiacono, C and Giummarra, A and Anguzza, U and Cascone, G},
doi = {10.1016/j.compag.2014.08.001},
issn = {0168-1699},
journal = {Comput. Electron. Agric.},
keywords = {Animal behaviour,Animal tracking,AoAAngle-of-Arrival,Behavioural indices,HFHigh Frequency,HTTPhypertext transfer protocol,IDIdentification number,LECLocation Engine Configurator,OpenCVOpen source Computer Vision,PoEPower-over-Ethernet,RFIDRadio Frequency Identification,RTLSReal-Time Location System,TDoATime Difference of Arrival,UHFUltra-High Frequency,UIuser interface,UWB tag,UWBUltra Wide Band,fpsframe per second},
number = {C},
pages = {221--229},
publisher = {Elsevier Science Publishers B. V.},
title = {{Localisation and Identification Performances of a Real-time Location System Based on Ultra Wide Band Technology for Monitoring and Tracking Dairy Cow Behaviour in a Semi-open Free-stall Barn}},
url = {https://doi.org/10.1016/j.compag.2014.08.001},
volume = {108},
year = {2014}
}
@article{Potgantwar2016319,
abstract = {In today's era finding the location and navigation of an object is essential for many reasons. The primary reason is locating the object, and navigation helps systems to make decisions faster. Secondary reason is we may detect fault and posses faster processing and operation. Another side of development and research is for cost-effective techniques involving indoor and outdoor systems. Many researchers are working on indoor positioning and developing lightweighted solutions using radio frequencies. Managing and monitoring radio frequencies in an indoor system have physical barriers; they also have some technological limitations where we can provide solutions. The solutions for indoor localization and tracking are GPS signal, Bluetooth, infrared, RFID, and wireless LAN. All these radio frequencies deal with a crucial issue of gaining RSS (Received Signal Strength). In this work, we are focusing on RFID-based indoor environment where RSS is our main attention, we also target on gaining efficiency and accuracy, stability, robustness. The proposed algorithm of this work is mainly targeting with directional antenna by which we can overcome the physical and other barriers of radio frequency. These kinds of indoor environments such as health care, loyalty management system, automatic parking allotment system, tracking services for older people, or customers inside living communities, mobile robot, logistics system, etc., can be facilitated using directional antenna and RFID tagging for navigation indoor positioning. {\textcopyright} Springer Science+Business Media Singapore 2016.},
annote = {cited By 0},
author = {Potgantwar, A D and Wadhai, V M},
doi = {10.1007/978-981-10-0129-1_34},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Antennas; Cost effectiveness; Directive antennas;,DAWN; Directional Antenna; Indoor environment; In,Indoor positioning systems},
pages = {319--328},
title = {{Improved indoor positioning using RSS and directional antenna integrating with RFID and wireless technology}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958979913{\&}doi=10.1007{\%}2F978-981-10-0129-1{\_}34{\&}partnerID=40{\&}md5=ac1207fe5fea779ea575c8d18aa3c4d9},
volume = {408},
year = {2016}
}
@inproceedings{Pradhan2009115,
abstract = {Indoor localization, a process of determining the location of a user or an object, is important for different types of applications, such as localization of first responders inside a building, ubiquitous computing and tracking of materials in an enclosed warehouse. Different types of technologies based on ultrasound waves, infrared waves and radio signals are currently used for indoor localization. The technology based on radio signal strength is widely used as a mechanism for localization. Currently existing technologies are not able to provide localization accurately within a few meters as they are prone to different types of signal propagation problems, and they often rely on prior data on localization. To improve localization accuracy and avoid collecting prior localization data, the authors investigated an alternative technology which combines an inertial measurement system and correction points for indoor localization. The authors have developed and tested an approach based on a Kaiman filter to fuse location data from correction points and an inertial measurement system for outdoor localization. The outdoor test results of the presented approach showed that accuracy up to a few meters (3 meters) can be achieved. The same approach can be used for indoor localization with minor changes. {\textcopyright} 2009 ASCE.},
annote = {cited By 4},
author = {Pradhan, A and Akinci, B and {Garrett Jr.}, J H},
booktitle = {Proceedings of the 2009 ASCE International Workshop on Computing in Civil Engineering},
doi = {10.1061/41052(346)12},
keywords = {Alternative technologies; First responders; Indoor,Civil engineering; Technology,Ubiquitous computing},
pages = {115--124},
title = {{Development and testing of inertial measurement system for indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350158826{\&}doi=10.1061{\%}2F41052{\%}28346{\%}2912{\&}partnerID=40{\&}md5=c9a60938fb577e03f4be17cc2cd97075},
volume = {346},
year = {2009}
}
@article{Pradhan2009230,
abstract = {Indoor localization is needed for guiding people who are not familiar with a facility. This need is more critical when guidance is needed to locate people or objects that need immediate attention. For example, an inexperienced facility worker might need to locate a building component (e.g., leaking pipe) for repair to prevent any damage to a facility or its residents. In such situations, an approach that can help the user to reach his/her destination point (i.e., a component of interest or a specific location in a facility) based on his/her current location is desired. To provide such guidance, the location of a person needs to be determined at a given point in time. This process is known as localization. The objective of this research study is to determine the technological viability of using radio frequency identification (RFID) to support localization. To assess the capability of RFID for localization, the writers conducted multiple field tests under real operating conditions within a facility at Carnegie Mellon University. Hypothesis tests and K -nearest neighborhood algorithm were used to determine the technological feasibility of RFID to support localization. The results showed that it is possible to identify the location of a user using this approach; however, some improvements in accuracy are needed. {\textcopyright} 2009 ASCE.},
annote = {cited By 74},
author = {Pradhan, A and Ergen, E and Akinci, B},
doi = {10.1061/(ASCE)0887-3801(2009)23:4(230)},
journal = {Journal of Computing in Civil Engineering},
keywords = {Automatic identification system; Carnegie Mellon U,Automation; Data acquisition; Electronic data int,Evolutionary algorithms},
number = {4},
pages = {230--238},
title = {{Technological assessment of radio frequency identification technology for indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-67651012119{\&}doi=10.1061{\%}2F{\%}28ASCE{\%}290887-3801{\%}282009{\%}2923{\%}3A4{\%}28230{\%}29{\&}partnerID=40{\&}md5=c332c58522af2f70787f2c3d3ae9000c},
volume = {23},
year = {2009}
}
@book{Preisach:2008:DAM:1383516,
author = {Preisach, Christine and Burkhardt, Hans and Schmidt-Thieme, Lars and Decker, Reinhold},
edition = {1},
isbn = {3540782397, 9783540782391},
publisher = {Springer Publishing Company, Incorporated},
title = {{Data Analysis, Machine Learning and Applications: Proceedings of the 31st Annual Conference of the Gesellschaft Fr Klassifikation e.V., Albert-Ludwigs-Universitt ... Data Analysis, and Knowledge Organization)}},
year = {2008}
}
@inproceedings{Pujar2018,
abstract = {There has been significant progress in recognition of outdoor scenes but indoor scene recognition is still an challenge. This is due to the high appearance fluctuation of indoor situations. With the recent developments in indoor and mobile robotics, identifying the indoor scenes has gained importance. Many approaches have been proposed to detect scenes using object detection and geotags. In contrast, the proposal of this paper uses the convolutional neural network which has gained importance with advancement in machine learning methodologies. Our method has higher efficiency than the existing models as we try to classify the environment as a whole rather than using object identification for the same. We test this approach on our dataset which consists of RGB and also depth images of common locations present in academic environments such as class rooms, labs etc. The proposed approach performs better than previous ones with accuracy up to 98{\%}. {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Pujar, K and Chickerur, S and Patil, M S},
booktitle = {2017 IEEE International Conference on Computational Intelligence and Computing Research, ICCIC 2017},
doi = {10.1109/ICCIC.2017.8524231},
keywords = {Academic environment; Convolutional neural networ,Convolution; Image classification; Neural networks,Deep learning},
title = {{Combining RGB and Depth Images for Indoor Scene Classification Using Deep Learning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057984189{\&}doi=10.1109{\%}2FICCIC.2017.8524231{\&}partnerID=40{\&}md5=c2d7b27f7088bd291b8eb65c0775e9b6},
year = {2018}
}
@article{Qi20181391,
abstract = {The design and implementation of an indoor location system based on wireless sensor networks(WSN) and ultrasonic are studied. The distance between the locating object and the anchor node is calculated using time of flight(ToF) and velocity of ultrasonic. Then the trilateration localization is applied to compute coordinates. The envelope detection method is used to measure ToF, which treats the highest value point of the envelope signal as the arrival time. Considering the effect of noise in the actual circuit, the measured value will fluctuate at the actual peak, it affects the stability and precision of the system. The digital lock-in amplifying technique is adopted in this paper, the result of experiment and simulation show that this method can reduce the effects of noise and interference, and improve greatly the positioning accuracy and the capacity of anti-jamming compared with the existing methods. Without considering the ultrasonic radiation, the distance measurement error is within 2 mm, and the standard deviation is less than 0.15 mm in the experiments, which is reduced about 50{\%} comparing with the best result achieved currently 0.3 mm. {\textcopyright} 2018, Editorial Office of Control and Decision. All right reserved.},
annote = {cited By 0},
author = {Qi, J and Liu, G.-P.},
doi = {10.13195/j.kzyjc.2017.0514},
journal = {Kongzhi yu Juece/Control and Decision},
keywords = {Anchor nodes; Design and implementations; Effect,Indoor positioning systems; Sensor nodes; Ultrason,Ultrasonic applications},
number = {8},
pages = {1391--1398},
title = {{Design and implementation of an indoor localization system based on wireless sensor networks and ultrasonic []}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057072775{\&}doi=10.13195{\%}2Fj.kzyjc.2017.0514{\&}partnerID=40{\&}md5=9769ac4cf420fbd9bf6b0d6feda89bd7},
volume = {33},
year = {2018}
}
@inproceedings{Qin:2008:MET:1437900.1438746,
address = {Washington, DC, USA},
author = {Qin, Hang and Du, Youfu},
booktitle = {Proceedings of the 2008 Second International Conference on Genetic and Evolutionary Computing},
doi = {10.1109/WGEC.2008.13},
isbn = {978-0-7695-3334-6},
keywords = {Indoor positioning,Pareto optimality,evolutionary algorithm,fingerprint,multiobjective optimization},
pages = {42--46},
publisher = {IEEE Computer Society},
series = {WGEC '08},
title = {{A Multiobjective Evolutionary Tracking Indoor Positioning Algorithm for Smart Space}},
url = {https://doi.org/10.1109/WGEC.2008.13},
year = {2008}
}
@article{Qiu2015,
abstract = {Real-time location system (RLS) based on RFID is an effective indoor positioning system. The battery-free and low cost UHF passive tags can be attached on almost any objects, which are recognized as the best medium to achieve high precision ranging and positioning for large-scale objects. This paper proposes an indoor range measurement based on multifrequency phase difference of arrival (MF-PDoA) using UHF RFID passive tags and discusses the measurement principle, experiment implementation, and results evaluation in detail. After a theoretical overview of MF-PDoA range measurement principle, it introduces an experimental prototype under EPC C1G2 standard for range measurements. Both our prototype and a commercial off-the-shelf RFID reader have been used to verify the measurement method. We propose a Kalman filter and weighting method to process the measuring data. Experiment results indicate that, in a real environment, this method can effectively improve the ranging accuracy, which lays a foundation to extend the proposed measurement into two to three dimensions indoor object positioning. {\textcopyright} 2015 Lanxin Qiu et al.},
annote = {cited By 3},
author = {Qiu, L and Huang, Z and Zhang, S and Jing, C and Li, H and Li, S},
doi = {10.1155/2015/715307},
journal = {International Journal of Distributed Sensor Networks},
keywords = {Commercial off the shelves; Epc c1g2 standards; E,Sensor networks,Telecommunication networks},
title = {{Multifrequency phase difference of arrival range measurement: Principle, implementation, and evaluation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947597763{\&}doi=10.1155{\%}2F2015{\%}2F715307{\&}partnerID=40{\&}md5=3f4dc4bf854148cd82c43126e0cb40f5},
volume = {2015},
year = {2015}
}
@article{Qiu:2016:MPD:2930210.2930219,
address = {London, UK, United Kingdom},
author = {Qiu, Lanxin and Huang, Zhangqin and Zhang, Shaohua and Jing, Cheng and Li, Hao and Li, Shuyao},
doi = {10.1155/2015/715307},
issn = {1550-1329},
journal = {Int. J. Distrib. Sen. Netw.},
pages = {9:9----9:9},
publisher = {Hindawi Limited},
title = {{Multifrequency Phase Difference of Arrival Range Measurement: Principle, Implementation, and Evaluation}},
url = {https://doi.org/10.1155/2015/715307},
volume = {2015},
year = {2016}
}
@inproceedings{Rafiee2013742,
abstract = {Indoor physical security, as a perpetual and multi-layered phenomenon, is a timeintensive and labor-consuming task. Various technologies have been leveraged to develop automatic access control, intrusion detection, or video monitoring systems. Video surveillance has been significantly enhanced by the advent of Pan-Tilt-Zoom (PTZ) cameras and advanced video processing, which together enable effective monitoring and recording. The development of ubiquitous object identification and tracking technologies provide the opportunity to accomplish automatic access control and tracking. Intrusion detection has also become possible through deploying networks of motion sensors for alerting about abnormal behaviors. However, each of the above-mentioned technologies has its own limitations. This paper presents a fully automated indoor security solution that leverages an Ultra-wideband (UWB) Real-Time Locating System (RTLS), PTZ surveillance cameras and a Building Information Model (BIM) as three sources of environmental data. Providing authorized persons with UWB tags, unauthorized intruders are distinguished as the mismatch observed between the detected tag owners and the persons detected in the video, and intrusion alert is generated. PTZ cameras allow for wide-area monitoring and motion-based recording. Furthermore, the BIM is used for space modeling and mapping the locations of intruders in the building. Fusing UWB tracking, video and spatial data can automate the entire security procedure from access control to intrusion alerting and behavior monitoring. Other benefits of the proposed method include higher accuracy and robustness, more complex query processing, and interoperability with other BIM-based solutions. A prototype system is implemented that demonstrates the feasibility of the proposed method.},
annote = {cited By 0},
author = {Rafiee, M and Siddiqui, H and Hammad, A},
booktitle = {ISARC 2013 - 30th International Symposium on Automation and Robotics in Construction and Mining, Held in Conjunction with the 23rd World Mining Congress},
keywords = {Access control; Architectural design; Automation;,BIM; Building Information Model - BIM; Indoors sec,Ultra-wideband (UWB)},
pages = {742--752},
title = {{Improving indoor security surveillance by fusing data from BIM, UWB and video}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893536518{\&}partnerID=40{\&}md5=6f33a77ae29f8fec5414b762467290bf},
year = {2013}
}
@article{RafinaDestiarti2018520,
abstract = {Tracking system is one of concerning issue in wireless sensor network (WSN) application. The accuracy of the location estimation from nodes is important parameter in tracking system. However, many various attacks try to manipulate the estimated location or try to provide false nodes data transmission. The secure and privacy data sharing of the estimation is also become another priority in WSN. Hence, this paper focuses on employing secure wireless object tracking (SWOT) system which is added by the reliable method in privacy data sharing. By proposing the transmission system based cryptographic mechanism, some parameter data that are required in estimated calculation such as RSSI, coordinates, pathloss exponent (PLE), and estimated distance will be hidden using encryption process. Due to the limited computational device, we propose security scheme without raising computational capability. Layered encryption using AES 128, RSA 2048, MD5 and SHA-1 provide high performance authentication and data encryption services for each nodes. Implementing mobile cooperative tracking scenario refers to previous work, the proposed security scheme is efficient in terms of processing time which could not influenced to the estimated location accuracy. Moreover, the authentication protocol which is adopted from one time password scenario can apply the key renewal mechanism for AES 128 and MD5 algorithm. The experimental results show that SWOT system achieves 75.95 ms processing time using Raspberry Pi devices including trilateration algorithm and security process. Meanwhile, PC server consumes around 82.7 ms for decrypting, calculating and showing the estimated position by modified iterated extended Kalman filter (IEKF) algorithm. {\textcopyright} IJASEIT.},
annote = {cited By 1},
author = {{Rafina Destiarti}, A and Kristalina, P and Sudarsono, A},
doi = {10.18517/ijaseit.8.2.5268},
journal = {International Journal on Advanced Science, Engineering and Information Technology},
number = {2},
pages = {520--531},
title = {{SWOT: Secure wireless object tracking with key renewal mechanism for indoor wireless sensor network}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046552024{\&}doi=10.18517{\%}2Fijaseit.8.2.5268{\&}partnerID=40{\&}md5=f0227bce358e179861ad6657f2481809},
volume = {8},
year = {2018}
}
@inproceedings{5583565,
abstract = {The prevalent visions of ambient intelligence leverage natural interaction between user and available services in a learning space. In this pursuit, we present a framework for augmenting physical objects with annotated information in order to improve physical browsing. The proposed system incorporates an intuitive camera based annotation scheme to catalog and author information about the physical learning objects in an environment. Each annotated data is encoded in such a way that they provide access points for available information or services about the physical objects. The system uses adequate visual cues and provides tactile feedback in order to leverage the touch-based interactions with the objects. These real world interaction techniques with the physical environment and seamless virtual learning information acquisition make the system transparent from the young learners and help them to become engaged in their learning activities.},
author = {Rahman, A M and Saddik, A E},
booktitle = {2010 IEEE International Conference on Multimedia and Expo},
doi = {10.1109/ICME.2010.5583565},
issn = {1945-788X},
keywords = {computer aided instruction;information retrieval;i},
pages = {436--441},
title = {{Touch me interaction paradigm for physically browsing personal learning spaces}},
year = {2010}
}
@phdthesis{Rajagopalan:2008:MOA:1559152,
address = {Syracuse, NY, USA},
annote = {AAI3323077},
author = {Rajagopalan, Ramesh},
isbn = {978-0-549-74262-3},
publisher = {Syracuse University},
title = {{A Multi-objective Optimization Approach for Sensor Network Design}},
year = {2008}
}
@article{Ramachandran2018203,
abstract = {Literature indicates that frequency diversity can be utilized to compensate channel uncertainties such as multipath fading. Therefore, in this paper it is exploited for improving accuracy in locating stationary and mobile objects in the indoor environment. First, frequency diversity technique is introduced for small scale and temporal variation compensation of received signals and it is demonstrated analytically to enhance location accuracy. A novel metric is introduced in selection combining in order to achieve location accuracy through the addition of frequency diversity upon two of the available location determination schemes. The results are evaluated experimentally against the case where there is no frequency diversity for reception by using low cost wireless RF devices such as motes. An asset location tracking system is then devised to both improve accuracy and predict asset movement. Frequency diversity in terms of channel spacing of 55 MHz is evaluated and shown to provide a reduction in location determination error between 18 to 23{\%} when compared to a system without frequency diversity. Finally, results from frequency diversity are compared against the spatial diversity techniques in terms of improvement in location accuracy, power consumption of the transmitter, and hardware and software costs. {\textcopyright} 2007 Old City Publishing, Inc.},
annote = {cited By 1},
author = {Ramachandran, A and Jagannathan, S},
journal = {Ad-Hoc and Sensor Wireless Networks},
number = {3-4},
pages = {203--233},
title = {{Use of frequency diversity in signal strength based location determination}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78751616360{\&}partnerID=40{\&}md5=4c22d715e5a08498da1c74018d52b757},
volume = {5},
year = {2018}
}
@inproceedings{Ramesh2018122,
abstract = {The aim of this research is to design an intelligent system that addresses the problem of real-time localization and navigation of visually impaired (VI) in an indoor environment using a monocular camera. Systems that have been developed so far for the VI use either many cameras (stereo and monocular) integrated with other sensors or use very complex algorithms that are computationally expensive. In this research work, a computationally less expensive integrated system has been proposed to combine imaging geometry, Visual Odometry (VO), Object Detection (OD) along with Distance-Depth (D-D) estimation algorithms for precise navigation and localization by utilizing a single monocular camera as the only sensor. The developed algorithm is tested for both standard Karlsruhe and indoor environment recorded datasets. Tests have been carried out in real-time using a smartphone camera that captures image data of the environment as the person moves and is sent over Wi-Fi for further processing to the MATLAB software model running on an Intel i7 processor. The algorithm provides accurate results on real-time navigation in the environment with an audio feedback about the person's location. The trajectory of the navigation is expressed in an arbitrary scale. Object detection based localization is accurate. The D-D estimation provides distance and depth measurements up to an accuracy of 94-98{\%}. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Ramesh, K and Nagananda, S N and Ramasangu, H and Deshpande, R},
booktitle = {2018 5th International Conference on Industrial Engineering and Applications, ICIEA 2018},
doi = {10.1109/IEA.2018.8387082},
keywords = {Cameras; Computer vision; Engineering research; Im,Estimation algorithm; KLT tracker; Monocular came,Stereo image processing},
pages = {122--128},
title = {{Real-time localization and navigation in an indoor environment using monocular camera for visually impaired}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050139861{\&}doi=10.1109{\%}2FIEA.2018.8387082{\&}partnerID=40{\&}md5=baa1ed95f7a805ec5cb0e63680051c8b},
year = {2018}
}
@article{Ramirez-Serrano2008246,
abstract = {Purpose - The purpose of this paper is to address the online localization of mobile (service) robots in real world dynamic environments. Most of the techniques developed so far have been designed for static environments. What is presented here is a novel technique for mobile robot localization in quasi-dynamic environments. Design/methodology/approach - The proposed approach employs a probability grid map and Baye's filtering techniques. The former is used for representing the possible changes in the surrounding environment which a robot might have to face. Findings - Simulation and experimental results show that this approach has a high degree of robustness by taking into account both sensor and world uncertainty. The methodology has been tested under different environment scenarios where diverse complex objects having different sizes and shapes were used to represent movable and non-movable entities. Practical implications - The results can be applied to diverse robotic systems that need to move in changing indoor environments such as hospitals and places where people might require assistance from autonomous robotic devices. The methodology is fast, efficient and can be used in fast-moving robots, allowing them to perform complex operations such as path planning and navigation in real time. Originality/value - What is proposed here is a novel mobile robot localization approach that enables unmanned vehicles to effectively move in real time and know their current location in dynamic environments. Such an approach consists of two steps: a generation of the probability grid map; and a recursive position estimation methodology employing a variant of the Baye's filter. {\textcopyright} Emerald Group Publishing Limited.},
annote = {cited By 6},
author = {Ramirez-Serrano, A and Liu, H and Pettinaro, G C},
doi = {10.1108/01439910810868570},
journal = {Industrial Robot},
keywords = {Baye's filtering; Mobile robot localization; Onli,Bayesian networks; Probability; Robotics; Sensors,Mobile robots},
number = {3},
pages = {246--258},
title = {{Mobile robot localization in quasi-dynamic environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-42549136478{\&}doi=10.1108{\%}2F01439910810868570{\&}partnerID=40{\&}md5=d20eeec25bcf6fb35c5e561ca52f2d62},
volume = {35},
year = {2008}
}
@phdthesis{Randeniya:2007:AGI:1368776,
address = {Tampa, FL, USA},
annote = {AAI3292574},
author = {Randeniya, Duminda I B},
isbn = {978-0-549-35595-3},
publisher = {University of South Florida},
title = {{Automatic Geo-referencing by Integrating Camera Vision and Inertial Measurements}},
year = {2007}
}
@inproceedings{Ranganathan20081,
abstract = {While robot mapping has seen massive strides recently, higher level abstractions in map representation are still not widespread. Maps containing semantic concepts such as objects and labels are essential for many tasks in manmade environments as well as for human-robot interaction and map communication. In keeping with this aim, we present a model for places using objects as the basic unit of representation. Our model is a 3D extension of the constellation object model, popular in computer vision, in which the objects are modeled by their appearance and shape. The 3D location of each object is maintained in a coordinate frame local to the place. The individual object models are learned in a supervised manner using roughly segmented and labeled training images. Stereo range data is used to compute 3D locations of the objects. We use the Swendsen-Wang algorithm, a cluster MCMC method, to solve the correspondence problem between image features and objects during inference. We provide a technique for building panoramic place models from multiple views of a location. An algorithm for place recognition by comparing models is also provided. Results are presented in the form of place models inferred in an indoor environment.We envision the use of our place model as a building block towards a complete object-based semantic mapping system.},
annote = {cited By 11},
author = {Ranganathan, A and Dellaert, F},
booktitle = {Robotics: Science and Systems},
pages = {1--8},
title = {{Semantic modeling of places using objects}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959297413{\&}partnerID=40{\&}md5=0f1cf99344354b0a10985db9de5e2bfd},
volume = {3},
year = {2008}
}
@article{Raper2007836,
abstract = {Purpose - The purpose of this paper concerns the dimensions of relevance in information retrieval systems and their completeness in new retrieval contexts such as mobile search. Geography as a factor in relevance is little understood and information seeking is assumed to take place in indoor environments. Yet the rise of information seeking on the move using mobile devices implies the need to better understand the kind of situational relevance operating in this kind of context. Design/methodology/approach - The paper outlines and explores a geographic information seeking process in which geographic information needs (conditioned by needs and tasks, in context) drive the acquisition and use of geographic information objects, which in turn influence geographic behaviour in the environment. Geographic relevance is defined as "a relation between a geographic information need" (like an attention span) and "the spatio-temporal expression of the geographic information objects needed to satisfy it" (like an area of influence). Some empirical examples are given to indicate the theoretical and practical application of this work. Findings - The paper sets out definitions of geographical information needs based on cognitive and geographic criteria, and proposes four canonical cases, which might be theorised as anomalous states of geographic knowledge (ASGK). The paper argues that geographic relevance is best defined as a spatio-temporally extended relation between information need (an "attention" span) and geographic information object (a zone of "influence"), and it defines four domains of geographic relevance. Finally a model of geographic relevance is suggested in which attention and influence are modelled as map layers whose intersection can define the nature of the relation. Originality/value - Geographic relevance is a new field of research that has so far been poorly defined and little researched. This paper sets out new principles for the study of geographic information behaviour. {\textcopyright} Emerald Group Publishing Limited.},
annote = {cited By 36},
author = {Raper, J},
doi = {10.1108/00220410710836385},
journal = {Journal of Documentation},
number = {6},
pages = {836--852},
title = {{Geographic relevance}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548488705{\&}doi=10.1108{\%}2F00220410710836385{\&}partnerID=40{\&}md5=0662b5aaf77d7d73c2592fd532015623},
volume = {63},
year = {2007}
}
@inproceedings{Rashid2015139,
abstract = {We present a data driven approach to holistic scene understanding. From a single image of an indoor scene, our approach estimates its detailed 3D geometry, i.e. the location of its walls and floor, and the 3D appearance of its containing objects, as well as its semantic meaning, i.e. a prediction of what objects it contains. This is made possible by using large datasets of detailed 3D models alongside appearance based detectors. We first estimate the 3D layout of a room, and extrapolate 2D object detection hypotheses to three dimensions to form bounding cuboids. Cuboids are converted to detailed 3D models of the predicted semantic category. Combinations of 3D models are used to create a large list of layout hypotheses for each image-where each layout hypothesis is semantically meaningful and geometrically plausible. The likelihood of each layout hypothesis is ranked using a learned linear model-and the hypothesis with the highest predicted likelihood is the final predicted 3D layout. Our approach is able to recover the detailed geometry of scenes, provide precise segmentation of objects in the image plane, and estimate objects' pose in 3D. {\textcopyright} 2014 IEEE.},
annote = {cited By 0},
author = {Rashid, M and Hebert, M},
booktitle = {Proceedings - 2014 International Conference on 3D Vision, 3DV 2014},
doi = {10.1109/3DV.2014.32},
keywords = {Appearance based; Data-driven approach; Large dat,Image segmentation; Semantics,Object detection},
pages = {139--146},
title = {{Detailed 3D model driven single view scene understanding}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925332995{\&}doi=10.1109{\%}2F3DV.2014.32{\&}partnerID=40{\&}md5=cd8e1c0d63333122c0c6e94fa9733c68},
year = {2015}
}
@inproceedings{Rty20081011,
abstract = {The Area of Interest (AoI) is a distributed scalable video transmission subsystem, for a surveillance system, which concentrates on decrementing the amount of video information transmitted to the end-user equipped with a mobile device. The video information is processed by the Video Surveillance Intelligent Platform (VSIP) to discriminate the essential images of the indoor area under stationary video surveillance. The AoI system analyzes the output of the VSIP's images and extended Markup Language (XML) image information. The AoI system is able to define and extract the essential information, e.g., a tracked individual, and it transmits only this image to the end-user. First, the AoI transmits the entire image of the indoor area to the mobile device of the end-user. Then, the AoI system transmits only the secluded tracked objects' images to the mobile device. The end-user's device portrays the scaled portrait images of the targeted object on top of the background image. The AoI system endeavors to decrease the size of the video images transmitted to a smart phone over a wireless network and to retain the comprehension of a tracking situation. The operability of the constructed prototype indicates that this endeavor is attained. The research is based on the constructive method of the related publications and technologies and the results are derived by the implemented AoI system. {\textcopyright} 2008 IEEE.},
annote = {cited By 4},
author = {R{\"{a}}ty, T and Lehikoinen, L and Bremond, F},
booktitle = {Proceedings - International Conference on Information Technology: New Generations, ITNG 2008},
doi = {10.1109/ITNG.2008.11},
keywords = {Cooperative information systems; Intelligent senso,Information retrieval systems; Mobile telecommuni,Multimedia systems},
pages = {1011--1016},
title = {{Scalable video transmission for a surveillance system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-44049085358{\&}doi=10.1109{\%}2FITNG.2008.11{\&}partnerID=40{\&}md5=6f9f45c7efe67f2a0130c9197aad42ca},
year = {2008}
}
@article{Rea2019201,
abstract = {We consider an environment strongly affected by the presence of metallic objects, that can be considered representative of an indoor industrial environment with metal obstacles. This scenario is a very harsh environment where radio communication has notorious difficulties, as metallic objects create a strong blockage component and surfaces are highly reflective. In this environment, we investigate how to dynamically allocate MAC resources in time to static and mobile users based on context awareness extracted from a legacy WiFi positioning system. In order to address this problem, we integrate our WiFi ranging and positioning system in the WiSHFUL architecture and then define a hypothesis test to declare if the link is in line-of-sight (LOS) or non-line-of-sight (NLOS) based on angular information derived from ranging and position information. We show that context information can help increase the network throughput in the above industrial-like scenario. {\textcopyright} ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2019.},
annote = {cited By 0},
author = {Rea, M and Garlisi, D and Cordob{\'{e}}s, H and Giustiniano, D},
doi = {10.1007/978-3-030-05195-2_20},
journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
keywords = {Broadband networks,Context information; Context- awareness; Indoor l,Mobile telecommunication systems; Radio communicat},
pages = {201--211},
title = {{Location-aware MAC scheduling in industrial-like environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059748108{\&}doi=10.1007{\%}2F978-3-030-05195-2{\_}20{\&}partnerID=40{\&}md5=75d805ce4f7f6bdd1d89b2421b5a663a},
volume = {263},
year = {2019}
}
@inproceedings{Reddy2017353,
abstract = {The advent of indoor personal mobile robots has clearly demonstrated their utility in assisting humans at various places such as workshops, offices, homes, etc. One of the most important cases in such autonomous scenarios is where the robot has to search for certain objects in large rooms. Exploring the whole room would prove to be extremely expensive in terms of both computing power and time. To address this issue, we demonstrate a fast algorithm to reduce the search space by identifying possible object locations as two classes, namely - Support Structures and Clutter. Support Structures are plausible object containers in a scene such as tables, chairs, sofas, etc. Clutter refers to places where there seem to be several objects but cannot be clearly distinguished. It can also be identified as unorganized regions which can be of interest for tasks such as robot grasping, fetching and placing objects. The primary contribution of this paper is to quickly identify potential object locations using a Support Vector Machine(SVM) learnt over the features extracted from the depth map and the RGB image of the scene, which further culminates into a densely connected Conditional Random Field(CRF) formulated over the image of the scene. The inference over the CRF leads to assignment of the labels - support structure, clutter, others to each pixel. There have been reliable outcomes even during challenging scenarios such as the support structures being far from the robot. The experiments demonstrate the efficacy and speed of the algorithm irrespective of alterations to camera angles, modifications to appearance change, lighting and distance from locations etc. Copyright {\textcopyright} 2017 by SCITEPRESS - Science and Technology Publications, Lda. All rights reserved.},
annote = {cited By 0},
author = {Reddy, S and Gandhi, V and Krishna, M},
booktitle = {VISIGRAPP 2017 - Proceedings of the 12th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
keywords = {Clutter (information theory); Computation theory;,Computer vision,Conditional random field; Personal mobile robots;},
pages = {353--361},
title = {{3D Region proposals for selective object search}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047862772{\&}partnerID=40{\&}md5=2916e89f960c06294fbf482ad68ecb20},
volume = {5},
year = {2017}
}
@article{Rehman200773,
abstract = {The functionality of architectural framework developed by computer laboratory of the Univerity of Cambridge, for interactive context-aware applications, is discussed. Architecure is based on the Model-View-Controller (MVC) paradigm. Architectural framework use the SPIRIT (Spatially Indexed Resource Indentification and Tracking) backend, which maintain a world model based on sensor's real-world observations. It uses an indoor ultrasound location system for tracking small tags. SPIRIT evaluates spatial relationships between objects and people in the world model. MVC enables users to represent a model in multiple ways by attaching multiple views. It makes communication between the user and application more intelligible. It allows designers to use object-oriented design to construct and communicate domain models. It provides a set of abstractions such as the context component to simplify the process of communicating the application's workings to the user.},
annote = {cited By 30},
author = {Rehman, K and Stajano, F and Coulouris, G},
doi = {10.1109/MPRV.2007.5},
journal = {IEEE Pervasive Computing},
keywords = {Communication; Interactive computer systems; Prog,Computer architecture,Computer laboratory; Object oriented design; Ultra},
number = {1},
pages = {73--80},
title = {{An architecture for interactive context-aware applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847733527{\&}doi=10.1109{\%}2FMPRV.2007.5{\&}partnerID=40{\&}md5=16a2257b4f0f05d5734069c4725eadfb},
volume = {6},
year = {2007}
}
@inproceedings{Reitmayr:2003:LBA:820086.820103,
address = {Darlinghurst, Australia, Australia},
author = {Reitmayr, Gerhard and Schmalstieg, Dieter},
booktitle = {Proceedings of the Fourth Australasian User Interface Conference on User Interfaces 2003 - Volume 18},
isbn = {0-909925-96-8},
keywords = {augmented reality,location based computing,mobile computing,tracking,wearable computing},
pages = {65--73},
publisher = {Australian Computer Society, Inc.},
series = {AUIC '03},
title = {{Location Based Applications for Mobile Augmented Reality}},
url = {http://dl.acm.org/citation.cfm?id=820086.820103},
year = {2003}
}
@inproceedings{Ren2008,
abstract = {Augmented Reality (AR) is a growing research area in virtual reality and generates a composite view for the user. It is combination of the real scene viewed by the user and a virtual scene generated by the computer that augments the scene with additional information. About 80 percent information in the real world is related with spatial location. The combination of Geographical information system (GIS) and AR technologies would promote the development of outdoor AR systems, and also would explore a new research direction for GIS. The key technologies of outdoor augmented reality GIS, including basic tracking methods, display devices, typical applications and registration processes, are discussed. In indoor augmented reality's closed environments the tracking of position and head orientation as well as the presentation of information is much more unproblematic than the same task in an outdoor environment. The main application task of outdoor augmented reality GIS is the presentation of information to a user while moving through an unknown region. The system helps to detect automatically objects in sight of a person who need its information. It compares the conventional solutions of 3D registration with, while it discusses their algorithm procedure to basic parameters to give out their advantages and disadvantages at different condition. While affine transformation approach uses the idea of computer graphics and vision technology for reference. Its accuracy is mainly based on the precision and speed of scene feature point extracted from natural or artificial feature. {\textcopyright} 2008 SPIE.},
annote = {cited By 0},
author = {Ren, F and Du, Q and Wu, X},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.814924},
keywords = {3-d registrations; Affine transformation; Applica,Augmented reality,Data processing; Display devices; Geographic infor},
title = {{Key technologies of outdoor augmented reality GIS}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-60749083898{\&}doi=10.1117{\%}2F12.814924{\&}partnerID=40{\&}md5=18ce10997a171d536ec3d075ef5f8175},
volume = {7285},
year = {2008}
}
@article{Ren2018181,
abstract = {The reconstruction of crime scene plays an important role in digital forensic application. Although the 3D scanning technique is popular in general scene reconstruction, it has great limitation in the practice use of crime scene presentation. This article integrates computer graphics, sketch-based modeling and virtual reality (VR) techniques to develop a low-cost and rapid 3D crime scene presentation approach, which can be used by investigators to analyze and simulate the criminal process. First, we constructed a collection of 3D models for indoor crime scenes using various popular techniques, including laser scanning, image-based modeling and software-modeling. Second, to quickly obtain an object of interest from the 3D model database that is consistent with the geometric structure of the real object, a sketch-based retrieval method was proposed. Finally, a rapid modeling system that integrates our database and retrieval algorithm was developed to quickly build a digital crime scene. For practical use, an interactive real-time virtual roaming application was developed in Unity 3D and a low-cost VR head-mounted display (HMD). Practical cases have been implemented to demonstrate the feasibility and availability of our method. {\textcopyright} ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2018.},
annote = {cited By 0},
author = {Ren, P and Zhou, M and Liu, J and Fan, Y and Zhao, W and Shui, W},
doi = {10.1007/978-3-319-73697-6_14},
journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
keywords = {3-d modeling; Crime scenes; Forensic applications,Computer crime,Computer forensics; Computer graphics; Crime; Data},
pages = {181--194},
title = {{Sketch-based modeling and immersive display techniques for indoor crime scene presentation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041129567{\&}doi=10.1007{\%}2F978-3-319-73697-6{\_}14{\&}partnerID=40{\&}md5=d8245e1f47becc9cf9ca60c6793e4795},
volume = {216},
year = {2018}
}
@inproceedings{Retscher2006547,
abstract = {For the location determination of persons and objects in indoor environments a variety of systems have been developed in recent years. The main methods are described and compared in this paper, i.e., location methods using infrared, ultrasonic or radio signals and optical tracking systems. Thereby it can be distinguished if the system is specially designed for positioning and has to be installed in the building or if already available infrastructure (such as WiFi, UWB or Bluetooth) is employed. The indoor location techniques can be integrated in modern navigation systems where also a location determination of the user in a building is required apart from positioning in urban outdoor environments. As most common indoor location techniques provide only 2-D position determination, however, a challenging task is to determine the correct floor of a user in a multi-storey building. In this case it can be recommended to augment the positioning system with a barometric pressure sensor for direct observation of height differences. In the research project NAVIO (Pedestrian Navigation Systems in Combined Indoor/Outdoor Environements) conducted at our University tests with different sensors have been performed. The tests have shown that it is possible to determine the correct floor of a user using a barometric pressure sensor as the standard deviation of the estimation of the height differences is better than  1 m. Currently a combination of WiFi positioning with a barometric pressure sensor and other dead reckoning sensors (for observation of the direction of motion and traveled distance) is tested in our office building. A typical application would be the guidance and navigation of a pedestrian who is unfamiliar with the environment to a a certain office or a person at the Vienna University of Technology. The selcted approach and test results will be presented in the paper. {\textcopyright} 2006 IEEE.},
annote = {cited By 20},
author = {Retscher, G},
booktitle = {Record - IEEE PLANS, Position Location and Navigation Symposium},
doi = {10.1109/PLANS.2006.1650643},
keywords = {Acoustic signal processing; Navigation systems; Op,Indoor location techniques; Navigation and guidan,Tracking (position)},
pages = {547--555},
title = {{Location determination in indoor environments for Pedestrian navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845565345{\&}doi=10.1109{\%}2FPLANS.2006.1650643{\&}partnerID=40{\&}md5=aa2f6a7eac8c4633be27086ecdf83415},
volume = {2006},
year = {2006}
}
@inproceedings{Retscher2008,
abstract = {Alternative location methods for absolute positioning in areas where no GNSS position determination is possible due to obstruction of the satellite signals are needed in mobile positioning. Active RFID (Radio Frequency Identification) can be used also for position determination, although the system was not only developed for positioning and tracking but mainly for identification of objects. Using RFID in positioning, different approaches can be distinguished, i.e., cell-based positioning if the RFID tags are installed at active landmarks (i.e., known locations) in the surroundings, trilateration if ranges to the RFID tags are deducted from received signal strength (RSS in RFID terms) values and location fingerprinting where the measured signal power levels are used directly to obtain a position fix. Using Cell of Origin (CoO) the achievable positioning accuracy depends on the size of the cell and is therefore usually several metres up to 10's of metres using long range RFID equipment. Higher positioning accuracies can be obtained using trilateration and fingerprinting. In this paper the use of trilateration is investigated in an office building of the Vienna University of Technology and its surroundings. The received signal strength from the RFID tag at the reader depends also on the distance between the tag and the reader. To convert the measured signal strength into a range a conversion model has to be deduced. The conversion of the signal strength to the distance can be performed using a radio wave propagation model. That is an empirical mathematical formulation for the characterization of radio wave propagation as a function of frequency, distance and other conditions. Such models typically predict the path loss along a link or the effective coverage area of a transmitter. For that purpose signal strength observations have been performed along a known baseline and at a regular grid in a building and in urban environment. For the signal strength to distance conversion two different models are introduced and described in the paper. In the first model a logarithmic relationship between the signal strength and the distance is formulated, whereas in the second model a linear regression using a polynomial function is used. The models are employed for a signal strenght to distance conversion in short range from the tags in indoor environment and its surroundings. In practical tests performed at the Vienna University of Technology the conversion of the signal strength to a distance has been tested. The tests have shown that active RFID is a meaningful method for indoor positioning. It can be also employed for positioning in the transistion zones between indoor to outdoor and in urban environment as well as in combination with other methods such as WiFi, UWB or GNSS. From the test results it could be seen that the mean of the residuals is larger using the logarithmic model than for the simple polynomial fit for the signal strength to distance conversion in trilateration. For this reason, the simple polynomial model provides a more accurate fit to the distance data as the logarithmic model. The range to the RFID tag is then obtained with a standard deviation of bettter than half a metre and therefore the location of the mobile user can be determined with a standard deviation of around 2 m.},
annote = {cited By 0},
author = {Retscher, G and Fu, Q},
booktitle = {ENC-GNSS 2008 - European Navigation Conference},
keywords = {Cobalt compounds; Engineering education; Functions,Function of frequency; Indoor and outdoor positio,Radio frequency identification (RFID)},
title = {{RFID trilateration for indoor and outdoor positioning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924162516{\&}partnerID=40{\&}md5=2463a0cca0379b19b7793fddfdbd2e6d},
year = {2008}
}
@article{Rezaee:2017:RLP:3147972.3147975,
address = {Hershey, PA, USA},
author = {Rezaee, Raoufeh and Baslyman, Malak and Amyot, Daniel and Mouttham, Alain and Chreyh, Rana and Geiger, Glen},
doi = {10.4018/IJHISI.2017070103},
issn = {1555-3396},
journal = {Int. J. Healthc. Inf. Syst. Inform.},
keywords = {Internet of Things,Mobile Asset Management,Patient Monitoring,Patient Safety,Patient-Device Associations,Radio-Frequency Identification,Real-Time Location Systems},
number = {3},
pages = {37--61},
publisher = {IGI Global},
title = {{Real-Time, Location-Based Patient-Device Association Management: Design and Proof of Concept}},
url = {https://doi.org/10.4018/IJHISI.2017070103},
volume = {12},
year = {2017}
}
@inproceedings{Rituerto:2016:TSI:2982142.2982202,
address = {New York, NY, USA},
author = {Rituerto, Alejandro and Fusco, Giovanni and Coughlan, James M},
booktitle = {Proceedings of the 18th International ACM SIGACCESS Conference on Computers and Accessibility},
doi = {10.1145/2982142.2982202},
isbn = {978-1-4503-4124-0},
keywords = {blindness,low vision.,navigation,wayfinding},
pages = {287--288},
publisher = {ACM},
series = {ASSETS '16},
title = {{Towards a Sign-Based Indoor Navigation System for People with Visual Impairments}},
url = {http://doi.acm.org/10.1145/2982142.2982202},
year = {2016}
}
@inproceedings{Rivadeneyra20091643,
abstract = {Recent research has shown that robots can model their world with Multi-Level (ML) surface maps, which utilize 'patches' in a 2D grid space to represent various environment elevations within a given grid cell. Though these maps are able to produce 3D models of the environment while exploiting the computational feasibility of single elevation maps, they do not take into account in-plane uncertainty when matching measurements to grid cells or when grouping those measurements into 'patches.' To respond to these drawbacks, this paper proposes to extend these ML surface maps into Probabilistic Multi-Level (PML) surface maps, which uses formal probability theory to incorporate estimation and modeling errors due to uncertainty. Measurements are probabilistically associated to cells near the nominal location, and are categorized through hypothesis testing into 'patches' via classification methods that incorporate uncertainty. Experimental results comparing the performances of the PML and ML surface mapping algorithms on representative objects found in both indoor and outdoor environments show that the PML algorithm outperforms the ML algorithm in most cases including in the presence of noisy and sparse measurements. The experimental results support the claim that the PML algorithm produces more densely populated, conservative representations of its environment with fewer measurements than the ML algorithm. {\textcopyright} 2009 IEEE.},
annote = {cited By 14},
author = {Rivadeneyra, C and Miller, I and Schoenberg, J R and Campbell, M},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.2009.5152767},
keywords = {3D models; Classification methods; Computational f,Algorithms; Cell membranes; Conformal mapping; Nu,Uncertainty analysis},
pages = {1643--1648},
title = {{Probabilistic estimation of multi-level terrain maps}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350383287{\&}doi=10.1109{\%}2FROBOT.2009.5152767{\&}partnerID=40{\&}md5=66ac0665b832fcdccd2bdec1e4593eba},
year = {2009}
}
@inproceedings{Kolodziej:2004:IPM:1018418.1019530,
abstract = {This work proposes a distributed access control mechanism based on location data and its application in the context of smart buildings. Our approach includes an access control engine embedded into smart objects, which are responsible to make authorization decisions by considering both user location data and access credentials. User location data are estimated using magnetic field data measured and sent by users through their personal phone. The proposed location-aware access control mechanism does not require any additional hardware or intermediate entities, providing the benefits of a decentralized and flexible solution for indoor environments. From the results obtained, we can consider our proposal as an appropriate solution in order to tackle the challenging security requirements of typical pervasive environments. {\textcopyright} 2014 IEEE.},
address = {Washington, DC, USA},
annote = {From Duplicate 2 (Wrong Siren! A Location Spoofing Attack on Indoor Positioning Systems: The Starbucks Case Study - Cho, J; Yu, J; Oh, S; Ryoo, J; Song, J; Kim, H)
And Duplicate 24 (FineMesh: High-density sampling platform using an autonomous robot - Kawauchi, K; Rekimoto, J)
And Duplicate 27 (The design and implementation of the Cicada wireless sensor network indoor localization system - Jiang, W; Chen, Y; Shi, Y; Sun, Y)
And Duplicate 41 (Indoor relative positioning scheme using illuminance and color temperature - Aida, H; Ichikawa, H; Okada, M; Miki, M)
And Duplicate 69 (A surveillance system integrating visual telepresence - Peixoto, P; Gon{\c{c}}alves, J; Antunes, H; Batista, J; Ara{\'{u}}jo, H)

cited By 1

From Duplicate 7 (Semantic event retrieval from surveillance video databases - Chen, X; Zhang, C)
And Duplicate 14 (An experimental study on the behavior of received signal strength in indoor environment - Ullah, K; Custodio, I V; Shah, N; Moreira, E D S)
And Duplicate 53 (The camera-driven interactive table - Schwarz, C; Da Vitoria Lobo, N)

cited By 3

From Duplicate 8 (Sextant: Towards ubiquitous indoor localization service by photo-taking of the environment - Gao, R; Tian, Y; Ye, F; Luo, G; Bian, K; Wang, Y; Wang, T; Li, X)

cited By 23

From Duplicate 10 (Comparative survey of indoor positioning technologies, techniques, and algorithms - Al-Ammar, M A; Alhadhrami, S; Al-Salman, A; Alarifi, A; Al-Khalifa, H S; Alnafessah, A; Alsaleh, M)

cited By 46

From Duplicate 11 (AR-based positioning for mobile devices - Cheng, Y.-C.; Lin, J.-Y.; Yi, C.-W.; Tseng, Y.-C.; Kuo, L.-C.; Yeh, Y.-J.; Lin, C.-W.)
And Duplicate 56 (Using virtual reference tags to improve the accuracy of active RFID-based positioning systems - Seyyedi, S; Akbari, B; Arab, E; Ramezani, I; Mahdavi, M)
And Duplicate 60 (Harmonium: Asymmetric, Bandstitched UWB for Fast, Accurate, and Robust Indoor Localization - Kempke, B; Pannuto, P; Dutta, P)

cited By 9

From Duplicate 13 (Vision-based global localization for mobile robots with hybrid maps of objects and spatial layouts - Park, S; Kim, S; Park, M; Park, S.-K.)

cited By 28

From Duplicate 18 (Broadband 3-D sonar system using a sparse array for indoor navigation - Steckel, J; Boen, A; Peremans, H)

cited By 25

From Duplicate 19 (Smart phone based indoor pedestrian localization system - Agrawal, L; Toshniwal, D)
And Duplicate 22 (Indoor Location and Idetification of Objects with Video Survillance System and WiFi Module - Grzechca, D; Wrobel, T; Bielecki, P)
And Duplicate 31 (Spatial indexing for location-aware systems - Harle, R K)
And Duplicate 50 (Laser and vision based map building techniques for mobile robot navigation - Majdik, A L; Szoke, I; Tamas, L; Popa, M; Lazea, Gh.)

cited By 2

From Duplicate 20 (Indoor positioning for moving objects using a hardware device with spread spectrum ultrasonic waves - Itagaki, Y; Suzuki, A; Iyota, T)

cited By 13

From Duplicate 21 (A foundation for efficient indoor distance-aware query processing - Lu, H; Cao, X; Jensen, C S)

cited By 38

From Duplicate 23 (Learning structured hough voting for joint object detection and occlusion reasoning - Wang, T; He, X; Barnes, N)

cited By 17

From Duplicate 25 (Exploiting text-related features for content-based image retrieval - Schroth, G; Hilsenbeck, S; Huitl, R; Schweiger, F; Steinbach, E)

cited By 11

From Duplicate 26 (Bayesian geometric modeling of indoor scenes - Del Pero, L; Bowdish, J; Fried, D; Kermgard, B; Hartley, E; Barnard, K)

cited By 60

From Duplicate 28 (Indoor localisation of humans, objects, and mobile robots with RFID infrastructure - Koch, J; Wettach, J; Bloch, E; Berns, K)

cited By 34

From Duplicate 29 (A distributed flow-based guiding protocol in wireless sensor networks - Chen, P.-Y.; Kao, Z.-F.; Chen, W.-T.; Lin, C.-H.)

cited By 18

From Duplicate 32 (Interactive exploration of surveillance video through action shot summarization and trajectory visualization - Meghdadi, A H; Irani, P)
And Duplicate 70 (Efficient distance-aware query evaluation on indoor moving objects - Xie, X; Lu, H; Pedersen, T B)

cited By 22

From Duplicate 34 (LANDMARC: Indoor location sensing using active RFID - Ni, L M; Liu, Y; Lau, Y C; Patil, A P)

cited By 720

From Duplicate 37 (3D map visualization for real time RSSI indoor location tracking system on PDA - Lee, B.-G.; Lee, Y.-S.; Chung, W.-Y.)

cited By 4

From Duplicate 40 (Behaviors of antenna polarization for RSSI location identification - Huang, X; Barralet, M; Sharma, D)

cited By 6

From Duplicate 42 (Modeling location monitoring system using directional antennas - Kathiravan, K; Pradeep, P; Ronak, G; Roshan, S S)
And Duplicate 43 (Slocalization: Sub-$\mu$W Ultra Wideband Backscatter Localization - Pannuto, P; Kempke, B; Dutta, P)
And Duplicate 44 (A new ray-tracying acceleration algorithm based on voronoi diagram - Yuan, Z.-W.; Wang, D.-D.)
And Duplicate 46 (Self-contained localization without auxiliary signals on smart devices - Peng, H.-H.; Lo, C.-C.; Lin, T.-C.; Tseng, Y.-C.)

cited By 0

From Duplicate 45 (Extraction of moving objects from their background based on multiple adaptive thresholds and boundary evaluation - Wang, L; Yung, N H C)

cited By 58

From Duplicate 47 (Visualization of construction graphics in outdoor augmented reality - Behzadan, A H; Kamat, V R)

cited By 43

From Duplicate 48 (Characterizing the influence of human presence on bistatic passive RFID-system - Lieckfeldt, D; You, J; Timmermann, D)
And Duplicate 57 (Smart spaces: Indoor wireless location management system - Joy, V; Laxman P, V)

cited By 7

From Duplicate 49 (Antenna polarization as complementarities on RSSI based location identification - Huang, X)
And Duplicate 63 (Accurate indoor positioning system using near-ultrasonic sound from a smartphone - Murata, S; Yara, C; Kaneta, K; Ioroi, S; Tanaka, H)

cited By 10

From Duplicate 54 (Combining image regions and human activity for indirect object recognition in indoor wide-angle views - Peursum, P; West, G; Venkatesh, S)

cited By 47

From Duplicate 55 (Saliency detection and object localization in indoor environments - Rudinac, M; Jonker, P P)
And Duplicate 73 (Probabilistic estimation of multi-level terrain maps - Rivadeneyra, C; Miller, I; Schoenberg, J R; Campbell, M)

cited By 14

From Duplicate 58 (A new location-aware authorization mechanism for indoor environments - Moreno, M V; Hernandez, J L; Skarmeta, A F)

cited By 12

From Duplicate 59 (Hyper-Lapse From Multiple Spatially-Overlapping Videos - Wang, M; Liang, J.-B.; Zhang, S.-H.; Lu, S.-P.; Shamir, A; Hu, S.-M.)

cited By 5

From Duplicate 61 (Bayesian robot localization using spatial object contexts - Yi, C; Suh, I H; Lim, G H; Choi, B.-U.)
And Duplicate 65 (Autonomous ultrasonic indoor tracking system - Zhao, J; Wang, Y)

cited By 15

From Duplicate 66 (RFID indoor positioning based on probabilistic RFID map and Kalman Filtering - Bekkali, A; Sanson, H; Matsumoto, M)

cited By 150

From Duplicate 67 (Semantic pose using deep networks trained on synthetic RGB-D - Papon, J; Schoeler, M)

cited By 16

From Duplicate 71 (DOLPHIN: An autonomous indoor positioning system in ubiquitous computing environment - Fukuju, Y; Minami, M; Morikawa, H; Aoyama, T)

cited By 103},
author = {Rivadeneyra, C and Miller, I and Schoenberg, J R and Campbell, M and Ramachandran, Anil and Sarangapani, Jagannathan and Fukuju, Y and Minami, M and Morikawa, H and Aoyama, T and Xie, X and Lu, Hua and Pedersen, Torben Bach and Peixoto, P and Gon{\c{c}}alves, J and Antunes, H and Batista, J and Ara{\'{u}}jo, H and Kolodziej, Kris and Danado, Jose and Papon, J and Schoeler, M and Bekkali, A and Sanson, H and Matsumoto, M and Zhao, Jizhong and Wang, Y and Casas, Roberto and Cuartielles, David and Marco, Alvaro and Gracia, Hector J and Falco, Jorge L and Murata, S and Yara, C and Kaneta, K and Ioroi, S and Tanaka, H and Xie, Haijiang and Lin, Li and Jiang, Zhiping and Xi, Wei and Zhao, Kun and Ding, Meiyong and Zhao, Jizhong and Yi, C.-W. and Suh, I H and Lim, G H and Choi, B.-U. and Kempke, B and Pannuto, P and Dutta, P and Wang, M and Liang, J.-B. and Zhang, S.-H. and Lu, S.-P. and Shamir, A and Hu, S.-M. and Moreno, M V and Hernandez, J L and Skarmeta, A F and Joy, V and {Laxman P}, V and Seyyedi, S and Akbari, B and Arab, E and Ramezani, I and Mahdavi, M and Rudinac, M and Jonker, P P and Peursum, P and West, G and Venkatesh, S and Schwarz, C and {Da Vitoria Lobo}, N and Christensen, Kenneth Fuglsang and Christiansen, Lasse Linnerup and Pedersen, Torben Bach and Pihl, Jeppe and Ramachandran, Anil and Jagannathan, S and Majdik, A L and Szoke, I and Tamas, L and Popa, M and Lazea, Gh. and Huang, Xu and Lieckfeldt, D and You, J and Timmermann, D and Behzadan, A H and Kamat, V R and Peng, H.-H. and Lo, C.-C. and Lin, T.-C. and Tseng, Y.-C. and Wang, L and Yung, N H C and Yuan, Z.-W. and Wang, D.-D. and Pannuto, P and Kempke, B and Dutta, P and Kathiravan, K and Pradeep, P and Ronak, G and Roshan, S S and Aida, H and Ichikawa, H and Okada, M and Miki, M and Huang, Xu and Barralet, Mark and Sharma, Dharmendra and Wallbaum, Michael and Spaniol, Otto and Sato, Yousuke and Hashimoto, Koji and Shibata, Yoshitaka and Lee, B.-G. and Lee, Y.-S. and Chung, W.-Y. and Xu, Jianqiu and Guting, Ralf Hartmut and Zou, Xiaotao and Bhanu, Bir and Ni, L M and Liu, Y and Lau, Y C and Patil, A P and Goncalo, Gomes and Helena, Sarmento and Meghdadi, A H and Irani, P and Harle, R K and Talukder, Nilothpal and Ahamed, Sheikh I and Abid, Rezaul M and Chen, P.-Y. and Kao, Z.-F. and Chen, W.-T. and Lin, C.-H. C.-W. and Koch, J and Wettach, J and Bloch, E and Berns, K and Jiang, W and Chen, Y and Shi, Y and Sun, Y and {Del Pero}, L and Bowdish, J and Fried, D and Kermgard, B and Hartley, E and Barnard, K and Schroth, G and Hilsenbeck, S and Huitl, R and Schweiger, F and Steinbach, E and Kawauchi, K and Rekimoto, J and Wang, T and He, X and Barnes, N and Grzechca, D and Wrobel, T and Bielecki, P and Lu, Hua and Cao, X and Jensen, Christian S and Itagaki, Y and Suzuki, A and Iyota, T and Agrawal, L and Toshniwal, D and Steckel, J and Boen, A and Peremans, H and Bhaskar, H and Mihaylova, L and Achim, A and Rashid, Maheen and Hebert, Martial and Ahmed, Tanvir and Pedersen, Torben Bach and Lu, Hua and Ullah, K and Custodio, I V and Shah, N and Moreira, E D S and Park, S.-K. and Kim, S and Park, M and Park, S.-K. and {de Amorim Silva}, Rafael and {da S. Gon{\c{c}}alves}, Paulo Andr{\'{e}} and Cheng, Y.-C. and Lin, J.-Y. and Yi, C.-W. and Tseng, Y.-C. and Kuo, L.-C. and Yeh, Y.-J. and Lin, C.-H. C.-W. and Al-Ammar, M A and Alhadhrami, S and Al-Salman, A and Alarifi, A and Al-Khalifa, H S and Alnafessah, A and Alsaleh, M and Iannizzotto, G and Costanzo, C and Lanzafame, P and {La Rosa}, F and Gao, R and Tian, Y and Ye, F and Luo, G and Bian, K and Wang, Y and Wang, T and Li, X and Chen, X and Zhang, C and Wongphati, Mahisorn and Niparnan, Nattee and Sudsang, Attawith and Pushee, I and Morde, A and Silverstein, J and Ma, X and McAuliffe, S and Guler, S and Heidari, M and Pahlavan, K and Radaelli, Laura and Sabonis, Dovydas and Lu, Hua and Jensen, Christian S and Cho, J and Yu, J and Oh, S and Ryoo, J and Song, J and Kim, H and Barralet, Mark and Huang, Xu and Sharma, Dharmendra},
booktitle = {Proceedings of the 32Nd IEEE Conference on Local Computer Networks},
doi = {10.1109/MDM.2011.35},
isbn = {978-0-7695-4973-6},
issn = {1051-8215},
keywords = {3D Data,3D geometry,3D graphics,3D modeling tools,3D models,3D objects,3D positions,3d sc,Acceleration algorithm,Accelerometers,Access control,Access control mechanism,Accurate estimation,Acoustic flow,Acoustic waves,Active RFID,Active vision system,Ad hoc networks,Adaptive thresholds,Aggregate Queries,Algorithms,Alpha-stable distribution,Analytical approximation,Analytical methods,Antennas,Applications,Approximate string matching,Array beamforming,Artificial Intelligence,Artificial potentials,Assembly line,Assisted living,Augmented reality,Augmented space,Authorization decision,Automated,Automatic iden,Automatic identification,Automation,Autonomous Mobile Robot,Autonomous devices,Auxiliary signals,Average deviation,Background image,Backscattering,Balloons,Battery life,Bayesian,Bayesian model,Bayesian network,Bayesian networks,Beamforming,Bistatic,Bluetooth,Boolean functions,Boundary ev,Broadband beamfo,Broadband networks,CBIR,CQPF,Calibration,Camera focal length,Camera model,Cameras,Cell membranes,Cellular communication systems,Cellular radio systems,Centerlines,Centralized processing,Classification methods,Clutter (information theory),Cluttered scenes,Co,Coarse positioning,Coarse-to-fine strategy,Color,Color channels,Color temperatures,Com,Commodity components,Communicatio,Communication,Communication overheads,Communication systems,Communication technologies,Comparative analysis,Complex networks,Computational complexity,Computational f,Computational geometry,Computer Gra,Computer Vision,Computer scie,Computer science,Computer simulation,Computer suppo,Computer vision,Computer-Assisted,Computing applica,Computing system,Computing technology,Conformal mapping,Construction graphics,Content based i,Content based retrieval,Context aware applications,Context representation,Context-Aware,Contextual information,Continuous parameters,Control theory,Convolutional neural network,Correlation value,Costs,Coupled hidden Markov models,Coverage areas,Curve fitting,D,Daily us,Data Driven,Data sets,Decision trees,Design and implementa,Detecting objects,Detection and tracking,Detectors,Development platform,Digital compass,Directional patt,Distance calculation,Distance computation,Distributed computer systems,Distributed parameter networks,Dolphins (structures),Drag-and-,Dynamic objects,E,Ele,Electr,Electrical engineering,Embedded s,Embedded systems,Embedded technology,Environme,Environmenta,Environmental,Environmental contexts,Environmental references,Error detection,Euclidean distance,Euclidian distance,Event-based systems,Experi,Experiment results,Experimental evaluation,Exploration methods,Feature extraction,Feature-,Feedback,Feedbacks],Frequency Diversity,GIS applications,Geo-location,Geometric center,Geometry,Geometry Estimation,Global positioning system,Global system for mobile communications,Graph theory,Hand held computers,Hardware,Hardware prot,Hea,Helmet mounted displays,Heuristic algorithms,Hidden Markov models,Hidden p,Hough v,Hu,Human computer intera,Human detection and tracking,Human-centred approach,Hybrid s,Hyper-lapse Video,I,Image matching,Image matching algorith,Image processing tools,Image re,Image retrieval,Image segmentation,In,In-door navigations,Ind,Indexing (of information),Indexing framework,Indexing m,Indoo,Indoor,Indoor e,Indoor env,Indoor environ,Indoor environment,Indoor po,Indoor posi,Indoor positioni,Indoor positioning,Indoor positioning system,Indoor positioning systems,Indoor tracking,Indu,Industrial plants,Information management,Information theor,Intelligent control,Intelligent robots,Intelligent systems,Interacti,Interactive computer graphics,Interactive rooms,Internet,Internet of things,Least squares approximat,Lighting,Lo,Loca,Local area networks,Locat,Locatio,Location,Location Accuracy,Location Determination,Location base,Location based,Location based services,Location estimation,Long-term inte,Luminance,Mobile computing,Mobile devices,Mobile rob,Mobile robots,Monitoring,Moving Objects,Moving objects,Nav,Neural networks,Noisy environ,Nu,Object Flow,Object recognition,Opt,Parameter estimation,Pattern,Pattern Recognition,Pattern recognition systems,Photography,Physical,Polar,Positioning algo,Prediction,Propagation,Query Hierarchy,Query processing,RF,RFID,RSSI,Radio f,Radio frequency identification (RFID),Ray tracing,Reproducibility of Result,Robot applications,Robotics,Robots,Sampling,Scene Understanding,Security syst,Security systems,Selection Combining,Selection Queries,Semantics,Sensor networking,Sensors,Shortest path searches,Signal analysis,Signal detection,Signal encoding,Smartphones,Smooth,Sonar,Spatial Diversity,Spatio-temporal Range Queries,Special effects,Spectroscopy,Stereo vision,Surveillance System,Surveillance video,Surveying,Surveys,Symbolic Space,Technology,Th,Three dimensional,Tools,Topology,Tracking (position),Traffic congestion,Transmitters,Triangulation,Ubiquitous,Ubiquitous computing,Ultra-wideband (UWB),Ultras,Ultrasonic waves,Ultrasonics,Uncertainty analysis,Value engineering,Video browsing,Video recording,Video signal processing,Video summariz,Virtual reality,Visualization,WAF,WLAN Location Determination,Wi-Fi,Wir,Wireless networks,Wireless sensor networks,ZigBee,aggregation,algorithm,artificial intelligence,automated pat,automatic object detection,background subtraction (BS),density,frequent patterns,graph-based model,indoor location,indoor moving objects,indoor space,interval query,localiz,localization,location,moving objects,segmentation,sensor networking,sensor networks,system deployments,temporal index,trajectory mining,ubiquitous computing,ultrasound,zigbee},
number = {2},
pages = {1--8},
publisher = {IEEE Computer Society},
series = {LCN '07},
title = {{A New Statistical Model for the Behavior of Ranging Errors in TOA-Based Indoor Localization}},
url = {http://dl.acm.org/citation.cfm?id=1701955.1702004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017660676{\&}doi=10.1109{\%}2FMCOM.2017.1600595CM{\&}partnerID=40{\&}md5=b490ce56bbe1cbb6ffbbe4163cebdbb0 https://doi.org/10.1109/MDM.2013.29 http://dx.doi.org/10.},
volume = {1},
year = {2009}
}
@inproceedings{Rosencrantz:2003:LME:860575.860613,
address = {New York, NY, USA},
author = {Rosencrantz, Matthew and Gordon, Geoffrey and Thrun, Sebastian},
booktitle = {Proceedings of the Second International Joint Conference on Autonomous Agents and Multiagent Systems},
doi = {10.1145/860575.860613},
isbn = {1-58113-683-8},
keywords = {laser tag,particle filter,robot exploration},
pages = {233--240},
publisher = {ACM},
series = {AAMAS '03},
title = {{Locating Moving Entities in Indoor Environments with Teams of Mobile Robots}},
url = {http://doi.acm.org/10.1145/860575.860613},
year = {2003}
}
@article{Rostamian2017270,
abstract = {Localization and tracking of objects (e.g. objects or people) in indoor environment will facilitate many location dependent or contextaware applications. Localization of passive ultra high frequency (UHF) radio-frequency identification (RFID) tags attached to objects or people is of special interest because of the low cost of the tags and backscatter communication that is power efficient. An augmented RFID system for localization based on a new tag called Sense-a-Tag (ST) that communicates with the RFID reader as a passive tags and can detect and record communication of other passive tags in its proximity was introduced several years ago. In ST-based localization system, a large set of passive landmark tags are placed at the known locations. The system localizes ST based on the aggregation of binary detection measurements according to localization algorithm, such as weighted centroid localization (WCL). However, the aforementioned method is easily affected by the outlier detection of distant landmark tags by ST. To improve localization accuracy, this paper propose to iteratively refine the interrogation area of the reader so that it includes only the most relevant landmark tags. The performance of the proposed method is demonstrated by extensive computer simulation and realistic experiments. {\textcopyright} ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2017.},
annote = {cited By 1},
author = {Rostamian, M and Wang, J and Boli{\'{c}}, M},
doi = {10.1007/978-3-319-51204-4_22},
journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
keywords = {Ad hoc networks; Indoor positioning systems; Inter,Context aware applications; Indoor localization s,Radio frequency identification (RFID)},
pages = {270--281},
title = {{An accurate passive RFID indoor localization system based on sense-a-tag and zoning algorithm}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009513036{\&}doi=10.1007{\%}2F978-3-319-51204-4{\_}22{\&}partnerID=40{\&}md5=b350f5ca68a43610062c444dc554d52b},
volume = {184 LNICST},
year = {2017}
}
@inproceedings{Ruan2018591,
abstract = {Anchor Nodes in a localization system obviously play a crucial role in determining the system's quality. Their placement directly affects the localization accuracy and their number directly impacts the total cost of the system. Nowadays, the deployment of Bluetooth nodes in industry generally relies on the experience knowledge of engineers and the cost of positioning beacon does not considered the global level. In this paper, we put forward a method to extract the number and location of BLE beacon automatically and ensure a high positioning accuracy of the indoor positioning system based the rules of indoor positioning, which use all kinds of space objects and structure characteristics of indoor map. The triangulation method was selected to study the global optimal placement of BLE beacon for localization based on indoor map. The impacts and requirements of BLE beacon placement were systematic analysed from the triangulation positioning method, indoor positioning environment and indoor user distribution characteristics. According to the characteristics of indoor environment structure and user distribution, we built an optimization model of BLE beacon placement method based on genetic algorithm which can generate the number and the location of BLE beacon. At last, the Bluetooth indoor positioning prototype system is developed to compare the experience method deployment scheme and the global optimization deployment scheme in the real indoor positioning environment. {\textcopyright} Authors 2018.},
annote = {cited By 0},
author = {Ruan, L and Zhang, L and Cheng, F and Long, Y},
booktitle = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
doi = {10.5194/isprs-archives-XLII-4-529-2018},
keywords = {Ble beacons; Indoor positioning; Localization acc,Bluetooth; Genetic algorithms; Global optimization,Indoor positioning systems},
number = {4},
pages = {591--595},
title = {{The global optimal placement of ble beacon for localization based on indoor map}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056197433{\&}doi=10.5194{\%}2Fisprs-archives-XLII-4-529-2018{\&}partnerID=40{\&}md5=b92106ee5b1d839f5389720c859c1289},
volume = {42},
year = {2018}
}
@inproceedings{Ruan2016,
abstract = {Device-free indoor localization aims to localize people without requiring them to carry any devices or being actively involved in the localizing process. It underpins a wide range of applications including older people surveillance, intruder detection and indoor navigation. However, in a cluttered environment such as a residential home, the Received Signal Strength Indicator (RSSI) is heavily obstructed by furniture or metallic appliances, thus reducing the localization accuracy. This environment is important to observe as human-object interaction (HOI) events, detected by pervasive sensors, can potentially reveal people's interleaved locations during daily living activities, such as watching TV, opening the fridge door. This paper aims to enhance the performance of commercial off-the-shelf (COTS) RFID-based localization system by leveraging HOI contexts in a furnished home. Specifically, we propose a general Bayesian probabilistic framework to integrate both RSSI signals and HOI events to infer the most likely location and trajectory. Experiments conducted in a residential house demonstrate the effectiveness of our proposed method, in which we can localize a resident with average 95{\%} accuracy and track a moving subject with 0.58m mean error distance. {\textcopyright} 2016 IEEE.},
annote = {cited By 9},
author = {Ruan, W and Sheng, Q Z and Yao, L and Gu, T and Ruta, M and Shangguan, L},
booktitle = {WoWMoM 2016 - 17th International Symposium on a World of Wireless, Mobile and Multimedia Networks},
doi = {10.1109/WoWMoM.2016.7523524},
keywords = {Bayesian probabilistic frameworks; Cluttered envi,Housing; Intrusion detection,Indoor positioning systems},
title = {{Device-free indoor localization and tracking through Human-Object Interactions}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983770560{\&}doi=10.1109{\%}2FWoWMoM.2016.7523524{\&}partnerID=40{\&}md5=6959cda95fe200efab2e903a31afcfca},
year = {2016}
}
@inproceedings{Ruan2016,
abstract = {Unobtrusive indoor localization aims to localize people without requiring them to carry any devices or being actively involved with the localizing process. It underpins a wide range of applications including older people surveillance, intruder detection and indoor navigation. However, in a residential home, the Received Signal Strength Indicator (RSSI) is heavily obstructed by furniture or domestic appliances, reducing the localization accuracy. This environment is important to observe as human-object interaction (HOI) events, detected by pervasive sensors, can reveal people's interleaved locations during daily living activities. Thus, this paper aims to enhance the performance of the RFID-based localization system by fusing human-object interactions. Specifically, we propose a general Bayesian probabilistic multi-sensor fusion framework to integrate both RSSI signals and human-object interaction events to infer the most likely location and trajectory. Unlike other RFID-based unobtrusive localization systems, which are limited to deployment and testing in cleared spacial areas, our system can work in a furnished environment. The extensive experiments with this system have a localization accuracy up to 96.7{\%}, and average 0.58m tracking error. {\textcopyright} 2016 IEEE.},
annote = {cited By 3},
author = {Ruan, W and Sheng, Q Z and Yao, L and Yang, L and Gu, T},
booktitle = {2016 IEEE International Conference on Pervasive Computing and Communication Workshops, PerCom Workshops 2016},
doi = {10.1109/PERCOMW.2016.7457055},
keywords = {Daily living activities; Human localizations; Hum,Domestic appliances; Intrusion detection; Ubiquito,Indoor positioning systems},
title = {{HOI-Loc: Towards unobstructive human localization with probabilistic multi-sensor fusion}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966549625{\&}doi=10.1109{\%}2FPERCOMW.2016.7457055{\&}partnerID=40{\&}md5=437d84f662864abc2b9a1bcb61f49b20},
year = {2016}
}
@inproceedings{Rudinac2010404,
abstract = {In this paper we present a scene exploration method for the identification of interest regions in unknown indoor environments and the position estimation of the objects located in those regions. Our method consists of two stages: First, we generate a saliency map of the scene based on the spectral residual of three color channels and interest points are detected in this map. Second, we propose and evaluate a method for the clustering of neighboring interest regions, the rejection of outliers and the estimation of the positions of potential objects. Once the location of objects in the scene is known, recognition of objects / object classes can be performed or the locations can be used for grasping the object. The main contribution of this paper lies in a computationally inexpensive method for the localization of multiple salient objects in a scene. The performance obtained on a dataset of indoor scenes shows that our method performs good, is very fast and hence highly suitable for real-world applications, such as mobile robots and surveillance. {\textcopyright} 2010 IEEE.},
annote = {cited By 14},
author = {Rudinac, M and Jonker, P P},
booktitle = {Proceedings - International Conference on Pattern Recognition},
doi = {10.1109/ICPR.2010.107},
keywords = {Color channels; Data sets; Exploration methods; In,Location; Robotics; Robots,Object recognition},
pages = {404--407},
title = {{Saliency detection and object localization in indoor environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78149490022{\&}doi=10.1109{\%}2FICPR.2010.107{\&}partnerID=40{\&}md5=0220f64f79ea68589a984432b1610332},
year = {2010}
}
@article{Ruotsalainen:2013:EPA:2524920.2524924,
address = {Bristol, PA, USA},
author = {Ruotsalainen, Laura and Bancroft, Jared and Lachapelle, G{\&}{\#}xE9;rard and Kuusniemi, Heidi},
doi = {10.1080/17489725.2013.819450},
issn = {1748-9725},
journal = {J. Locat. Based Serv.},
keywords = {Hough Transform,INS,pedestrian navigation,vanishing point,vision aiding},
number = {3},
pages = {209--222},
publisher = {Taylor {\&} Francis, Inc.},
title = {{Enhanced Pedestrian Attitude Estimation Using Vision Aiding}},
url = {http://dx.doi.org/10.1080/17489725.2013.819450},
volume = {7},
year = {2013}
}
@inproceedings{Rusli201672,
abstract = {Indoor positioning system (IPS) allows an object to be located and tracked within an indoor environment. With the introduction of Internet of Things (IoT), the business interest in location-based application and services has also increased. Hence, the demand for accurate indoor localization services has become important. Until now, researches related to IPS are still being conducted with the objective to improve the performance of positioning techniques. Trilateration is one of the techniques available to determine the location of an object. This paper proposes an improved WiFi trilateration-based method for indoor positioning system. The improved model is based on the test results which was conducted by using Intel Galileo (Gen2) board as an access point. The signal blocking problem caused by obstacles existed inside the building is resolved by improving received signal strength measurement. The proposed model includes implementation of trilateration technique to determine the position of users and then using specific reference points to improve the positioning results. {\textcopyright} 2016 IEEE.},
annote = {cited By 21},
author = {Rusli, M E and Ali, M and Jamil, N and Din, M M},
booktitle = {Proceedings - 6th International Conference on Computer and Communication Engineering: Innovative Technologies to Serve Humanity, ICCCE 2016},
doi = {10.1109/ICCCE.2016.28},
keywords = {Access points; Internet of Things (IOT); IOT boar,Indoor positioning systems; Internet of things; Su,Location based services},
pages = {72--77},
title = {{An Improved Indoor Positioning Algorithm Based on RSSI-Trilateration Technique for Internet of Things (IOT)}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014993110{\&}doi=10.1109{\%}2FICCCE.2016.28{\&}partnerID=40{\&}md5=f2add6b07a4ed04521839ee3b6b5d77b},
year = {2016}
}
@inproceedings{Rustagi:2018:ANS:3281505.3281616,
address = {New York, NY, USA},
author = {Rustagi, Taru and Yoo, Kyungjin},
booktitle = {Proceedings of the 24th ACM Symposium on Virtual Reality Software and Technology},
doi = {10.1145/3281505.3281616},
isbn = {978-1-4503-6086-9},
keywords = {augmented reality,indoor navigation,tilesets},
pages = {71:1----71:2},
publisher = {ACM},
series = {VRST '18},
title = {{AR Navigation Solution Using Vector Tiles}},
url = {http://doi.acm.org/10.1145/3281505.3281616},
year = {2018}
}
@inproceedings{Rybarczyk:2016:ITI:2933267.2933538,
address = {New York, NY, USA},
author = {Rybarczyk, Ryan and Raje, Rajeev and Tuceryan, Mihran},
booktitle = {Proceedings of the 10th ACM International Conference on Distributed and Event-based Systems},
doi = {10.1145/2933267.2933538},
isbn = {978-1-4503-4021-2},
keywords = {accuracy,indoor tracking,sensors,subset selection,trust},
pages = {374--377},
publisher = {ACM},
series = {DEBS '16},
title = {{Infusing Trust in Indoor Tracking: Poster}},
url = {http://doi.acm.org/10.1145/2933267.2933538},
year = {2016}
}
@article{5504205,
abstract = {Indoor positioning systems (IPSs) locate objects in closed structures such as office buildings, hospitals, stores, factories, and warehouses, where Global Positioning System devices generally do not work. Most available systems apply wireless concepts, optical tracking, and/or ultrasound. This paper presents a standalone IPS using radio frequency identification (RFID) technology. The concept is based on an object carrying an RFID reader module, which reads low-cost passive tags installed next to the object path. A positioning system using a Kalman filter is proposed. The inputs of the proposed algorithm are the measurements of the backscattered signal power propagated from nearby RFID tags and a tag-path position database. The proposed algorithm first estimates the location of the reader, neglecting tag-reader angle-path loss. Based on the location estimate, an iterative procedure is implemented, targeting the estimation of the tag-reader angle-path loss, where the latter is iteratively compensated from the received signal strength information measurement. Experimental results are presented, illustrating the high performance of the proposed positioning system.},
author = {Saab, S S and Nakad, Z S},
doi = {10.1109/TIE.2010.2055774},
issn = {0278-0046},
journal = {IEEE Transactions on Industrial Electronics},
keywords = {iterative methods;Kalman filters;radiofrequency id},
number = {5},
pages = {1961--1970},
title = {{A Standalone RFID Indoor Positioning System Using Passive Tags}},
volume = {58},
year = {2011}
}
@article{Saadane2012132,
abstract = {This paper presents a ray-tracing method for modeling Ultra Wide Bandwidth indoor propagation channels. A validation of the ray tracing model with our indoor measurement is also presented. Based on the validated model, the multipath channel parameter like the fading statistics and root mean square delay spread for Ultra Wide bandwidth frequencies are simply extracted. The proposed ray-tracing method is based on image method. This is used to predict the propagation of UWB electromagnetic waves. First, we have obtained that the fading statistics can be well fitted by log normal distribution in static case. Second, as in realistic environment we cannot neglect the significant impact of Human Body Shadowing and other objects in motion on indoor UWB propagation channel. Hence, our proposed model allows a simulation of propagation in a dynamic indoor environment. Results of the simulation show that this tool gives results in agreement with those reported in the literature. Specially, the effects of people motion on temporal channel properties. Other features of this approach also are outlined.},
annote = {cited By 5},
author = {Saadane, R and Wahbi, M},
journal = {International Journal of Communication Networks and Information Security},
number = {2},
pages = {132--143},
title = {{UWB Indoor radio propagation modelling in presence of human body shadowing using ray tracing technique}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865412100{\&}partnerID=40{\&}md5=8ffc00e285a2277c941ac04658314103},
volume = {4},
year = {2012}
}
@article{Saadi2016332,
abstract = {Widespread applications of location based services for indoor environments have created an opportunity for researchers to develop new techniques for accurate position estimation with less complexity. In this paper, we present a heuristic approach to localization by employing clustering for an indoor environment. Depending upon the number of light emitting diodes (LEDs) used as transmitter, level 1 clustering is achieved by simply comparing the signal strength for each combination of transmitter's light intensities at the receiver. For level 2 clustering, a new technique of clustering is proposed, named portion clustering, is applied to further partition the area where the object of interest can be located. From the simulation results, it can be observed that the location estimation up to 16 centimeters can be achieved for an indoor environment with the dimensions of 3  3  3 3 m using LEDs. {\textcopyright} 2005 - 2016 JATIT {\&} LLS. All rights reserved.},
annote = {cited By 5},
author = {Saadi, M and Zhao, Y and Wuttisttikulkij, L and Khan, M T A},
journal = {Journal of Theoretical and Applied Information Technology},
number = {3},
pages = {332--338},
title = {{A heuristic approach to indoor localization using light emitting diodes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959298473{\&}partnerID=40{\&}md5=8ef2d7a9a3f3bfa5d4a124b100407f0f},
volume = {84},
year = {2016}
}
@article{Sabirin20152299,
abstract = {The problem of identifying moving objects in a video recording produced by a range sensor camera is due to the limited information available for classifying different objects. On the other hand, the infrared signal from a range sensor camera is more robust for extreme luminance intensity when the monitored area has light conditions that are too bright or too dark. This paper proposes a method of detection and tracking moving objects in image sequences captured by stationary range sensor cameras. Here, the depth information is utilized to correctly identify each of detected objects. Firstly, camera calibration and background subtraction are performed to separate the background from the moving objects. Next, a 2D projection mapping is performed to obtain the location and contour of the objects in the 2D plane. Based on this information, graph matching is performed based on features extracted from the 2D data, namely object position, size and the behavior of the objects. By observing the changes in the number of objects and the objects' position relative to each other, similarity matching is performed to track the objects in the temporal domain. Experimental results show that by using similarity matching, object identification can be correctly achieved even during occlusion. {\textcopyright} Copyright 2015 The Institute of Electronics, Information and Communication Engineers.},
annote = {cited By 1},
author = {Sabirin, H and Sankoh, H and Naito, S},
doi = {10.1587/transinf.2015EDP7108},
journal = {IEICE Transactions on Information and Systems},
keywords = {3D sensor; Background subtraction; Detection and,Cameras; Classification (of information); Image pr,Object detection},
number = {12},
pages = {2299--2307},
title = {{Utilizing attributed graph representation in object detection and tracking for indoor range sensor surveillance cameras}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948809090{\&}doi=10.1587{\%}2Ftransinf.2015EDP7108{\&}partnerID=40{\&}md5=d8f1fc560fb162237afb74ce60952461},
volume = {E98D},
year = {2015}
}
@article{Sadhukhan20181,
abstract = {Localization is highly required to develop the smart-phone based pervasive computing applications. Because of very poor signal strength of global positioning system in indoor areas, various indoor localization systems have been proposed in literature. Among these, received signal strength (RSS) based fingerprinting localization systems are very popular. However, these localization systems at first, need to construct a fingerprint database by collecting RSS patterns at a set of known training locations and then determine the location of an object by comparing the currently observed RSS pattern with all the RSS patterns stored in the fingerprint database. Thus, such localization systems can provide better positioning accuracy by including large number of training data, which in turn, increase the searching overhead. To resolve this issue, several clustering strategies, which restrict the search within a smaller subset of the whole fingerprint database for such localization systems, have been proposed in the literature over the past decade. This paper presents an extensive comparative performance analysis of various clustering-based fingerprinting localization systems to demonstrate their effectiveness on the large-scale positioning system in the presence of radio irregularities and wall attenuation in the wireless environment. {\textcopyright} 2018 Springer Science+Business Media, LLC, part of Springer Nature},
annote = {cited By 0; Article in Press},
author = {Sadhukhan, P},
doi = {10.1007/s11276-018-1682-7},
journal = {Wireless Networks},
pages = {1--14},
title = {{Performance analysis of clustering-based fingerprinting localization systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041500853{\&}doi=10.1007{\%}2Fs11276-018-1682-7{\&}partnerID=40{\&}md5=452529ae8f4d0c9a089f8886e9cf1f08},
year = {2018}
}
@inproceedings{Sadrearhami2017401,
abstract = {Wave propagation analysis inside a 2D rectangular room in the presence of an object is studied. Closed form Green's function of the empty room is derived and the problem is solved by implementing the Method of Moments. The Green's function is obtained by employing the Characteristic Green's Function (CGF) technique in conjunction with the Complex Images (CI) method. The proposed form is independent from location of transmitter/receiver and a single run of the procedure is sufficient to completely model the empty room. The performance of the presented method is studied in an example. {\textcopyright} 2016 IEEE.},
annote = {cited By 0},
author = {Sadrearhami, M H and Shishegar, A A},
booktitle = {2016 8th International Symposium on Telecommunications, IST 2016},
doi = {10.1109/ISTEL.2016.7881850},
keywords = {Characteristic Green's function; Closed-form Gree,Green's function; Method of moments,Wave propagation},
pages = {401--404},
title = {{Propagation and scattering analysis in a 2D rectangular room using closed-form Green's Function}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017652138{\&}doi=10.1109{\%}2FISTEL.2016.7881850{\&}partnerID=40{\&}md5=36a352281ce3a932bcdf41b464cf0dc4},
year = {2017}
}
@inproceedings{528282,
abstract = {Describes a fuzzy-based approach to self localization to support real-time indoor robot navigation. The authors use a hierarchical representation of map and environmental objects that are perceived from sensors. Each perceived object is matched against a map object to obtain an estimate of the robot's location with respect to the map. The authors use fuzzy techniques to characterize partial matches, and to combine estimates discerned by distinct objects. The authors' approach has been tested on the SRI mobile robot, Flakey.},
author = {Saffiotti, A and Wesley, L P},
booktitle = {Proceedings of the Intelligent Vehicles '95. Symposium},
doi = {10.1109/IVS.1995.528282},
keywords = {inference mechanisms;fuzzy logic;mobile robots;pat},
pages = {202--207},
title = {{Hierarchical locative reasoning for autonomous mobile platforms}},
year = {1995}
}
@inproceedings{Saha2015538,
abstract = {Location estimation is essential to the success of location based services. Since GPS does not work well in indoor and the urban areas, several indoor localization systems have been proposed in the literature. Among these, the fingerprinting-based localization systems involving two phases: training phase and positioning phase, are used mostly. In the training phase, a radio map is constructed by collecting the received signal strength (RSS) measurements at a set of known training locations. In the positioning phase, the training location whose corresponding RSS pattern matches best with the currently observed RSS pattern is selected as the estimated location of the object. The positioning accuracy of such systems depends on the grain size of the training locations, i.e., better localization accuracy can be achieved with increasing number of training locations, which in turn, increases the comparison cost as well as the searching time in the positioning phase. Several clustering strategies have been proposed in the literature to reduce the searching time by grouping several training locations into a cluster and selecting the right cluster in the positioning phase followed by searching within the selected cluster to localize an object. However, selection of some false cluster degrades the positioning accuracy of the localization system. Thus, this paper aims at devising some novel clustering strategy that would reduce the searching time without compromising the positioning accuracy. {\textcopyright} 2015 IEEE.},
annote = {cited By 6},
author = {Saha, A and Sadhukhan, P},
booktitle = {2015 IEEE 2nd International Conference on Recent Trends in Information Systems, ReTIS 2015 - Proceedings},
doi = {10.1109/ReTIS.2015.7232937},
keywords = {Cluster analysis; Indoor positioning systems; Info,Cluster; Clustering strategy; Fingerprinting; Pos,Location based services},
pages = {538--543},
title = {{A novel clustering strategy for fingerprinting-based localization system to reduce the searching time}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954181920{\&}doi=10.1109{\%}2FReTIS.2015.7232937{\&}partnerID=40{\&}md5=dc5d0c256037dafae54a7a8bda40340b},
year = {2015}
}
@inproceedings{Saha2016457,
abstract = {Tracking of locations of a mobile object or person continuously using smart phones using conventional Global Positioning System (GPS) puts a huge toll on the battery life of power-limited smart phones. The power consumption of a GPS unit is much more than any other sensors in a smart phone. Worse, the GPS unit cannot be switched off even if the smart phone is in sleep mode. GPS, in addition, is not effective in indoor locations because suitable number of satellites cannot be obtained for acceptable communication. To overcome these problems, in this work, we have proposed a low power and low cost fast location tracking system for a smart phone device that is effective in tracking continuous locations of a moving device with very good accuracy. The inbuilt sensors of a smart phone like the accelerometer, the magnetometer and the gyroscope have been utilized, instead of the costly GPS unit, to track the continuous locations of a mobile device. Distance covered between any two time instants is calculated using the accelerometer readings, while the magnetometer readings give the direction of movement of the mobile device. These sensors are used to get an initial estimate of the number of foot counts and the average foot length of the person that carries the smart phone. Basically, a pattern has been framed using the change of acceleration due to gravity when a footstep is taken. These values are then used to continuously find the location of a mobile person carrying the device. The system based on these sensor measures has been implemented on Android based smart phone devices. Implementation results have generated an accuracy level of as low as 2 meters distance. The system has been tested on both indoor as well as outdoor locations without any observable differences in performance measures. Huge savings in terms of battery power consumption, as high as 20 percent for a run of 3 hours, have been found, with savings increasing rapidly with the increase in time of run of our system. Our results strongly suggest the use of our proposed system as a good alternative for the costly GPS system of location tracking. {\textcopyright} 2015 IEEE.},
annote = {cited By 4},
author = {Saha, S and Chatterjee, S and Gupta, A K and Bhattacharya, I and Mondal, T},
booktitle = {2015 International Conference on Computing and Network Communications, CoCoNet 2015},
doi = {10.1109/CoCoNet.2015.7411226},
keywords = {Acceleration due to gravity; Battery power consum,Accelerometers; Communication satellites; Electric,Cellular telephone systems},
pages = {457--464},
title = {{TrackMe - A low power location tracking system using smart phone sensors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964880804{\&}doi=10.1109{\%}2FCoCoNet.2015.7411226{\&}partnerID=40{\&}md5=74480beb7c8127189ec879f7a2f65703},
year = {2016}
}
@article{Saikia2018513,
abstract = {The task of retrieving a specific object from an image, which is similar to a query object is one of the critical applications in the computer vision domain. The existing methods fail to return similar objects when the region of interest is not specified correctly in a query image. Furthermore, when the feature vector is large, the retrieval from big collections is usually computationally expensive. In this paper, we propose an object retrieval method, which is based on the neural codes (activations) generated by the last inner-product layer of the Faster R-CNN network demonstrating that it can be used not only for object detection but for retrieval too. To evaluate the method, we have used a subset of ImageNet comprising of images related to indoor scenes, and to speed-up the retrieval, we first process all the images from the dataset and we save information (i.e. neural codes, objects present in the image, confidence scores and bounding box coordinates) corresponding to each detected object. Then, given a query image, the system detects the object present and retrieves its neural codes, which are then used to compute the cosine similarity against saved neural codes. We retrieved objects with high cosine similarity scores, and then we compared it with the results obtained using confidence scores. We showed that our approach takes only 0.534 s to retrieve all the 1454 objects in our test set. {\textcopyright} 2018, Springer International Publishing AG.},
annote = {cited By 1},
author = {Saikia, S and Fidalgo, E and Alegre, E and Fern{\'{a}}ndez-Robles, L},
doi = {10.1007/978-3-319-67180-2_50},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Codes (symbols); Deep learning; Education; Image c,Confidence score; Convolutional neural network; C,Search engines},
pages = {513--523},
title = {{Query based object retrieval using neural codes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028671229{\&}doi=10.1007{\%}2F978-3-319-67180-2{\_}50{\&}partnerID=40{\&}md5=f009d7c31d2383727c8642eac424fe05},
volume = {649},
year = {2018}
}
@article{Salem:2013:EAM:2584443.2584448,
address = {Hershey, PA, USA},
author = {Salem, Nahed and Abdul-Wahab, Sabah and Ali, Sappurd},
doi = {10.4018/ijkm.2013070105},
issn = {1548-0666},
journal = {Int. J. Knowl. Manag.},
keywords = {Archival Collections,Indoor Environmental Factors,Knowledge Management,Manuscripts Library,Semi-Active Records,Storage Media},
number = {3},
pages = {65--81},
publisher = {IGI Global},
title = {{Environmental Assessment in Manuscripts Library and Storages of Semi-Active Record at Sultanate of Oman}},
url = {http://dx.doi.org/10.4018/ijkm.2013070105},
volume = {9},
year = {2013}
}
@inproceedings{Salvador2003389,
abstract = {Shadow segmentation is a critical issue for systems aiming at extracting, tracking or recognizing objects in a given scene. Shadows can in fact modify the shape and colour of objects and therefore affect scene analysis and interpretation systems in many applications, such as video database search and retrieval, as well as video analysis in applications such as video surveillance. We present a shadow segmentation algorithm which includes two stages. The first stage extracts moving cast shadows in each frame of the sequence. The second stage tracks the extracted shadows in the subsequent frames. Tentative moving shadow regions are first identified based on spectral and geometrical properties of shadows. In order to confirm this tentative identification, shadow regions are then tracked over time. This second stage aims at exploiting the prior knowledge of a shadow detected in previous frames by evaluating its temporal behaviour. Shadow tracking is a difficult task, since colour, texture, and motion features in shadow regions cannot be used for solving the correspondence problem. Colour and texture change according to changes in the background's characteristics. The measurement of motion cannot be reliably computed for shadows. Therefore shadows may be described only by a limited amount of information. The proposed tracking algorithm makes use of this information and provides a reliability estimation of shadow recognition results of the first stage over time. This temporal analysis eliminates the possible ambiguities of the first stage and improves the efficiency of the overall shadow detection algorithm. The benefit of the proposed shadow segmentation and tracking algorithm is evaluated on both indoor and outdoor scenes. The obtained results are validated based on subjective as well as objective comparisons.},
annote = {cited By 6},
author = {Salvador, E and Cavallaro, A and Ebrahimi, T},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.476523},
keywords = {Algorithms; Color; Database systems; Feature extra,Image analysis,Image sequences; Shadow segmentation; Shadow trac},
pages = {389--400},
title = {{Spatio-temporal shadow segmentation and tracking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0043128565{\&}doi=10.1117{\%}2F12.476523{\&}partnerID=40{\&}md5=f539aab98ce8152be5d1d34932a9057a},
volume = {5022 I},
year = {2003}
}
@inproceedings{Santos-Gonzalez:2015:PIL:2797044.2797053,
address = {New York, NY, USA},
author = {Santos-Gonz{\'{a}}lez, Iv{\'{a}}n and Caballero-Gil, Pino and Rivero-Garc$\backslash$'$\backslash$ia, Alexandra and Hern{\'{a}}ndez-Goya, Candelaria},
booktitle = {Proceedings of the 1st International Workshop on Experiences with the Design and Implementation of Smart Objects},
doi = {10.1145/2797044.2797053},
isbn = {978-1-4503-3535-5},
keywords = {QR codes,android application,bluetooth,indoor location},
pages = {27--28},
publisher = {ACM},
series = {SmartObjects '15},
title = {{Poster: Indoor Location System for Vehicles}},
url = {http://doi.acm.org/10.1145/2797044.2797053},
year = {2015}
}
@inproceedings{Saputra2012307,
abstract = {This research developed an application that could tracks and locates human's presence and position in indoor environment using multiple depth-cameras. Kinect as the most affordable device that equipped with depth-camera was used in this work. The application obtains stream data from Kinect and analyzes presence of human using skeletal tracking library on Kinect for Windows SDK v1. The final application also visualizes human location on 3D environment using Windows Presentation Foundation (WPF) 4.0. In order to visualize 3D object correctly, the application also took into account the coverage that may intersect when two Kinects were placed in adjacent position so that the final human location is combined. In the end, application was tested in 3 different scenarios and it's found that the average error in determining human location was 0.13589 meters. {\textcopyright} 2012 Universitas Indonesia.},
annote = {cited By 16},
author = {Saputra, M R U and Widyawan and Putra, G D and Santosa, P I},
booktitle = {2012 International Conference on Advanced Computer Science and Information Systems, ICACSIS 2012 - Proceedings},
keywords = {3-D environments; 3D object; Average errors; Human,Cameras,Computer science; Information systems; Three dime},
pages = {307--312},
title = {{Indoor human tracking application using multiple depth-cameras}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875110541{\&}partnerID=40{\&}md5=1614a2e746456f86fec68dea41c922e6},
year = {2012}
}
@inproceedings{Saska20181,
abstract = {A system designed for a unique multi-robot application of closely flying formations of Unmanned Aerial Vehicles (UAVs) in indoor areas is described in this paper. The proposed solution is aimed as a tool for historians and restorers working in large historical buildings such as churches to provide an access to areas that are difficult to reach by humans. In these objects, it is impossible to keep a large scaffolding for a long time due to regular services, which is necessary for studying a long-term influence of restorations works, and some parts of the churches were even not reached by people for decades and need to be inspected. To provide the same documentation and inspection techniques that are used by the experts in lower easily accessible parts of the buildings, we employ a formation of autonomous UAVs, where one of the robots is equipped by a visual sensor and the others by source of light, which provides the required flexibility for control of lightening. The described system in its full complexity has been implemented with achieved robustness and reliability required by deployment in real missions. The technology demonstration has been provided with real UAVs in historical objects to help restorers and conservationists with achieved valuable results used in plans of restoration works. In these missions, UAVs were autonomously hovering at designated locations to be able to demonstrate usefulness of such robotic lightening approach. {\textcopyright}2017 IEEE.},
annote = {cited By 2},
author = {Saska, M and Kr{\'{a}}tk{\'{y}}, V and Spurn{\'{y}}, V and B{\'{a}}{\v{c}}a, T},
booktitle = {IEEE International Conference on Emerging Technologies and Factory Automation, ETFA},
doi = {10.1109/ETFA.2017.8247654},
keywords = {Antennas; Factory automation; Restoration; Unmanne,Autonomous UAVs; Historical buildings; Inspection,Model predictive control},
pages = {1--8},
title = {{Documentation of dark areas of large historical buildings by a formation of unmanned aerial vehicles using model predictive control}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044467626{\&}doi=10.1109{\%}2FETFA.2017.8247654{\&}partnerID=40{\&}md5=a2c620a1f906a4da65543cfd61da7858},
year = {2018}
}
@inproceedings{5507298,
abstract = {Accurate tracking of elite athletes for performance monitoring allows sports scientists to optimize training to gain a competitive edge. An important challenge in this application is that the maneuverability of the athletes is high and the traditional Kalman filter (KF) will not provide satisfactory tracking accuracy. Further, high update rates, of the order of tens of updates per second for each player, are often required and hence, the tracking algorithm considered should be computationally efficient. In this paper we propose a computationally efficient multiple model particle filter (MM-PF) algorithm for tracking maneuvering objects. It uses a Gaussian proposal density based on the unscented KF and a deterministic sampling technique and provides tracking accuracy similar to that of the augmented MM-PF, but with much lower computational cost. The performance of the proposed algorithm was verified using simulations and data collected in field trials. The trials were conducted with the Australian Institute of Sport using a localization system we have designed.},
author = {Sathyan, T and Hedley, M},
booktitle = {IEEE/ION Position, Location and Navigation Symposium},
doi = {10.1109/PLANS.2010.5507298},
issn = {2153-3598},
keywords = {Gaussian processes;indoor communication;Kalman fil},
pages = {332--339},
title = {{Efficient particle filtering for tracking maneuvering objects}},
year = {2010}
}
@article{Savic:2010:IPU:1928785.1928794,
address = {New York, NY, United States},
author = {Savic, Vladimir and Poblaci{\'{o}}n, Adri{\'{a}}n and Zazo, Santiago and Garc$\backslash$'$\backslash$ia, Mariano},
doi = {10.1155/2010/963576},
issn = {1687-1472},
journal = {EURASIP J. Wirel. Commun. Netw.},
pages = {9:1----9:12},
publisher = {Hindawi Publishing Corp.},
title = {{Indoor Positioning Using Nonparametric Belief Propagation Based on Spanning Trees}},
url = {http://dx.doi.org/10.1155/2010/963576},
volume = {2010},
year = {2010}
}
@inproceedings{1309062,
abstract = {This paper describes an infrared-based system for tracking personnel in an indoor environment. The system uses three corner mounted infrared transmitter units, each consisting of eight infrared diodes, and a receiver unit worn by a user to determine the position of the user. Every diode of each transmitter unit scans the area sending its own unique code sequentially which can be decoded to identify both the transmitter and its beam angle when picked up by the receiver unit. The received codes are then sent to a personal computer (PC) to determine the position of the user by the method of triangulation. The prototype system built has a position update rate of once every 250ms with an accuracy of 0.57 metres. The system, whose accuracy could be improved with the use of better focusing elements for the infrared beams, should rind applications in the areas of military training, where the position of soldiers can be monitored throughout training sessions in buildings with multiple rooms, and any other applications that require the tracking of moving objects.},
author = {Sayeef, S and Madawala, U K and Handley, P G and Santoso, D},
booktitle = {PLANS 2004. Position Location and Navigation Symposium (IEEE Cat. No.04CH37556)},
doi = {10.1109/PLANS.2004.1309062},
keywords = {optical tracking;position measurement;indoor perso},
pages = {698--705},
title = {{Indoor personnel tracking using infrared beam scanning}},
year = {2004}
}
@inproceedings{Saygili2013,
abstract = {The Microsoft Kinect enables real time 3D reconstruction of an indoor environment with low computational power by producing depth measurements with high resolution. Yet, the measured depth images are not in perfect quality because of the reflectance properties of the objects inside the scene. In this paper, we propose a novel depth predic algorithm that is based on fitting a polynomial on the unknown depth locations. The parameters of the polynomials are found using the features and the depth measures of the pixels with known depth value. We conducted several experiments on different images and achieved predicting the depth of unknown locations with low error. {\textcopyright} 2013 IEEE.},
annote = {cited By 0},
author = {Saygili, G and Balim, C and Kalkan, H and Hendriks, E A},
booktitle = {2013 21st Signal Processing and Communications Applications Conference, SIU 2013},
doi = {10.1109/SIU.2013.6531177},
keywords = {Computational power; Depth Estimation; Depth measu,Polynomials,Signal processing},
title = {{Estimating the missing kinect depth information by polynomial fitting [Polinom uydurma ile kinect' de kayip derinlik bilgisi tahmini]}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880856628{\&}doi=10.1109{\%}2FSIU.2013.6531177{\&}partnerID=40{\&}md5=b927a96fc8858d9a53b8db61962e6931},
year = {2013}
}
@inproceedings{Schabus:2015:GIS:2982569.2982627,
address = {Portugal},
author = {Schabus, Stefan and Scholz, Johannes},
booktitle = {Proceedings of the 12th International Conference on Informatics in Control, Automation and Robotics - Volume 2},
doi = {10.5220/0005510804630470},
isbn = {978-989-758-123-6},
keywords = {Geographic Information Science,Industry 4.0,Smart Manufacturing,Space and Time.},
pages = {463--470},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
series = {ICINCO 2015},
title = {{Geographic Information Science and Technology As Key Approach to Unveil the Potential of Industry 4.0}},
url = {http://dx.doi.org/10.5220/0005510804630470},
year = {2015}
}
@inproceedings{Schfer2011,
abstract = {Personal location information is regarded as the most important contextual information transmitted in ubiquitous systems. Many pedestrian indoor localization systems rely on map-matching to constrain sensor errors. The maps required for computer aided localization and tracking need to incorporate a semantic structure. Such maps are not readily available and therefore most groups working on localization solutions manually create the required maps for specific testing scenarios. To provide a solution for map generation on a larger scale, we have developed a map generation toolkit that parses standard CAD-plans, to automatically generate topological maps for indoor environments. We propose a heuristic parser that separates superfluous data from the information depicting semantic building entities, e.g. rooms and doors. In our experiments approximately 95{\%} of all structures were detected successfully. After the extraction we transform the extracted building information into an object-based building model designed for the application of fast particle-filter-based map-matching algorithms. A performance test with a typical filter implementation demonstrates that the model is sufficiently optimized to achieve pedestrian tracking and localization in real-time. {\textcopyright} 2011 IEEE.},
annote = {cited By 15},
author = {Sch{\"{a}}fer, M and Knapp, C and Chakraborty, S},
booktitle = {2011 International Conference on Indoor Positioning and Indoor Navigation, IPIN 2011},
doi = {10.1109/IPIN.2011.6071951},
keywords = {Automatic Generation; Building model; Computer aid,Image matching,Real time systems; Semantics; Topology},
title = {{Automatic generation of topological indoor maps for real-time map-based localization and tracking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-82955197331{\&}doi=10.1109{\%}2FIPIN.2011.6071951{\&}partnerID=40{\&}md5=6d95300e71e3ae52824d4150c19f1b5d},
year = {2011}
}
@inproceedings{Schelkshorn2007,
abstract = {Nowadays knowledge about the position of persons indoors is relevant for a huge number of problems. An increasing number of modern applications and services is based on information refering to the users actual position and in some cases also on its velocity. In addition to these location based services also safety and security relevant tasks require these informations, e. g. critical infrastructure (CI) or small area surveillance. In outdoor scenarios the GPS-System is often used. In the case of indoor applications several approaches can be found in the literature. Most of them adopt the GPS-principle thus needing additional sensors and objects actively participating in the position finding task. We will present a system that is based on doppler measurement and only analyses a relative distance information between the object to be detected and four very basic sensors. Therefore no cooperation of the object is needed which is very important for the mentioned security relevant applications.},
annote = {cited By 2},
author = {Schelkshorn, S and Detlefsen, J},
booktitle = {Proceedings International Radar Symposium},
keywords = {Doppler measurement; Doppler sensors; Gps systems,Global positioning system; Radar; Telecommunicatio,Location based services},
title = {{Position finding using doppler sensors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927710592{\&}partnerID=40{\&}md5=ffc211b0d20d39dd4f1354eb549316e6},
volume = {2007-Janua},
year = {2007}
}
@inproceedings{Schroth201177,
abstract = {Distinctive visual cues are of central importance for image retrieval applications, in particular, in the context of visual location recognition. While in indoor environments typically only few distinctive features can be found, outdoors dynamic objects and clutter significantly impair the retrieval performance. We present an approach which exploits text, a major source of information for humans during orientation and navigation, without the need for error-prone optical character recognition. To this end, characters are detected and described using robust feature descriptors like SURF. By quantizing them into several hundred visual words we consider the distinctive appearance of the characters rather than reducing the set of possible features to an alphabet. Writings in images are transformed to strings of visual words termed visual phrases, which provide significantly improved distinctiveness when compared to individual features. An approximate string matching is performed using N-grams, which can be efficiently combined with an inverted file structure to cope with large datasets. An experimental evaluation on three different datasets shows significant improvement of the retrieval performance while reducing the size of the database by two orders of magnitude compared to state-of-the-art. Its low computational complexity makes the approach particularly suited for mobile image retrieval applications. {\textcopyright} 2011 IEEE.},
annote = {cited By 11},
author = {Schroth, G and Hilsenbeck, S and Huitl, R and Schweiger, F and Steinbach, E},
booktitle = {Proceedings - 2011 IEEE InternationalSymposium on Multimedia, ISM 2011},
doi = {10.1109/ISM.2011.21},
keywords = {Approximate string matching; CBIR; Content based i,Computational complexity; Feature extraction; Opt,Image retrieval},
pages = {77--84},
title = {{Exploiting text-related features for content-based image retrieval}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856326840{\&}doi=10.1109{\%}2FISM.2011.21{\&}partnerID=40{\&}md5=12c5171aa7eef9170f2e327e501bb133},
year = {2011}
}
@inproceedings{Schwarz2007,
abstract = {One emerging application of computing technology is that of interactive rooms and furniture. For instance, Interactive Tables allow for a workspace that is intuitive, natural, and conducive to creating multi-user collaborative work environments. Although several interactive table prototypes have been developed, we have engineered a method using a computer vision system instead of touch screen technology, which allows increased flexibility to the end user because of its ability to ignore or even make use of objects placed upon the table and its decreased likelihood of accidental input. In this work we present a method for implementing such a camera-driven interactive table with a ceiling-mounted camera and demonstrate some of its potential uses. The vision system makes use of a novel hand detection and segmentation technique designed to be tolerant of any level of background complexity on the display and any reasonable range of indoor lighting conditions, thus allowing the highest level of freedom to the end user. It searches the results of multi-scale line and curve finding systems to locate thimbleshaped finger models, marking them as candidate fingers and performing a set of geometric and texture-based tests on each to remove false positives. Finally, it groups finger detections that are similar to each other in location and appearance, while allowing the reintroduction of weak candidates that are supported by strong neighbors, into hand detections with finger and palm locations. Results demonstrate the system's ability extract enough information from images of hands in very complex backgrounds to allow for finger and palm placement recognition. {\textcopyright} 2007 IEEE.},
annote = {cited By 3},
author = {Schwarz, C and {Da Vitoria Lobo}, N},
booktitle = {Proceedings - IEEE Workshop on Applications of Computer Vision, WACV 2007},
doi = {10.1109/WACV.2007.58},
keywords = {Cameras; Computational complexity; Computer suppo,Computing technology; Interactive rooms; Interacti,Interactive computer graphics},
title = {{The camera-driven interactive table}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547210626{\&}doi=10.1109{\%}2FWACV.2007.58{\&}partnerID=40{\&}md5=e8bf0dd581bb075b37020d091dfca084},
year = {2007}
}
@inproceedings{Seco2010,
abstract = {The received signal strength (RSS) of radiofrequency signals emitted from beacons placed at known locations in an environment, can be used by a local positioning system (LPS) to estimate the location of a person or a mobile object. In indoor environments, interference, multipath propagation of RF signals, and the presence of obstacles and people, lead to a complex spatial distribution of the RSS, which is inaccurately described by simple parametric models. In this work, we present a Bayesian method for an indoor RFID location system which uses an observation model based in Gaussian processes (GPs) nonparametric regression to represent the environment-specific RSS distributions for the individual RFID tags. The experimental results in an indoor environment demonstrate the effectiveness of GPs in order to increase positioning accuracy. {\textcopyright} IEEE.},
annote = {cited By 38},
author = {Seco, F and Plagemann, C and Jim{\'{e}}nez, A R and Burgard, W},
booktitle = {2010 International Conference on Indoor Positioning and Indoor Navigation, IPIN 2010 - Conference Proceedings},
doi = {10.1109/IPIN.2010.5647095},
keywords = {Bayesian methods; Gaussian Processes; Indoor envir,Bayesian networks; Gaussian distribution; Gaussia,Communication channels (information theory)},
title = {{Improving RFID-based indoor positioning accuracy using Gaussian processes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650728659{\&}doi=10.1109{\%}2FIPIN.2010.5647095{\&}partnerID=40{\&}md5=5790a8fc7bc24137932d314eb913cce9},
year = {2010}
}
@article{Seo2018165,
abstract = {With the development of IoT technology, there is a growing demand for location based services for checking the mobility and identity of users, and remote controls for remote control of household appliances or electronic devices are used for home appliances or electronic devices there are many functions that are not available. In this case, when the remote controller is lost, there are difficulties in that a large number of home appliances or electronic devices can only be started by a limited operation or can't operate various operations. Especially, many people are losing a lot of remote control in everyday life, and the problem of wasting a considerable amount of time in finding a remote control is also happening. In order to solve this problem, the present invention proposes a method of opening a remote control search application content, registering a unique product number assigned to the remote control, generating a location notification request signal for requesting the location information of the remote controller, And then displays the captured location or dynamic model detected from the location notification response signal on the basis of the indoor framing for 2D or the indoor framing for 3D, It will be able to quickly and accurately locate the remote control that emits the beacon signal. In other words, in this paper, the application contents for remote controller search are opened to register a unique product number assigned to the remote controller, a location notification request signal for requesting the location information of the remote controller, and a location notification response And then displays the captured spot or dynamic model detected from the signal on the beacon for 2D or the 3D model for 3D. In the future, the research method to be carried out is limited to grasp the object information only by the remote controller (one single article object), but it is difficult to quickly recognize the object information transmitted from various objects having mobility used in the home or work We plan to implement and design an algorithm that optimizes the received signal strength of the BLE beacon so that there is no loss of beacon signal in a room that is subject to better system and multipath effects. {\textcopyright} 2018 Sung-Hyun Seo, Kwang-Hyun Ro.},
annote = {cited By 0},
author = {Seo, S.-H. and Ro, K.-H.},
doi = {10.14419/ijet.v7i2.33.13877},
journal = {International Journal of Engineering and Technology(UAE)},
number = {2},
pages = {165--170},
title = {{A study on design and implementation of dynamic location tracking system for locating remote control}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048248703{\&}doi=10.14419{\%}2Fijet.v7i2.33.13877{\&}partnerID=40{\&}md5=5f83a0d2058aa397237b3afddc6a3d4c},
volume = {7},
year = {2018}
}
@inproceedings{5654028,
abstract = {In a complex tracking environment like an airport many objects are tracked simultaneously. Some of these objects correlate to each other naturally, and thus the questions are how this correlation can be detected and how it can be used for increasing accuracy of the localisation system. The detection of the correlation is done by deciding if two objects are physically or logically bound or connected with each other. This could for example imply that a person is carrying a suitcase or sitting in a car, if these objects are tracked in a localisation system. The proposed approach to answer this question follows a two-step approach by checking computational-inexpensive preconditions first and evaluating a test statistic afterwards. This test statistic must be independent on the used fusion filter like Kalman or Particle Filter. Our results show, that one can reliably detect the physical binding and unbinding events and furthermore increase the location accuracy.},
author = {Settgast, C and Klepal, M and Weyn, M},
booktitle = {2010 Ubiquitous Positioning Indoor Navigation and Location Based Service},
doi = {10.1109/UPINLBS.2010.5654028},
keywords = {correlation methods;Kalman filters;mobile computin},
pages = {1--5},
title = {{Object correlation evaluation for location data fusion}},
year = {2010}
}
@inproceedings{Seyyedi20141078,
abstract = {Up to now, different indoor positioning algorithms based on Active RFID technology have been presented. These algorithms use the concept of reference tags to locate tracking tags that are attached to objects. Experimental results have shown that the increase of reference tags caused the increase of positioning accuracy. However if the number of these reference tags exceeds a limit two problems can arise. The first problem is the increase of multipath propagation and signal interference. The second problem is the increase of cost. In order to improve the performance of indoor environment this paper presents a new method to estimate the tracking tags' location based on virtual reference tags instead of increasing the number of real reference tags. In this method after calculating RSSI of each virtual reference tag by its surrounding real reference tags RSSI, sensing area is divided into several sections and tracking tags location is calculated by real or virtual reference tags which are in section that the objects has the highest probability to be enclosed within. Experimental results show that our purposed algorithm considerably reduced error estimation of previous algorithms. In comparison with LANDMARC and VIRE approach, we reduced average estimation error by about 70 percent and 10 percent respectively. {\textcopyright} 2014 IEEE.},
annote = {cited By 9},
author = {Seyyedi, S and Akbari, B and Arab, E and Ramezani, I and Mahdavi, M},
booktitle = {Proceedings - 2014 4th International Conference on Communication Systems and Network Technologies, CSNT 2014},
doi = {10.1109/CSNT.2014.220},
keywords = {Active RFID; Euclidian distance; Positioning algo,Algorithms,Communication systems; Internet of things; Radio f},
pages = {1078--1081},
title = {{Using virtual reference tags to improve the accuracy of active RFID-based positioning systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902593542{\&}doi=10.1109{\%}2FCSNT.2014.220{\&}partnerID=40{\&}md5=11e0e71c6fc87f190694f57d0d224a8d},
year = {2014}
}
@article{Shah2016238,
abstract = {During recent years, the demand for automated video surveillance has become the subject of much attention. Currently, video surveillance is an essential part of security and monitoring in banks, streets, buildings, department stores, stadiums, highways, railway stations, and crowded gatherings. One important reason for using video surveillance is to counter terrorism. In this context, a multi-camera handoff system for person re-identification using a color-based global appearance model is presented. We address two main factors that affect re-identification performance in this paper: (1) robust features (viewpoint orientation and indoor/outdoor cinematography) and (2) re-identification or classification. A hexagonal-superpixel method is introduced to minimize the false recognition rate due to the above-mentioned challenges. First we detect the human or object in a video and use a mixture of Gaussian models extended with a trajectory-learning algorithm to solve the trajectory dilemma. Second, a novel feature descriptor is proposed in which sensitive features are extracted using the proposed Color Hexagonal-SIFT and Color Histogram Features (CHF) methods. Third, we generate a combined appearance feature descriptor for re-identifying the human in different scenes. Finally, we introduce a Time-Tree-based learning method to minimize the gallery set's overhead and increase the accuracy of the re-identification results. The proposed framework is tested on videos taken using three cameras placed in three different locations. We also tested this framework on publically available data from the i-LIDS and VIPeR datasets. The results show outstanding speed and re-identification accuracy in dealing with the above-mentioned issues. {\textcopyright} 2016 Elsevier B.V.},
annote = {cited By 5},
author = {Shah, J H and Lin, M and Chen, Z},
doi = {10.1016/j.neucom.2016.01.037},
journal = {Neurocomputing},
keywords = {Article; camera; cineradiography; controlled stud,Automated video surveillance; Color histogram fea,Cameras; Color; Face recognition; Graphic methods;,Security systems},
pages = {238--248},
title = {{Multi-camera handoff for person re-identification}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957403395{\&}doi=10.1016{\%}2Fj.neucom.2016.01.037{\&}partnerID=40{\&}md5=fe991b5280013ba439828e974603101e},
volume = {191},
year = {2016}
}
@inproceedings{Shaikh2009193,
abstract = {Detecting or inferring human activity (e.g., an outdoor activity) by analyzing sensor data is often inaccurate, insufficient, difficult, and expensive. Therefore, this paper explains an approach to infer human activity and location considering the environmental sound cues and commonsense knowledge of everyday objects usage. Our system uses mel-frequency cepstral coefficients (MFCC) and their derivatives as features, and continuous density hidden Markov models (HMM) as acoustic models. Our work differs from others in three key ways. First, we utilize both indoor and outdoor environmental sound cues which are annotated according to the objects pertaining to the sound samples to build the idea regarding sounds and the objects which produce that particular sound. Second, use of portable microphone instead of having a fixed setup of an array of microphones to capture environmental sound we can also infer outdoor environments like being on the road, in a train station, etc., which previous research was limited to perform. Thirdly, our model is easy to incorporate new set of activities for further needs by adding more appropriately annotated sound clips and re-training of the HMM based recognizer. A perceptual test is made to study the human accuracy in the task and to obtain a baseline for the assessment of the performance of the system. Though the direct comparison of the system's performance to human performance is somewhat worse but the preliminary results are encouraging with the accuracy rate for outdoor and indoor sound categories for activities being above 67{\%} and 61{\%} respectively.},
annote = {cited By 0},
author = {Shaikh, M A M and Hirose, K and Prendinger, H},
booktitle = {SIGMAP 2009 - International Conference on Signal Processing and Multimedia Applications, Proceedings},
keywords = {Acoustic events; Activity detection; Auditory Scen,Acoustic logging; Acoustics; Hidden Markov models,Signal detection},
pages = {193--196},
title = {{Context awareness using environmental sound cues and commonsense knowledge}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-74549115218{\&}partnerID=40{\&}md5=667f85dd1d89d26780097be3ed7d9ffa},
year = {2009}
}
@inproceedings{Shangguan:2016:DIM:2906388.2906417,
address = {New York, NY, USA},
author = {Shangguan, Longfei and Jamieson, Kyle},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
doi = {10.1145/2906388.2906417},
isbn = {978-1-4503-4269-8},
keywords = {localization,multipath propagation,order tracking,rfid},
pages = {31--42},
publisher = {ACM},
series = {MobiSys '16},
title = {{The Design and Implementation of a Mobile RFID Tag Sorting Robot}},
url = {http://doi.acm.org/10.1145/2906388.2906417},
year = {2016}
}
@inproceedings{NoAuthor2009,
abstract = {The ACM International workshop on Interactive Multimedia for Consumer Electronics (IMCE) aims to bring together researchers from both academia and industry in domains including computer vision, machine learning, audio and speech processing, communications, artificial intelligence and media technology to share and discuss recent advances in interactive user interfaces and multimedia applications. Multimedia interaction is becoming a technology applied in many consumer electronics devices and can make user interfaces more intuitive and controllable. Multiple modalities including audio, video and haptics can be utilized and fused for media interaction.},
annote = {cited By 0},
author = {Shao, Ling and Shan, Caifeng and Luo, Jiebo and Etoh, Minoru},
booktitle = {1st ACM International Workshop on Interactive Multimedia for Consumer Electronics - IMCE'09, Co-located with the 2009 ACM International Conference on Multimedia, MM'09},
doi = {10.1145/1631272.1631544},
pages = {1149},
title = {{1st ACM international workshop on interactive multimedia for consumer electronics (IMCE'09)}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-72149092450{\&}partnerID=40{\&}md5=7e8b0f82579d7979a7ad99002255805f},
year = {2009}
}
@inproceedings{Shchekotov:2016:ACL:3181933.3181961,
address = {Helsinki, Finland, Finland},
author = {Shchekotov, Maxim},
booktitle = {Proceedings of the 19th Conference of Open Innovations Association FRUCT},
doi = {10.23919/FRUCT.2016.7892203},
keywords = {Bluetooth Low Energy,context-aware service,indoor localization,trilateration},
pages = {28:212----28:218},
publisher = {FRUCT Oy},
series = {FRUCT'19},
title = {{Automatic Calibration for Log-normal Path Loss Model Based on Bluetooth Low Energy Beacons}},
url = {https://doi.org/10.23919/FRUCT.2016.7892203},
year = {2016}
}
@inproceedings{7446817,
abstract = {In this paper, we investigate the problem of locating the indoor objects with the help of the received Wi-Fi signal strength fingerprints. Many Wi-Fi RSS based positioning techniques have been developed recently for indoor positioning purposes, but the positioning accuracy faces various challenges, including the high noise to signal ratio. In this paper, we consider two typical elements affecting the positioning performance: the slow attenuation of the signal strength, and the large measurement noise. We propose a novel approach to locate a target object in a given area by introducing a denoising algorithm based on the local linearity of the signal-location manifolds. This is implemented with a fixed set of linearization weights determined not by the signal values but by the relationships of the locations of the fingerprint samples. We also explore the relations among the prediction error and the manifold curvature, the number of APs used for positioning, and the signal noise level, characterizing the quality of the nearest point estimation with the signal measurement errors. A simple algorithm is presented to locate the target using the k-nearest neighbors in the signal space. Simulations in various settings demonstrate the effectiveness of the proposed approach.},
author = {Shen, G and Xie, Z},
booktitle = {11th International Conference on Wireless Communications, Networking and Mobile Computing (WiCOM 2015)},
doi = {10.1049/cp.2015.0685},
keywords = {indoor navigation;linearisation techniques;RSSI;si},
pages = {1--7},
title = {{Manifold locally linear denoising for Wi-Fi RSS based indoor positioning}},
year = {2015}
}
@inproceedings{Shen2012,
abstract = {Locating indoor object's position is a fundamental application in many industries. As a low cost and universal implementation in wireless sensor networks (WSN), received signal strength (RSS) based positioning faces challenges of interfered measurements introduced by multiple sources. In order to improve the location prediction accuracy, we proposed a Markov random field model for indoor positioning applications. A conditional distribution is adopted to quantify the RSS measurement quality used in prediction. A hierarchical algorithm is presented to lower the computational complexity. Experiments illustrated that the proposed approach rendered promising positioning accuracy. {\textcopyright} 2012 IEEE.},
annote = {cited By 1},
author = {Shen, G and Yu, J and Tan, L},
booktitle = {2012 International Conference on Wireless Communications, Networking and Mobile Computing, WiCOM 2012},
doi = {10.1109/WiCOM.2012.6478535},
keywords = {Conditional distribution; Hierarchical algorithm;,Image segmentation; Markov processes; Mobile comp,RSS},
title = {{Hierarchical RSS-based indoor positioning using a markov random field model}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876028354{\&}doi=10.1109{\%}2FWiCOM.2012.6478535{\&}partnerID=40{\&}md5=7e3438e07cbb8ebba6f8a2d3ceeb7434},
year = {2012}
}
@inproceedings{Shen:2013:WRB:2694643.2694650,
address = {New York, NY, USA},
author = {Shen, Gang and Xie, Zegang},
booktitle = {Proceedings of the 9th International Conference on Active Media Technology - Volume 8210},
doi = {10.1007/978-3-319-02750-0_5},
isbn = {978-3-319-02749-4},
keywords = {Conjugate gradients,Indoor positioning,Maximum a posteriori,Received Wi-Fi signal strength},
pages = {46--55},
publisher = {Springer-Verlag New York, Inc.},
series = {AMT 2013},
title = {{Wi-Fi RSS Based Indoor Positioning Using a Probabilistic Reduced Estimator}},
url = {http://dx.doi.org/10.1007/978-3-319-02750-0{\_}5},
year = {2013}
}
@article{Shen2016264,
abstract = {The success of the Global Positioning System (GPS) makes the demand for location-based services increase rapidly. However, in the indoor environment, since the reception of the satellite signal is disrupted severely, the accuracy of GPS positioning can not meet the requirements. Radio Frequency Identification (RFID) technology with the advantages of non-contact, non-visibility, low cost and high positioning accuracy, begins to get more and more attention and becomes the most suitable indoor positioning technology. RFID location is a technique which is based on signal strength positioning, using the received signal strength indication (Received Signal Strength Indicator, RSSI) to determine the position of the object. In recent years, the indoor positioning technology has made great progress, especially on the verity of the localization algorithm. In this paper, we will briefly describe the basic principles of RFID, then we introduce the algorithms of existing indoor RFID positioning system. Finally, we analyze their strengths and weaknesses. {\textcopyright} Springer International Publishing AG 2016.},
annote = {cited By 1},
author = {Shen, J and Jin, C and Liu, D},
doi = {10.1007/978-3-319-48674-1_24},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Global positioning system,Indoor positioning systems; Location based service,Indoor positioning; Localization algorithm; Posit},
pages = {264--274},
title = {{A survey on the research of indoor RFID positioning system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015341382{\&}doi=10.1007{\%}2F978-3-319-48674-1{\_}24{\&}partnerID=40{\&}md5=77582b546d718ff3c24ae0ce5dabcf6c},
volume = {10040},
year = {2016}
}
@article{Shen2014263,
abstract = {With the explosive growth of web-based cameras and mobile devices, billions of photographs are uploaded to the internet. We can trivially collect a huge number of photo streams for various goals, such as image clustering, 3D scene reconstruction, and other big data applications. However, such tasks are not easy due to the fact the retrieved photos can have large variations in their view perspectives, resolutions, lighting, noises, and distortions. Furthermore, with the occlusion of unexpected objects like people, vehicles, it is even more challenging to find feature correspondences and reconstruct realistic scenes. In this paper, we propose a structure-based image completion algorithm for object removal that produces visually plausible content with consistent structure and scene texture. We use an edge matching technique to infer the potential structure of the unknown region. Driven by the estimated structure, texture synthesis is performed automatically along the estimated curves. We evaluate the proposed method on different types of images: from highly structured indoor environment to natural scenes. Our experimental results demonstrate satisfactory performance that can be potentially used for subsequent big data processing, such as image localization, object retrieval, and scene reconstruction. Our experiments show that this approach achieves favorable results that outperform existing state-of-the-art techniques. {\textcopyright} 2014 River Publishers.},
annote = {cited By 3},
author = {Shen, J and Yang, J and Taha-abusneineh, S and Payne, B and Hitz, M},
doi = {10.13052/jcsm2245-1439.332},
journal = {Journal of Cyber Security and Mobility},
number = {3},
pages = {263--288},
title = {{Structure preserving large imagery reconstruction}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000702971{\&}doi=10.13052{\%}2Fjcsm2245-1439.332{\&}partnerID=40{\&}md5=0d185277f4e62de0cdd6448f06605b85},
volume = {3},
year = {2014}
}
@article{Shen:2017:DDM:3134224.3065949,
address = {New York, NY, USA},
author = {Shen, Jiaxing and Cao, Jiannong and Liu, Xuefeng and Zhang, Chisheng},
doi = {10.1145/3065949},
issn = {2157-6904},
journal = {ACM Trans. Intell. Syst. Technol.},
keywords = {AP deployment measuring,Wi-Fi AP,data-driven approach,room-level localization},
number = {1},
pages = {11:1----11:29},
publisher = {ACM},
title = {{DMAD: Data-Driven Measuring of Wi-Fi Access Point Deployment in Urban Spaces}},
url = {http://doi.acm.org/10.1145/3065949},
volume = {9},
year = {2017}
}
@article{Shewell2014195,
abstract = {This paper proposes an approach todetermining an occupant's indoor location through the use of machine vision techniques combined with wearable computing. Based on off-the-shelf machine vision tools a system is introduced to obtain a user's indoor location through the detection of reference objects in their immediate environment. This information is subsequently cross-referenced with a knowledge base containing details ofwhich rooms referencemarkers are located in.Details of the architecture required to realize the solution are presented which also accommodates for the fusion of information sources overcoming the heterogeneous nature of data gathered frommultiple sourceswithin the environment.The solution can be used to provide context aware assistance with Activities of Daily Living to those who may normally require assistance in their day-today life hence allowing them to live independently at home for longer. {\textcopyright} Springer International Publishing Switzerland 2014.},
annote = {cited By 0},
author = {Shewell, C and Nugent, C D and Donnelly, M and Wang, H},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Activities of Daily Living; Context-Aware; Immedi,Computer vision; Wearable technology,Knowledge based systems; Object detection; Wearabl},
pages = {195--202},
title = {{Wearable computing to support activities of daily living}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921725948{\&}partnerID=40{\&}md5=f10e5c7339bcaf4dc75b0fe6120af255},
volume = {8868},
year = {2014}
}
@inproceedings{Shih:2006:RMO:2173493.2173555,
address = {Berlin, Heidelberg},
author = {Shih, Ming-Yu and Fu, Bwo-Chau},
booktitle = {Proceedings of the First Pacific Rim Conference on Advances in Image and Video Technology},
doi = {10.1007/11949534_59},
isbn = {3-540-68297-X, 978-3-540-68297-4},
pages = {591--600},
publisher = {Springer-Verlag},
series = {PSIVT'06},
title = {{Robust Moving Object Detection on Moving Platforms}},
url = {http://dx.doi.org/10.1007/11949534{\_}59},
year = {2006}
}
@inproceedings{Shim2015502,
abstract = {Localization is a technique that is needed for the service robot to drive at indoors, and it has been studied in various ways. Most localization techniques let the robot measure environmental information to gain location information, but those require high costs as it use many equipment, and also complicate the robot development. But if an external device could calculate the location of the robot and transmit it to the robot, it will reduce the extra cost for the internal equipment needed to recognize the location, and it will also simplify the robot development. Therefore this study suggests an effective way to control the robot by using the location information of the robot included in a map made by visual information from the surveillance cameras installed at indoors. The object in a single image is difficult to tell its size because of the shadow components and occlusion. Therefore, combination of shadow removal technique using HSV image from indoors and images from different perspective using homography to create two-dimensional map with accurate object information is suggested. In the experiment, the effectiveness of the suggested method is shown by analyzing the movement result of the robot which applied the location information from the two-dimensional map that is based on the multi cameras, which its accuracy is measured in advance. {\textcopyright} 2015 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license.},
annote = {cited By 4},
author = {Shim, J.-H. and Cho, Y.-I.},
booktitle = {Procedia Computer Science},
doi = {10.1016/j.procs.2015.07.242},
keywords = {Cameras; Indoor positioning systems; Location; Mob,Environmental information; Homographies; Indoor;,Robots},
number = {1},
pages = {502--507},
title = {{A mobile robot Localization using external surveillance cameras at indoor}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939124915{\&}doi=10.1016{\%}2Fj.procs.2015.07.242{\&}partnerID=40{\&}md5=18266b69ee8591b67b944b8ea84d3680},
volume = {56},
year = {2015}
}
@inproceedings{1460408,
abstract = {There are strong demands to extend existing surveillance systems with monocular cameras to create systems that can automatically detect unusual situations and issue alarms to the administrator. Most public surveillance functions pay attention to human traffic: the speed and direction of human flow. This is because these clues help to identify exceptional situations. In this paper, we propose a method for estimating people-flow speed in video sequences by allocating stands on CG (computer generated) scenes. To effectively handle crowded indoor scenes captured through a common monocular camera, we calculate an actual motion vector with optical flows and a background scene model. Because the location of objects cannot be specified by cross shots, it is not possible to relate a motion vector in a video sequence to that in the real world. To overcome this problem, we infer the motion vector in the real world by scaling the vector in the video sequence. For this purpose, we employ the "scaling factor" which is derived from a probability distribution of camera-distances of CG objects in CG images. We examine the effectiveness of our method using video sequences captured by two train station surveillance cameras.},
author = {Shimmura, T and Arai, H and Inoue, U},
booktitle = {IEEE Conference on Cybernetics and Intelligent Systems, 2004.},
doi = {10.1109/ICCIS.2004.1460408},
keywords = {surveillance;image sequences;motion estimation;com},
pages = {179--184 vol.1},
title = {{Estimating human-flow speed for video surveillance by probabilistic stands}},
volume = {1},
year = {2004}
}
@article{Shin20121815,
abstract = {Existing R-tree that is based on a variety of outdoor-based techniques to manage moving objects have been investigated. Due to the different characteristics of the indoor and outdoor, it is difficult to management of moving object using existed methods in indoor setting. We propose a new index structure called ACII(adaptive Cell-based index for Indoor moving objects) for Indoor moving objects. ACII is Cell-based access structure adopting an overlapping technique. The ACII refines cells adaptively to handle indoor regional data, which may change its locations over time. The ACII consumed at most 30{\%} of the space required by R-tree based methods, and achieved higher query performance compared with r-tree based methods. {\textcopyright} 2012 KSII.},
annote = {cited By 7},
author = {Shin, S S and Kim, G and Bae, H},
doi = {10.3837/tiis.2012.07.006},
journal = {KSII Transactions on Internet and Information Systems},
keywords = {Access structure; Cell-based; Indoor; Moving objec,Cells; Data; Decision Making; Forestry; Trees,Cells; Decision trees; Forestry,Cytology},
number = {7},
pages = {1815--1830},
title = {{Adaptive cell-based index for moving objects in indoor}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864833967{\&}doi=10.3837{\%}2Ftiis.2012.07.006{\&}partnerID=40{\&}md5=1183932ccb4ca27e925981f2e1e78559},
volume = {6},
year = {2012}
}
@article{6140967,
abstract = {Ambient intelligence (AmI) considers responsive environments in which applications and services adapt their behavior according to the user's needs and changing context. One of the most challenging aspects for many applications in AmI environments is location and orientation of the surrounding objects. This is especially important for effective cooperation among mobile physical objects in such smart environments. In this paper, we propose a robust indoor positioning system that provides 2-D positioning and orientation information for mobile objects. The system utilizes low-range passive radio frequency identification (RFID) technology. The proposed system, which consists of RFID carpets and several peripherals for sensor data interpretation, is implemented and tested through extensive experiments. Our results show that the proposed system outperforms similar existing systems in minimizing the average positioning error.},
author = {Shirehjini, A A N and Yassine, A and Shirmohammadi, S},
doi = {10.1109/TIM.2011.2181912},
issn = {0018-9456},
journal = {IEEE Transactions on Instrumentation and Measurement},
keywords = {artificial intelligence;computerised instrumentati},
number = {6},
pages = {1664--1675},
title = {{An RFID-Based Position and Orientation Measurement System for Mobile Objects in Intelligent Environments}},
volume = {61},
year = {2012}
}
@inproceedings{1577132,
abstract = {This paper demonstrates the effectiveness of narrowband source localization techniques in indoor environments. Experiments are conducted using multiple antennas and a network analyzer. An active RF source is placed at different locations in a medium-sized office. Three sensors, placed at known positions, are used to estimate the location of the source using time of arrival (TOA) information. Trilateration is first utilized to obtain an initial estimate for the source location. Constrained optimization is then applied to improve estimation accuracy. In the experiment setup, only one sensor has a line-of-sight (LOS) communication path to the source, while the other two sensors are restricted to a non-line-of-sight setting. Different obstructed line-of-sight (OLOS) biases are physically introduced to demonstrate a real-life situation, where several moving objects may exist between the source and the sensors},
author = {Shoeb, M and Ahmad, F and Amin, M},
booktitle = {Proceedings of the Fifth IEEE International Symposium on Signal Processing and Information Technology, 2005.},
doi = {10.1109/ISSPIT.2005.1577132},
issn = {2162-7843},
keywords = {antenna arrays;indoor radio;network analysers;time},
pages = {411--416},
title = {{Narrowband source localization for indoor wireless environments}},
year = {2005}
}
@inproceedings{Shrestha2013122,
abstract = {Location Based Services require seamless tracking of human or object outdoor/indoor anywhere, everywhere. Based on its location and availability, it should make use of the underlying wireless system it has access to or it could process. In terms of vehicular system also, it requires seamless tracking also in the indoor parking or places where it lacks clear LOS and has to depend upon the widely accessed Wireless Local Area Network based localization. This paper focuses on Received Signal Strength measurements dynamics in WLAN indoor localization. Real-field measurement data taken 3 year apart in the same university building (situated in Tampere, Finland) are used for this analysis. The building AP network has undergone a substantial structural change in between the two sets of measurements, in such a way that most WLAN emitters were replaced and renewed. We study here the variability and dynamics of the indoor channel and accuracy of the positioning results when emitter configuration is changed, but the indoor scenario remains the same (same building structure, same rooms and furniture). {\textcopyright} 2013 IEEE.},
annote = {cited By 12},
author = {Shrestha, S and Talvitie, J and Lohan, E S},
booktitle = {2013 13th International Conference on ITS Telecommunications, ITST 2013},
doi = {10.1109/ITST.2013.6685532},
keywords = {Building structure; Fingerprinting (FP); Indoor l,College buildings; Dynamics; Location based servic,Wireless local area networks (WLAN)},
pages = {122--126},
title = {{On the fingerprints dynamics in WLAN indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893635234{\&}doi=10.1109{\%}2FITST.2013.6685532{\&}partnerID=40{\&}md5=47764486ba8197f68f567514c2d5e25a},
year = {2013}
}
@inproceedings{Siddiqua2018939,
abstract = {Depth image based 3D model retrieval faces challenges of occlusion, noise, and view variability present in depth images. In this work, we study a new supervised deep autoencoder for depth image-based 3D model retrieval. We investigate both supervised and unsupervised approaches to bring synthetic depth images rendered from 3D models and real depth images in the same feature space. We show that providing appropriate supervision in back propagation of the autoencoder can help the retrieval performance. The key novelty is the new objective function where supervised classification information is combined with the reconstruction error for joint optimization. It is interesting to manifest that, unlike any other pairwise model structures, crossdomain retrieval is still possible using only one single deep network in our model. We have evaluated the effectiveness of our model on NYUD2 depth image dataset and Model-Net10 models for ten indoor object categories. We have rendered 95 different views for each 3D model and found that training rendered and real depth images together is an effective way to bridge the gap between 3D models and depth data. The proposed supervised method outperforms the recent pairwise approach. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Siddiqua, A and Fan, G},
booktitle = {Proceedings - 2018 IEEE Winter Conference on Applications of Computer Vision, WACV 2018},
doi = {10.1109/WACV.2018.00108},
keywords = {3 d model retrievals; Joint optimization; Objecti,Backpropagation; Classification (of information);,Image retrieval},
pages = {939--946},
title = {{Supervised Deep-Autoencoder for Depth Image-Based 3D Model Retrieval}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050959663{\&}doi=10.1109{\%}2FWACV.2018.00108{\&}partnerID=40{\&}md5=fe6052b76a744455c3f7e6f3c209e952},
volume = {2018-Janua},
year = {2018}
}
@inproceedings{5415425,
abstract = {Localization of persons and objects is a current need of many industrial applications. Although in outdoor environments GPS or the cell-of-origin technique can have good results, they are very limited in indoor environments. In indoor environments other technologies such as RFID have a better performance. We propose an RFID based system, called TraceMe, to be used in real-time indoor localization. Besides localization it also enables area access control of people and objects, is able of alarm generation due to communications failure, access violation or tag violation, and is responsible for the interoperability of the deployed equipment. System specification, implementation, field tests and analysis of results are presented in this paper. As any traditional RFID system, it is constituted by Readers and Tags. The used tags are active and have the particularity of using two different communications frequencies. Besides the hardware also a Java-based middleware was developed. It is responsible to give meaning to data and to coordinate communications between all architecture elements. Final tests to the prototype were made in a public hospital.},
author = {Silva, P M M A and Paralta, M and Caldeirinha, R and Rodrigues, J and Ser{\^{o}}dio, C M J A},
booktitle = {2009 35th Annual Conference of IEEE Industrial Electronics},
doi = {10.1109/IECON.2009.5415425},
issn = {1553-572X},
keywords = {access control;middleware;open systems;radiofreque},
month = {nov},
pages = {2721--2725},
title = {{Traceme  indoor real-time location system}},
year = {2009}
}
@inproceedings{7011148,
abstract = {This paper describes TaggingCreaditor, a content authoring tool for location-based games. This tool is implemented both as a mobile and desktop application, which offers the possibility to end users to easily create, edit and/or mix content for these games. TaggingCreaditor has been designed to support a number of location-based games for learning in cultural heritage sites, based on the idea of connections between digital content and the physical world. Thus, the aim of the reported research was to create a tool that can support the users to customize these games by creating content in the form of textual and multimedia information that can be linked with specific locations or objects indoors and outdoors. In this paper we outline the design rationale and discuss the findings of an initial evaluation study.},
author = {Sintoris, C and Yiannoutsou, N and Ortega-Arranz, A and L{\'{o}}pez-Romero, R and Masoura, M and Avouris, N and Dimitriadis, Y},
booktitle = {2014 International Conference on Interactive Mobile Communication Technologies and Learning (IMCL2014)},
doi = {10.1109/IMCTL.2014.7011148},
keywords = {authoring systems;computer aided instruction;compu},
month = {nov},
pages = {280--284},
title = {{TaggingCreaditor: A tool to create and share content for location-based games for learning}},
year = {2014}
}
@inproceedings{Sivan:2016:CVB:2967878.2967923,
address = {New York, NY, USA},
author = {Sivan, Shankar and Darsan, Gopu},
booktitle = {Proceedings of the 7th International Conference on Computing Communication and Networking Technologies},
doi = {10.1145/2967878.2967923},
isbn = {978-1-4503-4179-0},
keywords = {Assistive technology,Computer vision,Image processing,electronic travel aids,wearable systems},
pages = {41:1----41:8},
publisher = {ACM},
series = {ICCCNT '16},
title = {{Computer Vision Based Assistive Technology for Blind and Visually Impaired People}},
url = {http://doi.acm.org/10.1145/2967878.2967923},
year = {2016}
}
@article{Sjberg2010190,
abstract = {The PicSOM multimedia analysis and retrieval system has previously been successfully applied to supervised concept detection in image and video databases. Such concepts include locations and events and objects of a particular type. In this paper we apply the general-purpose visual category recognition algorithm in PicSOM to the recognition of indoor locations in the ImageCLEF/ICPR RobotVision 2010 contest. The algorithm uses bag-of-visual-words and other visual features with fusion of SVM classifiers. The results show that given a large enough training set, a purely appearance-based method can perform very well - ranked first for one of the contest's training sets. {\textcopyright} 2010 Springer-Verlag.},
annote = {cited By 1},
author = {Sj{\"{o}}berg, M and Koskela, M and Viitaniemi, V and Laaksonen, J},
doi = {10.1007/978-3-642-17711-8_20},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Algorithms; Pattern recognition; Object recogniti,Appearance-based methods; Bag-of-visual-words; Cat,Signal processing; Pattern recognition},
pages = {190--199},
title = {{PicSOM experiments in ImageCLEF RobotVision}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650822972{\&}doi=10.1007{\%}2F978-3-642-17711-8{\_}20{\&}partnerID=40{\&}md5=82adbdae09e4f35360831a12011083a3},
volume = {6388 LNCS},
year = {2010}
}
@inproceedings{Sjoberg:2010:PEI:1939170.1939197,
address = {Berlin, Heidelberg},
author = {Sj{\"{o}}berg, Mats and Koskela, Markus and Viitaniemi, Ville and Laaksonen, Jorma},
booktitle = {Proceedings of the 20th International Conference on Recognizing Patterns in Signals, Speech, Images, and Videos},
isbn = {3-642-17710-7, 978-3-642-17710-1},
pages = {190--199},
publisher = {Springer-Verlag},
series = {ICPR'10},
title = {{PicSOM Experiments in ImageCLEF Robot Vision}},
url = {http://dl.acm.org/citation.cfm?id=1939170.1939197},
year = {2010}
}
@inproceedings{Smeaton:2006:OAT:2182271.2182330,
address = {Berlin, Heidelberg},
author = {Smeaton, Alan F and Jones, Gareth J F and Lee, Hyowon and O{\&}{\#}39;Connor, Noel E and Sav, Sorin},
booktitle = {Proceedings of the 28th European Conference on Advances in Information Retrieval},
doi = {10.1007/11735106_45},
isbn = {3-540-33347-9, 978-3-540-33347-0},
pages = {476--479},
publisher = {Springer-Verlag},
series = {ECIR'06},
title = {{Object-Based Access to TV Rushes Video}},
url = {http://dx.doi.org/10.1007/11735106{\_}45},
year = {2006}
}
@inproceedings{6523836,
abstract = {Our institution has on-going research projects which utilize autonomous mobile robots in a variety of settings. These robots navigate and interact with humans and their environment. As part of this effort a framework to integrate the navigational operation and the speech interaction to react to contextual stimuli is provided. This framework provides a system which is easy to configure and modify. The basis of this framework blends the rationale of human nature with the interpretation of sensor inputs. This combination of real-time and environmental information is at the core of having situational awareness. Context-based mapping allows the system to learn an environmental context and how to identify it from real-time interaction. Context-based mapping techniques link data prioritized by contextual value to physical locations on a visual or representative map. This system categorizes objects and events in an adaptive way. By determining the appropriate behavior in a given situation, a mobile robot uses only the relevant knowledge and data. This information is stored to allow both historical and real-time data to be used as appropriate. This approach allows the robot to access the previously collected data for statistical reference. As data are collected from various sensory inputs, the weighted contribution in that context is determined. This research examined the deployment of an autonomous mobile robot. The robot was able to function in the environment, which included both indoor and outdoor settings. Speech was used for input and as response explanations by the robot. The robot was trained initially in a supervised mode, but after the heuristics and adjustments had been reached, the robot was able to balance the sensors appropriately and learn without supervision. The result was a robot that could navigate autonomously and respond to the environment appropriately. Experiments were performed to demonstrate the ability of the robot to function effectively in indoor and outdoor environments and transition between them. The robot was also able to create a defined signature for a location using sensor information. After this training, the robot was able to exhibit situational awareness in dynamic environments, answering numerous questions regarding the state of the surrounding environment.},
author = {Smith, C V and Doran, M V and Daigle, R J and Thomas, T G},
booktitle = {2013 IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support (CogSIMA)},
doi = {10.1109/CogSIMA.2013.6523836},
keywords = {human-robot interaction;mobile robots;path plannin},
pages = {134--138},
title = {{Enhanced situational awareness in autonomous mobile robots using context-based mapping (October 2012)}},
year = {2013}
}
@inproceedings{Solea2013479,
abstract = {This paper proposes a framework to build a 3D model for an indoor object from partial data using a mobile robot. The purpose of the paper is to obtain photorealistic 3D models for objects from raw mobile laser scanning data and digital camera information (to improve the appearance information). The proposed method integrates and analyses the relationships between the visual data and raw mobile laser scanning data. This method is capable to recover the complete density range and the shape of the investigated object. In order to obtain 3D mapping using the laser sensor system (called Lidar), this is positioned to a vertical scan orientation and the tilt actuator provides a rotation movement to the Lidar in order to perform a 3D scan. In this paper, the mobile system acquires 3D Lidar Data only while it is stationary. A 3D map of an object is created by acquiring overlapping scans from multiple locations and viewpoints using local co-ordinates for each scan and merging the scan into a single global co-ordinate system. Video registration is used to texture the scan points in order to provide photo realistic 3D maps. Some techniques are also implemented to improve the resolution of the Lidar Scan with video data. Experiments on real-world data are given to illustrate the suitability of this approach. {\textcopyright} 2013 IEEE.},
annote = {cited By 3},
author = {Solea, R and Veliche, G and Cernega, D.-C. and Teaca, M.-R.},
booktitle = {2013 17th International Conference on System Theory, Control and Computing, ICSTCC 2013; Joint Conference of SINTES 2013, SACCS 2013, SIMSIS 2013 - Proceedings},
doi = {10.1109/ICSTCC.2013.6689007},
keywords = {3D object modeling; Camera information; Co-ordinat,Data fusion; Digital cameras; Laser applications;,Three dimensional},
pages = {479--484},
title = {{Indoor 3D object model obtained using data fusion from laser sensor and digital camera on a mobile robot}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893250490{\&}doi=10.1109{\%}2FICSTCC.2013.6689007{\&}partnerID=40{\&}md5=b7fc25be1df6c6b9f7b64518b09db8eb},
year = {2013}
}
@phdthesis{Somanath:2012:ISU:2518433,
address = {Newark, DE, USA},
annote = {AAI3555419},
author = {Somanath, Gowri},
isbn = {978-1-267-96974-3},
publisher = {University of Delaware},
title = {{Indoor Scene Understanding}},
year = {2012}
}
@article{Song20061040,
abstract = {Object detection is very important to service robots. Many tasks for service such as delivery, cleaning, and health-care for elderly people are strongly related to objects. Conventional approaches for object detection are mainly based on the geometric models, because they have been applied to static environments. In indoor environments having uncertainty, they have limitation in some situations where interesting objects are occluded by other ones or small in the scene. Context information can be helpful to overcome these uncertain situations. In this paper, we adopt objects as context information to allow for service robots to predict the probability of interesting objects through observed ones. For this, an object relationship model based on Bayesian network (BN) and integration method are proposed. Experimental results confirm that the proposed method predicts the objects very well. {\textcopyright} Springer-Verlag Berlin Heidelberg 2006.},
annote = {cited By 0},
author = {Song, Y.-S. and Cho, S.-B.},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Bayesian network integration; Context information,Computational geometry; Health care; Information r,Object recognition},
pages = {1040--1046},
title = {{Objects relationship modeling for improving object detection using bayesian network integration}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749574812{\&}partnerID=40{\&}md5=9c063b2db046bee1a223cc1e458c3e73},
volume = {4113 LNCS },
year = {2006}
}
@article{Song201842,
abstract = {In view of the shortcomings in localization accuracy of current multiple target localization algorithm, a method of multi-object localization based on compressive sensing(CS) and alternate iteration is proposed. Firstly, the measurement matrix of received signal strength(RSS) is expressed as the product of measurement matrix and sparse vector according to CS theory, which transforms multiple target localization problem to the reconstruction of sparse vector. Next, traditional localization algorithm based on CS is presented to obtain rough estimation of target positions. Finally, alternate iteration method is employed to further refine positions when localization results are not accurate. During the alternate iteration process, the diamond search is used to find the exact target locations. Simulation results show that the proposed algorithm overcomes the limitation of traditional compressive sensing localization techniques which can only locate targets in the center of grid, and improves the localization interference of the interaction between objects with high localization accuracy. The indoor operation and maintenance inspection area of a power company in Chongqing is chosen as an experimental site and the proposed method is applied to the actual inspection localization, and good results are achieved in the indoor localization. {\textcopyright} 2018, Chongqing Medical University. All right reserved.},
annote = {cited By 0},
author = {Song, Z and Zhong, Y and Chen, T and Li, J and Wang, K and Zhou, Y},
doi = {10.11835/j.issn.1000-582X.2018.03.005},
journal = {Chongqing Daxue Xuebao/Journal of Chongqing University},
number = {3},
pages = {42--50},
title = {{Multiple target localization algorithm based on alternate iteration using compressive sensing []}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060080398{\&}doi=10.11835{\%}2Fj.issn.1000-582X.2018.03.005{\&}partnerID=40{\&}md5=ea750028492f1626f796955466e18ad7},
volume = {41},
year = {2018}
}
@inproceedings{Sovi2011193,
abstract = {In this paper, we propose a particle filtering (PF) method for indoor tracking using radio frequency identification (RFID) based on aggregated binary measurements. We use an Ultra High Frequency (UHF) RFID system that is composed of a standard RFID reader, a large set of standard passive tags whose locations are known, and a newly designed, special semi-passive tag attached to an object that is tracked. This semi-passive tag has the dual ability to sense the backscatter communication between the reader and other passive tags which are in its proximity and to communicate this sensed information to the reader using backscatter modulation. We refer to this tag as a sense-a-tag (ST). Thus, the ST can provide the reader with information that can be used to determine the kinematic parameters of the object on which the ST is attached. We demonstrate the performance of the method with data obtained in a laboratory environment. {\textcopyright} 2011 IEEE.},
annote = {cited By 18},
author = {Sovi{\'{c}}, V and Athalye, A and Boli{\'{c}}, M and Djuri{\'{c}}, P M},
booktitle = {IEEE Workshop on Statistical Signal Processing Proceedings},
doi = {10.1109/SSP.2011.5967656},
keywords = {Agglomeration; Backscattering; Cryptography; Line,Backscatter modulation; Indoor tracking; Kinematic,Radio frequency identification (RFID)},
pages = {193--196},
title = {{Particle filtering for indoor RFID tag tracking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052246218{\&}doi=10.1109{\%}2FSSP.2011.5967656{\&}partnerID=40{\&}md5=855827dcdf7dc3ecea06f58cec5d5aa6},
year = {2011}
}
@inproceedings{7821015,
abstract = {This document describes a system to gather information from a stationary camera to identify moving objects. The proposed solution makes only use of motion vectors between adjacent frames, obtained from any algorithm. Starting from them, the system is able to retrieve clusters of moving objects in a scene acquired by an image sensor device. Since all the system is only based on optical flow, it is really simple and fast, to be easily integrated directly in low cost cameras. The experimental results show fast and robust performance of our method. The computation time is about 800 frame/sec for a VGA sequence on a 2.3GHz processor (ARM Cortex-A15). Moreover, the system has been tested for different applications, cross traffic alert and video surveillance, in different conditions, indoor and outdoor, and with different lens, linear and fish-eye.},
author = {Spampinato, G and Bruna, A R and Curti, S and D'Alto, V},
booktitle = {2016 Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA)},
doi = {10.1109/IPTA.2016.7821015},
issn = {2154-512X},
keywords = {cameras;image motion analysis;image retrieval;imag},
pages = {1--5},
title = {{Advanced low cost clustering system}},
year = {2016}
}
@inproceedings{Sriharee2015647,
abstract = {Indoor navigation is difficult because of complexity of indoor space. The efficient navigation system is required for locating the objects in space with accuracy. This research proposes an indoor navigation system which relies on symbolic information described by OWL. The description is used for path finding and for generating navigation instruction. The proposed indoor navigation system is developed using semantic web technology and the mobile application for navigation is developed on Android platform. With OWL-based symbolic information, spatial object information is described semantically in which both computer and human are readable and therefore, the spatial object information is easier to create and to maintain. Using direction-based navigation, interaction between human and system is flexible and the users are able to realise the orientation of current location easily. {\textcopyright} 2015 The Authors. Published by Elsevier B.V.},
annote = {cited By 1},
author = {Sriharee, G},
booktitle = {Procedia Computer Science},
doi = {10.1016/j.procs.2015.05.065},
keywords = {Android platforms; In-door navigations; Indoor na,Birds; Complex networks; Navigation systems; Ontol,Indoor positioning systems},
number = {1},
pages = {647--653},
title = {{A symbolic-based indoor navigation system with direction-based navigation instruction}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939172479{\&}doi=10.1016{\%}2Fj.procs.2015.05.065{\&}partnerID=40{\&}md5=3f4f8fca6230e9549671c8158ca528a3},
volume = {52},
year = {2015}
}
@article{Stahl:2011:UPB:1997767.1997782,
address = {New York, NY, USA},
author = {Stahl, James E and Holt, Julie K and Gagliano, Nancy J},
doi = {10.1007/s10916-009-9365-7},
issn = {0148-5598},
journal = {J. Med. Syst.},
keywords = {Operations research,Outpatient,RFID,System behavior,Time---motion},
number = {3},
pages = {291--297},
publisher = {Plenum Press},
title = {{Understanding Performance and Behavior of Tightly Coupled Outpatient Systems Using RFID: Initial Experience}},
url = {http://dx.doi.org/10.1007/s10916-009-9365-7},
volume = {35},
year = {2011}
}
@inproceedings{Starner1997169,
abstract = {The Locust infared system provides inexpensive messaging and location information without batteries and without its own network. The system is `privacy aware' in that it supplies information to the wearable computer user who can then control how much of this information is shared with others or the installed infrastructure. By combining the abilities of Locusts with an appropriately equipped wearable computer, the user can interact with web-like hyperlinks, graphics, and sounds virtually associated with objects in the physical world. In addition the user can annotate and change these links as desired.},
annote = {cited By 47},
author = {Starner, T and Kirsch, D and Assefa, S},
booktitle = {International Symposium on Wearable Computers, Digest of Papers},
keywords = {Data communication systems,Human computer interaction; Interactive computer s,Indoor location systems; Wearable computers},
pages = {169--170},
title = {{Locust swarm: An environmentally-powered, networkless location and messaging system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031359923{\&}partnerID=40{\&}md5=0c988bdb282891b2b897e3c14f44081d},
year = {1997}
}
@inproceedings{Starner:1998:VCA:857199.858017,
address = {Washington, DC, USA},
author = {Starner, Thad and Schiele, Bernt and Pentland, Alex},
booktitle = {Proceedings of the 2Nd IEEE International Symposium on Wearable Computers},
isbn = {0-8186-9074-7},
keywords = {augmented reality,computer vision,context,gesture,indoor position,object recognition,wearable computing},
pages = {50----},
publisher = {IEEE Computer Society},
series = {ISWC '98},
title = {{Visual Contextual Awareness in Wearable Computing}},
url = {http://dl.acm.org/citation.cfm?id=857199.858017},
year = {1998}
}
@article{Steckel2013161,
abstract = {Array beamforming techniques allow for the generation of 3-D spatial filters which can be used to localize objects in a large field of view (FOV) without the need for mechanical scanning. By combining broadband beamforming with a sparse, random array of receivers, we have constructed a low-cost, yet powerful, in-air sonar system, which is suited for a wide range of robotic applications. Experimental results in unmodified office environments show the performance of the sonar sensor. In particular, we document the sensor's capacity to produce 3-D location measurements in the presence of multiple highly overlapping echoes. We show how this capability makes possible the combination of a wide FOV with accurate 3-D localization, allowing the sensor to operate under real-time constraints in realistic environments. To demonstrate the use of this sensor, we describe an odometry application that estimates egomotion of a mobile robot using acoustic flow. {\textcopyright} 2004-2012 IEEE.},
annote = {cited By 25},
author = {Steckel, J and Boen, A and Peremans, H},
doi = {10.1109/TRO.2012.2221313},
journal = {IEEE Transactions on Robotics},
keywords = {Acoustic flow; Array beamforming; Broadband beamfo,Beamforming; Sensors; Ultrasonics,Sonar},
number = {1},
pages = {161--171},
title = {{Broadband 3-D sonar system using a sparse array for indoor navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873439448{\&}doi=10.1109{\%}2FTRO.2012.2221313{\&}partnerID=40{\&}md5=0831401be3059d7c91c4f160a0a9b0e9},
volume = {29},
year = {2013}
}
@inproceedings{2000:PC:876865.877122,
abstract = {Color is a powerful cue for determining the pose of 3D objects viewed by a single camera. We present a method based on hue histograms for locating multiple objects with respect to a fixed camera. The algorithm is tested on controlled blocks-world scenes and an indoor office scene. On these examples, a pose refinement algorithm performs better when guided by color than when guided by more traditional edge information},
address = {Washington, DC, USA},
author = {Stevens, M.R. and Draper, B.A. and Beveridge, J.R.},
booktitle = {Proceedings of the International Conference on Pattern Recognition - Volume 3},
doi = {10.1109/icpr.2000.903645},
pages = {718--721},
publisher = {IEEE Computer Society},
series = {ICPR '00},
title = {{Pose from color}},
url = {http://dl.acm.org/citation.cfm?id=876865.877122},
year = {2002}
}
@inproceedings{Strifors1998571,
abstract = {We study the backscattered echoes from selected targets that are extracted by an impulse radar system playing the role of a ground penetrating radar (GPR). The targets are metal and nonmetal objects buried to a selected depth in dry sand in an indoor sandbox. The recorded time-series data are analyzed in the joint time-frequency domain using a pseudo-Wigner distribution (PWD). These distributions with their extracted features in the two-dimensional time-frequency domain are viewed as the target signatures. To be useful for target identification purposes, a signature representation should display a "sufficient" amount of distinguishing features, yet be robust enough to suppress the interference of noise contained in the received signals. Multiple scattering between a target and the surface of the ground is another obstacle for successful target recognition that time-frequency distributions could counteract by unveiling the time progression of the returned target information. We have previously demonstrated the merits of the PWD relative to various competing time-frequency distributions, in particular its capability of extracting a target's time-frequency signature when the target is buried at different depths. We have also used a classification method developed from the fuzzy C-means clustering technique to reduce the number and kind of features in the PWD signature templates. This is accomplished by converting the PWD signature into a point cluster representation and then reducing the cluster to a (smaller) number of cluster centers. This classification method has been further developed by associating a weight with each point in the cluster representation. We put the classification algorithm to a test against validation data taken from an additional set of returned echoes. The same targets are used but they are buried at a different location in the sand. Class membership of a target is then decided using a simple metric. The results of our investigation serve to assess the possibility of identifying subsurface targets using a GPR.},
annote = {cited By 3},
author = {Strifors, H C and Abrahamson, S and Gustafsson, A and Gaunaurd, G C},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.323875},
keywords = {Algorithms; Backscattering; Echo suppression; Freq,Automatic target recognition,Fuzzy cluster representation; Pseudo-Wigner distr},
pages = {571--579},
title = {{Time-frequency signatures based on a fuzzy-cluster representation as a means for automatic classification of targets buried underground}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032404272{\&}doi=10.1117{\%}2F12.323875{\&}partnerID=40{\&}md5=2eac33d481ac089abb389bb3ed84bff7},
volume = {3371},
year = {1998}
}
@inproceedings{721495,
abstract = {We study the backscattered echoes from selected targets that are extracted by an impulse radar system playing the role of a ground penetrating radar (GPR). The targets are metal and nonmetal objects buried to a selected depth in dry sand in an indoor sandbox. The recorded time-series data are analyzed using a pseudo-Wigner distribution (PWD). These distributions with their extracted features in the two-dimensional time-frequency domain are viewed as the target signatures. We use a classification method developed from the "fuzzy C-means" clustering technique to reduce the number and kind of features in the PWD signatures. This is accomplished by converting the PWD signature into a point cluster representation where each point is associated with a weight proportional to the value of the modulus of the PWD. Using a modified fuzzy C-means technique the cluster representation is then reduced to a (smaller) set of cluster centers. We put the classification algorithm to a test against validation data taken from an additional set of returned echoes. The same targets are used but they are buried at a different location in the sand. Class membership of a target is then decided using a simple metric. The results of our investigation serve to assess the possibility of identifying subsurface targets using a GPR, by means of the present technique.},
author = {Strifors, H C and Gustafsson, A and Abrahamson, S and Gaunaurd, G C},
booktitle = {Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis (Cat. No.98TH8380)},
doi = {10.1109/TFSA.1998.721495},
keywords = {radar target recognition;time-frequency analysis;s},
pages = {597--600},
title = {{Fuzzy-cluster representation of time-frequency signatures as a means for automatic classification of buried mine-like targets}},
year = {1998}
}
@phdthesis{Stuntebeck:2010:ADP:2019716,
address = {Atlanta, GA, USA},
annote = {AAI3425155},
author = {Stuntebeck, Erich P},
isbn = {978-1-124-25882-9},
publisher = {Georgia Institute of Technology},
title = {{An Analysis of the Domestic Power Line Infrastructure to Support Indoor Real-time Localization}},
year = {2010}
}
@inproceedings{Su:2010:SPN:1904933.1905176,
address = {Washington, DC, USA},
author = {Su, Chao-Min and Chou, Jia-Wei and Yi, Chih-Wei and Tseng, Yu-Chee and Tsai, Chi-Hung},
booktitle = {Proceedings of the 2010 39th International Conference on Parallel Processing Workshops},
doi = {10.1109/ICPPW.2010.78},
isbn = {978-0-7695-4157-0},
keywords = {Global Positioning System,Inertial Measurement Unit,Kalman Filter,Pedestrian Tracking System,Personal Navigation System},
pages = {533--541},
publisher = {IEEE Computer Society},
series = {ICPPW '10},
title = {{Sensor-Aided Personal Navigation Systems for Handheld Devices}},
url = {http://dx.doi.org/10.1109/ICPPW.2010.78},
year = {2010}
}
@article{Suksakulchai20003354,
abstract = {This paper proposes a simple method for localization using an electronic compass. Electronic compasses are often used to detect the heading of mobile robots. However, electronic compasses have one drawback when used inside a building: they can easily be disturbed by electromagnetic sources (e.g., power lines) or large ferro-magnetic structures (e.g., bookshelves). However, this paper introduces another indoor application of electronic compasses. We take advantage of the magnetic field disturbances by using them as distinctive place recognition signatures. We first gather information about the changing heading as our robot travels along the hallway outside the lab, and then store this information. As the robot traverses the hallway, it gathers the information from the electronic compass and matches it with the pre-stored data. If a match is found, the robot can determine its current position. We use a sequential least-squares approximation approach for matching the signature. The simulation results will show that the robot can distinguish its location by using these signatures.},
annote = {cited By 56},
author = {Suksakulchai, S and Thongchai, S and Wilkes, D M and Kawamura, K},
doi = {10.1109/ICSMC.2000.886523},
journal = {Proceedings of the IEEE International Conference on Systems, Man and Cybernetics},
keywords = {Compasses (magnetic); Computer simulation; Least s,Corridors; Electronic compasses; Localization,Robotics},
pages = {3354--3359},
title = {{Mobile robot localization using an electronic compass for corridor environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034513047{\&}doi=10.1109{\%}2FICSMC.2000.886523{\&}partnerID=40{\&}md5=9266849da323aa814b1cbd46d07af469},
volume = {5},
year = {2000}
}
@article{Sumitra2017,
abstract = {In this paper, we evaluated the experiment and analysis measurement accuracy to determine object location based on wireless sensor network (WSN). The algorithm estimates the position of sensor nodes employing received signal strength (RSS) from scattered nodes in the environment, in particular for the indoor building. Besides that, we considered another algorithm based on weight centroid localization (WCL). In particular testbed, we combined both RSS and WCL as hybrid localization in case of noncooperative scheme with considering that source nodes directly communicate only with anchor nodes. Our experimental result shows localization accuracy ofmore than 90{\%} and obtained the estimation error reduction to 4{\%} compared to existing algorithms {\textcopyright} 2017 Irfan Dwiguna Sumitra et al.},
annote = {cited By 3},
author = {Sumitra, I D and Hou, R and Supatmi, S},
doi = {10.1155/2017/6596943},
journal = {Wireless Communications and Mobile Computing},
keywords = {Anchor nodes; Estimation error reduction; Experim,Sensor nodes,Wireless sensor networks},
title = {{Study of hybrid localization noncooperative scheme in wireless sensor network}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018665617{\&}doi=10.1155{\%}2F2017{\%}2F6596943{\&}partnerID=40{\&}md5=d47b0f2fce9e658f1266b36c3296beee},
volume = {2017},
year = {2017}
}
@inproceedings{Sun20188331,
abstract = {We focus on the task of amodal 3D object detection, which is to predict object locations, dimensions, poses and categories in the real world. We introduce a 3D Convolutional Neural Network that takes a volumetric representation of an indoor scene as input and predicts 3D object bounding boxes, object categories, and orientations. Unlike prior state-of-the-arts, our approach does not depend on region proposal techniques to hypothesize object locations. We treat detection and recognition as one regression problem in a single network. Our elegant model is extremely fast and all predictions are reasoned from the global context of a point cloud in a continuous pipeline. We evaluate our approach on two standard datasets: the NYUv2 RGBD dataset and the SUN RGBD dataset. Experiments show that our approach is faster than start-of-the-art 3D detectors by several orders of magnitude towards real-time amodal 3D object detection. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Sun, H and Meng, Z and Du, X and Ang, M H},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2018.8593837},
keywords = {Convolution; Intelligent robots; Neural networks;,Convolutional neural network; Object categories;,Object detection},
pages = {8331--8338},
title = {{A 3D Convolutional Neural Network Towards Real-Time Amodal 3D Object Detection}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062957329{\&}doi=10.1109{\%}2FIROS.2018.8593837{\&}partnerID=40{\&}md5=7db9605088dd07ca46b30e4510cba954},
year = {2018}
}
@inproceedings{Sun20171844,
abstract = {In this paper, we propose an indoor video-based feature recognition method to detect the fall behaviors of people. We firstly establish and update the video background using Gaussian mixture model, and apply background subtraction to extract the moving targets. To remove the shadow interference on these extracted moving targets, we eliminate these shadows by integrating color and gradient features. Then for the current frame, the four features of Hu's invariant moments, aspect ratio, attitude rate and velocity are used to make up a 7-dimensional feature vector. Totally, we extract such 15 frames by interval sampling per motion cycle, and form 105-dimension features to describe a behavior. Based on the feature representations, we employ support vector machines to classify six daily activities, i.e., walking, jogging, sitting down, squatting, bending, as well as falling. Numerical experiments demonstrate our method reaches an average correct recognition rate of 92{\%}, with high sensitivities and specificities. It is able to distinguish falling with the other different behaviors and has many potential applications such as old people remote nursing. {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Sun, J and Chen, Z and Zhang, Z and Hu, Y},
booktitle = {Proceedings - 2017 Chinese Automation Congress, CAC 2017},
doi = {10.1109/CAC.2017.8243068},
keywords = {Aspect ratio; Gaussian distribution; Image retriev,Background subtraction; Feature representation; G,Numerical methods},
pages = {1844--1847},
title = {{Research on recognition of indoor fall behaviors based on video monitoring}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050360325{\&}doi=10.1109{\%}2FCAC.2017.8243068{\&}partnerID=40{\&}md5=521834fd91894c1836349fef98433af2},
volume = {2017-Janua},
year = {2017}
}
@article{Sun201445,
abstract = {Most indoor business processes are based on the locations of physical objects, so building a well-formed model to represent the spatial knowledge about business process is necessary under ubiquitous computing environments. Current location modeling requires a large amount of manual effort and cannot balance well between multipurpose query and less cost. In this paper, having analyzed the requirements of typical location-based services and the suitability of existing location modeling approaches, we propose a combined indoor location model which extends an improved directly under'' relation-based hierarchy tree model by introducing a core set model, based on the level reachable'' relation. Through a series of modeling theoretical principles and a real example, we show that our model is simple but indoor general enough to capture both spatial connectivity and containment relationships and support more location-based applications. Furthermore, a single-location hierarchical tree model, which integrates room coordinates, the building exits, and corridor intersections together, can navigate more source and objective positions in reality and provide more than one candidate path corresponding to the changing environment. At the same time, our combined model can be more flexible to be integrated into a context-aware system model. {\textcopyright} Springer-Verlag Berlin Heidelberg 2014.},
annote = {cited By 0},
author = {Sun, J and Li, H and Huang, H},
doi = {10.1007/978-3-642-37829-4_5},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Changing environment; Context-aware systems; Core,Cognitive systems; Forestry; Intelligent systems;,Location based services,Models; Planning; Set},
pages = {45--60},
title = {{A general hierarchy-set-based indoor location modeling approach}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927626322{\&}doi=10.1007{\%}2F978-3-642-37829-4{\_}5{\&}partnerID=40{\&}md5=326f6d8645a04df4d8e6819b0c80888b},
volume = {213},
year = {2014}
}
@inproceedings{Sun2018844,
abstract = {Indoor scene images have the characteristics of small inter-class variety and large intra-class variety because of the content complexity of indoor scene images and the influence of illumination change and partial occlusion. This makes it difficult to effectively represent the semantic information of the indoor scene using traditional shallow feature learning. We present a comprehensive method combining deep features and sparse representation for indoor scene recognition in this paper. In terms of feature extraction, a Faster R-CNN based multi-class detector is training for extracting object information to be as the low-level features. An improved bag-of-words model is designed to build mid-level features from object-based low-level features, which retain the spatial information of low-level features. For improving the robustness of the proposed method, sparse representation is used to make the final decision of indoor scene recognition from mid-level features. Experimental results on indoor scene subset of MIT-67 dataset show that our proposed method can achieve a superior performance in comparison to baseline methods. {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Sun, N and Zhu, X and Liu, J and Han, G},
booktitle = {ICNC-FSKD 2017 - 13th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery},
doi = {10.1109/FSKD.2017.8393385},
keywords = {Deep learning,Faster R-CNN; Illumination changes; Mid-level fea,Feature extraction; Fuzzy systems; Information ret},
pages = {844--849},
title = {{Indoor scene recognition based on deep learning and sparse representation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050187944{\&}doi=10.1109{\%}2FFSKD.2017.8393385{\&}partnerID=40{\&}md5=1334db785eb84ca5fdc56991856cc29c},
year = {2018}
}
@article{Sun2017812,
abstract = {A human localization system using multi-source heterogeneous data in indoor environments is proposed in this paper. The system can be easily constructed with already deployed Wi-Fi and camera infrastructures and is able to make use of received signal strength samples, surveillance images, and room map information to achieve a comparable performance. In a corridor scenario, we optimize propagation model (PM) parameters with crowdsourcing data from only several locations and establish a data table of optimized parameters for trilateration localization. These crowdsourcing data are also used to correct trilateration localization results, through which localization performance can be greatly improved. In a room scenario, we locate a human object with a panoramic camera and room map. We first detect the human object on the observed image and search a pixel location that represents the object's location best. Then, the pixel location on the image is mapped to the room map using an artificial neural network. By this method, localization accuracy of sub-meter level can be obtained. We perform the proposed system in our experimental environment, and the experimental results show that our localization system not only requires no extensive time and labor cost, but also outperforms fingerprinting and PM localization systems. {\textcopyright} 2013 IEEE.},
annote = {cited By 16},
author = {Sun, Y and Meng, W and Li, C and Zhao, N and Zhao, K and Zhang, N},
doi = {10.1109/ACCESS.2017.2650953},
journal = {IEEE Access},
keywords = {Cameras; Compensation (personnel); Crowdsourcing;,Experimental environment; Human localizations; In,Object detection},
pages = {812--822},
title = {{Human localization using multi-source heterogeneous data in indoor environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018525602{\&}doi=10.1109{\%}2FACCESS.2017.2650953{\&}partnerID=40{\&}md5=34160478abd25bfc052258b64af0eb6e},
volume = {5},
year = {2017}
}
@inproceedings{Sun2017,
abstract = {The widespread application of camera-based surveillance systems has inspired extensive investigation on human localization. In this paper, we proposed a device-free localization method using panoramic camera and indoor map. The proposed method is able to provide precise location information of human object without any terminal device. After preprocessing the images observed with a panoramic camera, we detect human object as foreground using the widely used background subtraction method. Then we search all the foreground pixels and find the pixel whose location can represents the object's location best. The pixel location on the image is mapped to a corresponding location on an indoor map. Finally, localization coordinates are obtained in the coordinate system we construct. Experimental results show that our localization method does not need any terminal device and also is able to achieve a mean error of 0.37m, which is far less than those of popular fingerprinting and trilateration localization methods. {\textcopyright} 2016 IEEE.},
annote = {cited By 2},
author = {Sun, Y and Zhao, K and Wang, J and Li, W and Bai, G and Zhang, N},
booktitle = {2016 IEEE International Conference on Consumer Electronics-China, ICCE-China 2016},
doi = {10.1109/ICCE-China.2016.7849743},
keywords = {Background subtraction; Background subtraction me,Cameras; Location; Object detection; Pixels; Secur,Indoor positioning systems},
title = {{Device-free human localization using panoramic camera and indoor map}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015149965{\&}doi=10.1109{\%}2FICCE-China.2016.7849743{\&}partnerID=40{\&}md5=993a40af141615640de03c6026f0e1f0},
year = {2017}
}
@article{Sundaraj:2008:RBS:1486693.1486715,
address = {Stevens Point, Wisconsin, USA},
author = {Sundaraj, K},
issn = {1109-2750},
journal = {W. Trans. on Comp.},
keywords = {background modeling,biometric identification,face detection},
number = {10},
pages = {1762--1771},
publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
title = {{Real-time Background Subtraction Using Adaptive Thresholding and Dynamic Updating for Biometric Face Detection}},
url = {http://dl.acm.org/citation.cfm?id=1486693.1486715},
volume = {7},
year = {2008}
}
@inproceedings{Surie2008189,
abstract = {Within a smart home environment the information processing is supposed to be thoroughly integrated into everyday objects. This introduces the need to keep track of the everyday objects and their state changes produced based on the user's interaction with them. Such information is useful in recognizing the user's activities, situations, etc. In this paper we present a ZigBee communication protocol based wireless sensor networking of 42 everyday objects (embedded with 81 simple state change sensors of 8 sensor types) in a living laboratory smart home environment. The system was evaluated in a realistic setup with background noise. The sensing module has shown promising results with an overall system precision of 91.2 {\%} and a recall of 98.8 {\%} in keeping track of the state changes to everyday objects. The signal strength measure above the acceptable limit of {\textgreater}10 dB to obtain reliable data communication was found to be 97.5{\%} checked at 8 different locations in a home environment. Finally the transmission-reception range was evaluated to be 33 m with a single wall obstruction and 19 m with multiple wall obstruction in an indoor environment. {\textcopyright} 2008 IEEE.},
annote = {cited By 55},
author = {Surie, D and Laguionie, O and Pederson, T},
booktitle = {ISSNIP 2008 - Proceedings of the 2008 International Conference on Intelligent Sensors, Sensor Networks and Information Processing},
doi = {10.1109/ISSNIP.2008.4761985},
keywords = {Acceptable limits; Background noise; Change senso,Cellular radio systems; Communication; Intelligent,Wireless networks},
pages = {189--194},
title = {{Wireless sensor networking of everyday objects in a smart home environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-63149156313{\&}doi=10.1109{\%}2FISSNIP.2008.4761985{\&}partnerID=40{\&}md5=c16cf4bb39eece5bdc8aded6c93b38de},
year = {2008}
}
@inproceedings{1207538,
abstract = {Results of wideband (125 MHz) received power and rms delay spread measurements at 5.24 GHz in a practical office environment are compared with the prediction utilizing the frustum ray tracing technique (FRTT) and detailed penetration loss measurement of major blocking objects on site. Penetration loss was measured for an object at different incident angle at different surface locations. Direct waves through walls were separated from unwanted waves in time and in space by system and directional horn antennas. A periodical variation of penetration loss as a function of surface location was observed for objects with inhomogeneous internal structure. A model was developed to approximate mean penetration loss at each incident angle for such objects. Using this model, an excellent agreement with the measured results was obtained by the FRTT without post tuning of simulation parameters.},
author = {Suzuki, H},
booktitle = {The 57th IEEE Semiannual Vehicular Technology Conference, 2003. VTC 2003-Spring.},
doi = {10.1109/VETECS.2003.1207538},
issn = {1090-3038},
keywords = {loss measurement;business communication;ray tracin},
pages = {236--240 vol.1},
title = {{Accurate and efficient prediction of coverage map in an office environment using frustum ray tracing and in-situ penetration loss measurement}},
volume = {1},
year = {2003}
}
@inproceedings{Szczurek:2015:CAQ:3021700.3021724,
address = {Portugal},
author = {Szczurek, Andrzej and Maciejewska, Monika},
booktitle = {Proceedings of the 4th International Conference on Sensor Networks},
doi = {10.5220/0005225802110219},
isbn = {978-989-758-086-4},
keywords = {Classification.,Gas Sensor,Indoor Air Quality},
pages = {211--219},
publisher = {SCITEPRESS - Science and Technology Publications, Lda},
series = {SENSORNETS 2015},
title = {{Classification of Air Quality Inside Car Cabin Using Sensor System}},
url = {https://doi.org/10.5220/0005225802110219},
year = {2015}
}
@inproceedings{Tak:2014:MPS:2557977.2557998,
address = {New York, NY, USA},
author = {Tak, Sungwoo and Kim, Taehoon and Kim, Donglyul and Kim, Yougyung},
booktitle = {Proceedings of the 8th International Conference on Ubiquitous Information Management and Communication},
doi = {10.1145/2557977.2557998},
isbn = {978-1-4503-2644-5},
keywords = {AP placement,location-awareness,modeling,network performance},
pages = {21:1----21:8},
publisher = {ACM},
series = {ICUIMC '14},
title = {{Modeling and Performance Study of AP Placement Framework for Indoor Location-awareness and Network Performance}},
url = {http://doi.acm.org/10.1145/2557977.2557998},
year = {2014}
}
@inproceedings{Takacs2016239,
abstract = {This work presents how we can apply feature descriptor and classifier methods to support indoor navigation for robots. Our aim is to recognize objects (such as doors, elevators/lifts, chairs, fire extinguishers, sockets) in man-built environments where our robot can move. Having recognized the objects, information as to where each object can be found is transmitted to the mapping module for recording. This way the accuracy of map building and navigation can be improved significantly. To solve this problem we use feature detector and descriptor methods, such as SIFT or SURF, to narrow the scores before we apply a support vector machine. This is a classification method that, following a suitable training pattern, sorts the input images into the learned classes. Our solution follows out a kind of classification based on a 'Bag-of-Words' feature vector with the help of a support vector machine. Based on the result of this classification we do the SURF localization process with the help of carefully chosen model images. Combining these two algorithms and the models stored in a database, the recognition is manageable with success. {\textcopyright} 2015 IEEE.},
annote = {cited By 0},
author = {Takacs, M and Bencze, T and Szabo-Resch, M Z and Vamossy, Z},
booktitle = {CINTI 2015 - 16th IEEE International Symposium on Computational Intelligence and Informatics, Proceedings},
doi = {10.1109/CINTI.2015.7382930},
keywords = {Artificial intelligence; Feature extraction; Image,Built environment; Classification methods; Featur,Robots},
pages = {239--242},
title = {{Object recognition to support indoor robot navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964956253{\&}doi=10.1109{\%}2FCINTI.2015.7382930{\&}partnerID=40{\&}md5=ba100a5daaa8aa7133f7c66352ce9941},
year = {2016}
}
@inproceedings{4428448,
abstract = {We have been trying to develop assistive mobile robot system (AMOS). The aim of AMOS is to replace only simple assistive work that picking up, transporting and placing the daily use objects in designated indoor location semi autonomously to reduce the burden of the care taker. AMOS should avoid any kind of collisions in the environment. Therefore, the amount of sensors and functionalities are increased. In addition, the system is becoming huge and complicated. To control the AMOS robustly, we invented the concept of Shared Responsibility and the control method. The concept is applied to AMOS. Within the concept, the functionality of AMOS can be divided to four, vision based user interface, navigation system, object localization and grasping, and software framework. And finally all of four elements are developed.},
author = {Takagi, M and Takahashi, Y and Yamamoto, S and Koyama, H and Komeda, T},
booktitle = {2007 IEEE 10th International Conference on Rehabilitation Robotics},
doi = {10.1109/ICORR.2007.4428448},
issn = {1945-7898},
keywords = {geriatrics;handicapped aids;medical robotics;mobil},
pages = {341--346},
title = {{Vision Based Interface and Control of Assistive Mobile Robot System}},
year = {2007}
}
@article{Takahashi2004473,
abstract = {It can be exhausting, both physically and emotionally, to assist physically handicapped persons. Therefore, an assistive mobile system called AMOS (Assistive MObile robot System) has been developed to help alleviate this burden. The purpose of AMOS is to pick up and transport daily use objects, placing them in a designated indoor location semi-autonomously. AMOS consists of a self-contained mobile robot body, a user interface with a touch-panel and a computer network (Ethernet LAN, Internet). The user interacts with the mobile robot through a Web browser connected to a computer network, allowing for communication anytime, from anywhere and by anyone. This mode provides a simple way for communicating with and determining the status of the robot. Experiments were performed to verify the successful operation of AMOS. Although the system performed as designed, it would prove useful to the extend service area of the robot through communication mechanisms and the user interface.},
annote = {cited By 7},
author = {Takahashi, Y and Komeda, T and Koyama, H},
doi = {10.1163/156855304774195037},
journal = {Advanced Robotics},
keywords = {Assistive mobile robot system (AMOS); Assistive r,Local area networks; Medical problems; Quality ass,Mobile robots},
number = {5},
pages = {473--496},
title = {{Development of the assistive mobile robot system: AMOS - To aid in the daily life of the physically handicapped}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-3042594212{\&}doi=10.1163{\%}2F156855304774195037{\&}partnerID=40{\&}md5=7faff74e11c4237d7600acee81659943},
volume = {18},
year = {2004}
}
@inproceedings{Takala2007,
abstract = {In this paper, we introduce a novel real-time tracker based on color, texture and motion information. RGB color histogram and correlogram (autocorrelogram) are exploited as color cues and texture properties are represented by local binary patterns (LBP). Object's motion is taken into account through location and trajectory. After extraction, these features are used to build a unifying distance measure. The measure is utilized in tracking and in the classification event, in which an object is leaving a group. The initial object detection is done by a texture-based background subtraction algorithm. The experiments on indoor and outdoor surveillance videos show that a unified system works better than the versions based on single features. It also copes well with low illumination conditions and low frame rates which are common in large scale surveillance systems. {\textcopyright} 2007 IEEE.},
annote = {cited By 77},
author = {Takala, V and Pietik{\"{a}}inen, M},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2007.383506},
keywords = {Algorithms; Feature extraction; Real time systems;,Frame rates; Local binary patterns (LBP); Multi-o,Object recognition},
title = {{Multi-object tracking using color, texture and motion}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34948816600{\&}doi=10.1109{\%}2FCVPR.2007.383506{\&}partnerID=40{\&}md5=eeb624806f25b6910551ed118dbfadb0},
year = {2007}
}
@article{Takatsuka201644,
abstract = {This paper presents a unified locating service, KULOCS, which horizontally integrates the existing heterogeneous locating services. Focusing on technology-independent elements [when], [where] and [who] in querying locations of objects, KULOCS integrates data and operations of the existing services. In the data integration, we propose a method where the time representation, the locations, the namespace of user are consolidated by Unix time, the location labels and the alias table, respectively. We then propose KULOCS-API that integrates operations by all possible combinations of [when], [where] and [who]. Since KULOCS works as a seamless fa{\c{c}}ade to the underlying locating services, clients can consume location information easily and efficiently, without knowing concrete services actually locating target objects. Also, we examine feasibility of two practical value-added services with KULOCS. {\textcopyright} ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2016.},
annote = {cited By 0},
author = {Takatsuka, H and Saiki, S and Matsumoto, S and Nakamura, M},
doi = {10.1007/978-3-319-47075-7_6},
journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
keywords = {Concrete service; Locating service; Location awar,Data integration; Indoor positioning systems; Inte,Web services},
pages = {44--52},
title = {{On integrating heterogeneous locating services}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009820275{\&}doi=10.1007{\%}2F978-3-319-47075-7{\_}6{\&}partnerID=40{\&}md5=14988842ab323c1c48b97ff08dd64e3b},
volume = {170},
year = {2016}
}
@article{Takatsuka2016154,
abstract = {Purpose  The purpose of this paper is to develop a facade for seamlessly using locating services and enabling easy development of an application with indoor and outdoor location information without being aware of the difference of individual services. To achieve this purpose, in this paper, a unified locating service, called KULOCS (Kobe-University Unified LOCating Service), which horizontally integrates the heterogeneous locating services, is proposed. Design/methodology/approachBy focusing on technology-independent elements [when], [where] and [who] in location queries, KULOCS integrates data and operations of the existing locating services. In the data integration, a method where the time representation, the locations and the namespace are consolidated by the Unix time, the location labels and the alias table, respectively, is proposed. Based on the possible combinations of the three elements, an application-neutral application programming interface (API) for the operation integration is derived. FindingsUsing KULOCS, various practical services are enabled. In addition, the experimental evaluation shows the practical feasibility by comparing cases with or without KULOCS. The result shows that KULOCS reduces the effort of application development, especially when the number of locating services becomes large. Originality/valueKULOCS works as a seamless facade with the underlying locating services, the users and applications consume location information easily and efficiently, without knowing concrete services actually locating target objects. {\textcopyright} 2016, {\textcopyright} Emerald Group Publishing Limited.},
annote = {cited By 0},
author = {Takatsuka, H and Tokunaga, S and Saiki, S and Matsumoto, S and Nakamura, M},
doi = {10.1108/IJPCC-01-2016-0004},
journal = {International Journal of Pervasive Computing and Communications},
number = {1},
pages = {154--172},
title = {{KULOCS: unified locating service for efficient development of location-based applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976370592{\&}doi=10.1108{\%}2FIJPCC-01-2016-0004{\&}partnerID=40{\&}md5=241948d47055e4092fc5339c927cd6fe},
volume = {12},
year = {2016}
}
@article{Talepour:2013:OCM:2504592.2504661,
address = {Hingham, MA, USA},
author = {Talepour, Zeinab and Ahmadi-Shokouh, Javad and Tavakoli, Saeed},
doi = {10.1007/s11277-012-0919-5},
issn = {0929-6212},
journal = {Wirel. Pers. Commun.},
keywords = {Channel capacity,Genetic algorithm,Multi-input multi-output system,Ray-tracing,Received signal strength,Wireless local area network},
number = {3},
pages = {1989--2001},
publisher = {Kluwer Academic Publishers},
title = {{Optimum Coverage/Capacity in MIMO Indoor Channel with Minimum Transmitters}},
url = {http://dx.doi.org/10.1007/s11277-012-0919-5},
volume = {71},
year = {2013}
}
@inproceedings{Tamaazousti:2016:CLE:2911996.2912009,
address = {New York, NY, USA},
author = {Tamaazousti, Youssef and {Le Borgne}, Herv{\'{e}} and Popescu, Adrian},
booktitle = {Proceedings of the 2016 ACM on International Conference on Multimedia Retrieval},
doi = {10.1145/2911996.2912009},
isbn = {978-1-4503-4359-6},
keywords = {CBIR,concept sparsification,concept-sparsification,image classification,image-classification,image-retrieval,semantic features,semantic-features},
pages = {119--126},
publisher = {ACM},
series = {ICMR '16},
title = {{Constrained Local Enhancement of Semantic Features by Content-Based Sparsity}},
url = {http://doi.acm.org/10.1145/2911996.2912009},
year = {2016}
}
@article{Tamilselvi2011506,
abstract = {The DPPA is designed for a Robot to move in the Indoor Environment amidst moving obstacles. DPPA facilitates the Robot to find the shortest path to reach the target by navigating the obstacles of various sizes and shapes on the way, both in real time as well as in simulated environment. The proposed Indoor environment (10 x 10) is split into grid cells. DPPA uses the distinct position of each grid cell for fixing the location of the robot along with the static and dynamically moving objects. The collusion with the dynamically moving objects is avoided by DPPA by continuously updating the present status of the Robot in comparison with the neighboring grid cells' status. DPPA monitors the entire indoor environment during every step of the movement of the Robot and finalizes the shortest path thereby resulting in minimum cost. DPPA is tested in real time using fire bird V Robot with different complexities in the environment (75 x 80). The real time results encourage us to extend this DPPA in day-to-day applications in daily life. e.g. the DPPA powered wheel chair can be used by the old and sick for their mobility in their homes. {\textcopyright} EuroJournals Publishing, Inc. 2011.},
annote = {cited By 0},
author = {Tamilselvi, D and Shalinie, M and Hariharasudan},
journal = {European Journal of Scientific Research},
number = {4},
pages = {506--517},
title = {{Navigation of a robot amidst moving obstacles using DPPA (Dynamic Path Planning Agent)}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052216651{\&}partnerID=40{\&}md5=bafc7ba6ccd00373bae306c8ae83bd0e},
volume = {58},
year = {2011}
}
@article{Tan:2018:CTT:3279953.3264946,
address = {New York, NY, USA},
author = {Tan, Jiajie and Wong, Wangkit and Zhu, Xinyu and Wu, Hang and Chan, S.-H. Gary},
doi = {10.1145/3264946},
issn = {2474-9567},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
keywords = {Target tracking,fingerprint,indoor localization,mobile sensor,particle filter},
number = {3},
pages = {136:1----136:21},
publisher = {ACM},
title = {{Cooperative Target Tracking and Signal Propagation Learning Using Mobile Sensors}},
url = {http://doi.acm.org/10.1145/3264946},
volume = {2},
year = {2018}
}
@inproceedings{652980,
abstract = {Summary form only given. We have developed a system in which a mobile robot can modify maps of an indoor environment automatically through change detection at planned locations. The robot is a car-like one equipped with sonar sensors. The indoor space is assumed to be surrounded by walls and has some movable objects of planar surfaces perpendicular to the floor. In the map updating process, the robot moves to a planned observation location and collect range data on the local region around itself by using the sonar range sensors. The robot's position is estimated by a localization method, and visible changes are detected by comparison of structural range descriptions with the original and partially updated maps. As the result, the map is further modified and a new observation location is selected. In this paper, we present a method by which a mobile robot estimates its position at each location it reaches by using information from dead reckoning, real sonar range data and the partially outmoded map. Simulation experiments show the method is efficient enough for localization in a changeable complex environment.},
author = {Tanaka, K and Hasegawa, T},
booktitle = {Proceedings of IEEE/ASME International Conference on Advanced Intelligent Mechatronics},
doi = {10.1109/AIM.1997.652980},
keywords = {mobile robots;path planning;position control;sonar},
pages = {110--},
title = {{Mobile robot localization using incomplete maps for change detection in a dynamic environment}},
year = {1997}
}
@article{Tanaka2016385,
abstract = {In recent years, smartphones have become rapidly popular and their performance has improved remarkably. Therefore, it is possible to estimate user context by using sensors and functions equipped in smartphones. We propose a To-Do reminder system using user indoor position information and moving state. In conventional reminder systems, users have to input the information of place (resolution place). The resolution place is where the To-Do item can be solved and the user receives a reminder. These conventional reminder systems are constructed based on outdoor position information using GPS. In this paper, we propose a new reminder system that makes it unnecessary to input the resolution place. In this newly developed system, we introduce a rule-based system for estimating the resolution place in a To-Do item. The estimation is done based on an object word and a verb, which are included in most tasks in a To-Do list. In addition, we propose an automatic judgment method to determine if a To-Do task has been completed. {\textcopyright} Springer International Publishing Switzerland 2016.},
annote = {cited By 1},
author = {Tanaka, M and Yoshida, K and Matsuno, S and Ohyama, M},
doi = {10.1007/978-3-319-40542-1_63},
journal = {Communications in Computer and Information Science},
keywords = {Abstracting; Smartphones; Wi-Fi,Context- awareness; Indoor positioning; Judgment,Information use},
pages = {385--391},
title = {{Advancement of a to-do reminder system focusing on context of the user}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978224590{\&}doi=10.1007{\%}2F978-3-319-40542-1{\_}63{\&}partnerID=40{\&}md5=a8f917f7333f4ae952ed22a43e20bf47},
volume = {618},
year = {2016}
}
@inproceedings{Tao:2008:RDT:1491265.1492593,
address = {Washington, DC, USA},
author = {Tao, Jianguo and Yu, Changhong},
booktitle = {Proceedings of the 2008 Second International Symposium on Intelligent Information Technology Application - Volume 02},
doi = {10.1109/IITA.2008.428},
isbn = {978-0-7695-3497-8},
keywords = {object detection,object tracking},
pages = {860--863},
publisher = {IEEE Computer Society},
series = {IITA '08},
title = {{Real-Time Detection and Tracking of Moving Object}},
url = {http://dx.doi.org/10.1109/IITA.2008.428},
year = {2008}
}
@inproceedings{6707267,
abstract = {In this paper we introduce a real-time obstacle recognition framework designed to alert the visually impaired people/blind of their presence and to assist humans to navigate safely, in indoor and outdoor environments, by handling a Smartphone device. Static and dynamic objects are detected using interest points selected based on an image grid and tracked using the multiscale Lucas-Kanade algorithm. Next, we activated an object classification methodology. We incorporate HOG (Histogram of Oriented Gradients) descriptor into the BoVW (Bag of Visual Words) retrieval framework and demonstrate how this combination may be used for obstacle classification in video streams. The experimental results performed on various challenging scenes demonstrate that our approach is effective in image sequence with important camera movement, including noise and low resolution data and achieves high accuracy, while being computational efficient.},
author = {Tapu, R and Mocanu, B and Zaharia, T},
booktitle = {2013 E-Health and Bioengineering Conference (EHB)},
doi = {10.1109/EHB.2013.6707267},
keywords = {computer vision;image classification;image denoisi},
month = {nov},
pages = {1--4},
title = {{A computer vision system that ensure the autonomous navigation of blind people}},
year = {2013}
}
@article{Tazeem:2017:ISS:3048787.3048814,
address = {Norwell, MA, USA},
author = {Tazeem, Hadia and Farid, Muhammad Shahid and Mahmood, Arif},
doi = {10.1007/s11042-016-3260-2},
issn = {1380-7501},
journal = {Multimedia Tools Appl.},
keywords = {Global flow,Illumination compensation,Mosaicing,Scene stitching,Security surveillance},
number = {2},
pages = {2713--2732},
publisher = {Kluwer Academic Publishers},
title = {{Improving Security Surveillance by Hidden Cameras}},
url = {https://doi.org/10.1007/s11042-016-3260-2},
volume = {76},
year = {2017}
}
@article{Tellex201164,
abstract = {In order for robots to engage in dialogue with human teammates, they must have the ability to identify correspondences between elements of language and aspects of the external world. A solution to this symbol-grounding problem (Harnad, 1990) would enable a robot to interpret commands such as "Drive over to receiving and pick up the tire pallet." This article describes several of our results that use probabilistic inference to address the symbol-grounding problem. Our approach is to develop models that factor according to the linguistic structure of a command. We first describe an early result, a generative model that factors according to the sequential structure of language, and then discuss our new framework, generalized grounding graphs (G 3). The G 3 framework dynamically instantiates a probabilistic graphical model for a natural language input, enabling a mapping between words in language and concrete objects, places, paths, and events in the external world. We report on corpus-based experiments in which the robot is able to learn and use word meanings in three real-world tasks: indoor navigation, spatial language video retrieval, and mobile manipulation. Copyright {\textcopyright} 2011, Association for the Advancement of Artificial Intelligence.},
annote = {cited By 54},
author = {Tellex, S and Kollar, T and Dickerson, S and Walter, M R and Banerjee, A G and Teller, S and Roy, N},
journal = {AI Magazine},
keywords = {Concrete objects; Generative model; Indoor navigat,Graphic methods; Robots,Speech recognition},
number = {4},
pages = {64--76},
title = {{Approaching the symbol grounding problem with probabilistic graphical models}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858436215{\&}partnerID=40{\&}md5=3a2032b629a8cbfdaecd9330c5d74a10},
volume = {32},
year = {2011}
}
@inproceedings{Teo2017167,
abstract = {Indoor Spatial Data Infrastructure (indoor-SDI) is an important SDI for geosptial analysis and location-based services. Building Information Model (BIM) has high degree of details in geometric and semantic information for building. This study proposed direct conversion schemes to extract indoor building information from BIM to OGC IndoorGML. The major steps of the research include (1) topological conversion from building model into indoor network model; and (2) generation of IndoorGML. The topological conversion is a major process of generating and mapping nodes and edges from IFC to indoorGML. Node represents every space (e.g. IfcSpace) and objects (e.g. IfcDoor) in the building while edge shows the relationships between nodes. According to the definition of IndoorGML, the topological model in the dual space is also represented as a set of nodes and edges. These definitions of IndoorGML are the same as in the indoor network. Therefore, we can extract the necessary data in the indoor network and easily convert them into IndoorGML based on IndoorGML Schema. The experiment utilized a real BIM model to examine the proposed method. The experimental results indicated that the 3D indoor model (i.e. IndoorGML model) can be automatically imported from IFC model by the proposed procedure. In addition, the geometric and attribute of building elements are completely and correctly converted from BIM to indoor-SDI. {\textcopyright} Authors 2017.},
annote = {cited By 3},
author = {Teo, T.-A. and Yu, S.-C.},
booktitle = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
doi = {10.5194/isprs-archives-XLII-4-W2-167-2017},
keywords = {Analysis and location; Building Information Model,Architectural design,Buildings; Information theory; Location based serv},
number = {4W2},
pages = {167--170},
title = {{The extraction of indoor building information from bim to OGC indoorgml}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027222880{\&}doi=10.5194{\%}2Fisprs-archives-XLII-4-W2-167-2017{\&}partnerID=40{\&}md5=214bb1c70ba9131b9e83edeac98cb42e},
volume = {42},
year = {2017}
}
@article{Tian2013521,
abstract = {Independent travel is a well-known challenge for blind and visually impaired persons. In this paper, we propose a proof-of-concept computer vision-based wayfinding aid for blind people to independently access unfamiliar indoor environments. In order to find different rooms (e.g. an office, a laboratory, or a bathroom) and other building amenities (e.g. an exit or an elevator), we incorporate object detection with text recognition. First, we develop a robust and efficient algorithm to detect doors, elevators, and cabinets based on their general geometric shape, by combining edges and corners. The algorithm is general enough to handle large intra-class variations of objects with different appearances among different indoor environments, as well as small inter-class differences between different objects such as doors and door-like cabinets. Next, to distinguish intra-class objects (e.g. an office door from a bathroom door), we extract and recognize text information associated with the detected objects. For text recognition, we first extract text regions from signs with multiple colors and possibly complex backgrounds, and then apply character localization and topological analysis to filter out background interference. The extracted text is recognized using off-the-shelf optical character recognition software products. The object type, orientation, location, and text information are presented to the blind traveler as speech. {\textcopyright} 2012 Springer-Verlag.},
annote = {cited By 45},
author = {Tian, Y and Yang, X and Yi, C and Arditi, A},
doi = {10.1007/s00138-012-0431-7},
journal = {Machine Vision and Applications},
keywords = {Algorithms; Computer vision; Edge detection; Elev,Blind/visually impaired persons; Object Detection;,Handicapped persons},
number = {3},
pages = {521--535},
title = {{Toward a computer vision-based wayfinding aid for blind persons to access unfamiliar indoor environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879688003{\&}doi=10.1007{\%}2Fs00138-012-0431-7{\&}partnerID=40{\&}md5=2d08a9c386fe79646a181e1f10a05cc8},
volume = {24},
year = {2013}
}
@inproceedings{8559715,
abstract = {Recently, the hand gesture recognition has attracted great interest of researchers due to its important role in human-computer interaction (HCI), smart home applications and virtual reality (VR). The conventional systems mainly utilize additional equipment, such like dedicated sensors and cameras, resulting in higher cost and limitation in application scenarios. In this paper, we present a new gesture recognition system by leveraging the channel state information (CSI) which can be extracted from commodity Wi-Fi device. We design a novel interference elimination algorithm to diminish the influence caused by the signals reflected from static objects and the signal that travels from the transmitter to the receiver directly. After interference elimination, the system can capture the signal reflected from the hand and sample this signal. Then, the sample values are used to construct a virtual antenna array to estimate the moving trajectory of hand. At last, we use Support Vector Machine (SVM) to classify the trajectories and complete the gesture recognition. The extensive analytical and experimental results demonstrate our system can achieve an average accuracy of 0.97 for designed 6 single-hand gestures. Moreover, the system is capable of performing two-hand gesture recognition and it can reach an average accuracy of 0.95 for designed 3 two-hand gestures.},
author = {Tian, Z and Wang, J and Yang, X and Zhou, M},
booktitle = {2018 Ubiquitous Positioning, Indoor Navigation and Location-Based Services (UPINLBS)},
doi = {10.1109/UPINLBS.2018.8559715},
keywords = {antenna arrays;gesture recognition;interference su},
pages = {1--6},
title = {{Device-Free Hand Gesture Recognition System Based on Commercial Wi-Fi Devices}},
year = {2018}
}
@article{Tilch:2013:CCL:2439051.2439053,
address = {Bristol, PA, USA},
author = {Tilch, Sebastian and Mautz, Rainer},
doi = {10.1080/17489725.2012.688643},
issn = {1748-9725},
journal = {J. Locat. Based Serv.},
keywords = {6 DOF,CLIPS,indoor,indoor positioning,optical,positioning,real-time tracking},
number = {1},
pages = {3--22},
publisher = {Taylor {\&} Francis, Inc.},
title = {{CLIPS -- a Camera and Laser-based Indoor Positioning System}},
url = {http://dx.doi.org/10.1080/17489725.2012.688643},
volume = {7},
year = {2013}
}
@inproceedings{Todd20141,
abstract = {VirtuNav provides a haptic-enabled Virtual Reality (VR) environment that facilitates persons with visual impairment to explore a 3D computerized model of a real-life indoor location, such as a classroom or hospital. For administrative purposes, the screen displays a 2D overhead view of the map to monitor user progress and location as well as the 3D reconstructed environment. The system offers two unique interfaces: a freeroam interface where the user can navigate and interact with the environment, and an edit mode where the administrator can manage test users, maps and retrieve test data. VirtuNav is a practical application offering several unique features including map design, semi-automatic 3D map reconstruction and object classification from 2D map data. Visual and haptic rendering of real-time 3D map navigation are provided as well as automated administrative functions including shortest path calculation, actual path traversal, and assessment of performance indicators including time taken for exploration and collision data. VirtuNav is a research tool for investigation of user familiarity developed after repeated exposure to the indoor location, to determine the extent to which haptic and/or sound cues improve a visually impaired user's ability to navigate a room or building with or without occlusion. System testing reveals that spatial awareness and memory mapping improve with user iterations within the VirtuNav environment. This application aims to promote confidence by independent exploration, for the sight impaired. {\textcopyright} 2014 IEEE.},
annote = {cited By 2},
author = {Todd, C and Mallya, S and Majeed, S and Rojas, J and Naylor, K},
booktitle = {IEEE SSCI 2014 - 2014 IEEE Symposium Series on Computational Intelligence - CIR2AT 2014: 2014 IEEE Symposium on Computational Intelligence in Robotic Rehabilitation and Assistive Technologies, Proceedings},
doi = {10.1109/CIRAT.2014.7009734},
keywords = {3D reconstruction; Administrative functions; Hapt,Artificial intelligence; Display devices; Indoor p,Three dimensional computer graphics},
pages = {1--8},
title = {{VirtuNav: A Virtual Reality indoor navigation simulator with haptic and audio feedback for the visually impaired}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946685702{\&}doi=10.1109{\%}2FCIRAT.2014.7009734{\&}partnerID=40{\&}md5=26123a9ea886f43d57117f4812773825},
year = {2014}
}
@inproceedings{Tomono2002619,
abstract = {This paper presents a navigation system based on an inaccurate map. The map we consider here is a hybrid of topological map and geometrical map so that it can be built easily and permit changes in objects locations. A localization scheme and an object recognition technique are introduced in order to keep the robot pose consistent on such an inaccurate map. To cope with the problem that a path may also be inaccurate on an inaccurate map, the robot corrects the path based on its pose estimated by the localization method while tracking the path. An experiment shows that the robot successfully navigated in an indoor environment, recognizing several kinds of objects.},
annote = {cited By 2},
author = {Tomono, M and Yuta, S},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
keywords = {Indoor navigation; Robot localization,Mobile robots,Motion estimation; Motion planning; Navigation; Ob},
pages = {619--624},
title = {{Indoor navigation based on an inaccurate map using object recognition}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036453862{\&}partnerID=40{\&}md5=f095fcafd796286cc72aa97d4990d6ad},
volume = {1},
year = {2002}
}
@inproceedings{Torralba:2003:CVS:946247.946665,
address = {Washington, DC, USA},
author = {Torralba, Antonio and Murphy, Kevin P and Freeman, William T and Rubin, Mark A},
booktitle = {Proceedings of the Ninth IEEE International Conference on Computer Vision - Volume 2},
isbn = {0-7695-1950-4},
pages = {273----},
publisher = {IEEE Computer Society},
series = {ICCV '03},
title = {{Context-based Vision System for Place and Object Recognition}},
url = {http://dl.acm.org/citation.cfm?id=946247.946665},
year = {2003}
}
@article{Torres-Solis:2009:NSE:1605363.1605371,
address = {Amsterdam, The Netherlands, The Netherlands},
author = {Torres-Solis, Jorge and Guan, Mei and Biddiss, Elaine and Chau, Tom},
issn = {0928-7329},
journal = {Technol. Health Care},
number = {3},
pages = {237--251},
publisher = {IOS Press},
title = {{Navigation in Smart Environments Using Mediated Reality Tools}},
url = {http://dl.acm.org/citation.cfm?id=1605363.1605371},
volume = {17},
year = {2009}
}
@inproceedings{Treible2017134,
abstract = {Stereo matching is a well researched area using visible-band color cameras. Thermal images are typically lower resolution, have less texture, and are noisier compared to their visible-band counterparts and are more challenging for stereo matching algorithms. Previous benchmarks for stereo matching either focus entirely on visible-band cameras or contain only a single thermal camera. We present the Color And Thermal Stereo (CATS) benchmark, a dataset consisting of stereo thermal, stereo color, and cross-modality image pairs with high accuracy ground truth ({\textless} 2mm) generated from a LiDAR. We scanned 100 cluttered indoor and 80 outdoor scenes featuring challenging environments and conditions. CATS contains approximately 1400 images of pedestrians, vehicles, electronics, and other thermally interesting objects in different environmental conditions, including nighttime, daytime, and foggy scenes. Ground truth was projected to each of the four cameras to generate color-color, thermal-thermal, and cross-modality disparity maps. A semi-automatic LiDAR to camera alignment procedure was developed that does not require a calibration target. We compare state-of-the-art algorithms to baseline the dataset and show that in the thermal and cross modalities there is still much room for improvement. We expect our dataset to provide researchers with a more diverse set of imaged locations, objects, and modalities than previous benchmarks for stereo matching. {\textcopyright} 2017 IEEE.},
annote = {cited By 6},
author = {Treible, W and Saponaro, P and Sorensen, S and O'Neal, M and Kolagunda, A and Phelan, B and Sherbondy, K and Kambhamettu, C},
booktitle = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
doi = {10.1109/CVPR.2017.22},
keywords = {Calibration targets; Cross modality; Environmenta,Cameras; Color; Color matching; Computer vision; O,Stereo image processing},
pages = {134--142},
title = {{CATS: A color and thermal stereo benchmark}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043495615{\&}doi=10.1109{\%}2FCVPR.2017.22{\&}partnerID=40{\&}md5=04b4e05b5d5f69f9f9386ed5bc96e863},
volume = {2017-Janua},
year = {2017}
}
@article{Trogh:2015:ARI:2836307.2930119,
address = {London, UK, United Kingdom},
author = {Trogh, Jens and Plets, David and Martens, Luc and Joseph, Wout},
doi = {10.1155/2015/271818},
issn = {1550-1329},
journal = {Int. J. Distrib. Sen. Netw.},
pages = {19:19----19:19},
publisher = {Hindawi Limited},
title = {{Advanced Real-time Indoor Tracking Based on the Viterbi Algorithm and Semantic Data}},
url = {https://doi.org/10.1155/2015/271818},
volume = {2015},
year = {2015}
}
@article{Truyen2008903,
abstract = {Recognising daily activity patterns of people from low-level sensory data is an important problem. Traditional approaches typically rely on generative models such as the hidden Markov models and training on fully labelled data. While activity data can be readily acquired from pervasive sensors, e.g. in smart environments, providing manual labels to support fully supervised learning is often expensive. In this paper, we propose a new approach based on partially-supervised training of discriminative sequence models such as the conditional random field (CRF) and the maximum entropy Markov model (MEMM). We show that the approach can reduce labelling effort, and at the same time, provides us with the flexibility and accuracy of the discriminative framework. Our experimental results in the video surveillance domain illustrate that these models can perform better than their generative counterpart (i.e. the partially hidden Markov model), even when a substantial amount of labels are unavailable. {\textcopyright} 2008 Springer Berlin Heidelberg.},
annote = {cited By 4},
author = {Truyen, T T and Bui, H H and Phung, D Q and Venkatesh, S},
doi = {10.1007/978-3-540-89197-0_84},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Activity recognition; Conditional random fields;,Artificial intelligence; Bionics; Content based re,Hidden Markov models},
pages = {903--912},
title = {{Learning discriminative sequence models from partially labelled data for activity recognition}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-58349096565{\&}doi=10.1007{\%}2F978-3-540-89197-0{\_}84{\&}partnerID=40{\&}md5=9f872a013a382b42a7e35f8550afc46d},
volume = {5351 LNAI},
year = {2008}
}
@article{Tsou2014354,
abstract = {In this paper, we report how the feature matching method can be applied to deal with the indoor mobile robot localization problem. We assume that a robot equipped with a laser rangefinder can scan the environment in real time and get the geometry features, and then the robot can match these features with those collected in advance to find the possible locations. This approach would face two difficulties. Since there are locations with similar features, the robot have to move around and do the scan and match several times to make sure the right location. There is another difficult problem, the features might not be fix in real-world dynamic environment, e.g. people might be walking through, furniture might be shifted; therefore, a robust feature matching method is needed for dynamic environment. This paper describes an efficient method using omni-directional feature grouping to improve the feature matching method for robot localization. With the laser rangefinder, a robot finds the 360 degree coverage information. Omni-directional feature grouping has the advantage of dividing all the features of a hypothetical position through different directions to generate multiple sets of environmental features. The method can reduce the affection of moving objects in a dynamic environment. Experimental results show that our method improve the accuracy rate and has low average errors. {\textcopyright} Springer International Publishing Switzerland 2014.},
annote = {cited By 1},
author = {Tsou, T.-Y. and Wu, S.-H.},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Feature matching; Indoor environment; Indoor loca,Range finders; Robot applications,Robots},
pages = {354--365},
title = {{A robust feature matching method for robot localization in a dynamic indoor environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911862736{\&}partnerID=40{\&}md5=1aee0a920735ff9ee89db4c720edc9bf},
volume = {8916},
year = {2014}
}
@inproceedings{Tummala:2016:VVB:2980115.2980135,
address = {New York, NY, USA},
author = {Tummala, Gopi Krishna and Kundu, Rupam and Sinha, Prasun and Ramnath, Rajiv},
booktitle = {Proceedings of the 3rd Workshop on Hot Topics in Wireless},
doi = {10.1145/2980115.2980135},
isbn = {978-1-4503-4251-3},
keywords = {computer vision,experimentation,indoor tracking},
pages = {49--53},
publisher = {ACM},
series = {HotWireless '16},
title = {{Vision-track: Vision Based Indoor Tracking in Anchor-free Regions}},
url = {http://doi.acm.org/10.1145/2980115.2980135},
year = {2016}
}
@inproceedings{Turgut20161176,
abstract = {"Knowing the Location" and "Determining the Location" are the essential requirements of constructing a smart building. GPS technology, which is often used for the purpose of positioning, cannot be used efficiently while performing position detection indoors because of the losses occurring in the signal propagation. At the same time, the object of sensors, Bluetooth, IrDA and RFID devices which are commonly used in a building, and bandwidth constraints makes such location detection more difficult because of possible energy consumption and limited memory capacity. Since WiFi technology which will probably be used in nearly all Smart Buildings, Indoor localization algorithms have been surveyed and requirements which are essential for obtaining Internet of Things (IoT) technology have been researched, and a context-based approach for a Smart Building which has got IoT structure is proposed. {\textcopyright} 2016 Published by Elsevier B.V.},
annote = {cited By 10},
author = {Turgut, Z and Aydin, G Z G and Sertbas, A},
booktitle = {Procedia Computer Science},
doi = {10.1016/j.procs.2016.04.242},
keywords = {Bandwidth constraint; Building environment; Indoo,Buildings; Energy conservation; Energy utilization,Internet of things},
pages = {1176--1181},
title = {{Indoor Localization Techniques for Smart Building Environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971291433{\&}doi=10.1016{\%}2Fj.procs.2016.04.242{\&}partnerID=40{\&}md5=6bd1224c661fd2381b88636c80ae6f6c},
volume = {83},
year = {2016}
}
@book{Turk20153,
abstract = {Mobile augmented reality (AR) employs computer vision capabilities in order to properly integrate the real and the virtual, whether that integration involves the user's location, object-based interaction, 2D or 3D annotations, or precise alignment of image overlays. Real-time vision technologies vital for the AR context include tracking, object and scene recognition, localization, and scene model construction. For mobile AR, which has limited computational resources compared with static computing environments, efficient processing is critical, as are consideration of power consumption (i.e., battery life), processing and memory limitations, lag, and the processing and display requirements of the foreground application. On the other hand, additional sensors (such as gyroscopes, accelerometers, and magnetometers) are typically available in the mobile context, and, unlike many traditional computer vision applications, user interaction is often available for user feedback and disambiguation. In this chapter, we discuss the use of computer vision for mobile augmented reality and present work on a vision-based AR application (mobile sign detection and translation), a vision-supplied AR resource (indoor localization and post estimation), and a low-level correspondence tracking and model estimation approach to increase accuracy and efficiency of computer vision methods in augmented reality. {\textcopyright} Springer International Publishing Switzerland 2015.},
annote = {cited By 3},
author = {Turk, M and Fragoso, V},
booktitle = {Mobile Cloud Visual Media Computing: From Interaction to Service},
doi = {10.1007/978-3-319-24702-1_1},
keywords = {Augmented reality; Energy efficiency; Indoor posit,Computational resources; Indoor localization; Mob,Computer vision},
pages = {3--42},
title = {{Computer vision for mobile augmented reality}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956770225{\&}doi=10.1007{\%}2F978-3-319-24702-1{\_}1{\&}partnerID=40{\&}md5=9d780900ffc70ef0d08e8a73cac5d154},
year = {2015}
}
@phdthesis{Tyagi:2008:LTS:1559056,
address = {Columbus, OH, USA},
annote = {AAI3325777},
author = {Tyagi, Ambrish},
isbn = {978-0-549-77713-7},
publisher = {Ohio State University},
title = {{Layered Tracker Switching for Visual Surveillance}},
year = {2008}
}
@inproceedings{Ullah2013259,
abstract = {Due to widespread availability of WiFi networks in buildings, indoor location based systems become a reality. To provide indoor location based services (LBS), finding the current location of a human, a computer, a mobile device or equipment such as a small UAV (like Quad copter) is of great interest. The most prominent method for this purpose is the received signal strength (RSS)-based location from WiFi Access Points (APs) inside a building. Considerable amount of research is carried out in estimating current location and providing different services based on different wireless technologies. On the other hand, little attention has been paid to study and analyze the behavior of the received signal strength itself. It is challenging because the intensity of signal can change very frequently due to environmental features like topology, temperature, interaction with objects etc. In this paper, we study the behavior of WiFi signals in an indoor environment for RSS based localization by analyzing signals from three different access points by using triangulation technique. Our method is based on fingerprinting method. The experimental results reveal that the behavior of signal changes very frequently. The results lead us to the conclusion that understanding signals behavior is important before estimating current location and providing different LBS. {\textcopyright} 2013 IEEE.},
annote = {cited By 3},
author = {Ullah, K and Custodio, I V and Shah, N and Moreira, E D S},
booktitle = {Proceedings - 11th International Conference on Frontiers of Information Technology, FIT 2013},
doi = {10.1109/FIT.2013.54},
pages = {259--264},
title = {{An experimental study on the behavior of received signal strength in indoor environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894119405{\&}doi=10.1109{\%}2FFIT.2013.54{\&}partnerID=40{\&}md5=124000311f8fe7950bac3e7db5c6ee73},
year = {2013}
}
@inproceedings{Ulusoy20174531,
abstract = {Dense 3D reconstruction from RGB images is a highly ill-posed problem due to occlusions, textureless or reflective surfaces, as well as other challenges. We propose objectlevel shape priors to address these ambiguities. Towards this goal, we formulate a probabilistic model that integrates multi-view image evidence with 3D shape information from multiple objects. Inference in this model yields a dense 3D reconstruction of the scene as well as the existence and precise 3D pose of the objects in it. Our approach is able to recover fine details not captured in the input shapes while defaulting to the input models in occluded regions where image evidence is weak. Due to its probabilistic nature, the approach is able to cope with the approximate geometry of the 3D models as well as input shapes that are not present in the scene. We evaluate the approach quantitatively on several challenging indoor and outdoor datasets. {\textcopyright} 2017 IEEE.},
annote = {cited By 6},
author = {Ulusoy, A O and Black, M J and Geiger, A},
booktitle = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
doi = {10.1109/CVPR.2017.482},
keywords = {3D reconstruction; Approximate geometries; Ill po,Computer vision; Content based retrieval; Image re,Three dimensional computer graphics},
pages = {4531--4540},
title = {{Semantic multi-view stereo: Jointly estimating objects and voxels}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044274081{\&}doi=10.1109{\%}2FCVPR.2017.482{\&}partnerID=40{\&}md5=d023812d479e2202712579cf87ebbc73},
volume = {2017-Janua},
year = {2017}
}
@inproceedings{5654292,
abstract = {In this paper, we focus on evaluating the performance of NTrip/RTK solutions for accurate and precise car navigation (analysis of both the accuracy and availibility of RTK data using mobile communication). Our approach is to develop a functional system of determining lane positions on highways. A system is based on wireless radio communication among surrounding vehicles what complement and enhance the current vehicle driving system needs (lane change collision avoidance systems, vehicle tracking, lane keeping and obstacle avoidance). Because lane change collision avoidance system requires very high relative accuracies between moving objects, therefore we are introducing "moving basestation" option into our system. Relative Moving Base Software (RMBS) package is implemented in real-time into NovAtel Propak-v3 GNSS receivers. This solution provides centimeter level baseline accuracy in relative vehicle positioning. For the RMBS implementation, the moving base position is only single point position, and must be recomputed for every epoch. Therefore, RTK/Ntrip base solution is required in this system. Exchanging Position, baseline and velocity information among surrounding vehicles using the twoway PacificCrest radiomodem link, definitely improves safety and efficiency of automobile transportation on the highways. Two experiments were conducted on test routes using two cars in the combined driving conditions (highway + downtown). Both tests took place at Wuhan University, GNSS Research Center, China. One additional test was performed using an NTrip stream delivered by a free-standing mount point obtaining data from the reference Trimble NetR5 receiver. We demonstrate the versatility of the system, showing the advantages and disadvantages of each component.},
author = {Uradzinski, M and Liu, J and Jiang, W},
booktitle = {2010 Ubiquitous Positioning Indoor Navigation and Location Based Service},
doi = {10.1109/UPINLBS.2010.5654292},
keywords = {automobiles;collision avoidance;image motion analy},
pages = {1--8},
title = {{Towards precise car navigation: Detection of relative vehicle position on highway for collision avoidance}},
year = {2010}
}
@inproceedings{Vandecasteele2017,
abstract = {Despite the broad application of the handheld thermal imaging cameras in firefighting, its usage is mostly limited to subjective interpretation by the person carrying the device. As remedies to overcome this limitation, object localization and classification mechanisms could assist the fireground understanding and help with the automated localization, characterization and spatio-temporal (spreading) analysis of the fire. An automated understanding of thermal images can enrich the conventional knowledge-based firefighting techniques by providing the information from the data and sensing-driven approaches. In this work, transfer learning is applied on multi-labeling convolutional neural network architectures for object localization and recognition in monocular visual, infrared and multispectral dynamic images. Furthermore, the possibility of analyzing fire scene images is studied and their current limitations are discussed. Finally, the understanding of the room configuration (i.e., objects location) for indoor localization in reduced visibility environments and the linking with Building Information Models (BIM) are investigated. {\textcopyright} 2017 SPIE.},
annote = {cited By 0},
author = {Vandecasteele, F and Merci, B and Jalalvand, A and Verstockt, S},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.2262484},
keywords = {Architectural design; Convolution; Fire extinguish,Building Information Model - BIM; Classification,Object recognition},
title = {{Object localization in handheld thermal images for fireground understanding}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023613182{\&}doi=10.1117{\%}2F12.2262484{\&}partnerID=40{\&}md5=3931907d8d05e9f711e39368d9098b96},
volume = {10214},
year = {2017}
}
@article{Varshavsky:2007:GIL:1316086.1316291,
address = {Amsterdam, The Netherlands, The Netherlands},
author = {Varshavsky, Alex and de Lara, Eyal and Hightower, Jeffrey and LaMarca, Anthony and Otsason, Veljo},
doi = {10.1016/j.pmcj.2007.07.004},
issn = {1574-1192},
journal = {Pervasive Mob. Comput.},
keywords = {Fingerprinting,GSM,Localization,Location,Ubicomp},
number = {6},
pages = {698--720},
publisher = {Elsevier Science Publishers B. V.},
title = {{GSM Indoor Localization}},
url = {http://dx.doi.org/10.1016/j.pmcj.2007.07.004},
volume = {3},
year = {2007}
}
@inproceedings{Vasudevan2018323,
abstract = {Navigation to a specific destination indoors can be a challenge due to different reasons such as visual impairment, unknown environments, etc. There has been much work done to solve this issue such as indoor positioning systems, navigation using sensors and even using a robotic guide. In this paper, a novel and straightforward method of path planning (including object avoidance) is presented as a way of navigating to a desired location within a complex environment. The system proposed uses the combination of depth information from an RGB-D camera and the object information from a Neural Network based object identification technique, to efficiently calculate and plan a path in real-time, to a pre-specified destination. Persons to be helped are identified using object detection, and the most practical path to the desired destination is calculated. The path information would be sent to the handheld device of the person being helped in the suitable form of interface, such as visual, audio, etc. The surveillance type nature of the system enables it to help multiple persons in the same area. The model was tested in a controlled environment with one individual person being guided to nearby specified locations. While the testing showed promising results, strong conclusions are yet to be made with the current system. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Vasudevan, V and Yang, G and Saniie, J},
booktitle = {IEEE International Conference on Electro Information Technology},
doi = {10.1109/EIT.2018.8500243},
keywords = {Complex environments; Controlled environment; Dep,Complex networks; Indoor positioning systems; Moti,Visual servoing},
pages = {323--327},
title = {{Autonomous Indoor Pathfinding Using Neural Network in Complex Scenes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057113010{\&}doi=10.1109{\%}2FEIT.2018.8500243{\&}partnerID=40{\&}md5=2e3e82889178796f3566e235fe455d7e},
volume = {2018-May},
year = {2018}
}
@article{Vinicchayakul20153296,
abstract = {Scattering signals, which scatter from furniture items, walls or objects in an indoor environment, affect on the received signals. Furthermore, the scatters have an effect on the radio wave propagation. Therefore, the effects of the scattering signals from the items on the radio wave propagation are investigation and analysis. For this reason, this paper presents an effect between the scattering signals and an aluminum hollow rod in a frequency range of 3.011.0 GHz of ultra wideband (UWB) and each angel. Then, the aluminum hollow rod was moved to follow each location in order to test for the UWB applications. An experimental set-up was set by using a vector network analyzer (VNA) for bistatic radar cross section (RCS) measurements in an indoor environment. Then, the scattering signals from the aluminum hollow rod were analyzed in term of the RCS. After that, the RCS was applied to the UWB applications. {\textcopyright} 2015 American Scientific Publishers. All rights reserved.},
annote = {cited By 0},
author = {Vinicchayakul, W and Supanakoon, P and Promwong, S},
doi = {10.1166/asl.2015.6465},
journal = {Advanced Science Letters},
number = {10},
pages = {3296--3299},
title = {{Indoor radar cross section measurements of aluminum hollow rod for ultra wideband applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960430017{\&}doi=10.1166{\%}2Fasl.2015.6465{\&}partnerID=40{\&}md5=192919a4b85bdb45db366e806711bae0},
volume = {21},
year = {2015}
}
@inproceedings{Viyanon2017,
abstract = {Purchasing products for interior design always has a problem that the purchased products may not satisfy customers because they cannot put them in their own place before buying. The purpose of this research is to study and develop an android application called 'AR Furniture' with the use of Augmented Reality technology for design and decoration that will help customers visualize how furniture pieces will look and fit (to scale) in their homes and also can provide details of products to support customer decision. This application is a prototype to find out factors affecting the design and tracking of AR applications. This paper presents three factors that are important for designing and tracking AR applications. The principle of the application is started with analyzing images from the rear camera of a smartphone or tablet using marker tracking technique for displaying product's details and markerless tracking technique for displaying 3D models, performing feature tracking, and calculating positions to display a 3D model over the real world image. The implementation of the application can be split into 2 parts: Part 1 Creating 3D Models using Autodesk 3Ds Max and Part 2 Developing the application using Unity3D and Kudan Augmented Reality SDK as an engine for image analysis, image processing and 3D model rendering. Then we performed three experiments to test the application, 1) Image analysis with marker tracking 2) Image analysis with markerless tracking and 3) User's satisfaction of using the application. The results show that image analysis with marker tracking works well using markers which their size should not be less than 200 x 200 pixels, the distance between the camera and the marker should not be far more than 60 cm. Image analysis with markerless tracking works well with surfaces having a lot of features and at light levels of 100-300 lux (indoor light levels) with 70{\%} accuracy. The user experience evaluation shows that the weakness (2.86 out of 5 points) of the application is when a user found a problem in the application they would need time to solve it. The user experience evaluation shows that the strength (3.93 out of 5 points) of the application is the application can show 3D Object that meet user satisfaction. And the average overall user's satisfaction come up with 3.93 out of 5 point evaluation score. From the experiments, the application should be modified for better performance such as develop various maker patterns using QR code or barcode, distinguish walls and ceilings so that the application would show 3D objects on them properly, improve light robustness and make 3D models more realistic. {\textcopyright} 2017 Association for Computing Machinery.},
annote = {cited By 1},
author = {Viyanon, W and Songsuittipong, T and Piyapaisarn, P and Sudchid, S},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3144789.3144825},
keywords = {Android applications; AR application; AR display;,Architectural design; Augmented reality; Cameras;,Three dimensional computer graphics},
title = {{AR furniture: Integrating augmented reality technology to enhance interior design using marker and markerless tracking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037339950{\&}doi=10.1145{\%}2F3144789.3144825{\&}partnerID=40{\&}md5=345fbc79fd49eb9708358280809c3fe9},
volume = {Part F1318},
year = {2017}
}
@article{Voronov201761,
abstract = {This paper deals with an indoor positioning system. The system is based on the use of wireless local area network access points. A location calculation engine is based on Bayesian algorithms. Location accuracy depends on the number and placement of access points. This paper considers the mathematical model and the method of solving the problem of optimal access point placement for indoor positioning system. The criteria for evaluating the quality of the access points placement is the mathematical expectation of the localization error. We consider two strategies for localization of a mobile object. It is demonstrated that, for some strategies, the addition of access points can possibly increases the expectation errors, for example, the strategy selecting the most probable zone. A strategy, guaranteeing that the addition of access points does not lead to an increase in the expectation errors is proposed. An algorithm for solving the optimization problem is developed. We present the result of testing the algorithm on real data.},
annote = {cited By 1},
author = {Voronov, R V},
doi = {10.21638/11701/spbu10.2017.106},
journal = {Vestnik Sankt-Peterburgskogo Universiteta, Prikladnaya Matematika, Informatika, Protsessy Upravleniya},
number = {1},
pages = {61--73},
title = {{The problem of optimal placement of access points for the indoor positioning system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031111406{\&}doi=10.21638{\%}2F11701{\%}2Fspbu10.2017.106{\&}partnerID=40{\&}md5=36d454b49f36436714e3c38a0b138444},
volume = {13},
year = {2017}
}
@inproceedings{Wagner201342,
abstract = {An important basis of many smart city applications is knowledge about the location of persons and objects. In outdoor environments, this knowledge can be acquired reliably on a global scale using the well-known Global Positioning System (GPS). In indoor environments, both the availability and reliability of GPS is significantly limited. This, in turn, has led to active research on approaches and systems to enable indoor localization using various cooperating objects technologies. A key challenge during the development of any of these indoor localization approaches and systems is the systematic evaluation of their performance. To do this, developers have to perform extensive and time-consuming measurements at different locations over an extended period of time. In this paper, we discuss how the time requirements can be reduced by means of automation. Furthermore, based on our experiences with both, manual and automatic evaluation, we discuss the achievable benefits and possible limitations.},
annote = {cited By 0},
author = {Wagner, S and Smeets, H and Handte, M and Fet, N and Shih, C.-Y. and Marr{\'{o}}n, P J},
booktitle = {CEUR Workshop Proceedings},
keywords = {Automated evaluation; Automatic evaluation; Coope,Global positioning system,Indoor positioning systems},
pages = {42--57},
title = {{Automated evaluation of RF-based indoor localization systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922113100{\&}partnerID=40{\&}md5=9486d3b49ef2b17138268419b3f1f79f},
volume = {1002},
year = {2013}
}
@article{Wakamatsu2016124,
abstract = {The MIMO technique can improve system performance of not only communication system but also of radar systems. In this paper, we apply the MIMO radar with enhanced angular resolution to the indoor location estimation of humans. The Khatri-Rao (KR) matrix product is also adopted for further angular resolution enhancement. We show that the MIMO radar with the KR matrix product processing can increase the number of virtual elements effectively with suitable element arrangement, hence higher angular resolution can be realized. In general, the KR matrix product processing is not suitable for coherent radar because of signal correlation. However, when targets signals have enough Doppler frequency differential against each other, this approach works well because the signals are decorrelated. In addition, Doppler filtering is introduced to remove unwanted responses of stationary objects which make human detection difficult with conventional methods. Computer simulation and experimental results are provided to show performance of the proposed method. Copyright {\textcopyright} 2016 The Institute of Electronics, Information and Communication Engineers.},
annote = {cited By 5},
author = {Wakamatsu, Y and Yamada, H and Yamaguchi, Y},
doi = {10.1587/transcom.2015ISP0029},
journal = {IEICE Transactions on Communications},
keywords = {Angular resolution; Conventional methods; Doppler,Doppler effect; Doppler radar; Frequency estimatio,MIMO radar},
number = {1},
pages = {124--133},
title = {{MIMO Doppler radar using Khatri-Rao product virtual array for indoor human detection}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953209086{\&}doi=10.1587{\%}2Ftranscom.2015ISP0029{\&}partnerID=40{\&}md5=3521fd9f0b99cb5e2c6cf35917f0fe53},
volume = {E99B},
year = {2016}
}
@inproceedings{Wallbaum200617,
abstract = {Determining the context of users and machines is an important topic in current computing research. An essential detail of a physical object's context is its location, which includes both the actual position as well as the semantics of the surroundings. This paper focuses on the specific problem of determining the position of objects and people within buildings. A low-cost approach is based on wireless LANs, which are now widely deployed. The paper presents a sophisticated probabilistic algorithm for indoor positioning using wireless LANs, but also discusses the problems that need to be solved to make indoor geolocation commonplace. {\textcopyright} 2006 IEEE.},
annote = {cited By 14},
author = {Wallbaum, M and Spaniol, O},
booktitle = {Proceedings - IEEE John Vincent Atanasoff 2006 International Symposium on Modern Computing, JVA 2006},
doi = {10.1109/JVA.2006.28},
keywords = {Cost effectiveness; Probability; Problem solving;,Indoor positioning; Probabilistic algorithms,Tracking (position)},
pages = {17--24},
title = {{Indoor positioning using wireless local area networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547674711{\&}doi=10.1109{\%}2FJVA.2006.28{\&}partnerID=40{\&}md5=55ba32ddf42332903062428a1e871c42},
year = {2006}
}
@inproceedings{8115957,
abstract = {This paper describes an alternative approach to giving people with limited hand and arm movement the ability to select objects on a computing device using head movement (head mouse). To allow for better filtering of unintentional head movement, and to allow for a faster update rate of the head mouse, the full six-DoF pose of the head is estimated using a low-cost camera and IR markers, a 3-axis accelerometer, and a 3-axis magnetometer. The pose estimation problem was cast in a probabilistic fashion in which information from the different sensors is fused into a single a-posteriori distribution for the sensor pose. Simulations were run to analyze the influence of the proposed sensor fusion algorithm on the stability and accuracy of the pose estimation, and thus on the ability to point a mouse cursor to a specified location on a screen. Experiments were then performed validating the results from the simulations on real sensors. The proposed algorithm was shown to give more accurate and stable results than using only a camera to estimate the six-DoF pose.},
author = {Walsh, E and Daems, W and Steckel, J},
booktitle = {2017 International Conference on Indoor Positioning and Indoor Navigation (IPIN)},
doi = {10.1109/IPIN.2017.8115957},
issn = {2471-917X},
keywords = {accelerometers;cameras;handicapped aids;magnetomet},
pages = {1--7},
title = {{Stable six-DoF head-pose tracking in assistive technology application}},
year = {2017}
}
@inproceedings{7275532,
abstract = {High resolution ToF measurements from multiple ultrasonic transmitter/receiver pairs allow determination of distance and bearing of reflectors. By combining methods for solving the echo correspondence problem, in case of multiple reflectors, and avoiding outliers, typically occurring on object discontinuities, a high quality map of 3D reflection points is obtained. This information is suitable for 3D scene analysis making it possible to determine location, orientation and parameters of planes, cylinders and edges. The presented sensor herein is low in cost, compact in size, can operate under real-time constrains and is suitable for a wide range of applications. Experimental verification was performed in an office room with multiple reflectors. Two planes are in close proximity showing the performance of solving the echo correspondence problem and the reduction of outliers. Determination of the orientation of a cylinder and its parameters in 3D show the high accuracy of the proposed system.},
author = {Walter, C and Schweinzer, H},
booktitle = {2014 International Conference on Indoor Positioning and Indoor Navigation (IPIN)},
doi = {10.1109/IPIN.2014.7275532},
keywords = {echo;object detection;ultrasonic transducers;compa},
pages = {591--600},
title = {{Locating of objects with discontinuities, boundaries and intersections using a compact ultrasonic 3D sensor}},
year = {2014}
}
@article{Wang2013337,
abstract = {Scene classification is a challenging problem in computer vision. Though conventional methods show good performance in recognizing outdoor scenes, these methods does not work well in indoor scenes recognition. In recent years, high level image representations consisted of semantic attribute information has been introduced to solve this problem. However, a key technical challenge for these representations is the "curse of dimensionality", caused by the large numbers of objects and high dimensionality of the response vector for each object. In this paper, we propose a hypergraph learning algorithm based feature selection method for indoor scene classification. It performs feature selection by hypergraph regularization, which not only considers the interaction among features but also the interaction between the feature selection heuristics and the corresponding classifier. For the convenience of the prediction of the new images, a liner regression model is integrated in the framework, making the new images classification directly and in real time. The experimental results show that our approach has satisfactory performance compared with previously proposed methods. {\textcopyright} 2013 Elsevier B.V.},
annote = {cited By 7},
author = {Wang, C and Yu, J and Tao, D},
doi = {10.1016/j.neucom.2013.05.032},
journal = {Neurocomputing},
keywords = {Attribute; Curse of dimensionality; Feature select,Feature extraction; Regression analysis,Semantics,analytic method; article; computer interface; con},
pages = {337--343},
title = {{High-level attributes modeling for indoor scenes classification}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884164808{\&}doi=10.1016{\%}2Fj.neucom.2013.05.032{\&}partnerID=40{\&}md5=fe9d31814b0fa69ee130645739d51aeb},
volume = {121},
year = {2013}
}
@inproceedings{Wang2014,
abstract = {The research of indoor positioning is rapidly increasing in recent years, and most researchers have focused on RFID technology in indoor positioning; It is difficult to deal with the RFID positioning method, due to RFID is restricted by the disturbance of wireless signals. Therefore, this paper proposes an indoor location system combined with active RFID and Kinect. Based on the identification and positioning functions of RFID, and the effective object extraction ability of Kinect, our system can analyze the identification and position of persons accurately and effectively. {\textcopyright} 2014 IEEE.},
annote = {cited By 3},
author = {Wang, C.-S. and Chen, C.-L.},
booktitle = {2014 4th International Conference on Wireless Communications, Vehicular Technology, Information Theory and Aerospace and Electronic Systems, VITAE 2014 - Co-located with Global Wireless Summit},
doi = {10.1109/VITAE.2014.6934458},
keywords = {Indoor location system; Indoor positioning; Indoo,Information theory; Wireless telecommunication sys,Radio frequency identification (RFID)},
title = {{RFID-based and Kinect-based indoor positioning system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911924370{\&}doi=10.1109{\%}2FVITAE.2014.6934458{\&}partnerID=40{\&}md5=fb7f2d50eec80fa9d7eefec75ee72fa9},
year = {2014}
}
@phdthesis{Wang:2000:VRE:931079,
address = {Ann Arbor, MI, USA},
annote = {AAI9963913},
author = {Wang, Chi-Kuo Gregory},
isbn = {0-599-68045-8},
publisher = {University of Michigan},
title = {{Visibility in Reflective Environments}},
year = {2000}
}
@phdthesis{Wang:2008:LAS:1626714,
annote = {AAI3343430},
author = {Wang, Chong},
isbn = {978-0-549-98424-5},
publisher = {University of Louisiana at Lafayette},
title = {{Localization and Its Applications in Self-configurable Wireless Networks}},
year = {2008}
}
@article{6908039,
abstract = {This paper presents a hybrid radar system that incorporates a linear frequency-modulated continuous-wave (FMCW) mode and an interferometry mode for indoor human localization and life activity monitoring applications. The unique operating principle and signal processing method allow the radar to work at two different modes for different purposes. The FMCW mode is responsible for range detection while the interferometry mode is responsible for life activities (respiration, heart beat, body motion, and gesture) monitoring. Such cooperation is built on each mode's own strength. Beam scanning is employed to determine azimuth information, which enables the system to plot 360 2-D maps on which the room layout and objects' location can be clearly identified. Additionally, the transmitted chirp signal is coherent in phase, which is very sensitive to physiological motion and allows the proposed technique to distinguish human from nearby stationary clutters even when the human subjects are sitting still. Hence, the proposed radar is able to continuously track the location of individuals and monitor their life activities regardless of the complex indoor environment. A series of experiments have been carried out to demonstrate the proposed versatile life activity monitoring system.},
author = {Wang, G and Gu, C and Inoue, T and Li, C},
doi = {10.1109/TMTT.2014.2358572},
issn = {0018-9480},
journal = {IEEE Transactions on Microwave Theory and Techniques},
keywords = {CW radar;FM radar;indoor communication;medical sig},
month = {nov},
number = {11},
pages = {2812--2822},
title = {{A Hybrid FMCW-Interferometry Radar for Indoor Precise Positioning and Versatile Life Activity Monitoring}},
volume = {62},
year = {2014}
}
@article{8314084,
abstract = {Device-free localization of objects not equipped with RF radios is playing a critical role in many applications. This paper presents LIFS, a Low human-effort, device-free localization system with fine-grained subcarrier information, which can localize a target accurately without offline training. The basic idea is simple: channel state information (CSI) is sensitive to a target's location and thus the target can be localized by modelling the CSI measurements of multiple wireless links. However, due to rich multipath indoors, CSI can not be easily modelled. To deal with this challenge, our key observation is that even in a rich multipath environment, not all subcarriers are affected equally by multipath reflections. Our CSI pre-processing scheme tries to identify the subcarriers not affected by multipath. Thus, CSI on the clean subcarriers can still be utilized for accurate localization. Without the need of knowing the majority transceivers' locations, LiFS achieves a median accuracy of 0.5 m and 1.1 m in line-of-sight (LoS) and non-line-of-sight (NLoS) scenarios, respectively, outperforming the state-of-the-art systems.},
author = {Wang, J and Xiong, J and Jiang, H and Jamieson, K and Chen, X and Fang, D and Wang, C},
doi = {10.1109/TMC.2018.2812746},
issn = {1536-1233},
journal = {IEEE Transactions on Mobile Computing},
keywords = {indoor communication;mobile radio;multipath channe},
month = {nov},
number = {11},
pages = {2550--2563},
title = {{Low Human-Effort, Device-Free Localization with Fine-Grained Subcarrier Information}},
volume = {17},
year = {2018}
}
@article{Wang2018,
abstract = {Automatic object searching is one of the essential skills for domestic robots to operate in unstructured human environments. It involves concatenation of several capabilities including object identification, obstacle avoidance, path planning and navigation. In this paper, we propose an automatic object searching framework for a mobile robot equipped with a single RGB-D camera. The obstacle avoidance is achieved by a behavior learning algorithm based on Deep Belief Networks (DBNs). The target object is recognized using SIFT descriptors and the relative position between the target and mobile robot is estimated from the RGB-D data. Subsequently, the mobile robot makes a path planning to the target location using an improved bug-based algorithm. The framework is tested in indoor environments and requires the robot to perform obstacle avoidance and automatically search and approach the target object. The results indicate that the system is collision free and reliable in performing searching tasks. This system{\&}{\#}x2019;s functions make itself have the potential of being used for local navigation in unstructured environments. IEEE},
annote = {cited By 0; Article in Press},
author = {Wang, J and Yan, R and Tang, H and Sun, F},
doi = {10.1109/TCDS.2018.2841002},
journal = {IEEE Transactions on Cognitive and Developmental Systems},
keywords = {Bug-based algorithms; Deep belief networks; Indoo,Cameras; Collision avoidance; Deep learning; Intel,Robot programming},
title = {{Automatic Object Searching and Behavior Learning for Mobile Robots in Unstructured Environment by Deep Belief Networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047627817{\&}doi=10.1109{\%}2FTCDS.2018.2841002{\&}partnerID=40{\&}md5=e3a1b3ee7ea81ec8b47b9e1b89b73335},
year = {2018}
}
@phdthesis{Wang:2007:SRI:1415075,
address = {Stony Brook, NY, USA},
annote = {AAI3299724},
author = {Wang, Jianning},
isbn = {978-0-549-44412-1},
publisher = {State University of New York at Stony Brook},
title = {{Surface Reconstruction from Imperfect Point Models}},
year = {2007}
}
@inproceedings{Wang:2016:LLH:2973750.2973776,
address = {New York, NY, USA},
author = {Wang, Ju and Jiang, Hongbo and Xiong, Jie and Jamieson, Kyle and Chen, Xiaojiang and Fang, Dingyi and Xie, Binbin},
booktitle = {Proceedings of the 22Nd Annual International Conference on Mobile Computing and Networking},
doi = {10.1145/2973750.2973776},
isbn = {978-1-4503-4226-1},
keywords = {channel state information,device-free localization,low human-effort,multipath,power fading model},
pages = {243--256},
publisher = {ACM},
series = {MobiCom '16},
title = {{LiFS: Low Human-effort, Device-free Localization with Fine-grained Subcarrier Information}},
url = {http://doi.acm.org/10.1145/2973750.2973776},
year = {2016}
}
@article{2018:MIS:3165318.3165495,
abstract = {Automatic modeling of indoor scenes from raw point data has received considerable attention due to its wide applications in computer graphics and robotics. The raw point data, however, always suffer from incompleteness, noise and anisotropy in density, which make rapid reconstruction fairly challenging. To overcome these challenges, in this paper, we explore the repeatability and regularity of man-made structures, which is the crux of our automatic reconstruction of indoor scenes. As observed, repetitive structures oftentimes exhibit in indoor scenes, such as classrooms, meeting rooms, and auditoria. We detect repetitions hierarchically and extract each repetitive object separately in these scenes. The object is represented with a set of key points which are extracted by leveraging both the local and global information of the data. By retrieving the most similar models from the shape database, we align them with the input data to obtain a high-quality virtual representation of the scene, which is quite faithful to the original geometry. In contrast to previous methods, we discover the high-level structure of the scene and can obtain a complete reconstruction efficiently even in the presence of noise and incomplete scans. A variety of indoor scenes have been tested to verify the effectiveness and the robustness of our proposed method.},
address = {Newton, MA, USA},
author = {Wang, Jun and Wu, Qiaoyun and Remil, Oussama and Yi, Cheng and Guo, Yanwen and Wei, Mingqiang},
doi = {10.1016/j.cad.2017.09.001},
issn = {00104485},
journal = {CAD Computer Aided Design},
keywords = {Indoor scene modeling,Key point extraction,Raw LiDAR data,Repetition detection},
number = {C},
pages = {1--15},
publisher = {Butterworth-Heinemann},
title = {{Modeling indoor scenes with repetitions from 3D raw point data}},
url = {https://doi.org/10.1016/j.cad.2017.09.001},
volume = {94},
year = {2018}
}
@article{Wang201040,
abstract = {The extraction of moving objects from their background is a challenging task in visual surveillance. As a single threshold often fails to resolve ambiguities and correctly segment the object, in this paper, we propose a new method that uses three thresholds to accurately classify pixels as foreground or background. These thresholds are adaptively determined by considering the distributions of differences between the input and background images and are used to generate three boundary sets. These boundary sets are then merged to produce a final boundary set that represents the boundaries of the moving objects. The merging step proceeds by first identifying boundary segment pairs that are significantly inconsistent. Then, for each inconsistent boundary segment pair, its associated curvature, edge response, and shadow index are used as criteria to evaluate the probable location of the true boundary. The resulting boundary is finally refined by estimating the width of the halo-like boundary and referring to the foreground edge map. Experimental results show that the proposed method consistently performs well under different illumination conditions, including indoor, outdoor, moderate, sunny, rainy, and dim cases. By comparing with a ground truth in each case, both the classification error rate and the displacement error indicate an accurate detection, which show substantial improvement in comparison with other existing methods. {\textcopyright} 2010 IEEE.},
annote = {cited By 58},
author = {Wang, L and Yung, N H C},
doi = {10.1109/TITS.2009.2026674},
journal = {IEEE Transactions on Intelligent Transportation Systems},
keywords = {Adaptive thresholds; Background image; Boundary ev,Error detection,Image segmentation; Signal detection},
number = {1},
pages = {40--51},
title = {{Extraction of moving objects from their background based on multiple adaptive thresholds and boundary evaluation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77649273644{\&}doi=10.1109{\%}2FTITS.2009.2026674{\&}partnerID=40{\&}md5=b1394c78ad71bfb7461bf449973518ad},
volume = {11},
year = {2010}
}
@article{Wang20181735,
abstract = {Hyper-lapse video with high speed-up rate is an efficient way to overview long videos, such as a human activity in first-person view. Existing hyper-lapse video creation methods produce a fast-forward video effect using only one video source. In this paper, we present a novel hyper-lapse video creation approach based on multiple spatially-overlapping videos. We assume the videos share a common view or location, and find transition points where jumps from one video to another may occur. We represent the collection of videos using a hyper-lapse transition graph; the edges between nodes represent possible hyper-lapse frame transitions. To create a hyper-lapse video, a shortest path search is performed on this digraph to optimize frame sampling and assembly simultaneously. Finally, we render the hyper-lapse results using video stabilization and appearance smoothing techniques on the selected frames. Our technique can synthesize novel virtual hyper-lapse routes, which may not exist originally. We show various application results on both indoor and outdoor video collections with static scenes, moving objects, and crowds. {\textcopyright} 1992-2012 IEEE.},
annote = {cited By 5},
author = {Wang, M and Liang, J.-B. and Zhang, S.-H. and Lu, S.-P. and Shamir, A and Hu, S.-M.},
doi = {10.1109/TIP.2017.2749143},
journal = {IEEE Transactions on Image Processing},
keywords = {Graph theory,Hyper-lapse Video; Shortest path searches; Smooth,Video signal processing},
number = {4},
pages = {1735--1747},
title = {{Hyper-Lapse From Multiple Spatially-Overlapping Videos}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028976620{\&}doi=10.1109{\%}2FTIP.2017.2749143{\&}partnerID=40{\&}md5=19a2501e77a90a7dded740591ce81ae7},
volume = {27},
year = {2018}
}
@inproceedings{Wang2006,
abstract = {Video surveillance, object tracking and activity monitoring are some of the important issues for a home-care robotic system. In this work, an omnidirectional video camera is adopted to provide a 360 degree view angle of the indoor scene with a single image sequence. Some basic functions for smart living and elderly care, such as motion detection, object tracking and target behavior analysis, are implemented. For the motion detection, a background model is first created and the CamShift algorithm is used for object tracking by extracting color information of the target. To make the motion detection and object tracking fully automatic and robust under different illumination conditions, an optical flow approach is cooperated to detect small changes of the mobile object. In addition, the camera is calibrated to obtain the one-to-one correspondences between the image pixels and the locations on the ground. They are used for fall detection of the target by comparing the object length appeared in the image and the computed length according to the object's physical height. {\textcopyright} 2006 IEEE.},
annote = {cited By 2},
author = {Wang, M.-L. and Huang, C.-C. and Lin, H.-Y.},
booktitle = {2006 IEEE Conference on Cybernetics and Intelligent Systems, CIS 2006},
keywords = {Activity monitoring; Cam-shift algorithms; Illumi,Cybernetics; Image processing; Intelligent systems,Tracking (position)},
title = {{An intelligent surveillance system based on an omnidirectional vision sensor}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894158864{\&}partnerID=40{\&}md5=0789898d8455dbb7377055ec42b7fc45},
year = {2006}
}
@article{Wang2014157,
abstract = {With the development of the Internet of Things (IoT) and indoor positioning technologies, how to manage the rapidly increasing indoor moving object data is a research topic. The fundamental issue is to consider the representation of complicated indoor space as well as the moving object. In this paper, we aim to propose a complete indoor space model that can sup-port various indoor applications. The proposed model divides each indoor element into multi-granularity grids and introduces grids as indoor primitive geometry for the representation of connectivity between indoor elements and location of moving objects. The advantage of this approach is that it can simultaneously represent the connective relationship and geometric information of indoor elements, and give more accurate description of indoor distance and direction information. Several queries of indoor applications under the shopping mall scenar-io are employed to illustrate the completeness and robustness of our model. {\textcopyright} 2014 SERSC.},
annote = {cited By 5},
author = {Wang, N and Jin, P and Xiong, Y and Yue, L},
doi = {10.14257/ijmue.2014.9.4.17},
journal = {International Journal of Multimedia and Ubiquitous Engineering},
keywords = {Artificial intelligence; Industrial engineering; M,Engineering,Geometric information; Grids; Indoor applications},
number = {4},
pages = {157--170},
title = {{A multi-granularity grid-based graph model for indoor space}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899676581{\&}doi=10.14257{\%}2Fijmue.2014.9.4.17{\&}partnerID=40{\&}md5=f762ab1a090c4ba90d5bb1d03213997e},
volume = {9},
year = {2014}
}
@inproceedings{8559749,
abstract = {Traditional visual SLAM methods employ point features to implement motion estimation and environment map construction. However, in some low-texture indoor scenarios, such as office and corridor, less reliable point features may be found, which could jeopardize the SLAM solution. In addition, scene changes among sequential images are not only caused by the position changes of image acquisition, but also by pedestrians and other moving objects in an indoor dynamic environment. Thus, feature identification for moving objects is needed as an important part for practical application of indoor SLAM. This paper proposes a point-line feature based SLAM method that combines both of points and line segments to enhance the performance of feature extraction in indoor scene, which can extract many line features from walls, furniture and other artificial objects. In this method, added line features help to gain more robust and accurate results. Additionally, a real-time object detection algorithm is introduced to identify the features extracted from pedestrians, so that to eliminate the negative effects caused by moving objects. The experimental results demonstrates that the proposed method can obtain more robust and accurate localization results in dynamic indoor scene.},
author = {Wang, R and Wang, Y and Wan, W and Di, K},
booktitle = {2018 Ubiquitous Positioning, Indoor Navigation and Location-Based Services (UPINLBS)},
doi = {10.1109/UPINLBS.2018.8559749},
keywords = {feature extraction;image sensors;image texture;mob},
pages = {1--6},
title = {{A Point-Line Feature based Visual SLAM Method in Dynamic Indoor Scene}},
year = {2018}
}
@inproceedings{Wang:2011:ISD:2353337.2353441,
address = {Washington, DC, USA},
author = {Wang, Shuihua and Tian, Yingli},
booktitle = {Proceedings of the 2011 IEEE International Conference on Bioinformatics and Biomedicine Workshops},
doi = {10.1109/BIBMW.2011.6112422},
isbn = {978-1-4577-1612-6},
pages = {518--525},
publisher = {IEEE Computer Society},
series = {BIBMW '11},
title = {{Indoor Signage Detection Based on Saliency Map and Bipartite Graph Matching}},
url = {https://doi.org/10.1109/BIBMW.2011.6112422},
year = {2011}
}
@inproceedings{Wang20131790,
abstract = {We propose a structured Hough voting method for detecting objects with heavy occlusion in indoor environments. First, we extend the Hough hypothesis space to include both object location and its visibility pattern, and design a new score function that accumulates votes for object detection and occlusion prediction. In addition, we explore the correlation between objects and their environment, building a depth-encoded object-context model based on RGB-D data. Particularly, we design a layered context representation and allow image patches from both objects and backgrounds voting for the object hypotheses. We demonstrate that using a data-driven 2.1D representation we can learn visual codebooks with better quality, and more interpretable detection results in terms of spatial relationship between objects and viewer. We test our algorithm on two challenging RGB-D datasets with significant occlusion and intraclass variation, and demonstrate the superior performance of our method. {\textcopyright} 2013 IEEE.},
annote = {cited By 17},
author = {Wang, T and He, X and Barnes, N},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2013.234},
keywords = {Computer science; Electrical engineering; Pattern,Context representation; Detecting objects; Hough v,Object recognition},
pages = {1790--1797},
title = {{Learning structured hough voting for joint object detection and occlusion reasoning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887359553{\&}doi=10.1109{\%}2FCVPR.2013.234{\&}partnerID=40{\&}md5=f4da48e42cc35097c73684ab79c69fa3},
year = {2013}
}
@article{Wang:2015:TOR:2849459.2849483,
address = {Secaucus, NJ, USA},
author = {Wang, Wei and Chen, Lili and Liu, Ziyuan and K{\"{u}}hnlenz, Kolja and Burschka, Darius},
doi = {10.1007/s11554-013-0380-z},
issn = {1861-8200},
journal = {J. Real-Time Image Process.},
keywords = {Object recognition and pose estimation,Real-time robotic vision,Semantic map,Viewpoint oriented color---shape histogram},
number = {4},
pages = {667--682},
publisher = {Springer-Verlag New York, Inc.},
title = {{Textured/Textureless Object Recognition and Pose Estimation Using RGB-D Image}},
url = {http://dx.doi.org/10.1007/s11554-013-0380-z},
volume = {10},
year = {2015}
}
@article{Wang201876,
abstract = {Estimating the style compatibility between a pair of cross-category 3D indoor objects has received wide interests from the field of computer graphics in these years. Many previous works solve this task by extracting and analyzing the style-aware structures or elements from the input 3D models. In this paper, we propose a novel approach to solve this task by training a deep neural network to quantitatively assign a compatibility score between arbitrary pair of cross-category 3D objects. By entirely learning from raw data, the trained network is able to capture various compatibility conditions influenced by global style features, such as ergonomics and object category relation. The proposed deep estimator is generally robust and can facilitate various high-level tasks. We first show its application for object collection organization. After that, we show how layout-guided, style-consistent object retrieval for indoor scene synthesis can be achieved by integrating pairwise style estimations into a novel submodular formulation. Our experiments demonstrate the usability of the proposed approach, demonstrating results superior than previous works and even comparable with suggestions made by human observers. {\textcopyright} 2018 Elsevier Ltd},
annote = {cited By 1},
author = {Wang, X and Zhou, B and Zhang, Y and Zhao, Y},
doi = {10.1016/j.cag.2018.05.008},
journal = {Computers and Graphics (Pergamon)},
keywords = {Compatibility conditions; Human observers; ITS ap,Content based retrieval; Ergonomics; Estimation; O,Deep neural networks},
pages = {76--84},
title = {{Deep style estimator for 3D indoor object collection organization and scene synthesis}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050876294{\&}doi=10.1016{\%}2Fj.cag.2018.05.008{\&}partnerID=40{\&}md5=7bac06d28716002b190768ffc78da687},
volume = {74},
year = {2018}
}
@article{Wang2019728,
abstract = {Indoor positioning technology is the key to further development of LBS system. Based on RFID technology, it is efficient and feasible to combine the indoor navigation management system with LBS technology. The LBS system provides the functions of mobile device location, communication and service, and RFID based indoor positioning provides the function of locating objects indoor environment. The combination of the two technologies can further facilitate the positioning and navigation in our lives. In this paper, a novel indoor navigation system based on RFID and LBS is presented. The implementation of this system shows that it is feasible to support service in indoor environment. {\textcopyright} Springer International Publishing AG, part of Springer Nature 2019.},
annote = {cited By 0},
author = {Wang, Y and Xu, X and Wang, X and Xu, H},
doi = {10.1007/978-3-319-93554-6_71},
journal = {Advances in Intelligent Systems and Computing},
keywords = {In-door navigations; Indoor environment; Indoor n,Indoor positioning systems,Location based services; Mobile devices; Navigatio},
pages = {728--737},
title = {{A novel indoor navigation system based on RFID and LBS technology}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048624424{\&}doi=10.1007{\%}2F978-3-319-93554-6{\_}71{\&}partnerID=40{\&}md5=8157eeb257cf8f129f3c95c89bf088db},
volume = {773},
year = {2019}
}
@inproceedings{Wang2016165,
abstract = {The Global Positioning System (GPS) has been widely used to determine the location for a variety of different applications, However, it doesn't work well in indoor environments because it requires the line of sight to the satellites and therefore stops working when the line of sight is not available, High-precision indoor localization is critical to many personal and business applications, After Bluetooth Low Energy (BLE), an energy-efficient version of Bluetooth, is widely deployed, Bluetooth-based indoor localization turns out to be a practical method to locate Bluetooth-enabled devices due to its low battery cost, In this paper, we present two novel BLE-based localization schemes, Low-precision Indoor Localization (LIL) and High-precision Indoor Localization (HIL), Different than most of the existing localization methods that attempt to find the specific location of the object under investigation, LIL and HIL utilize the collected RSSI measurements to generate a small region in which the object is guaranteed to be found, Compared with LIL, HIL leads to smaller localization regions, However, HIL requires an extra data-training phase. {\textcopyright} 2015 IEEE.},
annote = {cited By 20},
author = {Wang, Y and Ye, Q and Cheng, J and Wang, L},
booktitle = {Proceedings - 11th International Conference on Mobile Ad-Hoc and Sensor Networks, MSN 2015},
doi = {10.1109/MSN.2015.14},
keywords = {Bluetooth le; Bluetooth low energies (BLE); Bluet,Bluetooth; Electromagnetic launchers; Energy effic,Indoor positioning systems},
pages = {165--171},
title = {{RSSI-Based Bluetooth Indoor Localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964545828{\&}doi=10.1109{\%}2FMSN.2015.14{\&}partnerID=40{\&}md5=f3dd58547e01d73acc0e5f9b48213cb2},
year = {2016}
}
@article{Wang201086,
abstract = {Several improvements of the existing reference tag-based nearest-neighbor positioning algorithm were introduced, including the method of dynamic setting of k value, the concept of reference tags' credibility and the algorithm of correction based on the positioning error of nearest tags. The algorithm based on the historical track of object tags was also adopted. The indoor positioning system was built with time-division multi-use antennas connected to its RF-ports. The visual software was also developed based on the algorithm proposed. Positioning accuracy and stability in complex environments were proved by experiments to be better than that of the existing algorithm.},
annote = {cited By 10},
author = {Wang, Y.-Z. and Mao, L.-H. and Liu, H and Xiao, J.-G.},
journal = {Tongxin Xuebao/Journal on Communications},
keywords = {Algorithms,Complex environments; Indoor positioning systems;,Error correction},
number = {2},
pages = {86--92},
title = {{Research and application of RFID location algorithm based on reference tags}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950986748{\&}partnerID=40{\&}md5=39a36998bc0be851a43df3fd9e8603fd},
volume = {31},
year = {2010}
}
@inproceedings{Wang:2015:RBI:2923299.2923390,
address = {Washington, DC, USA},
author = {Wang, Yixin and Ye, Qiang and Cheng, Jie and Wang, Lei},
booktitle = {Proceedings of the 2015 11th International Conference on Mobile Ad-hoc and Sensor Networks (MSN)},
doi = {10.1109/MSN.2015.14},
isbn = {978-1-5090-0329-7},
pages = {165--171},
publisher = {IEEE Computer Society},
series = {MSN '15},
title = {{RSSI-Based Bluetooth Indoor Localization}},
url = {http://dx.doi.org/10.1109/MSN.2015.14},
year = {2015}
}
@inproceedings{Wang:2017:WVS:3077286.3078713,
address = {New York, NY, USA},
author = {Wang, Z and Brown, T and Shan, T and Wang, F and Xue, J},
booktitle = {Proceedings of the SouthEast Conference},
doi = {10.1145/3077286.3078713},
isbn = {978-1-4503-5024-2},
keywords = {Visual Sensor Network,depth first search,heuristic,k-coverage},
pages = {145--148},
publisher = {ACM},
series = {ACM SE '17},
title = {{On 2-Angular-Coverage in Wireless Visual Sensor Network Deployment for 3D Indoor Monitoring}},
url = {http://doi.acm.org/10.1145/3077286.3078713},
year = {2017}
}
@inproceedings{Chin-DerWann:2007:HTW:2928264.2929019,
address = {Washington, DC, USA},
author = {Wann, Chin-Der and Chin, Hao-Chun},
booktitle = {Proceedings of the 2007 IEEE Wireless Communications and Networking Conference},
doi = {10.1109/WCNC.2007.720},
isbn = {1-4244-0658-7},
pages = {3940--3945},
publisher = {IEEE Computer Society},
title = {{Hybrid TOA/RSSI Wireless Location with Unconstrained Nonlinear Optimization for Indoor UWB Channels}},
url = {http://dx.doi.org/10.1109/WCNC.2007.720},
year = {2007}
}
@article{Wedge2010167,
abstract = {Developing a practical multi-camera tracking solution for autonomous camera networks is a very challenging task, due to numerous constraints such as limited memory and processing power, heterogeneous visual characteristics of objects between camera views, and limited setup time and installation knowledge for camera calibration. In this paper, we propose a unified multi-camera tracking framework, which can run online in real-time and can handle both independent field of view and common field of view cases. No camera calibration, knowledge of the relative positions of cameras, or entry and exit locations of objects is required. The memory footprint of the framework is minimised by the introduction of reusing kernels. The heterogeneous visual characteristics of objects are addressed by a novel location-based kernel matching method. The proposed framework has been evaluated using real videos captured in multiple indoor settings. The framework achieves efficient memory usage without compromising tracking accuracy. {\textcopyright} 2010 Springer-Verlag.},
annote = {cited By 0},
author = {Wedge, D and Scott, A F and Ma, Z and Vendrig, J},
doi = {10.1007/978-3-642-17691-3_16},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Calibration; Cameras; Computer vision; Video came,Camera calibration; Camera network; Camera view; D,Real time systems; Real time systems},
number = {PART 2},
pages = {167--178},
title = {{Object tracking over multiple uncalibrated cameras using visual, spatial and temporal similarities}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650878637{\&}doi=10.1007{\%}2F978-3-642-17691-3{\_}16{\&}partnerID=40{\&}md5=0ab8e29dd0702104ac08ad36efe01094},
volume = {6475 LNCS},
year = {2010}
}
@inproceedings{Wei:2015:DDR:2737095.2737118,
address = {New York, NY, USA},
author = {Wei, Bo and Varshney, Ambuj and Patwari, Neal and Hu, Wen and Voigt, Thiemo and Chou, Chun Tung},
booktitle = {Proceedings of the 14th International Conference on Information Processing in Sensor Networks},
doi = {10.1145/2737095.2737118},
isbn = {978-1-4503-3475-4},
pages = {166--177},
publisher = {ACM},
series = {IPSN '15},
title = {{dRTI: Directional Radio Tomographic Imaging}},
url = {http://doi.acm.org/10.1145/2737095.2737118},
year = {2015}
}
@inproceedings{Wei20161153,
abstract = {A Real Time Locationing System (RTLS) using phased array and active Radio Frequency Identification (RFID) technologies is presented in this paper. By electrically steering the main beam of a phased array antenna, the angle of arrival signals can be detected by each reader. With the angle information and the relative coordinator information of readers, accurate locations of tagged objects can be acquired. A practical positioning algorithm is proposed for alleviating the multipath effect caused by the indoor environments. {\textcopyright} 2016 IEEE.},
annote = {cited By 3},
author = {Wei, D and Hung, W and Wu, K.-L.},
booktitle = {2016 IEEE Antennas and Propagation Society International Symposium, APSURSI 2016 - Proceedings},
doi = {10.1109/APS.2016.7696284},
pages = {1153--1154},
title = {{A real time RFID locationing system using phased array antennas for warehouse management}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997502410{\&}doi=10.1109{\%}2FAPS.2016.7696284{\&}partnerID=40{\&}md5=1ddaeb6e5540881e4da7532d821814e2},
year = {2016}
}
@inproceedings{Wei20153920,
abstract = {Location fingerprints based indoor positioning, which uses received signal strength (RSS) from wireless access points (APs), has become a hot research topic during the last a few years. Statistical learning based technique is one of the popular and effective methods for fingerprinting localization. Unfortunately, they suffer from high computational burden and require a large number of classifiers to determine the object location. To handle this problem, axial decoupled least squares support vector machines (AD-LS-SVM) based fingerprinting localization is proposed in this paper. First, the framework of fingerprinting localization based on AD-LS-SVM is given. Then, the decoupled training and positioning process by fingerprinting samples is described in detail. The attention is focused on how to transfer the positioning problem to a multi-class classification problem, for which we adopt two popular approaches: one-against-one (OAO) and one-against-all (OAA). Experimental results show that the proposed AD-LS-SVM method has the highest location accuracy among the traditional Grid LS-SVM, Support Vector Machines (SVMs) and the popular k-nearest neighbors (k-NNs), while requires much smaller training time. {\textcopyright} 2015 Technical Committee on Control Theory, Chinese Association of Automation.},
annote = {cited By 3},
author = {Wei, Y and Wang, D and Zhou, Y},
booktitle = {Chinese Control Conference, CCC},
doi = {10.1109/ChiCC.2015.7260244},
pages = {3920--3925},
title = {{Axial decoupled LS-SVMs for indoor positioning using RSS fingerprints}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946544875{\&}doi=10.1109{\%}2FChiCC.2015.7260244{\&}partnerID=40{\&}md5=ece6dcf80259400a0315ce66ed79f750},
volume = {2015-Septe},
year = {2015}
}
@article{Wei201613,
abstract = {Indoor positioning using location fingerprints, which are received signal strength (RSS) from wireless access points (APs), has become a hot research topic during the last a few years. Traditional pattern classification based fingerprinting localization methods suffer high computational burden and require a large number of classifiers to determine the object location. To handle this problem, axial-decoupled indoor positioning based on location-fingerprints is proposed in this paper. The purpose is to reduce the decision complexity while keeping localization accuracy through computing the position on X- and Y-axis independently. First, the framework of axial-decoupled indoor positioning using location fingerprints is given. Then, the training and decision process of the proposed axial-decoupled indoor positioning is described in detail. Finally, pattern classifiers including the least squares support vector machine (LS-SVM), support vector machine (SVM) and traditional k-nearest neighbors (K-NN) are adopted and embedded in the proposed framework. Experimental results illustrate the effectiveness of the proposed axial-decoupled positioning method. {\textcopyright} Springer Nature Singapore Pte Ltd. 2016.},
annote = {cited By 0},
author = {Wei, Y and Zhou, Y and Wang, D and Wang, X},
doi = {10.1007/978-981-10-3002-4_2},
journal = {Communications in Computer and Information Science},
keywords = {Axial-decoupled; Computational burden; Indoor pos,Indoor positioning systems; Location; Mobile compu,Pattern recognition},
pages = {13--26},
title = {{Axial-decoupled indoor positioning based on location fingerprints}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994759907{\&}doi=10.1007{\%}2F978-981-10-3002-4{\_}2{\&}partnerID=40{\&}md5=4033ba3bcec4a3672b26b46e7dc901bf},
volume = {662},
year = {2016}
}
@inproceedings{Wei2017,
abstract = {Accurate orientation information is the key in many applications, ranging from map reconstruction with crowdsourcing data, location data analytics, to accurate indoor localization. Many existing solutions rely on noisy magnetic and inertial sensor data, leading to limited accuracy, while others leverage multiple, dense anchor points to improve the accuracy, requiring significant deployment efforts. This paper presents LiCompass, the first system that enables a commodity camera to accurately estimate the object orientation using just a single optical anchor. Our key idea is to allow a camera to observe varying intensity level of polarized light when it is in different orientations and, hence, perform estimation directly from image pixel intensity. As the estimation relies only on pixel intensity, instead of the location of the anchor in an image, the system performs reliably at long distance, with low resolution images, and with large perspective distortion. LiCompass' core designs include an elaborate optical anchor design and a series of signal processing techniques based on trigonometric properties, which extend the range of orientation estimation to full 360 degrees. Our prototype evaluation shows that LiCompass produces very accurate estimates with median errors of merely 2.5 degrees at 5 meters and 7.4 degrees at 2.5 meters with an irradiance angle of 55 degrees. {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Wei, Y.-L. and Wu, H.-I. and Wang, H.-C. and Tsai, H.-M. and Lin, K.C.-J. and Boubezari, R and {Le Minh}, H and Ghassemlooy, Z},
booktitle = {Proceedings - IEEE INFOCOM},
doi = {10.1109/INFOCOM.2017.8057100},
keywords = {Cameras; Light polarization; Pixels,Image pixel intensities; Indoor localization; Low,Signal processing},
title = {{LiCompass: Extracting orientation from polarized light}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034017412{\&}doi=10.1109{\%}2FINFOCOM.2017.8057100{\&}partnerID=40{\&}md5=42289c4a88f2acf5368fd3b0378bfb9d},
year = {2017}
}
@inproceedings{Westell20102088,
abstract = {This paper presents a system for object recognition and localization within unknown indoor environments. The system includes a GUI design through which the user may describe an object of interest by means of color, size, and shape. A novel coarse to fine identification mechanism that incorporates multiple views of an object is then used to locate the described object within an unknown environment. The system includes a training stage in which representative information is extracted from database images. A stereo vision system, mounted on an indoor robot platform (Fig. 1), is used to retrieve the 3D location of potential match candidates in the scene and to inspect possible matches from three distinct viewpoints. Experimental evaluation is performed for indoor environments and promising results are shown for the application of this system. {\textcopyright}2010 IEEE.},
annote = {cited By 0},
author = {Westell, J and Saeedi, P},
booktitle = {11th International Conference on Control, Automation, Robotics and Vision, ICARCV 2010},
doi = {10.1109/ICARCV.2010.5707215},
keywords = {3d object recognition; Coarse to fine; Database im,Computer vision; Object recognition; Robotics; Ro,Stereo vision},
pages = {2088--2095},
title = {{3D object recognition via multi-view inspection in unknown environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952418823{\&}doi=10.1109{\%}2FICARCV.2010.5707215{\&}partnerID=40{\&}md5=a211a6859f0cc6ee317ea800d6218522},
year = {2010}
}
@proceedings{Winter:2010:1865885,
address = {New York, NY, USA},
author = {Winter, Stephan and Jensen, Christian S and Li, Ki-Joune},
isbn = {978-1-4503-0433-7/10/11},
pages = {vi+53},
publisher = {ACM},
title = {{Proceedings of the 2nd ACM SIGSPATIAL International Workshop on Indoor Spatial Awareness}},
year = {2010}
}
@article{Wisitpongphan201383,
abstract = {Technology defined by ZigBee standard is intended for a wide range of ad hoc wireless sensor network (WSN) applications. Among which is the location-aware services which can be applied to both indoor and outdoor environments for locating expensive equipments or tracking any moving objects. While there are many existing localization algorithms, the fingerprint technique which relies on determining target location from an off-line empirical database seems to be the most practical indoor solution using off-the-shelf products. In this work, we present a wireless sensor network planning solution suitable for indoor localization using fingerprint technique. Based on our extensive feasibility studies, we derived several network planning solutions which answer some of the key wireless sensor network design questions such as (1) where to put the router or anchor nodes?, (2) how many routers should we use in designing location-aware WSN?, (3) how often should the end-device node transmit data to the server?, (4) what should be a suitable packet size?, and (5) does mobility have any impact on the network performance? {\textcopyright} 2013 Springer-Verlag.},
annote = {cited By 1},
author = {Wisitpongphan, N},
doi = {10.1007/978-3-642-37371-8_12},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Information technology; Network performance; Route,Zigbee,ad hoc; Ad hoc wireless sensor networks; fingerpr},
pages = {83--92},
title = {{Wireless sensor network planning for fingerprint based indoor localization using ZigBee: Empirical study}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876259628{\&}doi=10.1007{\%}2F978-3-642-37371-8{\_}12{\&}partnerID=40{\&}md5=592b82d949d858c5fbbca8375398cc99},
volume = {209 AISC},
year = {2013}
}
@techreport{Wixson:1994:GSV:898263,
address = {Rochester, NY, USA},
author = {Wixson, Lambert E},
publisher = {University of Rochester},
title = {{Gaze Selection for Visual Search}},
year = {1994}
}
@article{Woo2013753,
abstract = {To support daily life before performing an action, a robot partner must perceive an unknown environment. Much research has been done from various viewpoints on self-localization estimation and environment perception. In our research, the robot partner performs self-localization and environment recognition using Simultaneous Localization and Mapping for self-localization estimation and map building. In this paper, we propose a method for recognizing indoor environments by robot partners based on conversations with human beings. Information acquired from maps is identified in order to share the meaning with human beings after the required interpretation. In this paper, we therefore propose a method for recognizing environmental maps by labeling these maps based on symbolic information developed through conversation with human beings. The proposed method is composed of four parts. First, the robot partner applies a steady-state genetic algorithm for self-localization estimation. Second, we use a map building algorithm for expressing the topological map. Third, conversation with human beings is performed for acquiring symbolic information in order to recognize object and position locations through the map. Fourth, we perform experiments and discuss the effectiveness of the proposed technique.},
annote = {cited By 5},
author = {Woo, J and Kubota, N},
journal = {Journal of Advanced Computational Intelligence and Intelligent Informatics},
keywords = {Environment perceptions; Environment recognition;,Estimation; Genetic algorithms; Neural networks,Robots},
number = {5},
pages = {753--760},
title = {{Recognition of indoor environment by robot partner using conversation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884736027{\&}partnerID=40{\&}md5=25333611810cab21dfc1a993c7b40216},
volume = {17},
year = {2013}
}
@article{Wu:2010:ELT:1671962.1671964,
address = {New York, NY, USA},
author = {Wu, Junwen and Trivedi, Mohan M},
doi = {10.1145/1671962.1671964},
issn = {1551-6857},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
keywords = {Eye blink detection,human computer interface,particle filtering,video processing},
number = {2},
pages = {8:1----8:23},
publisher = {ACM},
title = {{An Eye Localization, Tracking and Blink Pattern Recognition System: Algorithm and Evaluation}},
url = {http://doi.acm.org/10.1145/1671962.1671964},
volume = {6},
year = {2010}
}
@article{Wu2015187,
abstract = {Indoor positioning with smartphones is of great importance for a lot of applications and has attracted many researchers' interests these years. Received Signal Strength (RSS) fingerprinting has been considered as an efficient method for indoor positioning. Numerous systems have been developed based on it. Location fingerprint sampling is the first step of the RSS fingerprinting method. Slow sampling speed will delay the positioning speed and will reduce the accuracy if the tracking object is moving. Theoretically, the sampling period is about one fingerprint per second. However, our experiments on some Android phones/pads show that it may even take more than 10 s to sample a fingerprint occasionally. By analyzing the Android WiFi scanning framework, it is easy to find which part of the fingerprint sampling process costs more time. After theoretically analysis and experimental measurement, we provide some suggestions on how to improve sampling speed on some practical WiFi positioning system architectures. To contribute to the research community of WiFi positioning, we make all our measurement codes and our data sets available as open source. {\textcopyright} Springer-Verlag Berlin Heidelberg 2015.},
annote = {cited By 0},
author = {Wu, Q and Lin, H and Liang, J},
doi = {10.1007/978-3-662-46981-1_18},
journal = {Communications in Computer and Information Science},
keywords = {Android (operating system); Indoor positioning sys,Android; Experimental analysis; Fingerprinting me,Mobile computing},
pages = {187--197},
title = {{Theoretical and experimental analysis of WiFi location fingerprint sampling period}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948397509{\&}doi=10.1007{\%}2F978-3-662-46981-1{\_}18{\&}partnerID=40{\&}md5=e7d752756f620c940ff04f2f0e9fa719},
volume = {501},
year = {2015}
}
@inproceedings{Wu2009,
abstract = {Virtual-real registration in Outdoor Augmented Reality is committed to enhance user's spatial cognition by overlaying virtual geographical objects on real scene. According to analyze fiducial detection registration method in indoor AR, for the purpose of avoiding complex and tedious process of position tracking and camera calibration in traditional registration methods, it puts forward and practices a virtual-real spatial information visualization registration method using affine representations. Based on the observation from Koenderink and van Doorn, Ullman and Basri in 1991 which is given a set of four or more non-coplanar 3D points, the projection of all points in the set can be computed as a linear combination of the projection of just four of the points, it sets up global affine coordinate system in light of world coordinates, camera coordinates and virtual coordinates and extracts four feature points from scene image and calculates the global affine coordinates of key points of virtual objects. Then according to a linear homogeneous coordinates of the four feature point's projection, it calculates projection pixel coordinates of key points of virtual objects. In addition, it proposes an approach to obtain pixel relative depth for hidden surface removal. Finally, by a case study, it verifies the feasibility and efficiency of the registration methods. The method would not only explore a new research direction for Geographical Information Science, but also would provide location-based information and services for outdoor AR. {\textcopyright} 2009 SPIE.},
annote = {cited By 0},
author = {Wu, X and Fu, R and Du, Q},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.837441},
keywords = {Affine coordinates; Camera calibration; Feature po,Augmented reality; Cameras; Image registration; I,Information use},
title = {{Virtual-real spatial information visualization registration using affine representations}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449659947{\&}doi=10.1117{\%}2F12.837441{\&}partnerID=40{\&}md5=b1d02a548a3788471b5d1bb62c4d130d},
volume = {7492},
year = {2009}
}
@article{Xiang2015641,
abstract = {Location-fingerprint based indoor localization has the advantage of being applicable in non-line-of-sight (NLOS) environment. However, it requires large-scale fingerprinting samples, which is difficult to calibrate manually. Existing semi-supervised learning (SSL) method for indoor localization is prohibitively slow and unsuitable for real-life large-scale fingerprinting calibration. To alleviate this problem, a scalable SSL (3SL) technique is proposed in this paper for building accurate fingerprinting from a small portion of labeled samples. From the perspective of compressed sensing, randomly selected landmark samples enable nonparametric regression that predicts the labels for each fingerprint as a locally weighted average of the labels on these landmarks. Then the object localization problem can be solved with high accuracy based on all calibrated samples. Finally, experiment results are included to demonstrate that the proposed 3SL method scales linearly with the data size. Compared with the existing LRSML method, it requires much smaller computational burden while having similar (if not better) location accuracy. {\textcopyright} 2015 International Information Institute.},
annote = {cited By 3},
author = {Xiang, L and Wang, D and Wei, Y and Zhou, Y},
journal = {Information (Japan)},
number = {2},
pages = {641--652},
title = {{Location-fingerprint based indoor localization via scalable semi-supervised learning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925386494{\&}partnerID=40{\&}md5=804b27833f6fc43a74a85f6f9d93784a},
volume = {18},
year = {2015}
}
@inproceedings{8559754,
abstract = {Large indoor spaces with wide field of vision and stable light (such as museums, malls and airports) provide a suitable scene for visual positioning. Static objects interior of these sites can be served as positioning references. Besides, increasingly powerful smartphones provide more strong computing support for visual methods. Therefore, this paper designed a visual positioning method integration with computer vision and deep learning algorithms. By using smartphone cameras, it detects static objects in large indoor spaces and calculate smartphones' position. Experiment in an art museum with complicated visual environment suggests that this method is able to achieve positioning accuracy within 1 meter.},
author = {Xiao, A and Chen, R and Wu, D and Chen, Y},
booktitle = {2018 Ubiquitous Positioning, Indoor Navigation and Location-Based Services (UPINLBS)},
doi = {10.1109/UPINLBS.2018.8559754},
keywords = {cameras;computer vision;learning (artificial intel},
pages = {1--7},
title = {{Positioning in Large Indoor Spaces using Smartphone Camera based on Static Objects}},
year = {2018}
}
@inproceedings{Xiao2012,
abstract = {WLAN-based indoor location fingerprinting has been attractive owing to the advantages of open access and high accuracy. Most fingerprinting-based systems so far rely on the received signal strength (RSS), which can be easily measured at the receiver with commercial WLAN equipment. However, RSS is a coarse value which simply measures the received power for a whole channel. Thus, it fluctuates over time in typical indoor environments with rich multipath effects and not unique for a specific location. In this paper, we present the design, implementation, and evaluation of a Fine-grained Indoor Fingerprinting System (FIFS). FIFS explores a PHYlayer Channel State Information (CSI) that specifies the channel status over all the subcarriers for location fingerprinting in WLAN. The system leverages the CSI values including different amplitudes and phases at multiple propagation paths, known as the frequency diversity, to uniquely manifest a location. Moreover, the multiple antennas provides the spatial diversity that can be further augmented in fingerprinting. We also present a coherence bandwidth-enhanced probability algorithm with a correlation filter to map object to the fingerprints. We conducted experiments in two typical indoor scenarios with commercial IEEE 802.11 NICs. The experimental results demonstrate that the overall positioning accuracy can be improved compared with the RSS-based Horus system. {\textcopyright} 2012 IEEE.},
annote = {cited By 92},
author = {Xiao, J and Wu, K and Yi, Y and Ni, L M},
booktitle = {2012 21st International Conference on Computer Communications and Networks, ICCCN 2012 - Proceedings},
doi = {10.1109/ICCCN.2012.6289200},
keywords = {Channel state information,Correlation filters; Frequency diversity; IEEE 802,Local area networks; RSS; Standards},
title = {{FIFS: Fine-grained indoor fingerprinting system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867817079{\&}doi=10.1109{\%}2FICCCN.2012.6289200{\&}partnerID=40{\&}md5=ff1b35f6b257dac042eb4c9db0d50e61},
year = {2012}
}
@article{Xiao2010118,
abstract = {Location-aware computing is important in pervasive computing and intelligent video surveillance. We propose a two-stage multimodal approach to locate the active speaker in intelligent environments. Firstly, human voice is captured as audio cue to find the approximate orientation of current speaker. Secondly, the colour feature of mouth region is extracted as visual cue to detect continuous mouth motion that identifies the active speaker. The speaking recognition is conducted by a well-trained Hidden Markov Model based on colour feature of mouth region during continuous motion. Experiments show that the proposed multimodal approach is effective for speaker localisation in intelligent indoor environments. Copyright {\textcopyright} 2010 Inderscience Enterprises Ltd.},
annote = {cited By 1},
author = {Xiao, R.-G. and Guo, T.-Q.},
doi = {10.1504/IJCAT.2010.034147},
journal = {International Journal of Computer Applications in Technology},
keywords = {Continuous motions; HMM; Human voice; Indoor envir,Hidden Markov models; Object recognition; Securit,Ubiquitous computing},
number = {1-3},
pages = {118--123},
title = {{A two-stage multimodal speaker location-aware approach in pervasive computing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955782619{\&}doi=10.1504{\%}2FIJCAT.2010.034147{\&}partnerID=40{\&}md5=793bb215a10447bd95fa526afce0c323},
volume = {38},
year = {2010}
}
@article{Xiao2018,
abstract = {Along with the penetration of smart devices and mobile applications in our daily life, how to effectively manage the mobility issues in wireless networks becomes a challenging task. The ability to continuously and accurately track the target object's position plays a vital role in mobility management. In this paper, we propose a novel indoor localization algorithm that fuses multiple signal features as the location fingerprints. The rationale that motivates our algorithm design stems from the following observation: although using one special signal feature (e.g., channel state information (CSI)) might achieve statistically higher accuracy than using another signal feature (e.g., received signal strength (RSS)), the accuracy for individual position estimations is usually diversified when only one signal feature is used in localization. For example, using RSS can obtain more accurate location estimation than using CSI for some individual positions. Thus, we propose a novel indoor localization algorithm that fuses multiple types of signal features as fingerprint of positions, which can effectively improve localization accuracy. We designed several fusion schemes and evaluated their performance. Experiments show that our algorithm achieves localization error below 0.5m and 1.1m in two typical indoor environments, about 30{\%} lower than the accuracy of algorithms by fusing multiple signal features. {\textcopyright} 2018 Yalong Xiao et al.},
annote = {cited By 3},
author = {Xiao, Y and Zhang, S and Wang, J and Zhu, C},
doi = {10.1155/2018/9517942},
journal = {Wireless Communications and Mobile Computing},
keywords = {Channel state information; Communication channels,Indoor localization; Localization accuracy; Local,Indoor positioning systems},
title = {{A Novel Indoor Localization Algorithm for Efficient Mobility Management in Wireless Networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049209097{\&}doi=10.1155{\%}2F2018{\%}2F9517942{\&}partnerID=40{\&}md5=58520d334cd1aff75219336dd67c3c77},
volume = {2018},
year = {2018}
}
@article{Xiao20171918,
abstract = {The position information of mobile users becomes the internal motivation to many locations based applications, such as indoor navigation, travel application and mobile advertising service. Fingerprinting-based indoor localization has been a hot topic in localization research in recent years due to its high accuracy, low complexity and low cost. This method, however, requires collecting a large number of reference point information in the offline training phase, which greatly limits its application in large environments. This paper proposes a new indoor localization algorithm based on multidimensional scaling (MDS), which utilizes the distance between two points' received signal strength vectors to approximately measure their distance in physical environment, and then calculates the target object's location with the distance constraints with MDS. We further propose a region refinement method to improve the localization accuracy, in which only reference points contained in a small rectangle that contains the estimated position of the target object are used to calculate the target's location. Experiment results in two real environments and large scale simulations demonstrate the usefulness of our approach. The results show that, compared with the Horus algorithm, the proposed algorithm can achieve similar or even higher accuracy and reduce the number of required reference points by almost one order of magnitude. The effectiveness of the proposed algorithm is validated via large-scale simulation. {\textcopyright} 2017, Science Press. All right reserved.},
annote = {cited By 1},
author = {Xiao, Y.-L. and Zhang, S.-G. and Wang, J.-X.},
doi = {10.11897/SP.J.1016.2017.01918},
journal = {Jisuanji Xuebao/Chinese Journal of Computers},
keywords = {Cyber Physical System; Embedded systems; Internet,Fingerprinting localization; Indoor localization;,Indoor positioning systems},
number = {8},
pages = {1918--1932},
title = {{An Indoor Localization Algorithm Based on Multidimensional Scaling and Region Refinement}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031395432{\&}doi=10.11897{\%}2FSP.J.1016.2017.01918{\&}partnerID=40{\&}md5=b6bc26b6230aacf9b4305b0becdf04ab},
volume = {40},
year = {2017}
}
@article{Xiao2012,
abstract = {A method is proposed to estimate illumination direction from cast shadows in images of outdoor scenes. First, shadow areas in the foreground are separated using a shadow detection method, and the brightness rate (BR), which is independent of reflection properties of the material but dependent on illumination intensity onto the material, is computed in shadow areas. A BR line is fitted onto the points that have minimal BR values. Second, based on the property that illumination intensity at the points in a cast shadow area varies depending on their locations, illumination direction is estimated by modeling the height of the object, incident rays from the source of the illumination, and the BR line. Finally, experiments with known illumination direction in indoor scenes, experiments in outdoor scenes, and comparative analyses are carried out. The results show that our method enables illumination direction to be estimated accurately and efficiently, without complicated image segmentation.},
annote = {cited By 1},
author = {Xiao, Z and Li, S and Li, R},
journal = {Jisuanji Fuzhu Sheji Yu Tuxingxue Xuebao/Journal of Computer-Aided Design and Computer Graphics},
keywords = {Cast shadow; Comparative analysis; Estimating illu,Estimation,Experiments; Image segmentation; Luminance},
number = {11},
pages = {1471--1476+1484},
title = {{Estimating illumination direction from cast shadow in outdoor scenes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870763755{\&}partnerID=40{\&}md5=375d4624f21f2860e9125378675848d8},
volume = {24},
year = {2012}
}
@inproceedings{Xie2016274,
abstract = {Indoor localization is of importance for many applications. Crowdsourcing individual users' measurements can provide accurate localization without costly site-survey. However, crowdsourcing based approaches suffer from the cold start problem, in which at the beginning of system deployment, there are insufficient users to contribute their measurements, resulting in inaccurate and time-inefficient localization. In this paper, we propose a hybrid indoor localization method to solve such problem, called ACIL. We first employ the inertial navigation technique to localize some core positions or paths. To tackle the inaccuracy problem, we propose an effective method that utilizes the channel state information (CSI) of wireless signals for accurate distance estimation. This method is based on a new observation: there is a ripple-like fading pattern in wireless signals upon moving objects. Leveraging this observation, our system is capable of calculating the distance of human's movement and his/her direction. We also propose a graph-matching algorithm to setup the correlation between the trajectory and floor map. With those extra obtained location information, the impact of cold start issue will be significantly mitigated, while the LBS can be guaranteed with high localization accuracy. Extensive experiments show that the effectiveness in the human localization and movement detection. Extensive experiments validate the great performance of our protocol in case of various human locations and diverse channel conditions. {\textcopyright} 2015 IEEE.},
annote = {cited By 4},
author = {Xie, H and Lin, L and Jiang, Z and Xi, W and Zhao, K and Ding, M and Zhao, J},
booktitle = {Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS},
doi = {10.1109/ICPADS.2015.42},
keywords = {Algorithms; Channel state information; Crowdsourci,Fingerprinting; Graph-matching algorithms; Human,Indoor positioning systems},
pages = {274--281},
title = {{Accelerating crowdsourcing based indoor localization using CSI}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964645139{\&}doi=10.1109{\%}2FICPADS.2015.42{\&}partnerID=40{\&}md5=5df99141238ebbea8cdb77f81e721a90},
volume = {2016-Janua},
year = {2016}
}
@inproceedings{Xie2013434,
abstract = {Indoor spaces accommodate large parts of people's life. The increasing availability of indoor positioning, driven by technologies like Wi-Fi, RFID, and Bluetooth, enables a variety of indoor location-based services (LBSs). Efficient indoor distance-aware queries on indoor moving objects play an important role in supporting and boosting such LBSs. However, the distance-aware query evaluation on indoor moving objects is challenging because: (1) indoor spaces are characterized by many special entities and thus render distance calculation very complex; (2) the limitations of indoor positioning technologies create inherent uncertainties in indoor moving objects data. In this paper, we propose a complete set of techniques for efficient distance-aware queries on indoor moving objects. We define and categorize the indoor distances in relation to indoor uncertain objects, and derive different distance bounds that can facilitate query evaluation. Existing works often assume indoor floor plans are static, and require extensive pre-computation on indoor topologies. In contrast, we design a composite index scheme that integrates indoor geometries, indoor topologies, as well as indoor uncertain objects, and thus supports indoor distance-aware queries efficiently without time-consuming and volatile distance computation. We design algorithms for range query and k nearest neighbor query on indoor moving objects. The results of extensive experimental studies demonstrate that our proposals are efficient and scalable in evaluating distance-aware queries over indoor moving objects. {\textcopyright} 2013 IEEE.},
annote = {cited By 22},
author = {Xie, X and Lu, H and Pedersen, T B},
booktitle = {Proceedings - International Conference on Data Engineering},
doi = {10.1109/ICDE.2013.6544845},
keywords = {Distance calculation; Distance computation; Experi,Location based services,Topology},
pages = {434--445},
title = {{Efficient distance-aware query evaluation on indoor moving objects}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881351001{\&}doi=10.1109{\%}2FICDE.2013.6544845{\&}partnerID=40{\&}md5=98308ed542fbba10a4d16cf952bf285c},
year = {2013}
}
@inproceedings{Xiong:2017:DGL:3298023.3298126,
author = {Xiong, Hao and Tao, Dacheng},
booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
pages = {3841--3847},
publisher = {AAAI Press},
series = {AAAI'17},
title = {{A Diversified Generative Latent Variable Model for WiFi-SLAM}},
url = {http://dl.acm.org/citation.cfm?id=3298023.3298126},
year = {2017}
}
@inproceedings{Xu:2013:SID:2461381.2461394,
address = {New York, NY, USA},
author = {Xu, Chenren and Firner, Bernhard and Moore, Robert S and Zhang, Yanyong and Trappe, Wade and Howard, Richard and Zhang, Feixiong and An, Ning},
booktitle = {Proceedings of the 12th International Conference on Information Processing in Sensor Networks},
doi = {10.1145/2461381.2461394},
isbn = {978-1-4503-1959-1},
keywords = {counting,device-free localization,fingerprint,multiple subjects,nonlinear fading,tracking,trajectory},
pages = {79--90},
publisher = {ACM},
series = {IPSN '13},
title = {{SCPL: Indoor Device-free Multi-subject Counting and Localization Using Radio Signal Strength}},
url = {http://doi.acm.org/10.1145/2461381.2461394},
year = {2013}
}
@article{Xu2015273,
abstract = {With the increasing development of indoor positioning technologies such as Wifi and RFID, indoor location based services (LBSs) has been a hot topic in recent years. Differing from GPS-based outdoor LBSs, we lack sufficient indoor maps which are the foundation of indoor LBSs. In this paper, we present a database approach to extract indoor spatial objects, e.g., rooms and doors, from CAD models, and then transform them into an indoor moving-object database. With this mechanism, we are able to efficiently generate indoor maps and support indoor-space queries. In addition, we implement a prototype system to demonstrate the feasibility of our proposal. It shows that our approach has a high precision on extracting indoor spatial objects and can support indoor spatial queries effectively. {\textcopyright} Springer International Publishing Switzerland 2015.},
annote = {cited By 3},
author = {Xu, D and Jin, P and Zhang, X and Du, J and Yue, L},
doi = {10.1007/978-3-319-22324-7_27},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Big data; Computer aided design; Extraction; Index,CAD modeling; Database approaches; Indoor locatio,Database systems},
pages = {273--279},
title = {{Extracting indoor spatial objects from CAD models: A database approach}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949940405{\&}doi=10.1007{\%}2F978-3-319-22324-7{\_}27{\&}partnerID=40{\&}md5=a21fbd6f670a64ff97755cee9a20828d},
volume = {9052},
year = {2015}
}
@inproceedings{Xu20171269,
abstract = {A novel indoor localization concept is introduced in this study. The navigating user takes an image inside a building to determine its own position. In the first step, this image is passed to a trained R-CNN that recognizes and localizes various types of objects in the image, such as doors, windows, signs, trash bins. Typically, the R-CNN output is a set of boxes representing the regions of the objects in the image, and their classification scores. The spatial relationships of these objects can be derived based on the box locations in the image and they can be represented as a directed graph, where the directions of the edges are the relationships, e.g., right-left, up-down. This graph is called image graph. The next step of the localization requires prior knowledge, basically the building model, obtained by blueprint or surveying, as the location of the used objects must be known. Assuming fixed positions, a graph can be derived similar to the image graph, but it is generated based on the building map. This graph is called position graph. Each unique position inside the building has its own position graph. Finally, the user location is obtained by measuring the similarity between the image graph and the stored position graphs. To prove the concept, a test was conducted in a typical yet challenging building. Images of selected objects were taken at randomly chosen locations around the test area. Correct solution was found in the 40.5{\%} of the cases with 5-10 m accuracy; the failure rate was 14.3{\%}; the rest 45.2{\%} produced multiple solutions. Note that the system is fail-safe at 85.7{\%}. The concept also allows deriving the direction of the image; the results suggest a 45-60 accuracy. {\textcopyright} 2017, Institute of Navigation. All rights reserved.},
annote = {cited By 1},
author = {Xu, H and Koppanyi, Z and Toth, C K and Brzezinska, D},
booktitle = {Proceedings of the 2017 International Technical Meeting of The Institute of Navigation, ITM 2017},
keywords = {Building model; Convolutional neural network; Cor,Buildings; Failure analysis; Indoor positioning sy,Directed graphs},
pages = {1269--1279},
title = {{Indoor localization using region-based convolutional neural network}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018261574{\&}partnerID=40{\&}md5=85bf0c763d89d0363a425097853ca8ed},
year = {2017}
}
@article{Xu:2017:ILU:3119382.3119388,
address = {Hershey, PA, USA},
author = {Xu, He and Ding, Ye and Li, Peng and Wang, Ruchuan},
doi = {10.4018/ijbdcn.2017070106},
issn = {1548-0631},
journal = {Int. J. Bus. Data Commun. Netw.},
keywords = {Indoor Position,Phase,RFID,Reference Tags},
number = {2},
pages = {69--82},
publisher = {IGI Global},
title = {{Indoor Localization Using the Reference Tags and Phase of Passive UHF-RFID Tags}},
url = {https://doi.org/10.4018/ijbdcn.2017070106},
volume = {13},
year = {2017}
}
@inproceedings{Xu20141646,
abstract = {Compare with outdoor positioning, indoor positioning has been overlooked by many investigators. While GNSS can be made to work indoors, the lower signal levels and poor multipath environment mean that performance is much worse than outdoors, and in some places there is no coverage at all. Indoor GNSS and cell-phone bearer positioning will be in general use for emergency calls from mobiles (E911/E112), but with an accuracy close to 100 m (which is sufficient for this particular service). In contrast to the GPS, the DTV signals are received from transmitters at relatively short distance, while the broadcast transmitters operate at levels up to the megawatts effective radiated power (ERP). Also the RF frequency of the DTV signal is much lower than the GPS, which makes it easier for the signal to penetrate buildings and other objects. So it is suitable for the precision positioning inside the building and the city center. The digital television terrestrial broadcasting (DTMB) is one of important standard about DTV, which is regulated by the national standard GB2006-20600. DTMB transmission system using time domain synchronous orthogonal frequency division multiplexing (TDS innovation OFDM) of single and multicarrier modulation. This modulation mainly for broadband transmission channel characteristics of terrestrial digital multimedia television broadcasting can achieve good performance in linear time-varying transmitter channel or frequency selective and time selective exist at the same time channel. Pseudorandom sequence (PN) is introduced in DTMB signal frame header, DTMB signal has more stronger correlation than other DTV standards. So DTMB is more suitable for precise indoor positioning. Integration of DTMB with GNSS can provide a seamless transition from outdoor to indoor position and vice-versa. The ranging accuracy expected from DTMB systems is expected to be better than 1m in severe multipath environments. The paper describes the concept of using the DTMB signal for indoor positioning and how it is proposed to ensure seamless operation with GNSS and crucial techniques of positioning system based on digital television terrestrial broadcasting is researched. Firstly, it proposal one acquisition and tracking method based on DTMB digital TV signal and the infrastructure of indoor positioning system based on DTMB is given. The operating principle of the indoor positioning system is very similar to that of a GNSS. Fixed terminals transmit accurately timed signals, along with information about the terminal's location and the transmission time. The handset has both GNSS and indoor DTMB receiving terminals, and uses either or both so that the positioning service is seamless. Secondly, it analyzes the DTMB system structure and signal frame structure, and takes an example as PN420 mode to research the relationship of signal frame head original function. PN sequence in DTMB signals should be used for position location and multipath estimation under some circumstances. However, large position location error may be introduced when there is co-channel interference in the DTMB signal. In the presence of co-channel interference, multipath estimation is actually the linear combination of the multipath channel responses from all the DTMB transmitters on the same channel, since an identical PN sequence is used for all co-channel DTMB transmitters. Thirdly, the receiver design in baseband is fulfilled by analyzing the operation principle of receiver and validated on Xilinx Virtex-5 FPGA. Some key receiver techniques in baseband includes the digital filtering signal tracking, carrier tracking and code tracking, FIR filter and raise cosine filter is investigated. Based on some advantages of Field Programmable Gate Array (FPGA), Implementation of the receiver in baseband is used on FPGA hardware platform. Finally, the positioning result combined with the GNSS and the DTMB signal is achieved. The result is shown that the positioning combined with satellite navigation signal and the DTMB signal is precise in the complex city environments. It provides that combined positioning system with GNSS and digital television terrestrial broadcasting signal is realizable in complex circumstance of city. Copyright {\textcopyright} (2014) by the Institute of Navigation All rights reserved.},
annote = {cited By 1},
author = {Xu, J and Lu, X and Wu, H and Zou, D},
booktitle = {27th International Technical Meeting of the Satellite Division of the Institute of Navigation, ION GNSS 2014},
keywords = {Broadband transmission; Digital television terres,Broadcasting; Cellular telephone systems; Cochanne,Global positioning system},
pages = {1646--1651},
title = {{Seamless indoor/outdoor positioning using digital television terrestrial broadcasting (DTMB) Technology integrated with GNSS}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939440842{\&}partnerID=40{\&}md5=86cc34c546c57c8df8e314903e2be23d},
volume = {2},
year = {2014}
}
@inproceedings{Xu2016339,
abstract = {The demand for indoor navigation is increasingly urgent in many applications such as safe management of underground spaces or location services in complex indoor environment, e.g. shopping centres, airports, museums, underground parking lot and hospitals. Indoor navigation is still a challenging research field, as currently applied indoor navigation algorithms commonly ignore important environmental and human factors and therefore do not provide precise navigation. Flexible and detailed networks representing the connectivity of spaces and considering indoor objects such as furniture are very important to a precise navigation. In this paper we concentrate on indoor navigation considering obstacles represented as polygons. We introduce a specific space subdivision based on a simplified floor plan to build the indoor navigation network. The experiments demonstrate that we are able to navigate around the obstacles using the proposed network. Considering to well-known path-finding approaches based on Medial Axis Transform (MAT) or Visibility Graph (VG), the approach in this paper provides a quick subdivision of space and routes, which are compatible with the results of VG.},
annote = {cited By 5},
author = {Xu, M and Wei, S and Zlatanova, S},
booktitle = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
doi = {10.5194/isprsarchives-XLI-B4-339-2016},
keywords = {2D Plan; In-door navigations; Obstacles; Shortest,Air navigation; Complex networks; Graph theory; Na,Indoor positioning systems},
pages = {339--346},
title = {{An indoor navigation approach considering obstacles and space subdivision of 2D plan}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978129667{\&}doi=10.5194{\%}2Fisprsarchives-XLI-B4-339-2016{\&}partnerID=40{\&}md5=a20d6f6a7db73a32401a3fbb30cc5fa8},
volume = {41},
year = {2016}
}
@inproceedings{Xu201351,
abstract = {3D models are more powerful than 2D maps for indoor navigation in a complicate space like Hubei Provincial Museum because they can provide accurate descriptions of locations of indoor objects (e.g., doors, windows, tables) and context information of these objects. In addition, the 3D model is the preferred navigation environment by the user according to the survey. Therefore a 3D model based indoor navigation system is developed for Hubei Provincial Museum to guide the visitors of museum. The system consists of three layers: application, web service and navigation, which is built to support localization, navigation and visualization functions of the system. There are three main strengths of this system: it stores all data needed in one database and processes most calculations on the webserver which make the mobile client very lightweight, the network used for navigation is extracted semi-automatically and renewable, the graphic user interface (GUI), which is based on a game engine, has high performance of visualizing 3D model on a mobile display.},
annote = {cited By 5},
author = {Xu, W and Kruminaite, M and Onrust, B and Liu, H and Xiong, Q and Zlatanova, S},
booktitle = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
doi = {10.5194/isprsarchives-XL-4-W4-51-2013},
keywords = {Applications; Database systems; Graphical user int,Context information; Graphic user interface (GUI),Indoor positioning systems},
number = {4W4},
pages = {51--55},
title = {{A 3D model based indoor navigation system for Hubei provincial museum}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924258041{\&}doi=10.5194{\%}2Fisprsarchives-XL-4-W4-51-2013{\&}partnerID=40{\&}md5=c0425778398c7ef01c25584b59638f02},
volume = {40},
year = {2013}
}
@inproceedings{7737904,
abstract = {In the web of things (WOT) paradigm, it is possible for users to have access to a big amount of connected objects to fulfil their requests. However, finding the right object is a difficult task as the search should take into account not only the functionalities of the objects but also their physical localisation and their distance from the user. In this paper, a new approach to build a WOT search engine is introduced. A new semantic similarity is proposed to compare objects in ontology. To answer a user's request, the proposed model recommends objects according to both their geo-localisation and capabilities. Moreover, the search of objects takes into account the user's profile and expectations. The solution we proposed relies on fuzzy rule engines and a formal location model that characterise the search space in which relevant connected objects are selected.},
author = {Xu, W and Marsala, C},
booktitle = {2016 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)},
doi = {10.1109/FUZZ-IEEE.2016.7737904},
keywords = {information retrieval;Internet of Things;ontologie},
pages = {1768--1775},
title = {{Personalized search in smart indoor environments: Combining a formal location model, user preferences and semantic similarity}},
year = {2016}
}
@inproceedings{Xu2010112,
abstract = {In this paper, anisotropic scale space is introduced to SIFT method. The method will detect stable elliptical Gaussian blob features of different orientations. Additional feature parameters can be utilized to match features with high probability. New salient features are detected by convolving image with elliptical Gaussian instead circular one. The elliptical Gaussian pyramid is carefully constructed so as to balance elliptical coverage and computational complexity. The new method is tested with both images and videos, which range from indoor objects to outdoor scenes. The results show it can detect several times more salient features than SIFT with same feature quality. This new implementation is not significantly slower than SIFT, and the time complexity is linear with respect to the increased salient features. Multiprocessor or multicore system can be constructed as parallel computing environment, and the method will be as quick as SIFT. SIFT mainly uses descriptors to match, but frame information can also contribute to it. Although new parameters have been introduced, basic neighborhood information will be used to illustrate this idea. {\textcopyright}2010 IEEE.},
annote = {cited By 0},
author = {Xu, X and Yang, J},
booktitle = {2010 Chinese Conference on Pattern Recognition, CCPR 2010 - Proceedings},
doi = {10.1109/CCPR.2010.5659135},
keywords = {Anisotropic; Gaussians; Isotropic; LoG; Pyramid; S,Anisotropy; Computational complexity; Parallel ar,Gaussian distribution},
pages = {112--116},
title = {{Directional SIFT - An improved method using elliptical gaussian pyramid}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651429603{\&}doi=10.1109{\%}2FCCPR.2010.5659135{\&}partnerID=40{\&}md5=005863806385fe21555ea30dcad2b67e},
year = {2010}
}
@article{Yagi199190,
abstract = {Intensive work has already been done on visionbased navigation of autonomous mobile robots. This paper proposes a new omnidirectional image sensor COPIS (COnic Projection Image Sensor) for guiding navigation of a mobile robot. In addition, a conic projection image sensor (COPIS) is described along with its application to estimate locations of static objects relative to the robot. The COPIS system acquires an omnidirectional view around the robot in realtime by using a conic mirror. Its feature is passive sensing of the omnidirectional environment in realtime using a conic mirror. Because the conic mirror is used, its image is under conic projection. Here, the azimuth of each point in the scene appears in the image as its direction from the image center. Under the assumption of constant motion of the robot, locations of objects around the robot can be estimated by detecting their azimuth changes in the omnidirectional image. Using this method, the robot generates an environmental map of an indoor scene while it is moving in the environment. Copyright {\textcopyright} 1991 Wiley Periodicals, Inc., A Wiley Company},
annote = {cited By 0},
author = {Yagi, Y and Kawato, S},
doi = {10.1002/scj.4690221208},
journal = {Systems and Computers in Japan},
keywords = {Conic Mirrors; Conic Projection Image Sensors; Ob,Mirrors; Navigation; Robots - Mobile; Robots - Vis,Sensors},
number = {12},
pages = {90--98},
title = {{Positionmeasuring method using omnidirectional image sensor with conic mirror}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026366964{\&}doi=10.1002{\%}2Fscj.4690221208{\&}partnerID=40{\&}md5=a7a4b09e1f6e0ab6b557f4da9125e812},
volume = {22},
year = {1991}
}
@inproceedings{6409761,
abstract = {In this paper, we propose a method for representing neighborhoods of moving objects such as people. By using neighborhoods, it is possible to determine whether the spatial relations between objects and their surrounding spatial information are strong. It can be said that a neighborhood is the spatial area of an object's attention, interest or concern. It is preferable that neighborhoods move while remaining centered on each respective moving object, avoiding walls as they expand through passable areas. Therefore, neighborhoods cannot be represented by a simple shape such as a rectangle or circle, and they must be calculated quickly in order to synchronize them with their respective objects' movements. We denote a method for rapidly generating potential fields by making use of the charge simulation method (CSM) and determine neighborhoods in consideration of the spatial structure from CSM.},
author = {Yamaoka, H and Ueki, M and Hada, Y and Okabayashi, K},
booktitle = {2012 Ubiquitous Positioning, Indoor Navigation, and Location Based Service (UPINLBS)},
doi = {10.1109/UPINLBS.2012.6409761},
keywords = {mobility management (mobile radio);radionavigation},
pages = {1--8},
title = {{A fast method for generating neighborhood areas of moving objects in consideration of spatial structure}},
year = {2012}
}
@article{8506426,
abstract = {Full-coverage synthetic-aperture radar (SAR) imaging and human target identification in complex scenes are very important for security and rescue applications. In this paper, a drone-based vital-SAR-imaging hybrid radar system is proposed to realize targets' imaging and human identification simultaneously. Carried by an operational custom-built drone with a designed S-shaped trajectory, 2-D SAR images of the entire region could be obtained through the frequency-modulated continuous-wave mode, and the vital Doppler effect of human target can be searched through the Doppler mode. Then, the vital-SAR-imaging could be achieved. Several experiments including cart-based SAR imaging with three trajectories, cart-based vital-SAR-imaging, and drone-based multitrajectory vital-SAR-imaging were carried out to reveal the capability and distinct operational features of the proposed system. Experimental results demonstrate that the system has the ability to obtain SAR imaging results in different scenes with multiple trajectories, and the human target could be effectively distinguished from other stationary objects. The results show that the lowest human target location error is 0.06 m in a 4 m  9 m indoor region, which illustrates the great potential for search and rescue applications.},
author = {Yan, J and Peng, Z and Hong, H and Chu, H and Zhu, X and Li, C},
doi = {10.1109/TMTT.2018.2874268},
issn = {0018-9480},
journal = {IEEE Transactions on Microwave Theory and Techniques},
keywords = {CW radar;Doppler radar;FM radar;object detection;r},
number = {12},
pages = {5852--5862},
title = {{Vital-SAR-Imaging With a Drone-Based Hybrid Radar System}},
volume = {66},
year = {2018}
}
@inproceedings{Yang:2009:SCR:1645953.1646039,
address = {New York, NY, USA},
author = {Yang, Bin and Lu, Hua and Jensen, Christian S},
booktitle = {Proceedings of the 18th ACM Conference on Information and Knowledge Management},
doi = {10.1145/1645953.1646039},
isbn = {978-1-60558-512-3},
keywords = {continuous range,indoor moving objects,symbolic indoor space},
pages = {671--680},
publisher = {ACM},
series = {CIKM '09},
title = {{Scalable Continuous Range Monitoring of Moving Objects in Symbolic Indoor Space}},
url = {http://doi.acm.org/10.1145/1645953.1646039},
year = {2009}
}
@article{Yang201133,
abstract = {Service systems used for various applications in home automation and security require estimating the locations precisely using certain sensors. Serving a mobile user automatically by sensing his/her locations in an indoor environment is considered as a challenge. However, indoor localization cannot be carried out effectively using the Global Positioning System (GPS). In recent years, the use of Wireless Sensor Networks (WSNs) in locating a mobile object in an indoor environment has become popular. Some physical features have also been discussed to solve localization in WSNs. In this paper, we inquire into received signal strength indication (RSSI)-based solutions and propose a new localization scheme called the closer tracking algorithm (CTA) for indoor localization. Under the proposed CTA, a mechanism on mode-change is designed to switch automatically between the optimal approximately closer approach (ACA) and the real-time tracking (RTT) method according to pre-tuned thresholds. Furthermore, we design a mechanism to move reference nodes dynamically to reduce the uncovered area of the ACA for increasing the estimation accuracy. We evaluate the proposed CTA using ZigBee CC2431 modules. The experimental results show that the proposed CTA can determine the position accurately with an error distance less than 0.9 m. At the same time, the CTA scheme has at least 87{\%} precision when the distance is less than 0.9 m. The proposed CTA can select an adaptive mode properly to improve the localization accuracy with high confidence. Moreover, the experimental results also show that the accuracy can be improved by the deployment and movement of reference nodes. {\textcopyright} 2011 World Scientific Publishing Company.},
annote = {cited By 2},
author = {Yang, C.-L. and Chang, Y.-K. and Chen, Y.-T. and Chu, C.-P. and Chen, C.-C.},
doi = {10.1142/S0218194011005153},
journal = {International Journal of Software Engineering and Knowledge Engineering},
keywords = {Ehealth; Home automation; Indoor localization; Loc,Global positioning system; Global system for mobi,Wireless sensor networks},
number = {1},
pages = {33--54},
title = {{A self-adaptable indoor localization scheme for wireless sensor networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960073559{\&}doi=10.1142{\%}2FS0218194011005153{\&}partnerID=40{\&}md5=8b0c2573f0b0a2320866eb458b0347f3},
volume = {21},
year = {2011}
}
@inproceedings{Yang2018,
abstract = {Simultaneous localization and mapping (SLAM) is a problem in robotics aiming to model the environment and estimate the pose of a device within it at the same time. Developed solution is the core technology for emerging applications such as self-driving cars, automated guided vehicles (AGV), and domestic robots. Inevitably, the performance of SLAM algorithms relies highly on input signals from optical equipment ranging from cameras, laser rangefinders, and LIDAR. Loop closure, the function detecting visited locations to correct accumulated errors, is a crucial element in a SLAM system. Conventionally, geometric features are used to interpret the scenes for similarity estimation. In scenarios with nearly identical scenes existing, the feature-based approaches remain ineffective. Semantic objects and the comparison of multi-frame, therefore, can be integrated into the process and present a new level of environmental information. In this article, we first provide an overview of the SLAM system. Then the semantic object-assisted and the time and spatial sequence comparison approach are proposed to improve the similarity measurement in the SLAM process. By integrating recognized objects like landmarks and signs, we can classify similar scenes better and significantly improve building-scale indoor mapping results. The performance of systems adopting various optical technologies is also compared in this work. {\textcopyright} 2018 SPIE.},
annote = {cited By 0},
author = {Yang, C.-Y. and Zhang, Y.-C. and Chen, Y.-H. and Huang, C.-W.},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
doi = {10.1117/12.2320035},
keywords = {Automated guided vehicles; Bag of words; Environm,Automatic guided vehicles; Indoor positioning syst,Robotics},
title = {{Toward semantic loop closure in simultaneous localization and mapping systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058310059{\&}doi=10.1117{\%}2F12.2320035{\&}partnerID=40{\&}md5=244964aa9e8e4b640705c34d51edeb19},
volume = {10745},
year = {2018}
}
@inproceedings{Yang20175396,
abstract = {Most pedestrian detection algorithms only provide the object region instead of the actual body segmentation in video. For reducing the large number of redundant information and extracting a clear contour and texture feature of an up-right person, a superpixel segmentation algorithm with region correlation saliency analysis is proposed from coarse to fine cutting without any prior information. This algorithm cuts single pedestrian target automatically and obtains strict features of human object regardless of whether or not the camera is moving. It exploits saliency analysis to find location and compute region energy in superpixel image to achieve a body segmentation. Experimental results indicate that the proposed approach detects pedestrian efficiently in the complex background environment in both indoor and outdoor videos with precise object cutting boundaries. {\textcopyright} 2017 Technical Committee on Control Theory, CAA.},
annote = {cited By 0},
author = {Yang, D and Mao, L and Ji, M and Zhang, R},
booktitle = {Chinese Control Conference, CCC},
doi = {10.23919/ChiCC.2017.8028210},
pages = {5396--5399},
title = {{A superpixel segmentation algorithm with region correlation saliency analysis for video pedestrian detection}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032211720{\&}doi=10.23919{\%}2FChiCC.2017.8028210{\&}partnerID=40{\&}md5=33d3305ef6c1b9389006dfb38d38dfb5},
year = {2017}
}
@inproceedings{Yang20172689,
abstract = {In order to improve the quality of the RSS (Received Signal Strength) during the offline phase, a Mixture Gaussian Calibration Model(MGCM) is proposed by us, and a Time Latency Calibration Model(TLCM) is proposed to address the time latency effect during the online phase for a fast moving object. Firstly, MGCM is applied to the collected RSS data to precisely extract the less noised RSS. Then a feed forward neural network is trained to build a model between RSS and physical location. Finally, TLCM is applied during the online phase. The experimental results indicate that MGCM and TLCM reduce error compared to traditional positioning method respectively, which demonstrate the advantages of the proposed algorithms. {\textcopyright} 2017 IEEE.},
annote = {cited By 1},
author = {Yang, G},
booktitle = {Proceedings of 2017 IEEE 2nd Advanced Information Technology, Electronic and Automation Control Conference, IAEAC 2017},
doi = {10.1109/IAEAC.2017.8054514},
keywords = {Calibration model; Fingerprint; Fusion methods; G,Calibration; RSS; Wireless local area networks (WL,Indoor positioning systems},
pages = {2689--2692},
title = {{Research on fusion method for indoor positioning system based on sensors and WLAN technology}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034583351{\&}doi=10.1109{\%}2FIAEAC.2017.8054514{\&}partnerID=40{\&}md5=e2f8d525b8e89e91c3a909e7b15b472b},
year = {2017}
}
@inproceedings{Yang201893,
abstract = {Indoor scenes have the characteristics of abundant semantic categories, illumination changes, occlusions and overlaps among objects, which poses great challenges for indoor semantic segmentation. Therefore, we in this paper develop a method based on higher-order Markov random field model for indoor semantic segmentation from RGB-D images. Instead of directly using RGB-D images, we first train and perform RefineNet model only using RGB information for generating the high-level semantic information. Then, the spatial location relationship from depth channel and the spectral information from color channels are integrated as a prior for a marker-controlled watershed algorithm to obtain the robust and accurate visual homogenous regions. Finally, higher-order Markov random field model encodes the short-range context among the adjacent pixels and the long-range context within each visual homogenous region for refining the semantic segmentations. To evaluate the effectiveness and robustness of the proposed method, experiments were conducted on the public SUN RGB-D dataset. Experimental results indicate that compared with using RGB information alone, the proposed method remarkably improves the semantic segmentation results, especially at object boundaries. {\textcopyright} Authors 2018.},
annote = {cited By 0},
author = {Yang, J and Kang, Z},
booktitle = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
doi = {10.5194/isprs-archives-XLII-4-717-2018},
keywords = {Color image processing,Convolution; Image segmentation; Information use;,Convolutional networks; Higher Order Potentials;},
number = {4},
pages = {93--100},
title = {{Indoor semantic segmentation from RGB-D images by integrating fully convolutional network with higher-order Markov random field}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056155783{\&}doi=10.5194{\%}2Fisprs-archives-XLII-4-717-2018{\&}partnerID=40{\&}md5=2aee0a6e4f4d2c13b7a6c1f5e0039f34},
volume = {42},
year = {2018}
}
@article{Yang2018,
abstract = {Indoor localization system using receive signal strength indicator from wireless access point has attracted lots of attention recently. Geometric method is one of the most widely used spatial graph algorithms to locate object in an indoor environment, but it does not achieve good results when it is applied to a limited amount of valid data, especially when using the trilateration method. On the other hand, localization based on fingerprint can achieve high accuracy but need to pay heavy manual labor for fingerprint database establishment. In this article, we propose a bilateral greed iteration localization method based on greedy algorithm in order to use all of the effective anchor points. Comparing to trilateration, fingerprint, and maximum-likelihood method, the bilateral greed iteration method improves the localization accuracy and reduces complexity of localization process. The method proposed, coupled with measurements in a real indoor environment, demonstrates its feasibility and suitability, since it outperforms trilateration and maximum-likelihood receive signal strength indicatorbased indoor location methods without using any radio map information nor a complicated algorithm. Extensive experiment results in a Wi-Fi coverage office environment indicate that the proposed bilateral greed iteration method reduces the localization error, 63.55{\%}, 9.93{\%}, and 47.85{\%}, compared to trilateration, fingerprint, and maximum-likelihood method, respectively. {\textcopyright} 2018, {\textcopyright} The Author(s) 2018.},
annote = {cited By 0},
author = {Yang, J and Li, Y and Cheng, W},
doi = {10.1177/1550147718767376},
journal = {International Journal of Distributed Sensor Networks},
keywords = {Greedy algorithms; Indoor localization; Indoor lo,Indoor positioning systems,Iterative methods; Maximum likelihood; Mobile comp},
number = {3},
title = {{An improved geometric algorithm for indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044790656{\&}doi=10.1177{\%}2F1550147718767376{\&}partnerID=40{\&}md5=42329939f105883dc950de1ed7a824f6},
volume = {14},
year = {2018}
}
@article{Yang2017175,
abstract = {Feature description for the 3D local shape in the presence of noise, varying mesh resolutions, clutter and occlusion is a quite challenging task in 3D computer vision. This paper tackles the problem by proposing a new local reference frame (LRF) together with a novel triple orthogonal local depth images (TOLDI) representation, forming the TOLDI method for local shape description. Compared with previous methods, TOLDI manages to perform efficient, distinctive and robust description for the 3D local surface simultaneously under various feature matching contexts. The proposed LRF differs from many prior ones in its calculation of the z-axis and x-axis, the z-axis is calculated using the normal of the keypoint and the x-axis is computed by aggregating the weighted projection vectors of the radius neighbors. TOLDI feature descriptors are then obtained by concatenating three local depth images (LDI) captured from three orthogonal view planes in the LRF into feature vectors. The performance of our TOLDI approach is rigorously evaluated on several public datasets, which contain three major surface matching scenarios, namely shape retrieval, object recognition and 3D registration. Experimental results and comparisons with the state-of-the-arts validate the effectiveness, robustness, high efficiency, and overall superiority of our method. Our method is also applied to aligning 3D object and indoor scene point clouds obtained by different devices (i.e., LiDAR and Kinect), the accurate outcomes further confirm the effectiveness of our method. {\textcopyright} 2016 Elsevier Ltd},
annote = {cited By 16},
author = {Yang, J and Zhang, Q and Xiao, Y and Cao, Z},
doi = {10.1016/j.patcog.2016.11.019},
journal = {Pattern Recognition},
keywords = {3D computer vision; 3D registration; Feature desc,Computer vision,Object recognition},
pages = {175--187},
title = {{TOLDI: An effective and robust approach for 3D local shape description}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010677111{\&}doi=10.1016{\%}2Fj.patcog.2016.11.019{\&}partnerID=40{\&}md5=cd614a206b049194fff51128177b287a},
volume = {65},
year = {2017}
}
@article{NoAuthor20151,
abstract = {The proceedings contain 75 papers. The special focus in this conference is on Power Control, Management, Network Architecture, Deployment and Location-Based Services in Wireless Sensor Networks. The topics include: Lifetime optimization algorithm with multiple mobile sink nodes for wireless sensor networks; barrier coverage with discrete levels of sensing and transmission power in wireless sensor networks; 3d self-deployment algorithm in mobile wireless sensor networks; a low redundancy and high coverage node scheduling algorithm for wireless sensor networks; compressive spectrum sensing based on sparse sub-band basis in wireless sensor network; an adaptive channel sensing approach and its analysis based on hierarchical colored Petri net in distributed cognitive radio networks; supporting batch execution with a preemptive real-time kernel; research on anti-interference algorithm for indoor RSSI measuring; channel estimation algorithm based on compressed sensing for underwater acoustic OFDM communication system; semi-stochastic topology control with application to mobile robot team of leader-following formation; research on improved DV-hop localization algorithm based on RSSI and feedback mechanism; multidimensional scaling iterative localization algorithm using RSSI in wireless sensor networks; node localization based on optimized genetic algorithm in wireless sensor networks; localization algorithm in wireless sensor networks based on multi-objective particle swarm optimization; heterogeneous data fusion model for passive object localization; a self-localization scheme with grid-based anchor selection in wireless sensor networks; distributed fault diagnosis of wireless sensor network and layered negotiation-based self-protection for wireless sensor networks.},
annote = {cited By 0},
author = {Yang, Jianlei and Member, Student and Sun, Zhenyu and Member, Student and Wang, Xiaobin},
doi = {10.1007/978-1-4614-9068-5_9},
isbn = {9781461490685},
issn = {21563357},
journal = {Communications in Computer and Information Science},
number = {2},
pages = {1--700},
title = {{8th China Conference on Wireless Sensor Networks, CWSN 2014}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948398579{\&}partnerID=40{\&}md5=42b8c0f47c93314d35ccede341b61093},
volume = {501},
year = {2015}
}
@article{Yang:2017:TOL:3051179.3051280,
address = {New York, NY, USA},
author = {Yang, Jiaqi and Zhang, Qian and Xiao, Yang and Cao, Zhiguo},
doi = {10.1016/j.patcog.2016.11.019},
issn = {0031-3203},
journal = {Pattern Recogn.},
keywords = {3D registration,Local feature descriptor,Local reference frame,Object recognition,Shape retrieval},
number = {C},
pages = {175--187},
publisher = {Elsevier Science Inc.},
title = {{TOLDI}},
url = {https://doi.org/10.1016/j.patcog.2016.11.019},
volume = {65},
year = {2017}
}
@inproceedings{7450354,
abstract = {Point clouds of 3D scenes are widely applied in guiding the visually impaired by precious research. Many auxiliary systems for the visually impaired are integrated with RGB-D sensors such as Kinect and binocular cameras, which are able to acquire depth pictures and 3D point clouds. Real-time location of objects is adjusted to the world coordinate system through utilization of attitude angle transducers. This paper proposed a novel approach of scene segmentation based on the estimation of normal vectors of a point cloud. Multiplying a point cloud's normal vectors in two directions helps to eliminate correlation in different directions. It is used to split a stereo scene into several surfaces such as ground, walls and slopes. The method is faster and can obtain more separated results than RANSAC algorithm. Besides, three ways to evaluate surface smoothness are compared, including inconsistent degree of normal vectors, variance of depths and difference between normal vectors of two sizes of adjacent regions. Experimental results attained from indoor and outdoor circumstances are presented to validate the approach. It is demonstrated that the proposed method can be efficiently applied into scene segmentation and guiding the visually impaired.},
author = {Yang, K and Wang, K and Cheng, R and Zhu, X},
booktitle = {2015 IET International Conference on Biomedical Image and Signal Processing (ICBISP 2015)},
doi = {10.1049/cp.2015.0778},
keywords = {handicapped aids;image colour analysis;image segme},
month = {nov},
pages = {1--6},
title = {{A new approach of point cloud processing and scene segmentation for guiding the visually impaired}},
year = {2015}
}
@article{Yang:2015:AEO:2881662.2882127,
address = {Piscataway, NJ, USA},
author = {Yang, Lei and Cao, Jiannong and Zhu, Weiping and Tang, Shaojie},
doi = {10.1109/TMC.2014.2381232},
issn = {1536-1233},
journal = {IEEE Transactions on Mobile Computing},
number = {11},
pages = {2188--2200},
publisher = {IEEE Educational Activities Department},
title = {{Accurate and Efficient Object Tracking Based on Passive RFID}},
url = {http://dx.doi.org/10.1109/TMC.2014.2381232},
volume = {14},
year = {2015}
}
@inproceedings{Yayan2015670,
abstract = {Nowadays, the number of indoor areas which are multi-layered, complex and spread to large areas is increasing. Because of that, location-based tracking systems have become an important place in the indoor areas. In our country, there isn't any system and service which provides tracking for indoor locations. In this study, indoor positioning system for remote tracking (U-TAKIP) has been developed. Using sensor network which will be set in the area and K-NN algorithm on the central server remote tracking (people / objects) system has been developed. As signal resource wearable or portable Bluetooth Low Energy tags was used. Use areas of the application is defined as personnel tracking, patient tracking, child tracking, logistics tracking. {\textcopyright} 2015 IEEE.},
annote = {cited By 0},
author = {Yayan, U and Inan, F and Guner, F and Yazici, A},
booktitle = {2015 23rd Signal Processing and Communications Applications Conference, SIU 2015 - Proceedings},
doi = {10.1109/SIU.2015.7129914},
keywords = {Bluetooth low energies (BTLE); Indoor positioning,Bluetooth; Complex networks; Indoor positioning sy,Target tracking},
pages = {670--673},
title = {{Comprehensive indoor remote tracking system [I{\c{c}} Ortamlarda Uzaktan Takip Ama{\c{c}}li Konumlandirma Sistemi]}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939201701{\&}doi=10.1109{\%}2FSIU.2015.7129914{\&}partnerID=40{\&}md5=db89681bc6c8e960d4367629baebb60b},
year = {2015}
}
@inproceedings{7129914,
abstract = {Nowadays, the number of indoor areas which are multi-layered, complex and spread to large areas is increasing. Because of that, location-based tracking systems have become an important place in the indoor areas. In our country, there isn't any system and service which provides tracking for indoor locations. In this study, indoor positioning system for remote tracking (U-TAKP) has been developed. Using sensor network which will be set in the area and K-NN algorithm on the central server remote tracking (people / objects) system has been developed. As signal resource wearable or portable Bluetooth Low Energy tags was used. Use areas of the application is defined as personnel tracking, patient tracking, child tracking, logistics tracking.},
author = {Yayan, U and nan, F and G{\"{u}}ner, F and Yazc, A},
booktitle = {2015 23nd Signal Processing and Communications Applications Conference (SIU)},
doi = {10.1109/SIU.2015.7129914},
issn = {2165-0608},
keywords = {Bluetooth;indoor navigation;indoor radio;neural ne},
pages = {670--673},
title = {{Comprehensive indoor remote tracking system}},
year = {2015}
}
@inproceedings{Yi20093467,
abstract = {We propose a semantic representation and Bayesian model for robot localization using spatial relations among objects that can be created by a single consumer-grade camera and odometry. We first suggest a semantic representation to be shared by human and robot. This representation consists of perceived objects and their spatial relationships, and a qualitatively defined odometry-based metric distance. We refer to this as a topological-semantic distance map. To support our semantic representation, we develop a Bayesian model for localization that enables the location of a robot to be estimated sufficiently well to navigate in an indoor environment. Extensive localization experiments in an indoor environment show that our Bayesian localization technique using a topological-semantic distance map is valid in the sense that localization accuracy improves whenever objects and their spatial relationships are detected and instantiated. {\textcopyright} 2009 IEEE.},
annote = {cited By 15},
author = {Yi, C and Suh, I H and Lim, G H and Choi, B.-U.},
booktitle = {2009 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2009},
doi = {10.1109/IROS.2009.5354462},
keywords = {Bayesian networks,Bayesian; Bayesian model; Indoor environment; Loca,Intelligent robots; Robot applications; Semantics},
pages = {3467--3473},
title = {{Bayesian robot localization using spatial object contexts}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-76249115613{\&}doi=10.1109{\%}2FIROS.2009.5354462{\&}partnerID=40{\&}md5=1ba3b8c9a7871246d348fac9e992a836},
year = {2009}
}
@inproceedings{Yi2018,
abstract = {Global Positioning System (GPS) is widely used as the outdoor position system because of it provides the satisfactory results especially for outdoor navigation. However, it is not suitable for the circumstances of non-line of sight (NLoS) and complex indoor environments. To fill the gap, Wi-Fi signal has grasped the great attention being purposed as the solution for Indoor Positioning System (IPS). Existing enormous efforts have been exerted to focus on the Wi-Fi fingerprinting to achieve high accuracy. Through deep learning and machine learning, the current Wi-Fi fingerprinting can localize the object with the accuracy better than GPS. Nonetheless, it involves huge labor-cost calibration and high training complexity for intensive site survey and requires recalibration for a different environment. Due to these limitations, the current approach using Wi-Fi fingerprinting is impractical as the indoor localization solution to present-day scientific and enterprise interest. In this paper, we proposed an adaptive Wi-Fi trilateration-based indoor localization system which involves minimum labor-cost calibration to achieve a good accuracy, as a prominent research solution to location-based services (LBS). {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Yi, G H and {Bin Djaswadi}, G W and {Bin Md Khir}, M H and Ramli, N},
booktitle = {International Conference on Intelligent and Advanced System, ICIAS 2018},
doi = {10.1109/ICIAS.2018.8540628},
keywords = {Calibration; Cost accounting; Deep learning; Emplo,Indoor environment; Indoor localization; Indoor l,Indoor positioning systems},
title = {{An Adaptive Wi-Fi Trilateration-Based Indoor Localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059748458{\&}doi=10.1109{\%}2FICIAS.2018.8540628{\&}partnerID=40{\&}md5=b7e4c8e95247ede4f2ac5ccda37e2259},
year = {2018}
}
@inproceedings{7808526,
abstract = {Indoor positioning system is a rapidly emerging technology. Unlike outdoor positioning, which uses triangulation from satellites in line-of-sight, current indoor positioning methods attempt triangulation using Received Signal Strength Indicator (RSSI) from indoor transmitters, like WiFi and RFID. These methods, however, are not accurate and suffer from issues like multi-path and absorption by walls and other objects. In this paper we propose an alternate and novel approach to indoor positioning, that combines signals from multiple sensors. In particular, we focus on visual and inertial sensors that are ubiquitously found in mobile devices. We utilize a Building Information Model (BIM) of the indoor environment as a guideline for navigable paths. The sensor suite signals are processed to generate a trajectory of device moving through the indoor environment. We compute features on this trajectory in real-time and data mine pre-computed features on BIM's navigable paths to determine the location of the device in real-time. We demonstrate our approach on BIM in our university campus. The key benefit of our approach is that unlike previous methods that require installation of a wireless sensor network of several transmitters spanning the indoor environment, we only require a floor-plan BIM and cheap ubiquitous sensor suite on board a mobile device for indoor positioning.},
author = {Yilmaz, A and Gupta, A},
booktitle = {2016 IEEE SENSORS},
doi = {10.1109/ICSENS.2016.7808526},
keywords = {indoor navigation;inertial navigation;mobile hands},
pages = {1--3},
title = {{Indoor positioning using visual and inertial sensors}},
year = {2016}
}
@inproceedings{Yim2018,
abstract = {In this paper we propose a system that recognizes the location and direction of a target in an indoor environment using impulse radio ultra wideband (IR-UWB) radar. The position measurement using IR-UWB radar uses at least two radars in the conventional algorithm, but assuming that the object is a point, the volume of the object is not considered at all. So it is impossible to predict where the real center of the body is located, and what kind of behavior it is, by only locating it by the reflection signal to the surface of the object. However, if we use the distance information of each of the four radars, we can measure the accurate position of the target and the direction of the target's body. We can also see what behavior patterns we have, and there is no privacy problem at all. In order to verify the proposed system, we installed a radar in four directions in the room and experimented with humans. We could track the position of the object and measure the direction of the body in real time. {\textcopyright} 2018 German Institute of Navigation - DGON.},
annote = {cited By 0},
author = {Yim, D and Cho, S H},
booktitle = {Proceedings International Radar Symposium},
doi = {10.23919/IRS.2018.8448008},
keywords = {Behavior patterns; Conventional algorithms; Direc,Indoor positioning systems; Radar; Radar tracking;,Radar measurement},
title = {{Indoor positioning and body direction measurement system using IR-UWB radar}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053599786{\&}doi=10.23919{\%}2FIRS.2018.8448008{\&}partnerID=40{\&}md5=6736754ac266c646604b7452c2985f0d},
volume = {2018-June},
year = {2018}
}
@article{Yim2012221,
abstract = {A location-based service (LBS) cannot be realized unless solutions of the positioning problem are available at hand. For the outdoor positioning, GPS based practical solutions have been introduced. Using GPS they have developed so many commercial LBS systems. Navigation, logistics, troop management and fleet management are all examples of LBS. LBS is so useful that it should be available in doors. However, GPS signal is so weak inside buildings that we cannot determine the location of a moving object in doors with GPS only. Therefore, so many indoor positioning researches have been performed. Cricket, Active Badge and BAT are pioneers in the field of indoor positioning. They are very accurate but they require special equipments dedicated for positioning. Using special equipments is not economical. Therefore, many researchers have suggested using wireless local area networks (WLAN) in positioning. Among the methods they are using, the fingerprinting methods are most accurate. The deployment of the fingerprinting methods consists of two phases: the off-line phase and the on-line phase. During the off-line phase a site-survey of the received signal strength indices (RSSIs) from access points (APs) is performed. The vector of the RSSI values at a point is called the location fingerprint of that point. A lot of location fingerprints must be collected at each of the points in the site during the off-line phase. This is extremely tedious and time consuming. An alternative choice is the trilateration method. This method converts RSSIs from APs into distances and determines the location of the moving object with the distances and the locations of the APs. That is, we only need the coordinates of the APs in the site to get ready to run the trilateration positioning program. The conversion rule of RSSIs into distances is based on the RF propagation loss model. The model is a simple mathematical expression representing the relationship between the RSSI and the distance. However, the RSSI is influenced by obstructions, reflections and multipath and the RF propagation loss model is very erroneous. As a result, WLAN based trilateration is much less accurate than the fingerprinting method. Nevertheless, the trilateration method could be more practical than the fingerprinting method because it does not require the time consuming off-line phase process. Therefore, they established IEEE 802.15.4 A where the distance is determined by the speed of RF and TOF (Time of Flight). Ubi-nanoLOC mote complies with IEEE 802.15.4 A. This paper discusses the advantages and disadvantages of the WLAN-based trilateration indoor positioning and the Ubi-nanoLOC indoor positioning draws our final conclusions.},
annote = {cited By 6},
author = {Yim, J},
journal = {International Journal of Multimedia and Ubiquitous Engineering},
keywords = {Access points; Fleet management; GPS signals; IEEE,Fleet operations; Location based services; Standa,Global positioning system},
number = {2},
pages = {221--234},
title = {{Comparison between RSSI-based and TOF-based indoor positioning methods}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865636917{\&}partnerID=40{\&}md5=c18946316bf4e38c7b8a4dfa3b4ce5b7},
volume = {7},
year = {2012}
}
@article{Yim20131365,
abstract = {This paper presents a Petri net representation of an ontology for indoor location-based services. The ontology is described within the Resource Description Framework (RDF). Therefore, this paper proposes a method for transforming the RDF model into a CPN (colored Petri net). The proposed method represents the semantics of the RDF model in the CPN by mapping the classes and properties of the RDF model onto CPN places and representing the relationships between those classes and properties as token transitions in the CPN. To represent an RDF statement in the CPN, the method introduces a transition that produces a (complex) token composed of two ordered (simple) tokens: one corresponding to the subject and the other corresponding to the object of the statement. Applying the proposed method, we build a sample {\c{C}}PN for an RDF model and perform simulations using the model to answer RDF queries. This paper also introduces a simple ontology for an indoor location-based service. Using the proposed transformation method, we transform the ontology into a CPN. Finally, we introduce our inference algorithm for the CPN and a prototype database system for demonstrating the practicality of our method. The results indicate that the proposed database system can resolve the semantic ambiguities in the query by using the ontology. {\textcopyright}2013 International Information Institute.},
annote = {cited By 0},
author = {Yim, J and Joo, J and Lee, G},
journal = {Information (Japan)},
number = {2 B},
pages = {1365--1370},
title = {{Ontology for indoor location-based services and CPN model}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876131852{\&}partnerID=40{\&}md5=7ba93950d59aab460a1d5d09a8abd456},
volume = {16},
year = {2013}
}
@article{Yim2011423,
abstract = {This paper presents a Petri net representation of an ontology for indoor location-based services. The ontology is described within the Resource Description Framework (RDF). Therefore, this paper proposes a method for transforming the RDF model into a CPN (colored Petri net). The proposed method represents the semantics of the RDF model in the CPN by mapping the classes and properties of the RDF model onto CPN places and representing the relationships between those classes and properties as token transitions in the CPN. To represent an RDF statement in the CPN, the method introduces a transition that produces a (complex) token composed of two ordered (simple) tokens: one corresponding to the subject and the other corresponding to the object of the statement. Applying the proposed method, we build a sample CPN for an RDF model and perform simulations using the model to answer RDF queries. This paper also introduces a simple ontology for an indoor location- based service. Using the proposed transformation method, we transform the ontology into a CPN. Finally, we introduce our inference algorithm for the CPN and a prototype database system for demonstrating the practicality of our method. The results indicate that the proposed database system can resolve the semantic ambiguities in the query by using the ontology. {\textcopyright} 2011 Springer-Verlag.},
annote = {cited By 1},
author = {Yim, J and Joo, J and Lee, G},
doi = {10.1007/978-3-642-27180-9_52},
journal = {Communications in Computer and Information Science},
keywords = {Colored Petri Nets; Inference algorithm; Location-,Computer simulation; Database systems; Encoding (,Ontology},
pages = {423--430},
title = {{Petri net representation of ontologies for indoor location-based services}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-83755162454{\&}doi=10.1007{\%}2F978-3-642-27180-9{\_}52{\&}partnerID=40{\&}md5=c5d2ad209f1e45b2bc73f9c7b75a72bd},
volume = {261 CCIS},
year = {2011}
}
@article{Yin20181,
abstract = {The TD-LTE wireless private network for electric power systems is an important component of smart grids, and coverage analysis and interference identification are essential in operating and optimizing of power wireless private networks. This paper presents an approach to analyzing indoor and outdoor coverage scopes of cell radio signals and recognizing locations and sources of intra-network interference in the network deployed in a dense urban environment. This approach takes scenario modeling to represent terrain and on-ground objects given by digital maps, utilizes ray tracing to track the signal propagation trajectories, and calculates strength attenuation of radio signals due to signal propagation such as direct transmission, reflection, diffraction and refraction. The uniform grid is employed as the acceleration structure to speed up tracing signal propagation paths, and drive-testing measurement data and scenario-oriented propagation model calibration are used to improve analysis accuracy. Weak coverage spots and interference defect spots are defined and used to identify interference types and sources. We applied the approach to a tentative TD-LTE power wireless private network in a southern city in China, proving that the ray-tracing-based scheme is able to make precise analysis on coverage and interference in practical networks. {\textcopyright} 2018 Springer Science+Business Media, LLC, part of Springer Nature},
annote = {cited By 0; Article in Press},
author = {Yin, J and Miao, W and Ye, W and Teng, J and Jiang, C and Liu, R},
doi = {10.1007/s11280-018-0589-7},
journal = {World Wide Web},
keywords = {Computer networks; Data flow analysis; Digital rad,Coverage; Dense urban environments; Interference,Smart power grids},
pages = {1--31},
title = {{Interference identification in smart grid communications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049142910{\&}doi=10.1007{\%}2Fs11280-018-0589-7{\&}partnerID=40{\&}md5=def130190618efe2df2888fe7443b833},
year = {2018}
}
@article{Yoo2015565,
abstract = {Supervised machine learning has become popular in discovering context descriptions from sensor data. However, collecting a large amount of labeled training data in order to guarantee good performance requires a great deal of expense and time. For this reason, semi-supervised learning has recently been developed due to its superior performance despite using only a small number of labeled data. In the existing semi-supervised learning algorithms, unlabeled data are used to build a graph Laplacian in order to represent an intrinsic data geometry. In this paper, we represent the unlabeled data as the spatial-temporal dataset by considering smoothly moving objects over time and space. The developed algorithm is evaluated for position estimation of a smartphone-based robot. In comparison with other state-of-art semi-supervised learning, our algorithm performs more accurate location estimates. {\textcopyright} ICROS 2015.},
annote = {cited By 0},
author = {Yoo, J and Kim, H J},
doi = {10.5302/J.ICROS.2015.14.0121},
journal = {Journal of Institute of Control, Robotics and Systems},
keywords = {Accurate location; Graph Laplacian; Indoor locali,Algorithms; Artificial intelligence; Learning syst,Learning algorithms},
number = {6},
pages = {565--570},
title = {{Semi-supervised learning for the positioning of a smartphone-based robot}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930809591{\&}doi=10.5302{\%}2FJ.ICROS.2015.14.0121{\&}partnerID=40{\&}md5=75bf76e7073de4ce505ee140ed73788d},
volume = {21},
year = {2015}
}
@article{Yoon20161318,
abstract = {We present ACMI, an FM-based indoor localization system that does not require proactive site profiling. ACMI constructs the fingerprint database based on pure estimation of indoor received signal strength (RSS) distribution, where only the signals transmitted from commercial FM radio stations are used. Based on extensive field measurement study, we established our own signal propagation model that harnesses FM radio characteristics and open information of FM transmission towers in combination with the floor-plan of a building. Output of the model is an RSS fingerprint database. Using the fingerprint database as a knowledge base, ACMI refines a positioning result via the two-step process; parameter calibration and path matching, during its runtime. Without site profiling, our evaluation indicates that ACMI in seven campus locations and three downtown buildings using eight distinguished FM stations finds positions with only about 6 and 10 meters of errors on average, respectively. {\textcopyright} 2002-2012 IEEE.},
annote = {cited By 6},
author = {Yoon, S and Lee, K and Yun, Y and Rhee, I},
doi = {10.1109/TMC.2015.2465372},
journal = {IEEE Transactions on Mobile Computing},
keywords = {Database systems; Frequency modulation; Indoor pos,Fingerprint database; FM signals; Indoor localiza,Mobile computing},
number = {6},
pages = {1318--1332},
title = {{ACMI: FM-based indoor localization via autonomous fingerprinting}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969638925{\&}doi=10.1109{\%}2FTMC.2015.2465372{\&}partnerID=40{\&}md5=c962efdfa068c05629c3213e7cd2744d},
volume = {15},
year = {2016}
}
@inproceedings{Yoshisada201873,
abstract = {This paper presents a new algorithm for building an indoor map by integrating point clouds of 2D light detection and ranging (LIDAR) scanners in indoor environments. Iterative closest point (ICP) algorithm is one of the well-known methods for such purpose and often used for mobile robot SLAM. However, the algorithm is designed based on 'dense' (or 'continuous') measurement of the same space with known relative positions of measurement points and angles, and it does not often work efficiently if the measurement is sparse and/or LIDAR locations are unknown. Such situations are seen when some installed LIDARs in a room are used to build a background indoor map for object tracking, or mobile LIDARs are used by technicians to build a digital indoor map, where each space is captured only at a few locations with different angles. To tackle this issue, our method extracts line segments and edge points as features from given LIDAR point clouds and finds shape coincidences commonly contained in a pair of given point clouds to identify positional relationships between LIDARs. By this information, these point clouds can be integrated into common 2D coordinates. Indoor map generation is realized by sequentially applying this integration procedure to every pair of point clouds. Also, the experiments on real data show that our method can identify the relative positions of LIDARs with 10cm-order errors in average, and by sequentially applying the point-cloud integration, the generated maps have only 3{\%} errors. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Yoshisada, H and Yamada, Y and Hiromori, A and Yamaguchi, H and Higashino, T},
booktitle = {Proceedings - 2018 IEEE International Conference on Smart Computing, SMARTCOMP 2018},
doi = {10.1109/SMARTCOMP.2018.00076},
keywords = {Integration procedure; Iterative closest point al,Iterative methods,Optical radar},
pages = {73--80},
title = {{Indoor map generation from multiple lidar point clouds}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051466535{\&}doi=10.1109{\%}2FSMARTCOMP.2018.00076{\&}partnerID=40{\&}md5=58b12647ab4183131434d772120d21b9},
year = {2018}
}
@inproceedings{Yu2014428,
abstract = {The development of context-aware control for smart space applications becomes popular recently, in which radio frequency identification (RFID) plays an important role. For an indoor context-aware smart space system, RFID tags and readers are utilized to locate object coordinates, cf. GPS utilizes GNSS for capture outdoor location information. Previous researches proposed to deploy regularly spaced reference tags, based on which the space location of target object tag can be estimated. Due to tag signal collision and received signal errors, the estimation accuracy is limited. We propose to utilize more than one RFID readers and control the reading power to eliminate estimation error. Passive tags that are cost effective are deployed for dense tag grid, e.g., for high accuracy location estimation. Experiments show that the proposed method can significantly reduce the estimation error from 69 cm to be under 15 cm. This RFID-based object location system can be applied to help people to locate personal belongings. In addition, a video surveillance system can be integrated with the object location method to provide context-awareness service. {\textcopyright} 2014 IEEE.},
annote = {cited By 5},
author = {Yu, H.-Y. and Chen, J.-J.},
booktitle = {Proceedings - International Conference on Machine Learning and Cybernetics},
doi = {10.1109/ICMLC.2014.7009153},
keywords = {Adaptive control systems; Artificial intelligence;,Intelligent spaces; Location estimation; Location,Radio frequency identification (RFID)},
pages = {428--433},
title = {{An intelligent space location identification system based on passive RFID tags}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921513029{\&}doi=10.1109{\%}2FICMLC.2014.7009153{\&}partnerID=40{\&}md5=2ae6adc148f1e5af93f0d94058f76c0b},
volume = {1},
year = {2014}
}
@inproceedings{Yuan2012292,
abstract = {The ray-tracing method is an effective method for indoor location, it can overcome NLOS and multi-path propagation. Because of the low computational efficiency, traditional methods are not widely used. This paper analyzes the main factors affecting the efficiency of the ray-tracing operation, and proposes a new method to improve the efficiency of indoor ray-tracing operation. This method combines ray-tracing and voronoi diagram, uses sphere of influence features and local dynamic characteristics of voronoi diagram. The geometric center of indoor objects are viewed as the growing point, indoor environment is voronoi polygon division, thereby the intersection calculation is reduced between ray and objects. The simulation results show the effectiveness of the method. {\textcopyright} 2012 IEEE.},
annote = {cited By 0},
author = {Yuan, Z.-W. and Wang, D.-D.},
booktitle = {Proceedings - 2012 International Conference on Computer Science and Service System, CSSS 2012},
doi = {10.1109/CSSS.2012.80},
keywords = {Acceleration algorithm; Geometric center; Indoor e,Algorithms; Computational geometry; Computer scie,Ray tracing},
pages = {292--295},
title = {{A new ray-tracying acceleration algorithm based on voronoi diagram}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873875466{\&}doi=10.1109{\%}2FCSSS.2012.80{\&}partnerID=40{\&}md5=be3dc61b835b8e38ce4c5a1e9dfd25bd},
year = {2012}
}
@article{Zadgaonkar201647,
abstract = {The paper provides wide range survey of techniques, methodologies and systems for Object localization in indoor environment space using BLE (Bluetooth Low Energy) technology. It also presents study to track moving smart objects and provides their comparison based on factors such as privacy, accuracy, and location type. One important problem in object localization using Bluetooth is to identify the position of BLE tags and produce accurate location results using certain algorithms. In this survey, theft prominent research directions are categorized, analyzed and discussed. {\textcopyright} Springer Nature Singapore Pte Ltd. 2016.},
annote = {cited By 0},
author = {Zadgaonkar, H and Chandak, M},
doi = {10.1007/978-981-10-3433-6_6},
journal = {Communications in Computer and Information Science},
keywords = {Accurate location; Bluetooth low energies (BTLE);,Bluetooth; Object recognition; Surface discharges;,Indoor positioning systems},
pages = {47--53},
title = {{Object localization analysis using BLE: Survey}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009486546{\&}doi=10.1007{\%}2F978-981-10-3433-6{\_}6{\&}partnerID=40{\&}md5=f58a878862226fde6c0d474cf2340cb4},
volume = {628 CCIS},
year = {2016}
}
@inproceedings{8568632,
abstract = {In this paper, we consider chip-to-chip communication such as processor to memory link where the motherboard is placed in a casing similar to a desktop or a laptop. At THz frequencies, the dimensions of the casing are large enough that signal may reflect from the objects inside the box and the sides of the box creating resonant cavity effect. To model propagation in such an environment, we model casing as overmoded cavity and consider other objects in the casing as conductive objects. We propose a geometry-based statistical propagation model that describes chip-to-chip propagation in metal enclosures filled with conductive objects. Based on the geometrical model, a simulation model for multipath fading in this cavity is developed and correlation function is derived. The simulation results show that multiple reflections created in the resonant cavity significantly impact correlation function and power delay profile and need careful consideration when modeling chip-to-chip propagation in metal enclosures.},
author = {Zajic, A and Juyal, P},
booktitle = {12th European Conference on Antennas and Propagation (EuCAP 2018)},
doi = {10.1049/cp.2018.0954},
keywords = {cavity resonators;fading channels;indoor radio;int},
pages = {1--5},
title = {{Modeling of THz chip-to-chip wireless channels in metal enclosures}},
year = {2018}
}
@inproceedings{Zanaty2009501,
abstract = {Localization is a fundamental task in mobile robotics and in indoor environments we can use various sensors to solve this problem. In the Intelligent Space environment we can use laser range finders or ultrasonic positioning systems to localize and track mobile robots. Nevertheless, our final goal is to substitute these sensors and accomplish this task using just cameras. In this paper, we show the feasibility of determining the robot's location based on the images received from a single camera. In our experimental room we used a surveillance camera, which can be controlled to pan/tilt in order to change the point of view. The camera had been mounted on the ceiling and six preset positions were selected to cover the whole area. The object recognition is based on colour space filtering and contour detection. Finally, the contours of the detected objects are transformed from the image space to the world coordinate system and the polygons are reduced to simpler ones. The system is able to detect not only the position of the objects, but their orientations.},
annote = {cited By 1},
author = {Zanaty, P and Korondi, P and Sziebig, G and Jeni, L A},
booktitle = {10th International Symposium of Hungarian Researchers on Computational Intelligence and Informatics, CINTI 2009},
keywords = {Artificial intelligence; Calibration; Cameras; Im,Indoor environment; Intelligent spaces; ISpace; La,Security systems},
pages = {501--512},
title = {{Image-based automatic object localisation in iSpace environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863677548{\&}partnerID=40{\&}md5=2e7066b099127eb113e3957ec41ce4a8},
year = {2009}
}
@inproceedings{Zeng1995183,
abstract = {Teleoperation of complex environments from a remote place requires careful attention of the operator. In such environments as spacestations where operation errors will cause heavy damages, operators need to be well trained and experienced before practical teleoperation. Robot vision will help a lot in recognizing and locating objects in the environments. In such case, feature extraction is very important. Real time processing depends on quick and correct feature extraction of objects. If we place a man-made marker on an object, feature extraction will be much easier than directly extracting natural features of the object. We have developed a practical and robust method for object recognition and location using specially designed markers. Circle, rectangle and triangle are chosen as three primitives, and a marker is formed by combining any two of these primitives. Here primitive combination is used because it can both increase the number of markers without increasing primitives and distinguish markers from complex background. Edge information is mainly utilized in the process of object recognition because edges are relatively long and stable compared with corners. A marker is recognized by first recognizing each primitive in it and then determining their position relation. After recognition, back projective projection of a marker is taken and its 3D pose are calculated by solving spatial plane equations with the aid of parameters of each primitive in the marker such as diameters of a circle, equations of their images in the image plane. Extensive experiments have been done to verify effectiveness of the proposed method and quite good results are obtained for both indoor and outdoor environments, for both recognition and location of objects with markers.},
annote = {cited By 0},
author = {Zeng, Jianchao and Yang, Yudong and Wu, Mingrui and Xu, Guangyou},
booktitle = {Proceedings of SPIE - The International Society for Optical Engineering},
keywords = {Computer vision; Human engineering; Imaging techn,Edge information; Markers; Object location; Teleop,Remote control},
pages = {183--191},
title = {{Recognizing and locating objects with the aid of specially designed markers}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029530635{\&}partnerID=40{\&}md5=98b3af1459d148937dd696ad7305d1aa},
volume = {2590},
year = {1995}
}
@article{Zhang2018978,
abstract = {Aiming at the low positioning accuracy of image space location in urban environments, this paper proposes a new method of space location of image in urban environments based on C/S structure. First, a series of indoor images are taken in advance. We use the nearest neighbor distance ratio (NNDR) and normalized cross correlation (NCC) to get the SIFT coarse matches, then use RANSAC method to optimize it, and calculate the fundamental matrix and projection matrix. Building 3D point cloud model is established, and the object space feature library including image feature points, image point coordinates and object space point coordinates are got. Second, we regard the building images which are taken by user's mobile phone as the location images. Image feature points of location images are extracted and matched with the feature points of object space feature library, then the object space point coordinates are obtained. Finally, we use collinearity equation model to accurately calculate the exterior orientation elements, and display the user's space position on the phone, thus space positioning is realized. The experimental results show that the positioning method in this paper can reach the centimeter level positioning accuracy, and can meet the requirements of the user positioning accuracy. {\textcopyright} 2018, Research and Development Office of Wuhan University. All right reserved.},
annote = {cited By 0},
author = {Zhang, C and Wang, X and Guo, B},
doi = {10.13203/j.whugis20160455},
journal = {Wuhan Daxue Xuebao (Xinxi Kexue Ban)/Geomatics and Information Science of Wuhan University},
keywords = {Exterior orientation; Fundamental matrix; Project,Image matching; Location; Nearest neighbor search;,Image processing},
number = {7},
pages = {978--983},
title = {{Space Location of Image in Urban Environments Based on C/S Structure [C/S]}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054661076{\&}doi=10.13203{\%}2Fj.whugis20160455{\&}partnerID=40{\&}md5=cb3e1bf9038f443066a1e15729c43fb7},
volume = {43},
year = {2018}
}
@inproceedings{Zhang2010,
abstract = {Traditional RF-based indoor positioning approaches use only Radio Signal Strength Indicator (RSSI) to locate the target object. But RSSI suffers significantly from the multi-path phenomenon and other environmental factors. Hence, the localization accuracy drops dramatically in a large tracking field. To solve this problem, this paper introduces one more resource, the dynamic of RSSI, which is the variance of signal strength caused by the target object and is more robust to environment changes. By combining these two resources, we are able to greatly improve the accuracy and scalability of current RF-based approaches. We call such hybrid approach COCKTAIL. It employs both the technologies of active RFID and Wireless Sensor Networks (WSNs). Sensors use the dynamic of RSSI to figure out a cluster of reference tags as candidates. The final target location is estimated by using the RSSI relationships between the target tag and candidate reference tags. Experiments show that COCKTAIL can reach a remarkable high degree of localization accuracy to 0.45m, which outperforms significantly to most of the pure RF-based localization approaches. {\textcopyright}2010 IEEE.},
annote = {cited By 22},
author = {Zhang, D and Yang, Y and Cheng, D and Liu, S and Ni, L M},
booktitle = {IEEE International Conference on Communications},
doi = {10.1109/ICC.2010.5502137},
keywords = {Active RFID; Degree of localization; Environment c,Sensors; Targets,Wireless sensor networks},
title = {{COCKTAIL: An RF-based hybrid approach for indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955398306{\&}doi=10.1109{\%}2FICC.2010.5502137{\&}partnerID=40{\&}md5=42276278658722914a6965941c941b14},
year = {2010}
}
@phdthesis{Zhang:2010:LTO:2049168,
annote = {AAI3434084},
author = {Zhang, Dian},
isbn = {978-1-124-40388-5},
publisher = {Hong Kong University of Science and Technology (People's Republic of China)},
title = {{Localizing Transceiver-free Objects: The Rf-based Approaches}},
year = {2010}
}
@article{Zhang20184031,
abstract = {With the development of the Internet of Things technology, indoor tracking has become a popular application nowadays, but most existing solutions can only work in line-of-sight scenarios, or require regular recalibration. In this paper, we propose WiBall, an accurate and calibration-free indoor tracking system that can work well in non-line-of-sight based on radio signals. WiBall leverages a stationary and location-independent property of the time-reversal focusing effect of radio signals for highly accurate moving distance estimation. Together with the direction estimation based on inertial measurement unit and location correction using the constraints from the floorplan, WiBall is shown to be able to track a moving object with decimeter-level accuracy in different environments. Since WiBall can accommodate a large number of users with only a single pair of devices, it is low-cost and easily scalable, and can be a promising candidate for future indoor tracking applications. {\textcopyright} 2014 IEEE.},
annote = {cited By 0},
author = {Zhang, F and Chen, C and Wang, B and Lai, H.-Q. and Han, Y and {Ray Liu}, K J},
doi = {10.1109/JIOT.2018.2854825},
journal = {IEEE Internet of Things Journal},
keywords = {Calibration; Database systems; Estimation; Feature,Focusing,Inertial measurement unit; Internet of things tec},
number = {5},
pages = {4031--4041},
title = {{WiBall: A Time-Reversal Focusing Ball Method for Decimeter-Accuracy Indoor Tracking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049798902{\&}doi=10.1109{\%}2FJIOT.2018.2854825{\&}partnerID=40{\&}md5=cbb459015023e2a56bf992622c0654ce},
volume = {5},
year = {2018}
}
@article{Zhang2015,
abstract = {This article proposes a saliency-based pedestrian navigation data model using the UML in order to support the research and application of saliency-based pedestrian navigation. This data model mainly organizes the salient objects and their spatial topological relations. Moreover, this data model organizes the multimodal pedestrian environment including outdoor, indoor and transportation. In order to implement the proposed model, this article designs a database and a smartphone system to check its feasibility with a set of experimental data.},
annote = {cited By 1},
author = {Zhang, H and Fang, Z and Guo, Y and Wu, J and Liu, C},
doi = {10.14188/j.2095-6045.2015.03.015},
journal = {Journal of Geomatics},
keywords = {database; GIS; navigation; numerical model; pedest},
number = {3},
pages = {57--59 and 70},
title = {{A saliency-based pedestrian navigation data model}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940652622{\&}doi=10.14188{\%}2Fj.2095-6045.2015.03.015{\&}partnerID=40{\&}md5=4033ff0257ac3d905241176054810bce},
volume = {40},
year = {2015}
}
@article{Zhang20112734,
abstract = {Most of existing RFID indoor localization algorithm is based on the signal strength values, reference tags and ranging location. After these algorithms are applied to the occasions of large space and complex environment such as exhibition hall, hospitals and prisons they are facing some problems such as high system cost, deploying difficulties and detecting difficulties of working state of readers. Aiming at the network reader, we present an improved localization algorithm which is implemented by tracking real-time objects and detecting the reader's working state, and the system can still work when there are abnormalities in the reader. The experiment results show that the proposed methods can be used in the large space and complex environment. {\textcopyright} 2011 ACADEMY PUBLISHER.},
annote = {cited By 3},
author = {Zhang, H and Miao, P},
doi = {10.4304/jcp.6.12.2734-2739},
journal = {Journal of Computers},
keywords = {Algorithms,Complex environments; Indoor localization; Large s,Exhibition buildings; Radio frequency identificat},
number = {12},
pages = {2734--2739},
title = {{An improved RFID localization algorithm based on layer by layer exclusion}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-83455199100{\&}doi=10.4304{\%}2Fjcp.6.12.2734-2739{\&}partnerID=40{\&}md5=11f5f0ede34ae6ae13d1129747ae7984},
volume = {6},
year = {2011}
}
@inproceedings{Zhang20173289,
abstract = {Collaborative Navigation (CN) is developed to provide an improvement on positioning performance for various navigation applications. This paper aims to investigate the CN technology in the way of object detection based on deep learning. A novel concept which integrates Inertial Measurement Units (IMUs) and digital cameras to achieve CN is presented in this paper. This approach utilizes a pre-Trained faster region-based convolutional neural network (Faster-RCNN) to detect neighboring users from images. Then, by the image-based ranging approach proposed in this study, we obtain space ranges between users which would be tightly integrated with a local Kalman filter to provide IMU with error estimates. Unlike traditional location and ranging methods, this approach allows positioning solution to be performed in indoor environments, where radio frequency (RF) signal is generally blocked, reflected and attenuated by obstacles. To evaluate the performance of the proposed approach, a test at the Ohio State University was implemented. The test results show that the ranging accuracy of image-based ranging approach stays around 1m at various range level. Also, bounding boxes with a higher score are more beneficial to achieve high ranging accuracy. The CP solution is able to drag the trajectory back to the ground truth and restricts the horizontal error to around 1m in an indoor area. {\textcopyright} 2017 Institute of Navigation. All rights reserved.},
annote = {cited By 0},
author = {Zhang, L and Xu, H and Lian, B and Toth, C K},
booktitle = {30th International Technical Meeting of the Satellite Division of the Institute of Navigation, ION GNSS 2017},
keywords = {Collaborative navigation; Convolutional neural ne,Deep learning; Indoor positioning systems; Navigat,Global positioning system},
pages = {3289--3300},
title = {{Integrated IMU/Image collaborative navigation for indoor environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047863911{\&}partnerID=40{\&}md5=a9b4f38a4423c255e4c17e2909a60491},
volume = {5},
year = {2017}
}
@article{Zhang:2014:MPT:2582453.2582464,
address = {Hingham, MA, USA},
author = {Zhang, Peng and Zhang, Yanning and Thomas, Tony and Emmanuel, Sabu},
doi = {10.1007/s11042-012-1110-4},
issn = {1380-7501},
journal = {Multimedia Tools Appl.},
keywords = {Detection,Latent semantic analysis,Tracking,Visual surveillance},
number = {3},
pages = {991--1021},
publisher = {Kluwer Academic Publishers},
title = {{Moving People Tracking with Detection by Latent Semantic Analysis for Visual Surveillance Applications}},
url = {http://dx.doi.org/10.1007/s11042-012-1110-4},
volume = {68},
year = {2014}
}
@article{Zhang2011181,
abstract = {Radio Frequency Identification (RFID) technology has been used in Intelligent Environments to track objects and people, but the technology is subject to reliability issues of sensor malfunction, sensor range, interference and location coverage. This paper discusses the optimal deployment for a fixed RFID reader network in an indoor environment with the aim of achieving more accurate location whist minimizing the equipment costs. Given that data may be occasionally lost, a rule-based pre-processing algorithm was developed for missing data judgment and correction, to improve the robustness of the technique. The algorithms were evaluated using experiments of single mobile tag and multiple mobile tags. The average subarea location accuracy based on pre-processed and original data is 77.1{\%} vs. 68.7{\%} for fine-grained coverage, and 95.8{\%} vs. 85.4{\%} for the coarse-grained coverage. {\textcopyright} 2011 Springer-Verlag Berlin Heidelberg.},
annote = {cited By 2},
author = {Zhang, S and McCullagh, P J and Nugent, C and Zheng, H and Black, N},
doi = {10.1007/978-3-642-19937-0_23},
journal = {Advances in Intelligent and Soft Computing},
keywords = {Accurate location; Coarse-grained; Equipment costs,Algorithms; Artificial intelligence; Cryptography,Radio frequency identification (RFID)},
pages = {181--188},
title = {{Reliability of location detection in intelligent environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053048688{\&}doi=10.1007{\%}2F978-3-642-19937-0{\_}23{\&}partnerID=40{\&}md5=d629d1d6ff20ba93c7f3146fe1bd58a2},
volume = {92},
year = {2011}
}
@inproceedings{Zhang:2011:VSM:2908675.2908679,
author = {Zhang, Shiqi and Sridharan, Mohan},
booktitle = {Proceedings of the 9th AAAI Conference on Automated Action Planning for Autonomous Mobile Robots},
pages = {20--26},
publisher = {AAAI Press},
series = {AAAIWS'11-09},
title = {{Visual Search and Multirobot Collaboration Based on Hierarchical Planning}},
url = {http://dl.acm.org/citation.cfm?id=2908675.2908679},
year = {2011}
}
@inproceedings{Zhang20174634,
abstract = {Loop closure detection is an important part of visual simultaneous location and mapping (SLAM) system. Most of traditional loop closure detection approaches using hand-crafted features often lack robustness with respect to object occlusions and illumination changes, especially for the complicated indoor environment. Recently, convolutional neural network (CNN) makes a huge impact on many computer vision and pattern recognition applications. Depth images have complementary information to RGB images, which can encode the structural information of the scene. With the availability of inexpensive RGB-D sensors, it is expected that depth information can increase the accuracy in many computer vision applications. In this paper, we focus on indoor loop closure detection using the depth information. For the first time, we introduce a simple CNN model to train the depth images encoded by HHA method for indoor loop closure detection. The experiment demonstrates that HHA based CNN features can fully utilize the structural information of the scene, which shows that it is preferable than using raw depth images for loop closure detection. {\textcopyright} 2017 IEEE.},
annote = {cited By 1},
author = {Zhang, W and Liu, G and Tian, G},
booktitle = {Proceedings - 2017 Chinese Automation Congress, CAC 2017},
doi = {10.1109/CAC.2017.8243597},
keywords = {Computer vision applications; Convolutional neura,Computer vision; Convolution; Indoor positioning s,Feature extraction},
pages = {4634--4639},
title = {{HHA-based CNN image features for indoor loop closure detection}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050334990{\&}doi=10.1109{\%}2FCAC.2017.8243597{\&}partnerID=40{\&}md5=5587adede23d462a04ce91247e229e5e},
volume = {2017-Janua},
year = {2017}
}
@phdthesis{Zhang:2009:OMR:1714065,
annote = {AAI3362335},
author = {Zhang, Yun},
isbn = {978-1-109-21900-5},
publisher = {University of Louisiana at Lafayette},
title = {{One-dimensional Mapping and Ray Projection for Recovering Projective Transformations}},
year = {2009}
}
@article{6519282,
abstract = {Radio-frequency identification (RFID) with a received signal strength indicator (RSSI) is a low-cost and low-complexity approach for item-level indoor localization. Although RSSI-based algorithms suffer from multipath effect and other environmental factors, reference tags and RSSI changes can be utilized to further improve the localization accuracy. However, the current algorithms lack deep analysis of the influence of tag interaction on localization accuracy and faces the challenge of simultaneously locating multiple close targets. In this paper, we propose an analysis method about how tag interaction affects a tag antenna radiation pattern and an RSSI change. The tag interaction analysis guides us to improve the design of RSSI-based localization algorithms. We take the k-nearest neighbor (k-NN) algorithm and the Simplex algorithm as two examples. The experimental results show that the revised k-NN and the revised Simplex algorithms are robust to different numbers, spacing, and materials of target objects, and they are superior to other RFID localization schemes, considering cost, capability of simultaneous localization of multiple targets, and location estimation errors.},
author = {Zhang, Z and Lu, Z and Saakian, V and Qin, X and Chen, Q and Zheng, L},
doi = {10.1109/TIE.2013.2264785},
issn = {0278-0046},
journal = {IEEE Transactions on Industrial Electronics},
keywords = {indoor communication;radiofrequency identification},
number = {4},
pages = {2122--2135},
title = {{Item-Level Indoor Localization With Passive UHF RFID Based on Tag Interaction Analysis}},
volume = {61},
year = {2014}
}
@inproceedings{Zhao:2015:GDA:2737095.2742560,
address = {New York, NY, USA},
author = {Zhao, David and Chowdhery, Aakanksha and Kapoor, Ashish and Bahl, Shivani},
booktitle = {Proceedings of the 14th International Conference on Information Processing in Sensor Networks},
doi = {10.1145/2737095.2742560},
isbn = {978-1-4503-3475-4},
pages = {410--411},
publisher = {ACM},
series = {IPSN '15},
title = {{Games of Drones: An Affective Game with Cyber-physical Systems}},
url = {http://doi.acm.org/10.1145/2737095.2742560},
year = {2015}
}
@inproceedings{Zhao2008,
abstract = {This paper focuses on the location of the signal strength, and introduces the simple signal propagation model and an empirical model based on linear regression which is suitable for non-visible environments. Based on the two models, the object position is solved by simplex method. The simulation results demonstrate the proposed indoor positioning method using linear regression method and simplex method has good positioning performance. {\textcopyright} 2008 IEEE.},
annote = {cited By 1},
author = {Zhao, J and Ren, J and Yue, H and Lai, Z},
booktitle = {2008 International Conference on Wireless Communications, Networking and Mobile Computing, WiCOM 2008},
doi = {10.1109/WiCom.2008.495},
keywords = {Empirical models; Indoor positioning; Indoor posi,Linear regression; Mobile computing; Regression an,Wireless networks},
title = {{Combined linear regression and simplex method for signal strength based indoor position}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-58049093868{\&}doi=10.1109{\%}2FWiCom.2008.495{\&}partnerID=40{\&}md5=bea41b5b74f484184a44684b2792445a},
year = {2008}
}
@inproceedings{Zhao2008532,
abstract = {This paper proposes the Autonomous Ultrasonic Indoor Tracking System (AUITS), an ultrasound based system for locating and tracking mobile objects inside a building. Ultrasound shows promise to be exploited for a practical indoor location system due to its high accuracy ranging, low cost, safety, and imperceptibility. However, conventional ultrasonic location systems pose such challenges as high installation cost and manual calibration. The key idea of AUITS is to use only one autonomous device, Positioning on One Device (POD), to not only process signal acquisition but also conduct position computation. Structural topology is designed to make POD easily deployed and easily calibrated. In addition, a structural localization algorithm is proposed to provide an effective and affordable algorithm for POD to calculate the object's position. We describe the hardware prototype implementation of AUITS and evaluate its performance both experimentally and with simulation. The results show that the coverage area of a POD can reach 65 m2 and the positioning error is less than 15 cm with over 90{\%} probability. {\textcopyright} 2008 IEEE.},
annote = {cited By 15},
author = {Zhao, J and Wang, Y},
booktitle = {Proceedings of the 2008 International Symposium on Parallel and Distributed Processing with Applications, ISPA 2008},
doi = {10.1109/ISPA.2008.37},
keywords = {Acoustic waves; Distributed parameter networks; Lo,Autonomous devices; Coverage areas; Hardware prot,Ultrasonics},
pages = {532--539},
title = {{Autonomous ultrasonic indoor tracking system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-60649085775{\&}doi=10.1109{\%}2FISPA.2008.37{\&}partnerID=40{\&}md5=7bd0c81575bfaf0267ad4c1fa5344159},
year = {2008}
}
@inproceedings{Zhao201621,
abstract = {Enterprises are paying more attention to warehouse management which has a pivotal role in enhancing productivity of the whole supply chain. As a key enabling technology for business intelligence(BI) applications, indoor positioning contributes to the object location awareness in warehouse management such as order picking and stock taking. In this work, we propose a new and cost-effective indoor positioning approach using iBeacon technology released by Apple, Inc. for warehouse management. Also, improved trilateration and fingerprinting algorithms are proposed for a real-life case of warehouse management. Our results show that the proposed scheme can significantly improve the performance of order picking and stock taking process in warehouse management with high accuracy. The location related business intelligence can be achieved. {\textcopyright} 2016 IEEE.},
annote = {cited By 3},
author = {Zhao, Z and Fang, J and Huang, G Q and Zhang, M},
booktitle = {2016 4th International Symposium on Computational and Business Intelligence, ISCBI 2016},
doi = {10.1109/ISCBI.2016.7743254},
keywords = {Cost effectiveness; Indoor positioning systems; In,Enabling technologies; Fingerprinting; Fingerprin,Warehouses},
pages = {21--26},
title = {{IBeacon enabled indoor positioning for warehouse management}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85005952366{\&}doi=10.1109{\%}2FISCBI.2016.7743254{\&}partnerID=40{\&}md5=68c64516d92308287ad8fc14796219d6},
year = {2016}
}
@article{Zhou20111155,
abstract = {With the advances in wireless communication technologies and smart mobile devices, Location-based Services (LBS), which provide personalized services based on users' location information, have been widely applied in military, transportation, logistics etc. Currently, mainstream positioning techniques are mainly divided into three categories, including satellite-based positioning, network infrastructure-based positioning and presence sensing positioning. With the help of effective spatio-temporal indexes, LBS are capable of processing the service requests efficiently. LBS usually employ different location privacy preservation methods to protect the user privacy. Recently, because of the complexity of applications, the cooperation of multiple positioning techniques and the huge data volume, new challenges emerge. Indoor LBS, management of uncertain data, novel location privacy protection method, LBS on cloud infrastructure and social LBS are becoming critical issues. This paper introduces the architecture of an LBS system and the key techniques of its components. Second, After reviewing the main progresses in recent years, we discuss the future work briefly.},
annote = {cited By 58},
author = {Zhou, A.-Y. and Yang, B and Jin, C.-Q. and Ma, Q},
doi = {10.3724/SP.J.1016.2011.01155},
journal = {Jisuanji Xuebao/Chinese Journal of Computers},
keywords = {Critical infrastructures; Data privacy; Mobile de,Critical issues; Data volume; Key techniques; Loca,Tracking (position)},
number = {7},
pages = {1155--1171},
title = {{Location-based services: architecture and progress}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79961103978{\&}doi=10.3724{\%}2FSP.J.1016.2011.01155{\&}partnerID=40{\&}md5=52b247d1230fef4a4f32d602eb7b6bd3},
volume = {34},
year = {2011}
}
@article{8607106,
abstract = {The lack of digital floor plans is a huge obstacle to pervasive indoor location based services (LBS). Recent floor plan construction work crowdsources mobile sensing data from smartphone users for scalability. However, they incur long time (e.g., weeks or months) and tremendous efforts in data collection. In this paper, we propose BatMapper, which explores a previously untapped sensing modality - acoustics - for fast, fine grained and low cost floor plan construction. We design sound signals suitable for heterogeneous microphones on commodity smartphones, and acoustic signal processing techniques to produce accurate distance measurements to nearby objects. We further develop robust probabilistic echo-object association, recursive outlier removal and probabilistic resampling algorithms to identify the correspondence between distances and objects, thus the geometry of corridors and rooms. We compensate minute hand sway movements to identify small surface recessions, thus detecting doors automatically. Experiments in real buildings show BatMapper achieves 1-2 cm distance accuracy in ranges up around 4 m; a 2{\~{}}3 minute walk generates fine grained corridor shapes, detects doors at 92{\%} precision and 1{\~{}}2 m location error at 90-percentile; and tens of seconds of measurement gestures produce room geometry with errors {\textless}0.3 m at 80-percentile, at 1-2 orders of magnitude less data amounts and user efforts.},
author = {Zhou, B and Elbadry, M and Gao, R and Ye, F},
doi = {10.1109/TMC.2019.2892091},
issn = {1536-1233},
journal = {IEEE Transactions on Mobile Computing},
keywords = {Microphones;Acoustics;Frequency modulation;Smart p},
pages = {1},
title = {{Towards Scalable Indoor Map Construction and Refinement using Acoustics on Smartphones}},
year = {2019}
}
@inproceedings{Zhou:2017:DAS:3117811.3119864,
address = {New York, NY, USA},
author = {Zhou, Bing and Elbadry, Mohammed and Gao, Ruipeng and Ye, Fan},
booktitle = {Proceedings of the 23rd Annual International Conference on Mobile Computing and Networking},
doi = {10.1145/3117811.3119864},
isbn = {978-1-4503-4916-1},
keywords = {acoustic sensing,indoor floor plans,smartphones},
pages = {519--521},
publisher = {ACM},
series = {MobiCom '17},
title = {{Demo: Acoustic Sensing Based Indoor Floor Plan Construction Using Smartphones}},
url = {http://doi.acm.org/10.1145/3117811.3119864},
year = {2017}
}
@article{Zhou2009669,
abstract = {Localization of tagged objects is a valuable addition to the application of radio frequency identification (RFID) technology. This paper studies the localization performance in an indoor environment with an active RFID system. Three major localization methods, namely, multi-lateration, nearest-neighbor, and support vector machines (SVM) methods are implemented, and their results are compared. It shows that the SVM method outperforms the other two in terms of localization accuracy, but the three methods produce comparable localization precision values. For each method, observations and discussion are provided on how data sample size, beacon number, or neighbor number influences localization performance. In addition, time complexities of the three methods are compared. It is pointed out that, for practical applications, a balanced consideration of localization performance, method, hardware cost, and data collection effort is required for economical and yet satisfactory solutions. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
annote = {cited By 16},
author = {Zhou, J and Shi, J},
doi = {10.1016/j.compind.2009.05.002},
journal = {Computers in Industry},
keywords = {Active RFID; Active RFID systems; Data collection;,Image retrieval; Object recognition; Radio freque,Support vector machines},
number = {9},
pages = {669--676},
title = {{Performance evaluation of object localization based on active radio frequency identification technology}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349440593{\&}doi=10.1016{\%}2Fj.compind.2009.05.002{\&}partnerID=40{\&}md5=eaa30e58d001bf2d0758dfd6d394bb09},
volume = {60},
year = {2009}
}
@article{Zhou:2016:GSC:2915302.2915306,
address = {Chichester, UK},
author = {Zhou, Jie and Jiang, Hao and Kikuchi, Hisakazu},
doi = {10.1002/dac.2854},
issn = {1074-5351},
journal = {Int. J. Commun. Syst.},
keywords = {The theory of mobile communication,circular and elliptical scattering models,directional antenna,geometry-based channel model,probability density function,radio propagation environments,wireless sensor networks},
number = {3},
pages = {459--477},
publisher = {John Wiley and Sons Ltd.},
title = {{Geometry-based Statistical Channel Model and Performance for MIMO Antennas}},
url = {http://dx.doi.org/10.1002/dac.2854},
volume = {29},
year = {2016}
}
@article{Zhou2013437,
abstract = {With the development of technology and the proliferation of mobile computing devices, people's need for pervasive computing is rapidly growing. As a critical part of pervasive computing, Location Based Service (LBS) has drawn more and more attention. Localization techniques that report the real-time position of a moving object are key in this area. So far, the outdoor localization technologies (i.e, GPS) are relatively mature, while the indoor localization technologies are still under improvement. In this paper, we propose a novel WiFi localization method, called FIMO (FInd Me Out). In this method, we take the instability of signal strength and the movement of objects into consideration when determining the location based on Fingerprint. Experimental results show the proposed method is capable of estimating a moving object's location precisely. {\textcopyright} 2013 Springer-Verlag.},
annote = {cited By 2},
author = {Zhou, Y and Jin, L and Jin, C and Zhou, A},
doi = {10.1007/978-3-642-37401-2_44},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Location based services; Technology; Ubiquitous c,Tracking (position),indoor; Indoor localization; LBS; localization; Lo},
pages = {437--448},
title = {{FIMO: A novel WiFi localization method}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875871308{\&}doi=10.1007{\%}2F978-3-642-37401-2{\_}44{\&}partnerID=40{\&}md5=a1932bdb34e111a79c56c9c0c51b87a9},
volume = {7808 LNCS},
year = {2013}
}
@article{Zhou:2008:AAS:2322615.2324371,
address = {Piscataway, NJ, USA},
author = {Zhou, Zhongna and Chen, Xi and Chung, Yu-Chia and He, Zhihai and Han, T X and Keller, J M},
doi = {10.1109/TCSVT.2008.2005612},
issn = {1051-8215},
journal = {IEEE Trans. Cir. and Sys. for Video Technol.},
keywords = {Action recognition,activity analysis,eldercare,video summarization},
number = {11},
pages = {1489--1498},
publisher = {IEEE Press},
title = {{Activity Analysis, Summarization, and Visualization for Indoor Human Activity Monitoring}},
url = {https://doi.org/10.1109/TCSVT.2008.2005612},
volume = {18},
year = {2008}
}
@article{Zhu2018336,
abstract = {Indoor landmarks play an important role in the location-based service (LBS). On account of outdoor landmark extraction methods can not be fully applicable to complex indoor environment, we propose a suitable indoor landmark saliency quantitative evaluation model to extract indoor landmarks. In this paper, large shopping malls are regarded as research site, after analyzing the factors influencing the saliency of POI objects from perceptual, cognitive and spatial structure, a saliency measure model composed of these factors is constructed. Finally, we compute the significances of the POIs selected from the interior of Chicony shopping mall of Wuhan city. In this experiment, several level of landmarks are extracted to reflect different size of spatial knowledge in indoor spaces. Extracted indoor landmarks can be important symbols in indoor intelligent navigation system and as key clues in a large shopping malls wayfinding, multi-granularity route directions. {\textcopyright} 2018, Research and Development Office of Wuhan University. All right reserved.},
annote = {cited By 1},
author = {Zhu, H and Wen, Y and Mao, K and Li, L and Li, G and Li, Y},
doi = {10.13203/j.whugis20150149},
journal = {Wuhan Daxue Xuebao (Xinxi Kexue Ban)/Geomatics and Information Science of Wuhan University},
keywords = {Extraction; Mobile devices; Navigation systems; Sh,Hierarchy; Indoor environment; Indoor landmarks;,Location based services},
number = {3},
pages = {336--341},
title = {{A Quantitative POI Salience Model for Indoor Landmark Extraction}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047198093{\&}doi=10.13203{\%}2Fj.whugis20150149{\&}partnerID=40{\&}md5=e5cba09731e5ef4af8f8346203184cdc},
volume = {43},
year = {2018}
}
@inproceedings{Zhu2018428,
abstract = {Location-based services have become an important market. At their core, location-based services generally rely on identifying the location of individuals or objects. In outdoor environments, determining the location is typically accomplished by means of GPS. In indoor environments, Bluetooth Low Energy (BLE) based localization has received a lot of attention. Most recently, an increasing number of mobile devices are capable of supporting ANT as an alternative low-power communication protocol. Unlike BLE, however, the suitability of ANT for localization has not been analyzed extensively. We report the initial results of an experimental study to compare ANT and BLE when used for localization. The results suggest that ANT-based localization can clearly outperform BLE, when using fingerprinting as the underlying localization principle. {\textcopyright} 2018 Association for Computing Machinery.},
annote = {cited By 0},
author = {Zhu, X and Handte, M and Eskicioglu, R},
booktitle = {SenSys 2018 - Proceedings of the 16th Conference on Embedded Networked Sensor Systems},
doi = {10.1145/3274783.3275217},
keywords = {Bluetooth low energies (BLE); Indoor environment;,Embedded systems; Indoor positioning systems; Loca,Location based services},
pages = {428--429},
title = {{Poster abstract: RF technologies for indoor localization and positioning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061742571{\&}doi=10.1145{\%}2F3274783.3275217{\&}partnerID=40{\&}md5=a284e8bf686a0c925c6f00f0d97da97a},
year = {2018}
}
@article{Zhu2015285,
abstract = {This paper analysis the limitations and challenges of the traditional digital map in ubiquitous information and big data era. We extend the original concept of a Pan-location Information Map (PLIM) that in the ubiquitous network environment. PLIM dynamically associates mutli-temporal, multi-thematic, multi-hierarchical, multi-granular information about objects or events based on location, and provides a personalized location and location-related information service platform. Also, we describe the structure and characteristics of a new PLIM and demonstrate the key technologies in three aspects, including ubiquitous information acquisition, semantic location correlation, and establishment of a multi-dimensional visualization map. {\textcopyright}, 2015, Wuhan Daxue Xuebao (Xinxi Kexue Ban)/Geomatics and Information Science of Wuhan University. All right reserved.},
annote = {cited By 8},
author = {Zhu, X and Zhou, C and Guo, W and Hu, T and Liu, H and Gao, W},
doi = {10.13203/j.whugis20140462},
journal = {Wuhan Daxue Xuebao (Xinxi Kexue Ban)/Geomatics and Information Science of Wuhan University},
keywords = {Big data; Information services; Semantics,Granular informations; Information service platfo,Location based services,digital map; mapping; visualization},
number = {3},
pages = {285--295},
title = {{Preliminary study on conception and key technologies of the location-based pan-information map}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925292754{\&}doi=10.13203{\%}2Fj.whugis20140462{\&}partnerID=40{\&}md5=251932b5d62d4c91a64fe2e00abc6aea},
volume = {40},
year = {2015}
}
@inproceedings{Zhu:2018:RTI:3274783.3275217,
address = {New York, NY, USA},
author = {Zhu, Xuanjiao and Handte, Marcus and Eskicioglu, Rasit},
booktitle = {Proceedings of the 16th ACM Conference on Embedded Networked Sensor Systems},
doi = {10.1145/3274783.3275217},
isbn = {978-1-4503-5952-8},
pages = {428--429},
publisher = {ACM},
series = {SenSys '18},
title = {{RF Technologies for Indoor Localization and Positioning}},
url = {http://doi.acm.org/10.1145/3274783.3275217},
year = {2018}
}
@article{6305475,
abstract = {Active environment perception and autonomous place recognition play a key role for mobile robots to operate within a cluttered indoor environment with dynamic changes. This paper presents a 3-D-laser-based scene measurement technique and a novel place recognition method to deal with the random disturbances caused by unexpected movements of people and other objects. The proposed approach can extract and match the Speeded-Up Robust Features (SURFs) from bearing-angle images generated by a self-built rotating 3-D laser scanner. It can cope with the irregular disturbance of moving objects and the problem of observing-location changes of the laser scanner. Both global metric information and local SURF features are extracted from 3-D laser point clouds and 2-D bearing-angle images, respectively. A large-scale indoor environment with over 1600 m2 and 30 offices is selected as a testing site, and a mobile robot, i.e., SmartROB2, is deployed for conducting experiments. Experimental results show that the proposed 3-D-laser-based scene measurement technique and place recognition approach are effective and provide robust performance of place recognition in a dynamic indoor environment.},
author = {Zhuang, Y and Jiang, N and Hu, H and Yan, F},
doi = {10.1109/TIM.2012.2216475},
issn = {0018-9456},
journal = {IEEE Transactions on Instrumentation and Measurement},
keywords = {feature extraction;image matching;mobile robots;op},
number = {2},
pages = {438--450},
title = {{3-D-Laser-Based Scene Measurement and Place Recognition for Mobile Robots in Dynamic Indoor Environments}},
volume = {62},
year = {2013}
}
@article{Zhuang20111232,
abstract = {This paper mainly studies the indoor scene cognition problem for mobile robots. The structure of an indoor scene is assumed to be structured, while indoor objects are in a variety of forms, which are difficult to be represented by specific descriptive models. In our work, planes are extracted from 3D laser data using regional expansion algorithm, and the properties as well as the relationship of these planes are used for the indoor structure identification. In order to adopt digital image processing algorithm to implement object detection, a bearing angle model is used to represent laser point clouds, so that 3D laser scanning data can be converted to 2D bearing angle image. It is difficult to detect a large number of different classes of objects in cluttered indoor scenes, especially when the mobile robot acquires the 3D laser scanning data in different locations and angles of view. An approach based on gentleboost algorithm is proposed for multi-class object detection, which takes the fragments and the location with respect to the object center as the generic features for object detection. As the result of indoor structure identification, the specific region for ceiling, floor, wall and door can be labeled in the bearing angle image. With the help of known semantic information, the false object detection results can be eliminated effectively. Experiment results implemented on a real mobile robot show the validity of the proposed method. Copyright {\textcopyright} 2011 Acta Automatica Sinica. All rights reserved.},
annote = {cited By 7},
author = {Zhuang, Y and Lu, X.-B. and Li, Y.-H. and Wang, W},
doi = {10.3724/SP.J.1004.2011.01232},
journal = {Zidonghua Xuebao/Acta Automatica Sinica},
keywords = {3D Laser scanning; Descriptive Model; False object,Algorithms; Laser applications; Mobile robots; Ob,Three dimensional},
number = {10},
pages = {1232--1240},
title = {{Mobile robot indoor scene cognition using 3D laser scanning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-81055145601{\&}doi=10.3724{\%}2FSP.J.1004.2011.01232{\&}partnerID=40{\&}md5=d14de8ec2ca6501eb63ab9442ad276e8},
volume = {37},
year = {2011}
}
@article{Ziegler2012,
abstract = {The reliable automatic visual recognition of indoor scenes with complex object constellations using only sensor data is a nontrivial problem. In order to improve the construction of an accurate semantic 3D model of an indoor scene, we exploit human-produced verbal descriptions of the relative location of pairs of objects. This requires the ability to deal with different spatial reference frames (RF) that humans use interchangeably. In German, both the intrinsic and relative RF are used frequently, which often leads to ambiguities in referential communication. We assume that there are certain regularities that help in specific contexts. In a first experiment, we investigated how speakers of German describe spatial relationships between different pieces of furniture. This gave us important information about the distribution of the RFs used for furniture-predicate combinations, and by implication also about the preferred spatial predicate. The results of this experiment are compiled into a computational model that extracts partial orderings of spatial arrangements between furniture items from verbal descriptions. In the implemented system, the visual scene is initially scanned by a 3D camera system. From the 3D point cloud, we extract point clusters that suggest the presence of certain furniture objects. We then integrate the partial orderings extracted from the verbal utterances incrementally and cumulatively with the estimated probabilities about the identity and location of objects in the scene, and also estimate the probable orientation of the objects. This allows the system to significantly improve both the accuracy and richness of its visual scene representation. {\textcopyright} 2012 Marta Olivetti Belardinelli and Springer-Verlag.},
annote = {cited By 2},
author = {Ziegler, L and Johannsen, K and Swadzba, A and {De Ruiter}, J P and Wachsmuth, S},
doi = {10.1007/s10339-012-0460-1},
journal = {Cognitive Processing},
keywords = {Computer Simulation; Humans; Models,Psychological; Orientation; Pattern Recognition,Visual; Photic Stimulation; Space Perception,article; human; language ability; mathematical mod},
number = {1 SUPPL},
pages = {S369--S374},
title = {{Exploiting spatial descriptions in visual scene analysis}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872772829{\&}doi=10.1007{\%}2Fs10339-012-0460-1{\&}partnerID=40{\&}md5=7fa98fdae884d4d5961aa4f17f14cf33},
volume = {13},
year = {2012}
}
@article{Zuo20162983,
abstract = {Deep convolutional neural networks (CNNs) have shown their great success on image classification. CNNs mainly consist of convolutional and pooling layers, both of which are performed on local image areas without considering the dependence among different image regions. However, such dependence is very important for generating explicit image representation. In contrast, recurrent neural networks (RNNs) are well known for their ability of encoding contextual information in sequential data, and they only require a limited number of network parameters. Thus, we proposed the hierarchical RNNs (HRNNs) to encode the contextual dependence in image representation. In HRNNs, each RNN layer focuses on modeling spatial dependence among image regions from the same scale but different locations. While the cross RNN scale connections target on modeling scale dependencies among regions from the same location but different scales. Specifically, we propose two RNN models: 1) hierarchical simple recurrent network (HSRN), which is fast and has low computational cost and 2) hierarchical long-short term memory recurrent network, which performs better than HSRN with the price of higher computational cost. In this paper, we integrate CNNs with HRNNs, and develop end-to-end convolutional hierarchical RNNs (C-HRNNs) for image classification. C-HRNNs not only utilize the discriminative representation power of CNNs, but also utilize the contextual dependence learning ability of our HRNNs. On four of the most challenging object/scene image classification benchmarks, our C-HRNNs achieve the state-of-the-art results on Places 205, SUN 397, and MIT indoor, and the competitive results on ILSVRC 2012. {\textcopyright} 2016 IEEE.},
annote = {cited By 26},
author = {Zuo, Z and Shuai, B and Wang, G and Liu, X and Wang, X and Wang, B and Chen, Y},
doi = {10.1109/TIP.2016.2548241},
journal = {IEEE Transactions on Image Processing},
keywords = {C (programming language); Convolution; Costs; Enco,Contextual information; Convolutional neural netw,Image classification},
number = {7},
pages = {2983--2996},
title = {{Learning Contextual Dependence With Convolutional Hierarchical Recurrent Neural Networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971671959{\&}doi=10.1109{\%}2FTIP.2016.2548241{\&}partnerID=40{\&}md5=6fea18e037a4b4f95f0bcb4fb7d4d1d2},
volume = {25},
year = {2016}
}
@article{Zhu2014,
abstract = {Localization in wireless sensor networks is an important functionality that is required for tracking personnel and assets in industrial environments, especially for emergency response. Current commercial localization systems such as GPS suffer from the limitations of either high cost or low availability in many situations (e.g., indoor environments that exclude direct line-of-sight signal reception). The development of industrial wireless sensor networks such as WirelessHART provides an alternative. In this article, we present the design and implementation of ColLoc: a collaborative location and tracking system on WirelessHART as an industrially viable solution. This solution is built upon several technological advances. First, ColLoc adds the roaming functionality to WirelessHART and thus provides a means for keeping mobile WirelessHART devices connected to the network. Second, ColLoc employs a collaborative framework to integrate different types of distance measurements into the location estimation algorithm by weighing them according to their precision levels. ColLoc adopts several novel techniques to improve distance estimation accuracy and decreases the RSSI presurvey cost. These techniques include introducing distance error range constraints to the measurements, judiciously selecting the initial point in location estimation and online updating the signal propagationmodels in the anchor nodes, integrating Extended Kalman Filter (EKF) with trilateration to track moving objects. Our implementation of ColLoc can be applied to any WirelessHART-conforming network because no modification is needed on the WirelessHART field devices. We have implemented a complete ColLoc system to validate both the design and the effectiveness of our localization algorithm. Our experiments show that the mobile device never drops out of the WirelessHART network while moving around; with the help of even one dependable anchor, using RSSI can yield at least 75{\%} of distance errors below 5 meters, which is quite acceptable for many typical industrial automation applications. {\textcopyright} 2014 ACM.},
annote = {cited By 5},
author = {Zhu, X and Huang, P.-C. and Meng, J and Han, S and Mok, A K and Chen, D and Nixon, M},
doi = {10.1145/2584656},
journal = {Transactions on Embedded Computing Systems},
keywords = {Collaborative TOA/RSSI localization; Localization,Extended Kalman filters; Mobile devices; Surveying,Tracking (position)},
number = {4 SPEC. ISSUE},
title = {{ColLoc: A collaborative location and tracking system on WirelessHART}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905973451{\&}doi=10.1145{\%}2F2584656{\&}partnerID=40{\&}md5=dedb0b4a6645325b967a456fda4caa85},
volume = {13},
year = {2014}
}
@inproceedings{Vaucelle20094309,
abstract = {In this paper we present the design of a cost-effective wearable sensor to detect and indicate the strength and other characteristics of the electric field emanating from a laptop display. Our Electromagnetic Field Detector Bracelet can provide an immediate awareness of electric fields radiated from an object used frequently. Our technology thus supports awareness of ambient background emanation beyond human perception. We discuss how detection of such radiation might help to "fingerprint" devices and aid in applications that require determination of indoor location.},
annote = {cited By 3},
author = {Vaucelle, C and Paradiso, J A and Ishii, H},
booktitle = {Conference on Human Factors in Computing Systems - Proceedings},
doi = {10.1145/1520340.1520658},
keywords = {Abstracting; Computer science; Cost effectiveness,Ambient signals; Capacitive sensor; Electromagneti,Sensors},
pages = {4309--4314},
title = {{Cost-effective wearable sensor to detect EMF}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349191193{\&}doi=10.1145{\%}2F1520340.1520658{\&}partnerID=40{\&}md5=d6d1715cbc1e1b7128561c1221193612},
year = {2009}
}
@article{Pestana2012136,
abstract = {The SECAIR project provides an event-driven architecture for critical environments. It deals with context awareness issues and surveillance of moving objects in real-time. The proposed architecture adopts a data fusion process to handle with location based data. It is therefore well-suited for business activity monitoring, supporting managers at analysing and processing complex event streams in real-time. A prototype applied to the surveillance of situation awareness for airport environments is presented. The main goal is to monitor for events in very congested areas for indoor and outdoor areas. The SECAIR system provides a collaborative environment for a better management of ground handling operations, in compliance with existing business rules. An advanced Graphical-User Interface with geographical and analytical capabilities is also presented. {\textcopyright} 2012 Springer-Verlag.},
annote = {cited By 0},
author = {Pestana, G and Metter, J and Heuchler, S and Reis, P},
doi = {10.1007/978-3-642-34624-8_16},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Airport security; Data fusion; Intelligent system,Control services; Event-driven architectures; Situ,Digital storage},
pages = {136--142},
title = {{An event-driven architecture for spatio-temporal surveillance of business activities}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870926865{\&}doi=10.1007{\%}2F978-3-642-34624-8{\_}16{\&}partnerID=40{\&}md5=2906b0940df9b67a137bed992bea8983},
volume = {7661 LNAI},
year = {2012}
}
@inproceedings{Samadi20122074,
abstract = {In order for robots to intelligently perform tasks with humans, they must be able to access a broad set of background knowledge about the environments in which they operate. Unlike other approaches, which tend to manually define the knowledge of the robot, our approach enables robots to actively query the World Wide Web (WWW) to learn background knowledge about the physical environment. We show that our approach is able to search the Web to infer the probability that an object, such as a "coffee," can be found in a location, such as a "kitchen." Our approach, called ObjectEval, is able to dynamically instantiate a utility function using this probability, enabling robots to find arbitrary objects in indoor environments. Our experimental results show that the interactive version of ObjectEval visits 28{\%} fewer locations than the version trained offline and 71{\%} fewer locations than a baseline approach which uses no background knowledge. Copyright {\textcopyright} 2012, Association for the Advancement of Artificial Intelligence. All rights reserved.},
annote = {cited By 23},
author = {Samadi, M and Kollar, T and Veloso, M},
booktitle = {Proceedings of the National Conference on Artificial Intelligence},
keywords = {Arbitrary objects; Background knowledge; Indoor en,Artificial intelligence; Robots,World Wide Web},
pages = {2074--2080},
title = {{Using the web to interactively learn to find objects}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868266394{\&}partnerID=40{\&}md5=22290953d69caedee452f86b8afcc4f3},
volume = {3},
year = {2012}
}
@article{Lihan2008169,
abstract = {There have been a large amount of research and interest in the area of ubiquitous and indoor location aware computing in the past decade. Among several proposed algorithms, fingerprint algorithm stands as one of the most accurate systems for localization. However, there is a lack of theoretical basis and understanding on the orientation of the user. This paper presents a model for orientation-aware indoor location tracking system using a Zigbee based protocol wireless sensor called Sun's SPOT (Small Programmable Object Technology). Our experiment shows better accuracy in location tracking when orientation and attenuation factors are considered for the path loss prediction model than the traditional path loss model. Orientation-aware fingerprint algorithm is also examined in our experiment to have a basis of comparison on an empirical algorithm. {\textcopyright} Springer-Verlag Berlin Heidelberg 2008.},
annote = {cited By 11},
author = {Lihan, M and Tsuchiya, T and Koyanagi, K},
doi = {10.1007/978-3-540-85693-1_19},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Attenuation factors; Fingerprint algorithm; Indoo,Cellular radio systems; Experiments; Forecasting;,Wireless sensor networks},
pages = {169--178},
title = {{Orientation-aware indoor localization path loss prediction model for wireless sensor networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-52149104921{\&}doi=10.1007{\%}2F978-3-540-85693-1{\_}19{\&}partnerID=40{\&}md5=857df575081788291440695661b4f673},
volume = {5186 LNCS},
year = {2008}
}
@article{Niu20141901,
abstract = {Indoor tracking systems have become very popular, wherein pedestrian movement is analyzed in a variety of commercial and secure spaces. The inertial sensor-based method makes great contributions to continuous and seamless indoor pedestrian tracking. However, such a system is vulnerable to the cumulative locating errors when moving distance increases. Inaccurate heading values caused by the interference of body swing of natural walking and the geomagnetic disturbances are the main sources of the accumulative errors. To reduce such errors, additional infrastructure or highly accurate sensors have been used by previous works that considerably raise the complexity of the architecture. This paper presents an indoor pedestrian tracking system called WTrack, using only geomagnetic sensors and acceleration sensors that are commonly carried by smartphones. A fine-grained walk pattern of indoor pedestrians is modeled through Hidden Markov Model. With this model, WTrack can track indoor pedestrians by continuously recognizing the pre-defined pedestrians' walk pattern. More importantly, WTrack is able to resist both the interference of body swing of natural walking and the geomagnetic disturbances of nearby objects. Our experimental results reveal that the location error is {\textless}2m, which is considered adequate for indoor location-based-service applications. The adaptive sample rate adjustment mode further reduces the energy consumption by 52{\%} in comparison, as opposed to the constant sampling mode. {\textcopyright} 2014, Springer-Verlag London.},
annote = {cited By 4},
author = {Niu, X and Li, M and Cui, X and Liu, J and Liu, S and Chowdhury, K R},
doi = {10.1007/s00779-014-0796-x},
journal = {Personal and Ubiquitous Computing},
keywords = {Acceleration sensors; Accumulative errors; Geomag,Energy utilization; Errors; Geomagnetism; Hidden M,Location based services},
number = {8},
pages = {1901--1915},
title = {{WTrack: HMM-based walk pattern recognition and indoor pedestrian tracking using phone inertial sensors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921068950{\&}doi=10.1007{\%}2Fs00779-014-0796-x{\&}partnerID=40{\&}md5=8bb441996ee2b5ffd38e9ae1e2de3dc0},
volume = {18},
year = {2014}
}
@article{Rivadeneyra20111508,
abstract = {Recent research has shown that robots can model their world with Multi-Level (ML) maps, which utilize patches in a two-dimensional grid space to represent various environment elevations within a given grid cell. Although these maps are able to produce three-dimensional models of the environment while exploiting the computational feasibility of single elevation maps, they do not take into account in-plane uncertainty when matching measurements to grid cells or when grouping those measurements into patches. To respond to these drawbacks, this paper proposes to extend these ML maps into Probabilistic Multi-Level (PML) maps, which use formal probability theory to incorporate estimation and modeling errors due to uncertainty. Measurements are probabilistically associated with cells near the nominal location, and are categorized through hypothesis testing into patches via classification methods that incorporate uncertainty. Experimental results on representative objects found in both indoor and outdoor environments show that PML generally outperforms ML, including in noisy and sparse data environments, by producing more consistent, informative and conservative maps. In addition, PML provides the framework to heterogeneous, cooperative mapping and a way to probabilistically discriminate between conflicting maps. {\textcopyright} SAGE Publications 2011.},
annote = {cited By 6},
author = {Rivadeneyra, C and Campbell, M},
doi = {10.1177/0278364910392405},
journal = {International Journal of Robotics Research},
keywords = {3-D mapping; Classification methods; Computational,Mapping; Optical radar; Uncertainty analysis,Three dimensional},
number = {12},
pages = {1508--1526},
title = {{Probabilistic multi-level maps from LIDAR data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054757202{\&}doi=10.1177{\%}2F0278364910392405{\&}partnerID=40{\&}md5=c15ab1f6096475a5601817be5f3054c1},
volume = {30},
year = {2011}
}
@inproceedings{Baba2017134,
abstract = {Radio Frequency Identification (RFID) has evolved as a primary object tracking technology over the years. A Number of real world applications such as airport passenger baggage tracking have adapted RFID as a main technological tool for tracking and monitoring. However, the data generated by the RFID tracking contains errors. Therefore, it is important to remove such errors before data is used for any business processing. The primary focus of this paper is object bouncing problem, which happens when the object with attached RFID tag is detected by two or more RFID readers simultaneously or within a short period of time. Due to the bouncing, object appears to go back and forth between several locations in very short time, which is not realistically possible. To cater bouncing problem we exploit the reach-ability time constraints implied by the deployed readers in an indoor space. We evaluate the proposed work using the synthetically generated RFID data. The results shows that the approach is effective and efficient. {\textcopyright} 2017 ACM.},
annote = {cited By 0},
author = {Baba, A},
booktitle = {Proceedings of the SouthEast Conference, ACMSE 2017},
doi = {10.1145/3077286.3077568},
keywords = {Airport passenger; Business processing; Data anoma,Radio frequency identification (RFID)},
pages = {134--141},
title = {{Removing object bouncing from indoor tracking data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021406221{\&}doi=10.1145{\%}2F3077286.3077568{\&}partnerID=40{\&}md5=abbc0d53d7c29ef7dad438a5aeedc164},
year = {2017}
}
@inproceedings{Paucher20109,
abstract = {The computational capability of mobile phones has been rapidly increasing, to the point where augmented reality has become feasible on cell phones. We present an approach to indoor localization and pose estimation in order to support augmented reality applications on a mobile phone platform. Using the embedded camera, the application localizes the device in a familiar environment and determines its orientation. Once the 6 DOF pose is determined, 3D virtual objects from a database can be projected into the image and displayed for the mobile user. Off-line data acquisition consists of acquiring images at different locations in the environment. The online pose estimation is done by a featurebased matching between the cell phone image and an image selected from the precomputed database using the phone's sensors (accelerometer and magnetometer). The application enables the user both to visualize virtual objects in the camera image and to localize the user in a familiar environment. We describe in detail the process of building the database and the pose estimation algorithm used on the mobile phone. We evaluate the algorithm performance as well as its accuracy in terms of reprojection distance of the 3D virtual objects in the cell phone image. {\textcopyright} 2010 IEEE.},
annote = {cited By 41},
author = {Paucher, R and Turk, M},
booktitle = {2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops, CVPRW 2010},
doi = {10.1109/CVPRW.2010.5543249},
keywords = {Algorithm performance; Augmented reality applicati,Augmented reality; Cameras; Computer vision; Data,Three dimensional},
pages = {9--16},
title = {{Location-based augmented reality on mobile phones}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956504352{\&}doi=10.1109{\%}2FCVPRW.2010.5543249{\&}partnerID=40{\&}md5=5ee1272f65eaa20a6d532e05ba1dda22},
year = {2010}
}
@inproceedings{Othman20181,
abstract = {This paper proposes a method for indoor localization by introducing an online Radio Frequency (RF) fingerprinting approach instead of the traditional offline RF fingerprinting. The offline phase is a time-consuming stage where manual measurements made by the user cannot be at high accuracy due to the fact of shadowing effect that human body causes during the construction of RF radio map. Moreover, outdated RF radio map is another issue when it comes to the dynamic environment conditions (displacement of objects, moving people and/or the opening and closing of room doors). By proposing online fingerprinting, the problems mentioned above are solved by obtaining real-time RF maps and estimating an unknown location accordingly. Our method is unique when it comes to the approach, devices and the environment of deployment, and it has successfully shown up to 23{\%} improvement in localization accuracy. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Othman, H and At, N and Topal, C},
booktitle = {26th IEEE Signal Processing and Communications Applications Conference, SIU 2018},
doi = {10.1109/SIU.2018.8404808},
keywords = {Fingerprinting; Indoor; Localization; Online; Pos,Indoor positioning systems,Signal processing},
pages = {1--4},
title = {{Effectiveness of online RF fingerprinting for indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050812280{\&}doi=10.1109{\%}2FSIU.2018.8404808{\&}partnerID=40{\&}md5=9c4eb94f6660b8d40e92eb4242fdbaf8},
year = {2018}
}
@inproceedings{Mainetti2015704,
abstract = {Recent innovations in the ICT field are strongly focused towards the Internet of Things, which will definitely lead to an enhancement also in the domestic environments. Low-power and low-cost devices are expected to create a network of interconnected smart objects able to transform our homes into real Smart Homes. However, the heterogeneity of the underlying technologies prevents these smart objects to natively interoperate for adapting the environment to users' needs. In addition, common users are often excluded from the development of new applicative services that exploit physical devices, as they do not have sufficient programming and technological skills. To overcome these limitations, we propose a software ecosystem that allows different-skilled users to develop location-aware services able to autonomously manage the Smart Home. These services control the environment in accordance with user-defined rules and the users' location, calculated by exploiting an indoor localization mechanism. In addition, to directly interact with smart devices, users can also define customized interfaces for mobile devices. Finally, a multi-protocol middleware allows both the services and the mobile applications to access the physical network hiding the underlying heterogeneities. As a proof-of-concept, the first implementation steps are presented. {\textcopyright} 2015 IEEE.},
annote = {cited By 17},
author = {Mainetti, L and Mighali, V and Patrono, L},
booktitle = {IEEE International Conference on Communications},
doi = {10.1109/ICC.2015.7248404},
pages = {704--709},
title = {{An IoT-based user-centric ecosystem for heterogeneous Smart Home environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953744135{\&}doi=10.1109{\%}2FICC.2015.7248404{\&}partnerID=40{\&}md5=fe2681b05b81699a52fd7a759a3e92b3},
volume = {2015-Septe},
year = {2015}
}
@article{Riboni200939,
abstract = {In the last years, techniques for activity recognition have attracted increasing attention. Among many applications, a special interest is in the pervasive e-Health domain where automatic activity recognition is used in rehabilitation systems, chronic disease management, monitoring of the elderly, as well as in personal well being applications. Research in this field has mainly adopted techniques based on supervised learning algorithms to recognize activities based on contextual conditions (e.g., location, surrounding environment, used objects) and data retrieved from body-worn sensors. Since these systems rely on a sufficiently large amount of training data which is hard to collect, scalability with respect to the number of considered activities and contextual data is a major issue. In this paper, we propose the use of ontologies and ontological reasoning combined with statistical inferencing to address this problem. Our technique relies on the use of semantic relationships that express the feasibility of performing a given activity in a given context. The proposed technique neither increases the obtrusiveness of the statistical activity recognition system, nor introduces significant computational overhead to real-time activity recognition. The results of extensive experiments with data collected from sensors worn by a group of volunteers performing activities both indoor and outdoor show the superiority of the combined technique with respect to a solely statistical approach. To the best of our knowledge, this is the first work that systematically investigates the integration of statistical and ontological reasoning for activity recognition. {\textcopyright} 2009 Springer Berlin Heidelberg.},
annote = {cited By 57},
author = {Riboni, D and Bettini, C},
doi = {10.1007/978-3-642-02830-4_5},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Activity recognition; Body-worn sensors; Chronic d,Learning algorithms,Ontology; Patient rehabilitation; Sensors; Ubiqui},
pages = {39--53},
title = {{Context-aware activity recognition through a combination of ontological and statistical reasoning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350662015{\&}doi=10.1007{\%}2F978-3-642-02830-4{\_}5{\&}partnerID=40{\&}md5=943c49aa1b15d95aad8186470a8334d3},
volume = {5585 LNCS},
year = {2009}
}
@inproceedings{Conci20093485,
abstract = {In this paper, we propose a novel approach to automatically plan video cameras positioning in indoor environments for surveillance applications. In order to ensure maximum coverage of the observed scene, we have implemented an ad-hoc tool based on the particle swarm optimization. The camera is modeled as a 2D function. A Rayleigh distribution is used to characterize the relevance of the observed object with respect to the distance from the camera and a Gaussian distribution is adopted to model the horizontal field-of-view. Knowing the environment characteristics and the location of obstacles and walls, it is possible to derive a reliable positioning of the sensors. Results are first presented for very simple scenarios; the algorithm is then run to solve the problem in a more realistic environment model. {\textcopyright}2009 IEEE.},
annote = {cited By 10},
author = {Conci, N and Lizzi, L},
booktitle = {Proceedings - International Conference on Image Processing, ICIP},
doi = {10.1109/ICIP.2009.5413833},
keywords = {Camera model; Camera placement; D-function; Envir,Cameras; Image processing; Imaging systems; Monito,Security systems},
pages = {3485--3488},
title = {{Camera placement using particle swarm optimization in visual surveillance applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951973875{\&}doi=10.1109{\%}2FICIP.2009.5413833{\&}partnerID=40{\&}md5=d2ef1ab261c886f9890c70da2adeef65},
year = {2009}
}
@article{Gardner2017,
abstract = {We propose an automatic method to infer high dynamic range illumination from a single, limited field-of-view, low dynamic range photograph of an indoor scene. In contrast to previous work that relies on specialized image capture, user input, and/or simple scene models, we train an end-to-end deep neural network that directly regresses a limited field-of-view photo to HDR illumination, without strong assumptions on scene geometry, material properties, or lighting. We show that this can be accomplished in a three step process: 1) we train a robust lighting classifier to automatically annotate the location of light sources in a large dataset of LDR environment maps, 2) we use these annotations to train a deep neural network that predicts the location of lights in a scene from a single limited field-of-view photo, and 3) we fine-tune this network using a small dataset of HDR environment maps to predict light intensities. This allows us to automatically recover high-quality HDR illumination estimates that significantly outperform previous state-of-the-art methods. Consequently, using our illumination estimates for applications like 3D object insertion, produces photo-realistic results that we validate via a perceptual user study. {\textcopyright} 2017 Association for Computing Machinery.},
annote = {cited By 13},
author = {Gardner, M.-A. and Sunkavalli, K and Yumer, E and Shen, X and Gambaretto, E and Gagn{\'{e}}, C and Lalonde, J.-F.},
doi = {10.1145/3130800.3130891},
journal = {ACM Transactions on Graphics},
keywords = {Automatic method; Environment maps; High dynamic,Classification (of information); Deep learning; In,Deep neural networks},
number = {6},
title = {{Learning to predict indoor illumination from a single image}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038926287{\&}doi=10.1145{\%}2F3130800.3130891{\&}partnerID=40{\&}md5=032c1ce42bce7f5769cb5f88b530130c},
volume = {36},
year = {2017}
}
@article{Cai20104028,
abstract = {This paper presents a new stereo vision-based model for multi-object detection and tracking in surveillance systems. Unlike most existing monocular camera-based systems, a stereo vision system is constructed in our model to overcome the problems of illumination variation, shadow interference, and object occlusion. In each frame, a sparse set of feature points are identified in the camera coordinate system, and then projected to the 2D ground plane. A kernel-based clustering algorithm is proposed to group the projected points according to their height values and locations on the plane. By producing clusters, the number, position, and orientation of objects in the surveillance scene can be determined for online multi-object detection and tracking. Experiments on both indoor and outdoor applications with complex scenes show the advantages of the proposed system. {\textcopyright} 2010 Elsevier Ltd. All rights reserved.},
annote = {cited By 28},
author = {Cai, L and He, L and Xu, Y and Zhao, Y and Yang, X},
doi = {10.1016/j.patcog.2010.06.012},
journal = {Pattern Recognition},
keywords = {Cameras; Clustering algorithms; Object recognitio,Clustering; Co-ordinate system; Complex scenes; Fe,Stereo vision},
number = {12},
pages = {4028--4041},
title = {{Multi-object detection and tracking by stereo vision}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77957019955{\&}doi=10.1016{\%}2Fj.patcog.2010.06.012{\&}partnerID=40{\&}md5=1f58ca08b68e852d8bf3f507a2188fce},
volume = {43},
year = {2010}
}
@article{Patel2006272,
abstract = {Precise indoor localization is quickly becoming a reality, but application demonstrations to date have been limited to use of only a single piece of location information attached to an individual sensing device. The localized device is often held by an individual, allowing applications, often unreliably, to make high-level predictions of user intent based solely on that single piece of location information. In this paper, we demonstrate how effective integration of sensing and laser-assisted interaction results in a handheld device, the iCam, which simultaneously calculates its own location as well as the location of another object in the environment. We describe how iCam is built and demonstrate how location-aware at-a-distance interaction simplifies certain location-aware activities. {\textcopyright} Springer-Verlag Berlin Heidelberg 2006.},
annote = {cited By 9},
author = {Patel, S N and Rekimoto, J and Abowd, G D},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Computer science,Information analysis; Laser applications; Sensors,Laser-assisted interaction; Location information;},
pages = {272--287},
title = {{ICam: Precise at-a-distance interaction in the physical environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745931669{\&}partnerID=40{\&}md5=3afb28452bb77aa0c8add74a2577009c},
volume = {3968 LNCS},
year = {2006}
}
@article{Gorlatova201018,
abstract = {This article presents the design challenges posed by a new class of ultra-low-power devices referred to as Energy-Harvesting Active Networked Tags (EnHANTs). EnHANTs are small, flexible, and self-reliant (in terms of energy) devices that can be attached to objects that are traditionally not networked (e.g., books, furniture, walls, doors, toys, keys, produce, and clothing). EnHANTs will enable the Internet of Things by providing the infrastructure for various novel tracking applications. Examples of these applications include locating misplaced items, continuous monitoring of objects, and determining locations of disaster survivors. Recent advances in ultra-low-power circuit design, ultra-wideband (UWB) wireless communications, and organic energy harvesting techniques will enable the realization of EnHANTs in the near future. The harvesting components and the ultra-low-power physical layer have special characteristics whose implications on the higher layers have yet to be studied (e.g., when using UWB communications, the energy required to receive a bit is significantly higher than the energy required to transmit a bit). In this article, we describe paradigm shifts associated with technologies that enable EnHANTs and demonstrate their implications on higher-layer protocols. Moreover, we describe some of the components we have designed for EnHANTs. Finally, we briefly discuss our indoor light measurements and their implications on the design of higher-layer protocols. {\textcopyright} 2010 IEEE.},
annote = {cited By 59},
author = {Gorlatova, M and Kinget, P and Kymissis, I and Rubenstein, D and Wang, X and Zussman, G},
doi = {10.1109/MWC.2010.5675774},
journal = {IEEE Wireless Communications},
keywords = {Continuous monitoring; Design challenges; Higher-l,Design; Harvesting; Internet protocols; Ultra-wid,Energy harvesting},
number = {6},
pages = {18--25},
title = {{Energy harvesting active networked tags (EnHANTs) for ubiquitous object networking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650858034{\&}doi=10.1109{\%}2FMWC.2010.5675774{\&}partnerID=40{\&}md5=7b8c80a5461f9df9b59fbd74b932cc14},
volume = {17},
year = {2010}
}
@article{Blankenbach201122,
abstract = {During the last 10 years, many modern IT-based applications have developed inside buildings. Many of those applications would benefit by the ability to locate people and/or objects inside the building (indoor positioning). However, most of today's indoor positioning systems are not able to deliver precise position information ({\textless}10 cm) along with quality parameters. Ultra wide band (UWB) is a new radio-based technology that allows the determination of distances in indoor environments with a very high spatial resolution even through building materials. At the Institute of Geodesy of TU Darmstadt, a high-resolution UWB positioning system (UWB-ILPS; ILPS, indoor local positioning systems) based on trilateration principle has been developed to estimate the position of a mobile station precisely. To benefit from knowing the position and orientation, it is necessary to select and merge data linked to the user's location for indoor location services. By this means, the visitor to a public building may benefit from the system as his position is shown on a digital floor plan generated dynamically or by retrieving location-based information inside the building. Mixed reality systems also offer advantages for a mobile building information system. For this purpose, a webcam was replaced by the digital camera in the UWB-ILPS prototype. Knowing the camera's location in space and its view direction, one is able to merge the real world taken by the webcam with the virtual world represented by a 3D CAD model of the building. {\textcopyright} 2011 Taylor {\&} Francis.},
annote = {cited By 6},
author = {Blankenbach, J and Norrdine, A},
doi = {10.1080/17489725.2010.538016},
journal = {Journal of Location Based Services},
keywords = {3D-position; Indoor location services; Indoor mixe,Building materials; Buildings; Cameras; Computer,Tracking (position)},
number = {1},
pages = {22--37},
title = {{Building information systems based on precise indoor positioning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79751476176{\&}doi=10.1080{\%}2F17489725.2010.538016{\&}partnerID=40{\&}md5=79dd6410772f227ebe20c3b88eb35343},
volume = {5},
year = {2011}
}
@inproceedings{Du20171,
abstract = {We present an automatic spatial-segmentation method for a novel magnetic-field hybrid indoor positioning system. Unlike conventional approaches that implement magnetic field alone for the whole experimental space, our approach employs an efficient automatic segmentation method to make up the constraints of magnetic-field indoor positioning after fully evaluating local magnetic-field characteristics. By generating new partitioned databases, this method takes full advantage of characteristic changes in the geomagnetic field according to the distribution of disturbance objects inside buildings. Moreover, it reduces the processing time, as new databases contribute only to the region partition, and no further location calculation is involved. Experimental evaluations carried out with two different sets of hybrid techniques confirm satisfactory performance of the indoor localisation based on automatic spatial segmentation achieving more than a 1 meters' improvement in the average error distance compared to conventional magnetic-field localisation systems. {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Du, Y and Arslan, T},
booktitle = {2017 International Conference on Indoor Positioning and Indoor Navigation, IPIN 2017},
doi = {10.1109/IPIN.2017.8115866},
keywords = {Automatic segmentations; Conventional approach; E,Database systems; Geomagnetism; Magnetic fields; M,Indoor positioning systems},
pages = {1--8},
title = {{Magnetic field indoor positioning system based on automatic spatial-segmentation strategy}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043480136{\&}doi=10.1109{\%}2FIPIN.2017.8115866{\&}partnerID=40{\&}md5=3f076a1b1c18db42b5713e47abc20756},
volume = {2017-Janua},
year = {2017}
}
@inproceedings{Ng2011447,
abstract = {With the growth of context-aware applications, indoor location positioning receives much attention. RFID is one of the most widely adopted wireless positioning technologies. This paper applies Radial Basis Function Neural Network (RBFNN) to estimate locations of objects based on RFID signal strengths. The architecture of RBFNN is selected via a minimization of the Localized Generalization Error (L-GEM) which selects RBFNN with better generalization ability to unseen samples. Virtual reference tags are adopted to improve positioning performance without additional cost and RF interference. A nonlinear interpolation algorithm is proposed to calculate Received Signal Strength (RSS) for Virtual reference tags which is more reasonable than linear interpolation algorithm. Simulation experiments show that the proposed method outperforms existing method based RFID and virtual reference tags based on nonlinear interpolation algorithm improve positioning accuracy. {\textcopyright} 2011 IEEE.},
annote = {cited By 6},
author = {Ng, W W Y and Ding, H.-L. and Chan, P P K and Yeung, D S},
booktitle = {Proceedings - International Conference on Machine Learning and Cybernetics},
doi = {10.1109/ICMLC.2011.6016744},
keywords = {Additional costs; Context aware applications; Gene,Algorithms; Cryptography; Cybernetics; Interpolat,Neural networks},
pages = {447--453},
title = {{Efficiency of applying virtual reference tag to neural network based RFID indoor positioning method}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80155123919{\&}doi=10.1109{\%}2FICMLC.2011.6016744{\&}partnerID=40{\&}md5=fbb1700b1fdb559cf6cdc47750f8ed49},
volume = {1},
year = {2011}
}
@inproceedings{Blumrosen2010234,
abstract = {In this paper we develop a continuous high-precision tracking system based on Received Signal Strength Indicator (RSSI) measurements for small ranges. The proposed system uses minimal number of sensor nodes with RSSI capabilities to track a moving object in close-proximity and high transmission rate. The close-proximity enables conversion of RSSI measurements to range estimates and the high transmission rate enables continuous tracking of the moving object. The RSSI-based tracking system includes calibration, range estimation, location estimation and refinement. We use advanced statistical and signal processing methods to mitigate channel distortion and packet loss. The system is evaluated in indoor settings and achieves tracking resolution of few centimeters. Therefore, it becomes the motion trackers of notice in many applications. {\textcopyright} 2010 IEEE.},
annote = {cited By 18},
author = {Blumrosen, G and Hod, B and Anker, T and Dolev, D and Rubinsky, B},
booktitle = {2010 International Conference on Body Sensor Networks, BSN 2010},
doi = {10.1109/BSN.2010.36},
keywords = {Channel distortions; Continuous tracking; High tra,Navigation; Sensor networks; Sensor nodes; Signal,Wireless sensor networks},
pages = {234--239},
title = {{Continuous close-proximity RSSI-based tracking in wireless sensor networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955225930{\&}doi=10.1109{\%}2FBSN.2010.36{\&}partnerID=40{\&}md5=4450ef7cc03e115cd5a974d666f10acf},
year = {2010}
}
@article{Shafer2009174,
abstract = {The Facility Map Framework (FMF) is a new system of specifications and software for maps of privately owned spaces - campus, building, room detail, and shelf or rack. Based on a generic object model, FMF supports map authoring from CAD or other drawings, asset databases and location sensor systems, map access through browsers or applications, and development of application programs. FMF can integrate existing system components to support interoperability and extensibility, and has features to address a number of additional engineering problems in location systems for private spaces. FMF is a work in progress, with many key elements implemented and others currently under design. Several demos are now in place, representing a variety of different scenarios for using indoor maps. This paper gives an overview of the system components and a number of the engineering challenges and solutions; it represents a progress report on this evolving project. {\textcopyright} Springer-Verlag Berlin Heidelberg 2009.},
annote = {cited By 1},
author = {Shafer, S},
doi = {10.1007/978-3-642-01721-6_11},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Application programs; Engineering challenges; Engi,Computer aided design,Scheduling},
pages = {174--191},
title = {{A Framework for creating and using maps of privately owned spaces}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-68149141508{\&}doi=10.1007{\%}2F978-3-642-01721-6{\_}11{\&}partnerID=40{\&}md5=392068b4a7af39635b3b434abcbfd0b2},
volume = {5561 LNCS},
year = {2009}
}
@article{Zhang2015210,
abstract = {With a single input indoor image (including sofa, tea table, etc.), a 3D scene can be reconstructed from a single image using an existing model library in three stages: image analysis, model retrieval and relevance feedback. In the image analysis stage, we obtain the object information from the input image using geometric reasoning technology combined with an image segmentation method. In the model retrieval stage, line drawings are extracted from 2D objects and 3D models by using different line rendering methods. We exploit various tokens to represent local features and then organize them together as a star-graph to show a global description. By comparing similarity among the encoded line drawings, models are retrieved from the model library. Also, for a better user experience, we add a relevance feedback stage following the retrieval stage. The Support Vector Machine method is used to conduct the feedback operation. After this stage, the retrieved models are in conformance with the image semantic. The 3D scene is then reconstructed. Experimental results show that, driven by the given model library, indoor scenes modeling from a single image could be achieved automatically and efficiently. {\textcopyright} 2015 Elsevier Ltd. All rights reserved.},
annote = {cited By 2},
author = {Zhang, Y and Liu, Z and Miao, Z and Wu, W and Liu, K and Sun, Z},
doi = {10.1016/j.cag.2015.10.004},
journal = {Computers and Graphics (Pergamon)},
keywords = {Data driven; Feedback operations; Geometric reaso,Feedback; Image analysis; Image segmentation; Sema,Three dimensional computer graphics},
pages = {210--223},
title = {{Singe image-based data-driven indoor scenes modeling}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947810806{\&}doi=10.1016{\%}2Fj.cag.2015.10.004{\&}partnerID=40{\&}md5=94a07d8e262a08b5fb3b1d262eff8895},
volume = {53},
year = {2015}
}
@inproceedings{Schroeer2018,
abstract = {Tracking products, machines and important objects in factories is a key task for future efficient manufacturing processes. Providing workers and robots with accurate and reliable location information is the foundation for this innovation. In industrial facilities, the environment is more complex compared to consumer indoor positioning scenarios. Heavy machinery often blocks the line of sight path. Metal walls and surfaces increase reflections and multi-path effects. An ultra-wideband based time-difference-of-arrival positioning system is investigated. All base stations use four transceivers instead of one to increase the system robustness. Multi-path and non-line of sight situations are evaluated with respect to the channel effects and the influence on the position accuracy. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Schroeer, G},
booktitle = {IPIN 2018 - 9th International Conference on Indoor Positioning and Indoor Navigation},
doi = {10.1109/IPIN.2018.8533792},
keywords = {Indoor positioning systems,Indoor positioning; Industrial facilities; Indust,Machinery; Radio transceivers; Robots; Time differ},
title = {{A Real-Time UWB Multi-Channel Indoor Positioning System for Industrial Scenarios}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059062848{\&}doi=10.1109{\%}2FIPIN.2018.8533792{\&}partnerID=40{\&}md5=afe8bdae6015f61a1f63618c4f7f9f4e},
year = {2018}
}
@inproceedings{Sankar2017415,
abstract = {We propose a novel interactive system to simplify the process of indoor 3D CAD room modeling. Traditional room modeling methods require users to measure room and furniture dimensions, and manually select models that match the scene from large catalogs. Users then employ a mouse and keyboard interface to construct walls and place the objects in their appropriate locations. In contrast, our system leverages the sensing capabilities of a 3D aware mobile device, recent advances in object recognition, and a novel augmented reality user interface, to capture indoor 3D room models in-situ. With a few taps, a user can mark the surface of an object, take a photo, and the system retrieves and places a matching 3D model into the scene, from a large online database. User studies indicate that this modality is significantly quicker, more accurate, and requires less effort than traditional desktop tools. {\textcopyright} 2017 ACM.},
annote = {cited By 0},
author = {Sankar, A and Seitz, S M},
booktitle = {UIST 2017 - Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology},
doi = {10.1145/3126594.3126629},
keywords = {3-d modeling; Interactive modeling; Interactive s,Augmented reality; Computer aided design; Design;,User interfaces},
pages = {415--426},
title = {{Interactive room capture on 3D-aware mobile devices}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041549588{\&}doi=10.1145{\%}2F3126594.3126629{\&}partnerID=40{\&}md5=3f45235c3bdd9d9e22de9c9285ab140e},
year = {2017}
}
@inproceedings{Pongthawornkamol2010253,
abstract = {WiFi localization and tracking of indoor moving objects is an important problem in many contexts of ubiquitous buildings, first responder environments, and others. Previous approaches in WiFi-based indoor localization and tracking either assume prior knowledge of indoor environment or assume many data samples from location-fixed WiFi sources (i.e. anchor points). However, such assumptions are not always true, especially in emergency scenarios. This paper explores the possibility of real-time indoor localization and tracking without any knowledge of indoor environment and with real-time data samples from only few anchor points outside the building. By using a small set of synchronized directional antennas as outdoor anchor points to actively scan in various directions, a moving device inside the building can be localized and tracked from the received signal in real-time manner. The paper proposes an angle-of-arrival estimator for accurate localization and adaptive per-antenna angular scheduling for real-time indoor tracking. The validation results from real experiment and simulation yield effectiveness and accuracy of the proposed schemes. {\textcopyright}2009 IEEE.},
annote = {cited By 6},
author = {Pongthawornkamol, T and Ahmed, S and Nahrstedt, K and Uchiyama, A},
booktitle = {2010 IEEE International Conference on Pervasive Computing and Communications, PerCom 2010},
keywords = {Anchor point; Angle-of-arrival; Data sample; Direc,Directional patterns (antenna); Directive antenna,Ubiquitous computing},
pages = {253--261},
title = {{Zero-knowledge real-time indoor tracking via outdoor wireless directional antennas}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956447107{\&}partnerID=40{\&}md5=4ba8ee5fc3b2fcca015c192bd6b690a9},
year = {2010}
}
@inproceedings{Chandrasekaran2015,
abstract = {Radio Frequency Identification (RFID) is widely used in indoor positioning systems for object tracking and localization. However, there are several challenges that are yet to be addressed especially in 3-D space. When objects are cluttered densely, an arrangement synonymous to that of heaps of haphazardly arranged files in an office, locating and retrieving a file manually from the heap becomes a laborious task. In this paper, we address the challenge of localization and retrieval of objects in cluttered environments using passive RFID tags, by developing a novel indoor path loss translational model that considers the signal properties across the clutter. The proposed InPLaCE RFID system estimates the position of the object within a clutter by employing a robust translation model that accounts for the properties of the clutter and helps compensate for estimation errors over existing path loss models. Our experiments over different cluttered environments show that the proposed translational model improves the localization accuracy of objects over existing path loss models. {\textcopyright} 2015 IEEE.},
annote = {cited By 10},
author = {Chandrasekaran, V and Narayan, K and Vasani, R K and Balasubramanian, V},
booktitle = {2015 IEEE 10th International Conference on Intelligent Sensors, Sensor Networks and Information Processing, ISSNIP 2015},
doi = {10.1109/ISSNIP.2015.7106910},
keywords = {Clutter (information theory); Indoor positioning s,Cluttered environments; Estimation errors; Locali,Radio frequency identification (RFID)},
title = {{InPLaCE RFID: Indoor path loss translation for object localization in cluttered environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933563984{\&}doi=10.1109{\%}2FISSNIP.2015.7106910{\&}partnerID=40{\&}md5=0f12a0dafd37e0c566b89c13ca3f820f},
year = {2015}
}
@inproceedings{Su2009405,
abstract = {The proposed system provides a mechanism of detecting the stealing of valuables, and integrates wireless sensor networks with a location service to trace stolen valuables through deployed cameras in an indoor environment. Compared with traditional surveillance systems, it is able to actively notify the security manager that monitored valuables are stole and show the current positions, and real-time images of those stolen valuables when theft cases occur.},
annote = {cited By 0},
author = {Su, Y.-W. and Chuang, C.-C. and Lee, Y.-F. and Shen, C.-C.},
booktitle = {Proceedings of the 7th ACM Conference on Embedded Networked Sensor Systems, SenSys 2009},
doi = {10.1145/1644038.1644124},
keywords = {Embedded systems; Real time systems; Security sys,Indoor environment; Localization services; Locatio,Wireless sensor networks},
pages = {405--406},
title = {{Poster abstract: A stolen object detection and tracing system for mobile valuables}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-74549217945{\&}doi=10.1145{\%}2F1644038.1644124{\&}partnerID=40{\&}md5=85a0e876a4d1338fb7fb0c9d3c7ccf5f},
year = {2009}
}
@inproceedings{Upadhyay2016,
abstract = {Frontier detection is a critical component in autonomous exploration, wherein the robot decides the next best location to move in order to continue its mapping process. The existing frontier detection methods require dense reconstruction which is difficult to attain in a poorly textured indoor environment using a monocular camera. In this effort, we present an alternate method of detecting frontiers during the course of robot motion that circumvents the requirement of dense mapping. Based on the observation that frontiers typically occur around areas with sudden change in texture (zero-crossings), we propose a novel linear chain Conditional Random Field(CRF) formulation that is able to detect the presence or absence of frontier regions around such areas. We use cues like spread of 3D points and scene change around these areas as an observation to CRF. We demonstrate that this method gives us more relevant frontiers compared to other monocular camera based methods in the literature. Finally, we present results in an indoor environment, wherein frontiers are reliably detected around walls leading to new corridors, doors leading to new rooms or corridors and tables and other objects that open up to a new space in rooms. {\textcopyright} 2016 ACM.},
annote = {cited By 0},
author = {Upadhyay, S and Krishna, K M and Kumar, S},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3009977.3010063},
keywords = {Alternate method; Autonomous exploration; Conditi,Cameras; Computer vision; Mapping; Random processe,Image processing},
title = {{Fast frontier detection in indoor environment for monocular SLAM}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014848327{\&}doi=10.1145{\%}2F3009977.3010063{\&}partnerID=40{\&}md5=c14fba7f33b0bced563f4b361c44e3a0},
year = {2016}
}
@inproceedings{Yang2008165,
abstract = {Tracking the physical location of nodes in a 2D environment is critical in many applications such as camera tracking in virtual studio, indoor mobile objects tracking. RFID technique poses an interesting solution to localizing the nodes because the passive RFID tags could store the position unit information according to unique tag ID. Based on tags pattern, algebraic approach could solve the 2D trajectory tracking problem. However, the tracking accuracy of this approach is highly related to the tags position distribution and position unit. It would be inaccurate for some erratic trajectory tracking. Thus, we would try to apply and evaluate the probabilistic approaches, such as SLAM (Simultaneous Localization and Mapping), into RFID tag based trajectory tracking. In this paper, we propose an RFID tag based SLAM algorithm for 2D trajectory tracking. Also a technique called Map adjustment is proposed to increase the efficiency of the algorithm. The simulation results show that the approach could improve the accuracy for some parts of trajectory tracking compared to RFID algebraic approach. The limitation and future work are given in the conclusion. {\textcopyright} 2008 IEEE.},
annote = {cited By 16},
author = {Yang, P and Wu, W and Moniri, M and Chibelushi, C C},
booktitle = {2008 IEEE International Conference on RFID (Frequency Identification), IEEE RFID 2008},
doi = {10.1109/RFID.2008.4519349},
keywords = {Algebraic approaches; Camera tracking; Frequency i,Boolean algebra; Conformal mapping; Matrix algebr,Tracking (position)},
pages = {165--172},
title = {{SLAM algorithm for 2D object trajectory tracking based on RFID passive tags}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-49049105963{\&}doi=10.1109{\%}2FRFID.2008.4519349{\&}partnerID=40{\&}md5=d3e8233a84e6c074e069e300d73d1298},
year = {2008}
}
@inproceedings{Li200993,
abstract = {This paper describes a method for localizing objects in an actual living environment. We have developed this method by using a complementary combination of 1) received signal strength indicators (RSSIs) and vibration data acquired from active RFID tags, and 2) human behavior detected from various types of sensors embedded in the environment. Regarding the former, we use a pattern recognition method to select a feature appeared in SSIs received by several radio frequency (RF) readers at different places and to classify them into a particular location. In our work, we regard the estimated location as the most probable location where the object is placed. As for the latter, we use the detected human behavior to support the estimation based on the analysis of RSSIs. Experiment results showed that the proposed method improved the estimation performance from about 50 to 95{\%} compared with using only RSSIs to localize objects. Moreover, the results also suggested that we can estimate object location indoors without sensors for detecting human position. This indoor object localization method can contribute for constructing an indoor object management system that improves living comfort. Copyright 2009 ACM.},
annote = {cited By 1},
author = {Li, M and Mori, T and Noguchi, H and Shimosaka, M and Sato, T},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/1667780.1667799},
keywords = {Active RFID; Embedded sensors; Estimation performa,Behavioral research; Estimation; Pattern recognit,Chemical sensors},
pages = {93--99},
title = {{Use of active RFID and environment-embedded sensors for indoor object location estimation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-76749169841{\&}doi=10.1145{\%}2F1667780.1667799{\&}partnerID=40{\&}md5=c745780e0d377dc634afe0b612bef41a},
year = {2009}
}
@inproceedings{Cherntanomwong2015480,
abstract = {Visible light communication (VLC) has recently become popular due to its benefit of VLC. VLC can provide not only the data communication via light, but also illumination. Indoor localization using VLC is a solution to locate objects or people inside a building using visible light wave by reading the identification data from visible light tubes. However, the identification data cannot be read in the light overlapping area. Time division multiplexing (TDM) is used to deal with this issue. In this work, the proximity technique is used for localization. The LED spotlights at fixed locations are used as transmitters that transmit their unique IDs, while the photodiode is used as a target receiver. By using the proximity technique, the location of the target is identified using one received ID or more. {\textcopyright} 2015 IEEE.},
annote = {cited By 3},
author = {Cherntanomwong, P and Chantharasena, W},
booktitle = {Proceedings - 2015 7th International Conference on Information Technology and Electrical Engineering: Envisioning the Trend of Computer, Information and Engineering, ICITEE 2015},
doi = {10.1109/ICITEED.2015.7408994},
keywords = {Data-communication; Identification data; Indoor l,Indoor positioning systems; Light; Light emitting,Visible light communication},
pages = {480--483},
title = {{Indoor localization system using visible light communication}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966480719{\&}doi=10.1109{\%}2FICITEED.2015.7408994{\&}partnerID=40{\&}md5=6b0f2be8ec1bbdd2f739e5c6de933867},
year = {2015}
}
@article{Chen2015204,
abstract = {In recent years, the position location applications have increasingly. In this paper, we will use multiple Back-Propagation neural networks with genetic algorithm (GA) for a radio frequency identification (RFID) indoor location system to provide location services named indoor location with multiple neural networks and genetic algorithms (ILMNGA). In Section 1, we collect received signal strength (RSS) information from reference points to train the neural network models. In Section 2, genetic algorithm (GA) is used to find the weight of each neural network based on the performance of each neural network. Finally, we input the RSS information of each tracking object into the model that will provide the location of tracking objects based on the RSS information. The location will be integrated using the weights produced by the GA. The experiment conducted our methodology can provide better accuracy than a single neural network. {\textcopyright} 2015 Inderscience Enterprises Ltd.},
annote = {cited By 7},
author = {Chen, R C and Huang, S W and Lin, Y C and Zhao, Q F},
doi = {10.1504/IJSNET.2015.072863},
journal = {International Journal of Sensor Networks},
number = {3-4},
pages = {204--216},
title = {{An indoor location system based on neural network and genetic algorithm}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946904344{\&}doi=10.1504{\%}2FIJSNET.2015.072863{\&}partnerID=40{\&}md5=88f48d3afec032c65763f145d9898090},
volume = {19},
year = {2015}
}
@article{Lin2009180,
abstract = {The representation and recognition of complex semantic events (e.g. illegal parking, stealing objects) is a challenging task for high-level understanding of video sequence. To solve this problem, an attribute graph grammar for events modeling is studied in this paper. This grammar models the variability of semantic events by a set of meaningful "event components" with the spatio-temporal constraints. The event components are defined manually according to their semantic meaning, and further decomposed into atomic event primitives. These event primitives are learned on a object-trajectory table that describes mobile object attributes (location, velocity, and visibility) in a video sequence. A dictionary of temporal and spatial relations are defined to constrain the event primitives. With this representation, one observed event can be parsed into an "event parse graph", and all possible variability of one event can be modeled into an "event And-Or graph", in a syntactic way. The probability model of an "event And-Or graph" can be learned on a set of annotated event instances, and given a learned event And-Or graph, a Gibbs sampling scheme is utilized for inference on a testing video. In the experiments, we test events recognition performance of the proposed on both real indoor and outdoor videos and show quantitative recognition rate on the public LHI dataset. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
annote = {cited By 28},
author = {Lin, L and Gong, H and Li, L and Wang, L},
doi = {10.1016/j.patrec.2008.02.023},
journal = {Pattern Recognition Letters},
keywords = {Attribute graph grammar; Attribute graphs; Challe,Context sensitive grammars; Formal languages; Info,Graph theory},
number = {2},
pages = {180--186},
title = {{Semantic event representation and recognition using syntactic attribute graph grammar}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-56049121516{\&}doi=10.1016{\%}2Fj.patrec.2008.02.023{\&}partnerID=40{\&}md5=04456dc4bfcd0774e7b61a47f93a0d1a},
volume = {30},
year = {2009}
}
@inproceedings{Cankaya2015281,
abstract = {Usage areas of mobile phones have increased in the last 10 years. Although there have been improvements in many areas, most of the developments are in the field of positioning systems. Although the people's lives continue in indoor environments, location-based information system receives data from the satellites, which can detect a person's location in outdoor areas. In indoor areas, satellite signals can cause false information or can be interrupted by the objects in the area. In this study, an indoor navigation system has been designed and developed that only uses the accelerometer, the camera and the compass components on the phone and does not require satellite signals for positioning. To provide independence from the map in this application, augmented reality is applied during the routing process by utilizing built-in camera of the phone and no map is used. {\textcopyright} 2015 IEEE.},
annote = {cited By 3},
author = {Cankaya, I A and Koyun, A and Yigit, T and Yuksel, A S},
booktitle = {9th International Conference on Application of Information and Communication Technologies, AICT 2015 - Proceedings},
doi = {10.1109/ICAICT.2015.7338563},
keywords = {Augmented reality; Cameras; iOS (operating system),In-door navigations; Indoor environment; Indoor n,Indoor positioning systems},
pages = {281--284},
title = {{Mobile indoor navigation system in iOS platform using augmented reality}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960860974{\&}doi=10.1109{\%}2FICAICT.2015.7338563{\&}partnerID=40{\&}md5=724d75628891ff4a871c074b182242a8},
year = {2015}
}
@inproceedings{Rodriguez20101106,
abstract = {A femto access point (FAP) is a low-cost, low-power device intended to be installed by a home owner, to turn the home into a tiny wireless communication cell, that operates underneath a standard cell, in licensed spectrum bands. Femto-cells can improve user experience in indoor locations, and increase overall system capacity with modest monetary investment. But the unplanned dynamic nature of these cells, significantly complicate resource allocation and interference control. We propose a relatively simple, decentralised market-oriented scheme for sub-channel and power allocation when femto-cell users co-exist with those of an OFDMA macro-cell. Our scheme utilises the Dutch auction (price progressively falls until a participant buys the object). Special "confirmation messages" are used to control interference, achieve channel reuse across Femto-cells, and mitigate the "hidden terminal" problem. Secure software inside each terminal may record transactions for eventual payment collection, or the auction can be interpreted as a prioritised decentralised allocation algorithm, without real money exchange. Copyright 2010 ACM.},
annote = {cited By 0},
author = {Rodriguez, V and Mathar, R},
booktitle = {IWCMC 2010 - Proceedings of the 6th International Wireless Communications and Mobile Computing Conference},
doi = {10.1145/1815396.1815649},
keywords = {Auction; LTE; Microeconomics; Power pricing; Subch,Cells; Costs; Cytology; Electric batteries; Frequ,Economics},
pages = {1106--1110},
title = {{Simple decentralised market-oriented management of OFDMA femto-cells}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955155063{\&}doi=10.1145{\%}2F1815396.1815649{\&}partnerID=40{\&}md5=6553b16cc930008cb068708b3eabf35c},
year = {2010}
}
@inproceedings{Anzum2018,
abstract = {Precise indoor localization is of great importance to automatically track people or objects indoors and plays a vital role in modern life. Despite a number of innovative research present in the literature indoor localization still remains an open problem. To trace the main reason we identify that in the present literature the tendency is to pinpoint the exact coordinates of a target device although most of the location based services (LBSs) do not require exact coordinates. To support LBS, one can simply divide the area of interest into several zones and perform ''zone-fencing'', i.e., find under which zone the user is currently located at. In this paper, we propose a zone-based indoor localization scheme using neural networks. With the results from real world indoor settings, we show that a number of empty clusters is generated when the traditional counter propagation network (CPN) is applied as is. But a slight modification to the CPN reduces the number of empty clusters significantly and provides promising accuracy. The proposed scheme outperforms "k-Nearest Neighbor algorithm" (k-NN) and its promising accuracy makes it suitable for real-world deployment. {\textcopyright} 2018 IEEE.},
annote = {cited By 1},
author = {Anzum, N and Afroze, S F and Rahman, A},
booktitle = {IEEE International Conference on Communications},
doi = {10.1109/ICC.2018.8422182},
keywords = {Area of interest; Counter propagation networks; I,Indoor positioning systems,Location based services; Nearest neighbor search;},
title = {{Zone-based indoor localization using neural networks: A view from a real testbed}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051426839{\&}doi=10.1109{\%}2FICC.2018.8422182{\&}partnerID=40{\&}md5=2f7099a49211891e4b0513d594f22eb8},
volume = {2018-May},
year = {2018}
}
@inproceedings{Dubey2015176,
abstract = {Indoor localization and mapping has become very crucial part of pervasive computing in recent times. Conventional outdoor techniques using GPS, Wi-Fi, and Cellular Networks have proved expensive and unconventional for indoor mapping. This document presents unique method of real time indoor localization and mapping using FM and ASK wave transceivers implemented using Phased Locked Loop and Field Programmable Gate Array (FPGA). Localization is procured with respect to three FM transmitters tuned at different frequencies. The geometrical wave model of these transmitters renders family of circles, where radius of each circle represents 'Received Signal Strength Indicator' (RSSI) value corresponding to a particular transmitter. Solving this family of circles for a common point yields the location of object with respect to the transmitters. Object is installed with customized FPGA core and 3 FM receivers tuned to respective transmitter frequencies. RSSI values from each FM receiver are resolved into 4 bit digital values inclusively. FPGA acquire and process values from FM receivers via 3 parallel I2C buses which provide real time response. Unwanted continuous FM radiation is prevented by the use of wireless control over FM transmitters. Overall, a low cost solution is obtained to create a digital map which localizes and tracks objects in real-time. {\textcopyright} 2015 IEEE.},
annote = {cited By 1},
author = {Dubey, A and Kulkarni, A and Paras, A and Deole, A and Gandhi, A S and Bhurchandi, K M},
booktitle = {International Conference on ICT Convergence 2015: Innovations Toward the IoT, 5G, and Smart Media Era, ICTC 2015},
doi = {10.1109/ICTC.2015.7354522},
keywords = {Different frequency; Indoor localization; Phased,Field programmable gate arrays (FPGA); Mapping; Ph,Indoor positioning systems},
pages = {176--181},
title = {{FM based indoor localization and mapping system with real-time implementation on FPGA}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964870028{\&}doi=10.1109{\%}2FICTC.2015.7354522{\&}partnerID=40{\&}md5=2848172205fb7591d70a46ce71b4a779},
year = {2015}
}
@article{Hara2005493,
abstract = {Several techniques have been developed for recovering reflectance properties of real surfaces under unknown illumination. However, in most cases, those techniques assume that the light sources are located at inifinity, which cannot be applied safely to, for example, reflectance modeling of indoor environments. In this paper, we propose two types of methods to estimate the surface reflectance property of an object, as well as the position of a light source from a single view without the distant illumination assumption, thus relaxing the conditions in the previous methods. Given a real image and a 3D geometric model of an object with specular reflection as inputs, the first method estimates the light source position by fitting to the Lambertian diffuse component, while separating the specular and diffuse components by using an iterative relaxation scheme. Our second method extends that first method by using as input a specular component image, which is acquired by analyzing multiple polarization images taken from a single view, thus removing its constraints on the diffuse reflectance property. This method simultaneously recovers the reflectance properties and the light source positions by optimizing the linearity of a log-transformed Torrance-Sparrow model. By estimating the object's reflectance property and the light source position, we can freely generate synthetic images of the target object under arbitrary lighting conditions with not only source direction modification but also source-surface distance modification. Experimental results show the accuracy of our estimation framework. {\textcopyright} 2005 IEEE.},
annote = {cited By 66},
author = {Hara, K and Nishino, K and Ikeuchi, K},
doi = {10.1109/TPAMI.2005.82},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Algorithms; Computational geometry; Estimation; Li,Algorithms; Image Enhancement; Image Interpretati,Computer vision,Computer-Assisted; Information Storage and Retrie,Finite distance illumination; Light source positi,algorithm; article; computer assisted diagnosis;},
number = {4},
pages = {493--505},
title = {{Light source position and reflectance estimation from a single view without the distant illumination assumption}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-17144423911{\&}doi=10.1109{\%}2FTPAMI.2005.82{\&}partnerID=40{\&}md5=6e18657cd67b43f072177e3bdeff5ee7},
volume = {27},
year = {2005}
}
@inproceedings{Bobek201591,
abstract = {Location is one of the most valuable and extensively used information in mobile context-aware systems. Its understanding may vary from geolocation that uses GPS infrastructure to locate objects on Earth, up to microlocation, which aims at locating users and objects inside closed areas. Although geolocation can be considered as a mature field, there is an ongoing research in the area of microlocation. Despite that, microlocation techniques do not offer satisfactory level of accuracy and implementation flexibility to be practically incorporated into commercial solutions. This is mainly because of high workload that needs to be done in terms of maps preparation and algorithms tuning. In this paper we present a method that can overcome this issue by providing incremental rule learning algorithm for automated discovery of user location on a room-level accuracy. We also show a method of augmenting semantic annotations on physical objects with a use of Bluetooth Low Energy beacons. {\textcopyright} 2015 IEEE.},
annote = {cited By 10},
author = {Bobek, S and Grodzki, O and Nalepa, G J},
booktitle = {Proceedings - 2015 IEEE 2nd International Conference on Cybernetics, CYBCONF 2015},
doi = {10.1109/CYBConf.2015.7175912},
keywords = {Automated discovery; Bluetooth low energies (BTLE,Cybernetics; Location; Semantics; Tracking (positi,Learning algorithms},
pages = {91--96},
title = {{Indoor microlocation with BLE beacons and incremental rule learning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947997092{\&}doi=10.1109{\%}2FCYBConf.2015.7175912{\&}partnerID=40{\&}md5=60f0210d939de483123a00b878e50462},
year = {2015}
}
@inproceedings{Wu2010266,
abstract = {This paper studies the real-time location of human body and objects in indoor environments of several methods, and through reverse thinking, study of a RFID-based indoor signal blocking method for positioning, according to the experimental thinking, we did a reality scenario test, obtained relevant data. According to test results we obtained the optimum label release interval, which to provide support for the system design and development , but also a strong proof of the feasibility of this method. {\textcopyright} 2010 IEEE.},
annote = {cited By 0},
author = {Wu, J and Zhou, L and Xiang, Z},
booktitle = {2010 2nd International Conference on Computer Engineering and Applications, ICCEA 2010},
doi = {10.1109/ICCEA.2010.60},
keywords = {Computer applications,Human bodies; Indoor environment; Indoor position,Telecommunication networks},
pages = {266--270},
title = {{RETRACTED ARTICLE: The research of RFID-based indoor signal block positioning system optimum interval of placing tags}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952643783{\&}doi=10.1109{\%}2FICCEA.2010.60{\&}partnerID=40{\&}md5=033edfa7711c8b8b53b4b9763d31e495},
volume = {1},
year = {2010}
}
@inproceedings{Ding20101147,
abstract = {As pervasive computing becomes more popular, the importance of context-aware applications increases. Physical location of user is important to context-aware pervasive application providers. RFID is one of the most widely adopted wireless positioning technologies. Compared to other wireless technologies, e.g. GPS and WLAN, RFID is particularly suitable for indoor positioning. Existing methods usually assume a constant environment for the application field. However, this may not be true in many cases. For example, warehouse may have different goods yielding different interference to RFID signal in different days. This paper proposes a new method to estimate locations of objects based on RFID. The indoor positioning with RFID reader based on the received signal strength and passive UHF tags as reference tags. A Radial Basis Function Neural Network (RBFNN) trained via a minimization of the Localized Generalization Error (L-GEM) is adopted to learn the object location based on received RFID signals. The L-GEM provides an estimate on the generalization capability of the RBFNN which is important to locate future unseen samples correctly in different yet similar environments. Simulation experiments show that the proposed method outperforms existing RFID based indoor positioning method. {\textcopyright} 2010 IEEE.},
annote = {cited By 10},
author = {Ding, H.-L. and Ng, W W Y and Chan, P P K and Wu, D.-L. and Chen, X.-L. and Yeung, D S},
booktitle = {2010 International Conference on Machine Learning and Cybernetics, ICMLC 2010},
doi = {10.1109/ICMLC.2010.5580925},
pages = {1147--1152},
title = {{RFID indoor positioning using RBFNN with L-GEM}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78149292198{\&}doi=10.1109{\%}2FICMLC.2010.5580925{\&}partnerID=40{\&}md5=e2b4be532d84df66464e8f3e0cc88eed},
volume = {3},
year = {2010}
}
@inproceedings{Lu20131388,
abstract = {The Carrier Phase Measurement (CPM) of GPS may achieve high precise location because of its short wavelength. While when a moving object comes into an enclosed area, GPS signal will be limited. For this paper, we propose a new indoor positioning model which aims to achieve cm-level indoor location by using CPM method. One of the most important parts of this model is to extract the most accurate carrier phase values from the tracking loop in receivers, thus the affection and performance of the carrier tracking loop will be firstly analyzed. The discriminator function is achieved by CORDIC algorithm based on hardware platform instead of traditional look-up-table method. The result shows that with the increasing iterations, carrier phase error can reach to 10-7 rad which equals to the distance of 10-6cm and it has little impact on PVT. On the other hand, CORDIC algorithm saves hardware resources as well as has faster speed to process tracking loop. {\textcopyright} 2013 IEEE.},
annote = {cited By 0},
author = {Lu, X and Zhang, Y and Zheng, Z},
booktitle = {Proceedings - 2013 International Conference on Computational and Information Sciences, ICCIS 2013},
doi = {10.1109/ICCIS.2013.367},
keywords = {Algorithms; Hardware; Information science; Tracki,Carrier phase error; Carrier tracking loop; Carrie,Global positioning system},
pages = {1388--1391},
title = {{Carrier tracking loop improvement in a new indoor positioning system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890866462{\&}doi=10.1109{\%}2FICCIS.2013.367{\&}partnerID=40{\&}md5=ebc486a466f7fdcd2c78fb95ca9577bd},
year = {2013}
}
@article{Carlin201445,
abstract = {Indoor radio frequency tracking systems are generally quite expensive and can vary in accuracy due to interference, equipment quality or other environmental factors. Due to these limiting factors of the technology, many businesses today find it hard to justify investing in RFID tracking technologies to improve the safety, efficiency and security of their working environments. The aim of this project was to provide a budget RFID tracking system that was capable of tracking a person or object through an indoor environment. To minimize the cost of the RFID tracking system, the components of the system were built from existing electronic equipment and hardware. The software was also written to minimize licensing and support fees allowing a cost effective budget RFID tracking system to be developed. The tracking system consists of a tag, reader nodes and a PC reader which utilize synapse RF 100 engines with python scripts embedded on to the chips. The tracking system software operates through a web portal utilizing web technologies such as HTML, JavaScript and PHP to allow the tags location to be represented on a two dimensional map using scalable vector graphics. During development of the system a new trilateration algorithm was developed and used convert the signals received from the tag to a virtual position on the map correlating to the actual physical position of the tag. A unique contribution of this system is the low cost of building which we estimate as less than 200 UK sterling for a five node system. Copyright {\textcopyright} 2014, IGI Global.},
annote = {cited By 2},
author = {Carlin, S and Curran, K},
doi = {10.4018/ijaci.2014010104},
journal = {International Journal of Ambient Computing and Intelligence},
keywords = {Budget control; Cost benefit analysis; Cost effect,Environmental factors; Javascript; PHP; Radio fre,Radio frequency identification (RFID)},
number = {1},
pages = {45--79},
title = {{An active low cost mesh networking indoor tracking system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84927913864{\&}doi=10.4018{\%}2Fijaci.2014010104{\&}partnerID=40{\&}md5=e2f22d8dd7b165077b7168010c4839b5},
volume = {6},
year = {2014}
}
@inproceedings{Tiberio2012155,
abstract = {Self-localization is the process of knowing your position and location relative to your surroundings. This research integrated artificial intelligence techniques into a custom-built portable eye tracker for the purpose of automating the process of determining indoor self-localization. Participants wore the eye tracker and walked a series of corridors while a video of the scene was recorded along with fixation locations. Patches of the scene video without fixation information were used to train the classifier by creating feature maps of the corridors. For testing the classifier, fixation locations in the scene were extracted and used to determine the location of the participant. Scene patches surrounding fixations were used for the classification instead of objects in the environment. This eliminated the need for complex computer vision object recognition algorithms and made scene classification less dependent upon objects and their placement in the environment. This allowed for a sparse representation of the scene since image processing to detect and recognize objects was not necessary to determine location. Experimentally, image patches surrounding fixations were found to be a highly reliable indicator of location, as compared to random image patches, non-fixated salient image patches, or other non-salient scene locations. In some cases, only a single fixation was needed to accurately identify the correct location of the participant. To the best of our knowledge, this technique has not been used before for determining human self-localization in either indoor or outdoor settings. {\textcopyright} 2012 ACM.},
annote = {cited By 0},
author = {Tiberio, L M and Canosa, R L},
booktitle = {Eye Tracking Research and Applications Symposium (ETRA)},
doi = {10.1145/2168556.2168581},
keywords = {Artificial intelligence techniques; Eye trackers;,Artificial intelligence; Computer vision; Mapping,Object recognition},
pages = {155--160},
title = {{Self-localization using fixations as landmarks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862639671{\&}doi=10.1145{\%}2F2168556.2168581{\&}partnerID=40{\&}md5=8ad9ecf5b085c0e590a46d4148375e86},
year = {2012}
}
@inproceedings{Kataoka20123329,
abstract = {Detecting and identifying Regions of Interest (ROIs) is an important task for navigation and retrieval services. In this paper, we focus on indoor scene images and detect object regions such as shop signs and merchandise. Our method is based on two approaches; 1) Indoor structure analysis from a single image by learning the types of scenes. 2) Detect ROIs by taking advantage of the relationship of expected locations of planes and objects. We conduct a detection experiment and demonstrate the effectiveness of our proposal. {\textcopyright} 2012 ICPR Org Committee.},
annote = {cited By 2},
author = {Kataoka, K and Sudo, K and Morimoto, M},
booktitle = {Proceedings - International Conference on Pattern Recognition},
keywords = {Detection experiments; Object region; Region of in,Image segmentation,Pattern recognition},
pages = {3329--3332},
title = {{Region of Interest detection using indoor structure and saliency map}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874580870{\&}partnerID=40{\&}md5=677516e62b63206dfbcf55f511c08802},
year = {2012}
}
@inproceedings{Schulz2003921,
abstract = {Estimating the location of people using a network of sensors placed throughout an environment is a fundamental challenge in smart environments and ubiquitous computing. Id-sensors such as infrared badges provide explicit object identity information but coarse location information while anonymous sensors such as laser range-finders provide accurate location information only. Tracking using both sensor types simultaneously is an open research challenge. We present a novel approach to tracking multiple objects that combines the accuracy benefits of anonymous sensors and the identification certainty of id-sensors. Rao-Blackwellised particle filters are used to estimate object locations. Each particle represents the association history between Kalman filtered object tracks and observations. After using only anonymous sensors until id estimates are certain enough, id assignments are sampled as well resulting in a fully Rao-Blackwellised particle filter over both object tracks and id assignments. Our approach was implemented and tested successfully using data collected in an indoor environment.},
annote = {cited By 111},
author = {Schulz, D and Fox, D and Hightower, J},
booktitle = {IJCAI International Joint Conference on Artificial Intelligence},
keywords = {Accurate location; Indoor environment; Laser range,Artificial intelligence; Estimation; Monte Carlo,Sensors},
pages = {921--926},
title = {{People tracking with anonymous and ID-sensors using Rao-Blackwellised particle filters}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880830966{\&}partnerID=40{\&}md5=8e5f0ec9bf9fc498d430f0b16b8e7607},
year = {2003}
}
@article{Lee2012241,
abstract = {The task of formulating an efficient system for determining the location of an object, results in the creation of a wide number of applications and services. For this reason, most wireless sensor network applications assume the availability of sensor location information. In this paper, an indoor localization scheme, which is based on synchronized sensor nodes, is proposed. It is efficient in terms of power consumption and location update rate. Furthermore, it resolves the scalability problem usually found in most conventional indoor localization systems in large scale indoor environments. The performance of the proposed scheme is evaluated through experimental implementation and is compared with the Cricket system. The results demonstrate that the proposed scheme is a promising and feasible localization system for a large scale indoor environment. {\textcopyright} 2010 Springer Science+Business Media, LLC.},
annote = {cited By 3},
author = {Lee, W.-Y. and Hur, K and Kim, T and Eom, D.-S. and Kim, J.-O.},
doi = {10.1007/s11277-010-0117-2},
journal = {Wireless Personal Communications},
keywords = {Efficient systems; Indoor environment; Indoor loca,Location based services,Sensor nodes; Ubiquitous computing},
number = {1},
pages = {241--260},
title = {{Large scale indoor localization system based on wireless sensor networks for ubiquitous computing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856751395{\&}doi=10.1007{\%}2Fs11277-010-0117-2{\&}partnerID=40{\&}md5=ac692b432ffa94aa71ba476609104434},
volume = {63},
year = {2012}
}
@inproceedings{Krishna2012568,
abstract = {In recent years, the numbers of Visual Surveillance systems have greatly increased, and these systems have developed into intellectual systems that automatically detect, track, and recognize objects in video. Automatic moving object detection and tracking is a very challenging task in video surveillance applications. In this regard, many methods have been proposed for Moving Object Detection and Tracking based on edge, color, texture information. Due to unpredictable characteristics of objects in foggy videos, the task of object detection remains a challenging problem. In this paper, we propose a novel scheme for moving object detection based on Log Gabor filter (LGF) and Dominant Eigen Map (DEM) approaches. Location of the moving object is obtained by performing connected component analysis. In turn, a Moving Object is Tracked based on the centroid manipulation. Number of experiments is performed using indoor and outdoor video sequences. The proposed method is tested on standard PETS datasets and many real time video sequences. Results obtained are satisfactory and are compared with existing well known traditional methods. {\textcopyright} 2012 IEEE.},
annote = {cited By 1},
author = {Krishna, M T G and Ravishankar, M and Babu, R},
booktitle = {International Conference on Intelligent Systems Design and Applications, ISDA},
doi = {10.1109/ISDA.2012.6416600},
keywords = {Connected component analysis; Intellectual systems,Gabor filters; Intelligent systems; Security syst,Object recognition},
pages = {568--573},
title = {{LoG-DEM: Log Gabor filter and dominant eigen map approaches for moving object detection and}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874394791{\&}doi=10.1109{\%}2FISDA.2012.6416600{\&}partnerID=40{\&}md5=568753b4756129a47fe08acdcd69d469},
year = {2012}
}
@inproceedings{Mori200725,
abstract = {In this paper, we proposed the object location estimation method in sensor-embedded environment using active Radio Frequency Identification (RFID) technology. Based on the proposed method, we have developed the indoor object management system, which provides users with three main functionalities: the ability to access and manage targeted objects in the environment, real-timely monitor their locations, record and later search the particular information from historical database. The estimation of object's location is based on the analysis of RF signal strength retrieved from RFID system and position tracking of a person in the room using floor-distributed pressure sensors. The experiment result has shown that the integration of sensors significantly reduce the effects from external interferences in the analysis of RF signal strength, and improve the accuracy of object location sensing.},
annote = {cited By 8},
author = {Mori, T and Siridanupath, C and Noguchi, H and Sato, T},
booktitle = {Proceedings of Future Generation Communication and Networking, FGCN 2007},
keywords = {Active RFID; External-; Historical databases; Int,Estimation; Information management; Location; Mana,Frequency estimation},
pages = {25--30},
title = {{Active RFID-based object management system in sensor-embedded environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-52249121042{\&}partnerID=40{\&}md5=4e785872ae428977cd22ba18cb830ef1},
volume = {2},
year = {2007}
}
@article{Gu2006385,
abstract = {For supporting location-aware computing in indoor environments, the location sensing/positioning system not only need to provide objects' precise location, but also should own such characteristics as: isotropy and convenience for portability. In this paper, we present an indoor location sensing system, Cicada. This System is based on the TDOA (time difference of arrival) between Radiofrequency and ultrasound to estimate distance, and adopts a technology integrating Slide Window Filter (SWF) and Extended Kalman Filter (EKF) to calculate location. Consequently, it not only can determine the coordinate location within 5cm average deviation either for static objects or for mobile objects, but also owns a nearly omni-directional working area. Moreover, it is able to run independently, mini and light so that it is very easy to be portable and even embedded into people's paraphernalia. {\textcopyright} Springer-Verlag Berlin Heidelberg 2006.},
annote = {cited By 9},
author = {Gu, H and Shi, Y and Chen, Y and Wang, B and Jiang, W},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Computer software portability; Concentration (proc,Mobile objects; Omni-directional working; Slide W,Tracking (position)},
pages = {385--394},
title = {{Cicada: A highly-precise easy-embedded and omni-directional indoor location sensing system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745815077{\&}partnerID=40{\&}md5=b3e0144f2d6080390e7e62e8ca4bc284},
volume = {3947 LNCS},
year = {2006}
}
@inproceedings{Focken2002400,
abstract = {This paper presents our work on building a real time distributed system to track 3D locations of people in an indoor environment, such as a smart room, using multiple calibrated cameras. In our system, each camera is connected to a dedicated computer on which foreground regions in the camera image are detected. This is done using an adaptive background model. These detected foreground regions are broadcasted to a tracking agent, which computes believed 3D locations of persons based on the detected image regions. We have implemented both a best-hypothesis heuristic tracking approach as well as a probabilistic multi-hypothesis tracker to find the object tracks from these 3D locations. The two tracking approaches are evaluated on a sequence of two people walking in a conference room recorded with three cameras. The results suggest that the probabilistic tracker shows comparable performance to the heuristic tracker. {\textcopyright} 2002 IEEE.},
annote = {cited By 72},
author = {Focken, D and Stiefelhagen, R},
booktitle = {Proceedings - 4th IEEE International Conference on Multimodal Interfaces, ICMI 2002},
doi = {10.1109/ICMI.2002.1167028},
keywords = {Adaptive background model; Calibrated cameras; De,Cameras; Interactive computer systems; Location,Target tracking},
pages = {400--405},
title = {{Towards vision-based 3-D people tracking in a smart room}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963838718{\&}doi=10.1109{\%}2FICMI.2002.1167028{\&}partnerID=40{\&}md5=aa7c0adfefaf4d29ae5e077b13ed7829},
year = {2002}
}
@inproceedings{Wan2013249,
abstract = {3D scene segmentation is important but difficult especially when one object makes contact with another in scenes. This paper presents a new algorithm for automatic object extraction with the help of a shape repository, which is an effective approach applicable to 3D meshes without scene graphs. In the new algorithm, connected components are first computed and taken as initial clusters. Then, based on the global shape similarities between the supposed mergence of two shapes and any shape from the shape repository, we make a decision as to whether two close shapes should be merged or not. Our iterative merging scheme is performed until none of the close shapes can be merged. Experiments show that this method is very efficient on some indoor scenes. {\textcopyright} 2013 IEEE.},
annote = {cited By 0},
author = {Wan, L and Miao, Z and Chang, D and Cen, Y},
booktitle = {Proceedings - 2013 International Conference on Virtual Reality and Visualization, ICVRV 2013},
doi = {10.1109/ICVRV.2013.48},
keywords = {3D meshes; 3D model retrieval; Hier-archical clus,Algorithms; Image retrieval; Iterative methods; Me,Three dimensional},
pages = {249--252},
title = {{3D scene segmentation with a shape repository}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893282589{\&}doi=10.1109{\%}2FICVRV.2013.48{\&}partnerID=40{\&}md5=9df5449dfa3d89eeaa7bb97cedf80aa5},
year = {2013}
}
@inproceedings{Bouet2008,
abstract = {RFID is an automatic identification technology that enables tracking of people and objects. Both identity and location are generally key information for indoor services. An obvious and interesting method to obtain these two types of data is to localize RFID tags attached to devices or objects or carried by people. However, signals in indoor environments are generally harshly impaired and tags have very limited capabilities which pose many challenges for positioning them. In this work, we propose a classification and survey the current state-of-art of RFID localization by first presenting this technology and positioning principles. Then, we explain and classify RFID localization techniques. Finally, we discuss future trends in this domain. {\textcopyright} 2008 IEEE.},
annote = {cited By 195},
author = {Bouet, M and {Dos Santos}, A L},
booktitle = {2008 1st IFIP Wireless Days, WD 2008},
doi = {10.1109/WD.2008.4812905},
keywords = {Automatic identification; Future trends; Indoor en,Automation; Electronic data interchange,Radio navigation},
title = {{RFID tags: Positioning principles and localization techniques}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-67649757595{\&}doi=10.1109{\%}2FWD.2008.4812905{\&}partnerID=40{\&}md5=27a0ebb40a362656f6e1abb87a8e1c39},
year = {2008}
}
@article{Rivera-Rubio201330,
abstract = {Although the use of computer vision to analyse images from smartphones is in its infancy, the opportunity to exploit these devices for various assistive applications is beginning to emerge. In this paper, we consider two potential applications of computer vision in the assistive context for blind and partially sighted users. These two applications are intended to help provide answers to the questions of "Where am I?" and "What am I holding?". First, we suggest how to go about providing estimates of the indoor location of a user through queries submitted by a smartphone camera against a database of visual paths - descriptions of the visual appearance of common journeys that might be taken. Our proposal is that such journeys could be harvested from, for example, sighted volunteers. Initial tests using bootstrap statistics do indeed suggest that there is sufficient information within such visual path data to provide indications of: a) along which of several routes a user might be navigating; b) where along a particular path they might be. We will also discuss a pilot benchmarking database and test set for answering the second question of "What am I holding?". We evaluated the role of video sequences, rather than individual images, in such a query context, and suggest how the extra information provided by temporal structure could significantly improve the reliability of search results, an important consideration for assistive applications. {\textcopyright} 2013 Springer-Verlag.},
annote = {cited By 3},
author = {Rivera-Rubio, J and Idrees, S and Alexiou, I and Hadjilucas, L and Bharath, A A},
doi = {10.1007/978-3-642-41190-8_4},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Assistive devices; Localisation; Mobile computers;,Benchmarking,Image analysis; Query languages; Smartphones},
pages = {30--40},
title = {{Mobile visual assistive apps: Benchmarks of vision algorithm performance}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887073829{\&}doi=10.1007{\%}2F978-3-642-41190-8{\_}4{\&}partnerID=40{\&}md5=d132fd177df6d60e8b70b3e696252150},
volume = {8158 LNCS},
year = {2013}
}
@inproceedings{Han2017,
abstract = {Signal decay is the fundamental problem of wireless communications, especially in an indoor environment where line-of-sight (LOS) paths for signal propagation are often blocked and various indoor objects exacerbate signal fading. There are three reasons for signal decay: long transmission distance, signal penetration, and reflection. In this paper, we propose OptRe which optimally places metallic reflectors - providing a highly reflective surface that can reflect impinging signals almost 100{\%} - in indoor environments to reduce the reflection loss and enhance wireless transmissions. It enhances both WiFi signal and low-power IoT devices without changing their configurations or network protocols. To enable OptRe, we first develop an empirical signal propagation model that can accurately estimate the signal strength and adapt itself to the reflectors' location. Using micro-benchmarks, our empirical signal propagation model is shown to be more accurate than the other existing path loss models. We also optimally place reflectors to maximize the worst-case signal coverage within the target indoor areas. Our extensive experimental evaluation results have shown OptRe to enhance signal strength for different types of wireless signals by almost 2x. {\textcopyright} 2017 IEEE.},
annote = {cited By 5},
author = {Han, S and Shin, K G},
booktitle = {Proceedings - IEEE INFOCOM},
doi = {10.1109/INFOCOM.2017.8056966},
keywords = {Experimental evaluation; Line-of-sight paths; Met,Low power electronics; Network protocols; Reflecti,Wi-Fi},
title = {{Enhancing wireless performance using reflectors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034039191{\&}doi=10.1109{\%}2FINFOCOM.2017.8056966{\&}partnerID=40{\&}md5=3d2f505929c60a5953fed7029a56a912},
year = {2017}
}
@article{Ahmad2017297,
abstract = {Active large scale surveillance of indoor and outdoor environments with multiple cameras is becoming an undeniable necessity in today's connected world. Enhanced computational and storage capabilities in smart cameras establish them as promising platforms for implementing intelligent and autonomous surveillance networks. However, poor resolution, limited number of samples per object, and pose variation in multi-view surveillance streams, make the task of efficient image representation highly challenging. To address these issues, we propose an efficient and powerful convolutional neural network (CNN) based framework for features extraction using embedded processing on smart cameras. Efficient, high performance, pre-trained CNNs are separately fine-tuned on persons and vehicles to obtain discriminative, low dimensional features from segmented surveillance objects. Furthermore, multi-view queries of surveillance objects are used to improve retrieval performance. Experiments reveal better efficiency and retrieval performance in different surveillance datasets. {\textcopyright} 2017 Elsevier Ltd},
annote = {cited By 7},
author = {Ahmad, J and Mehmood, I and Rho, S and Chilamkurti, N and Baik, S W},
doi = {10.1016/j.compeleceng.2017.05.033},
journal = {Computers and Electrical Engineering},
keywords = {Autonomous surveillance; Convolutional neural net,Cameras; Convolution; Image retrieval; Information,Security systems},
pages = {297--311},
title = {{Embedded deep vision in smart cameras for multi-view objects representation and retrieval}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020495256{\&}doi=10.1016{\%}2Fj.compeleceng.2017.05.033{\&}partnerID=40{\&}md5=c42ea90d8a2e0ce0a7ffb93649080919},
volume = {61},
year = {2017}
}
@inproceedings{Andrean2013237,
abstract = {The paper presents a method to determine a position of objects in three dimentional coordinates. The proposed method uses a vision-based localization using two low cost cameras. The formulation is derived by using a pin-hole camera principal to project a location of a point in a 2D image into 3D space. This method can be used for indoor unmanned aerial vehicles localization to provide position information for control and navigation purposes. {\textcopyright} 2013 IEEE.},
annote = {cited By 1},
author = {Andrean, S Y and Joelianto, E and Widyotriatmo, A and Adiprawita, W},
booktitle = {Proceedings of 2013 International Conference on Robotics, Biomimetics, Intelligent Computational Systems, ROBIONETICS 2013},
doi = {10.1109/ROBIONETICS.2013.6743611},
keywords = {2D images; 3-D space; 3D localization; Low costs;,Biomimetics; Cameras; Computational complexity; R,Object recognition},
pages = {237--241},
title = {{Low cost vision-based 3D localization system for indoor unmanned aerial vehicles}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896768826{\&}doi=10.1109{\%}2FROBIONETICS.2013.6743611{\&}partnerID=40{\&}md5=d30ad6ce520904010d09902e0ce0ff6e},
year = {2013}
}
@inproceedings{Huang20181863,
abstract = {Tracking the location of mobile manufacturing objects is essential for manufacturing execution system. This paper presents a review of recent RFID-based localization and tracking technologies. Based on the literature review, we studied the feasibility of indoor localization that locates items on the manufacturing shop-floor automatically using wireless signals and RF-based localization technologies. Although the real-time locating systems (RTLS) exist to provide real-time localization, these technologies are costly to implement on a large scale. In this feasibility study, we measured received signal strength and phase shift signals from commercial off-the-shelf (COTS) wireless devices for tracking the location of manufacturing objects. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Huang, S and Mohanty, S and Ashfahani, A and Pratama, M},
booktitle = {2018 15th International Conference on Control, Automation, Robotics and Vision, ICARCV 2018},
doi = {10.1109/ICARCV.2018.8581192},
keywords = {Commercial off-the-shelf; Computer vision; Locatio,Feasibility studies; Localization and tracking; L,Indoor positioning systems},
pages = {1863--1867},
title = {{The Study on Indoor Localization for Manufacturing Execution System}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060782285{\&}doi=10.1109{\%}2FICARCV.2018.8581192{\&}partnerID=40{\&}md5=d701a5f9e51313560c51d6b569837ccf},
year = {2018}
}
@inproceedings{Lee2015232,
abstract = {Many man-made objects contains ferrous materials, the presence of which distort earth magnetic field around them. Motivated by this observation, this paper presents a way-finding method utilizing a magnetic tensor sensor (MTS) to help visually impaired people avoid ferrous obstacles and follow magnetic map for indoor navigation. With two orthogonal pairs of digital three-axis magnetic field sensors, the MTS simultaneously measures magnetic flux densities and magnetic tensor; the latter effectively eliminates the influence of geomagnetic field and enables the use of a single tensor-based parameter Q which increases exponentially when approaching an object for obstacle avoidance. A prototype MTS has been developed and its performance has been experimentally evaluated with two practical applications; outdoor obstacle avoidance and indoor navigation using only 1D map incorporating magnetic waypoints and an improved dynamic time warping method to estimate locations from the real-time measurements and pre-stored map. A method to enhance critical waypoints (such as stair) on magnetic map using vision-based line-detections is discussed. {\textcopyright} 2015 IEEE.},
annote = {cited By 4},
author = {Lee, K.-M. and Li, M and Lin, C.-Y.},
booktitle = {IEEE/ASME International Conference on Advanced Intelligent Mechatronics, AIM},
doi = {10.1109/AIM.2015.7222537},
keywords = {Dynamic time warping; Earth magnetic fields; Geom,Geomagnetism; Human rehabilitation equipment; Indo,Magnetic field effects},
pages = {232--237},
title = {{A novel way-finding method based on geomagnetic field effects and magnetic tensor measurements for visually impaired users}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951067870{\&}doi=10.1109{\%}2FAIM.2015.7222537{\&}partnerID=40{\&}md5=de8f1200e232eeec12271446861dddb6},
volume = {2015-Augus},
year = {2015}
}
@inproceedings{An2011989,
abstract = {This paper presents a ground view-based Simultaneous Localization and Mapping (SLAM) using a commercial web camera to construct a feature map of an unstructured indoor environment. A camera attached to a robot looks downward to exploit several advantages; being insensitive to lighting conditions; limiting visible region to be undisturbed by moving objects; extracting vertical edge features easily. In order to make full use of characteristics of indoor environment, we choose to extract a salient vertical edge feature. Feature parameters including uncertainty are estimated by a random sample consensus technique using the fact that all vertical edge features intersect at a fixed vanishing point. Through successive tracking of extracted feature, its initial location is determined by a non-linear least squares method. Experiment in a small-scale but highly unstructured environment shows a good SLAM performance under Extended Kalman Filtering algorithm that runs in real-time. {\textcopyright} 2011 IEEE.},
annote = {cited By 0},
author = {An, S.-Y. and Lee, L.-K. and Oh, S.-Y. and Kang, J.-G.},
booktitle = {2011 IEEE International Conference on Mechatronics and Automation, ICMA 2011},
doi = {10.1109/ICMA.2011.5985795},
keywords = {Cameras; Extended Kalman filters; Least squares a,Extended Kalman filtering; Feature map; Feature pa,Robotics},
pages = {989--996},
title = {{Ground view-based SLAM using a commercial web camera in unstructured indoor environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-81055138881{\&}doi=10.1109{\%}2FICMA.2011.5985795{\&}partnerID=40{\&}md5=59afa365158e49f031c5c8b59e863974},
year = {2011}
}
@inproceedings{Xu20171549,
abstract = {Virtual reality (VR) is a computer simulation technology, which can create a virtual world to allow users to immerse in the simulated environment, and be able to interact with objects in a nature way. This paper presents an indoor tracking and recognition system to meet the interactive of multiple users in virtual reality. As we all know, tracking in real time and accurately play a vital role in VR application. Interactive VR games require data update rate above 35HZ to make players fell well. In our system, we use infrared cameras, infrared markers and image processing techniques to acquire the users' position and orientation information in real time. We describe a relatively inexpensive, but can monitor the precise location and orientation information system. In our system, cheap infrared cameras are fixed on ceiling. Every user in the environment wears an infrared LED module. The distance between any two infrared LED in a LED module is different with others. We can distinguish every user and get their precise position and orientation in real time by stereo vision theory and our recognition algorithm. This system strikes a good balance between price and capability. {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Xu, W and Wang, B and Jiang, Y},
booktitle = {Proceedings of 2017 IEEE 2nd Advanced Information Technology, Electronic and Automation Control Conference, IAEAC 2017},
doi = {10.1109/IAEAC.2017.8054273},
keywords = {Cameras; Image processing; Infrared devices; Stere,Computer simulation technology; Image processing,Virtual reality},
pages = {1549--1553},
title = {{Multi-target indoor tracking and recognition system with infrared markers for virtual reality}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034573679{\&}doi=10.1109{\%}2FIAEAC.2017.8054273{\&}partnerID=40{\&}md5=f45e8f9085469eaa059cd0e34b895958},
year = {2017}
}
@inproceedings{MdMahfujurRahman2011,
abstract = {The prevalent visions of ambient intelligence leverage natural interaction between user and available services in a learning space. In this pursuit, we propose a framework to facilitate handheld device based PointMe interaction with annotated media content, where the user points his/her handheld device to the annotated physical atlas for interacting with a world map. The proposed system performs annotations by specifying spatial location of the atlas and mapping related learning information to them. Each annotated data is encoded in customized Learning Object Metadata (LOM) format and they provide access points for available information about the specific countries in the map. This real world interaction technique with the physical environment and seamless virtual learning information acquisition make the system transparent from the young learners and help them to become engaged in their learning activities. {\textcopyright} 2011 IEEE.},
annote = {cited By 1},
author = {{Md Mahfujur Rahman}, A S and {El Saddik}, A},
booktitle = {Proceedings - IEEE International Conference on Multimedia and Expo},
doi = {10.1109/ICME.2011.6012208},
keywords = {Hand held computers,Human computer interaction; Maps; Metadata; Multi,indoor physical map; Learning objects; Mobile inte},
title = {{Mobile pointme based pervasive gaming interaction with learning objects annotated physical atlas}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80155181443{\&}doi=10.1109{\%}2FICME.2011.6012208{\&}partnerID=40{\&}md5=0c5b3721d9afe202f4fb7ae65e91090d},
year = {2011}
}
@article{Zhang20091067,
abstract = {With the existence of "semantic gap" between the machine-readable low level features (e.g. visual features in terms of colors and textures) and high level human concepts, it is inherently hard for the machine to automatically identify and retrieve events from videos according to their semantics by merely reading pixels and frames. This paper proposes a human-centered framework for mining and retrieving events and applies it to indoor surveillance video databases. The goal is to locate video sequences containing events of interest to the user of the surveillance video database. This framework starts by tracking objects. Since surveillance videos cannot be easily segmented, the Common Appearance Intervals (CAIs) are used to segment videos, which have the flavor of shots in movies. The video segmentation provides an efficient indexing schema for the retrieval. The trajectories obtained are thus spatiotemporal in nature, based on which features are extracted for the construction of event models. In the retrieval phase, the database user interacts with the machine and provides "feedbacks" to the retrieval results. The proposed learning algorithm learns from the spatiotemporal data, the event model as well as the "feedbacks" and returns the refined results to the user. Specifically, the learning algorithm is a Coupled Hidden Markov Model (CHMM), which models the interactions of objects in CAIs and recognizes hidden patterns among them. This iterative learning and retrieval process contributes to the bridging of the "semantic gap", and the experimental results show the effectiveness of the proposed framework by demonstrating the increase of retrieval accuracy through iterations and comparing with other methods. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
annote = {cited By 12},
author = {Zhang, C and Chen, X and Zhou, L and Chen, W.-B.},
doi = {10.1016/j.patrec.2009.05.004},
journal = {Pattern Recognition Letters},
keywords = {Coupled hidden Markov models; Event model; Hidden,Database systems; Feedback; Hidden Markov models;,Security systems},
number = {12},
pages = {1067--1076},
title = {{Semantic retrieval of events from indoor surveillance video databases}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650269410{\&}doi=10.1016{\%}2Fj.patrec.2009.05.004{\&}partnerID=40{\&}md5=4e33ed4fb41d46be51fc9426a7c20f57},
volume = {30},
year = {2009}
}
@inproceedings{Tian2014,
abstract = {GPS-enabled devices have greatly facilitated the continuous collection of highly accurate locational data for moving objects including humans. The effective and efficient detection of mobility mode from raw GPS data is critically important for social behavior and public health research. In this paper, we propose a new method that can be used to automate the detection of human mobility mode by synthetically analyzing geographic location, duration, speed as well as spatial context information in the data. Ancillary GIS layers such as building footprints are also included to help identify the GPS points taken indoor. Five mobility modes: transporting, parking, walking, roaming and indoor are detected in our method. Preliminary testing of the method applied on three datasets showed an overall accuracy of above 90{\%} when compared with the human interpretation results. A software application has also been developed to automate the detection and report generation. {\textcopyright} 2014 IEEE.},
annote = {cited By 1},
author = {Tian, J and Jiang, Y and Chen, Y and Li, W and Mu, N},
booktitle = {Proceedings - 2014 22nd International Conference on Geoinformatics, Geoinformatics 2014},
doi = {10.1109/GEOINFORMATICS.2014.6950833},
keywords = {Application programs; Error detection; Geographic,Building footprint; Efficient detection; Geograph,Global positioning system},
title = {{Automated human mobility mode detection based on GPS tracking data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84918799034{\&}doi=10.1109{\%}2FGEOINFORMATICS.2014.6950833{\&}partnerID=40{\&}md5=cac35807217e1115ac8e4ffd3f72efb2},
year = {2014}
}
@inproceedings{Mujibiya2015241,
abstract = {We propose a design of self-powering room-wide power usage and crowd activity sensing that uses a single point of contact on a conductive surface of furniture or everyday objects such as metal frame of table or window, desktop PC case, rack, cabinet, and so on. We utilize these surfaces for energy scavenging from capacitive reactance and electromagnetic inductance, which are typically, occur in indoor house and office where there are many electrical appliances. We incorporate energy store and release strategy, and treat the charge accumulation time as a function of electrical appliance usage and human activity within a certain location. In this paper, we highlight principle of operation and prototype implementation result showing sensing log of an office room for 7 days timespan. {\textcopyright} Copyright 2015 ACM.},
annote = {cited By 1},
author = {Mujibiya, A and Torii, J},
booktitle = {Proceedings of the 2015 ACM International Conference on Interactive Tabletops and Surfaces, ITS 2015},
doi = {10.1145/2817721.2823487},
keywords = {Activity sensing; Capacitive reactance; Charge ac,Energy harvesting,Interactive devices},
pages = {241--246},
title = {{Walls have ears: Using conductive surfaces of furniture and everyday objects for room-wide power usage and crowd activity sensing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962861414{\&}doi=10.1145{\%}2F2817721.2823487{\&}partnerID=40{\&}md5=ac7eb74e28e4becbd4a2b9b26ae323b0},
year = {2015}
}
@inproceedings{Sharhan201528,
abstract = {Most service providers and data owners desire to control the access to sensitive resources. The user may express restrictions, such as who can access the resources, at which point in time and from which location. However, the location requirement is difficult to achieve in an indoor environment. Determining user locations inside of buildings is based on a variety of solutions. Moreover, current access control solutions do not consider restricting access to sensitive data in indoor environments. This article presents a graphical web interface based on OpenStreetMap (OSM), called Indoor Mapping Web Interface (IMWI), which is designed to use indoor maps and floor plans of several real-world objects, such as hospitals, universities and other premises. By placing Bluetooth Low Energy (BLE) beacons inside buildings and by labeling them on digital indoor maps, the web interface back-end will provide the stored location data within an access control environment. Using the stored information will enable users to express indoor access control restrictions. Moreover, the IMWI enables and ensures the accurate determination of a user device location in indoor scenarios. By defining several scenarios the usability of the IMWI and the validity of the policies have been evaluated. {\textcopyright} 2015 IEEE.},
annote = {cited By 4},
author = {Sharhan, S M H and Zickau, S},
booktitle = {2015 IEEE 11th International Conference on Wireless and Mobile Computing, Networking and Communications, WiMob 2015},
doi = {10.1109/WiMOB.2015.7347937},
keywords = {Access control; Bluetooth; Indoor positioning syst,Bluetooth low energies (BLE); Bluetooth low energ,Location based services},
pages = {28--36},
title = {{Indoor mapping for location-based policy tooling using Bluetooth Low Energy beacons}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964284466{\&}doi=10.1109{\%}2FWiMOB.2015.7347937{\&}partnerID=40{\&}md5=87474feaa8a2b38079c9e4158271b7fc},
year = {2015}
}
@inproceedings{Cheng201744,
abstract = {Along with the development of communication technology, the degree of involvement of location-based service in daily life increases accordingly. Through further combination between mobile devices and micro-location technology, mobile devices can now offer more precise and high-quality services which allow users to obtain required information while moving. The proposed intelligent device-oriented control system is based on the devices to be controlled and the location they use devices, providing a control service system with dynamic operation interface: When detecting the approaching users, the system would automatically notify users the available devices and provide users with the control options for the devices. The system function would come along with the device to be controlled, and the user interface would change with user's location and devices in the location, reducing the complexity of operation and enabling users to focus on the present objects to be operated. This system can be combined with I/O or smart devices, providing users with location-based device-oriented control service, making the update and maintenance of IoT application control system easier. {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Cheng, R.-S. and Lin, K W and Hong, W.-J. and Pan, Y.-J. and Yang, C.-W.},
booktitle = {Proceedings of the 2017 IEEE International Conference on Applied System Innovation: Applied System Innovation for Modern Technology, ICASI 2017},
doi = {10.1109/ICASI.2017.7988341},
keywords = {Appliance controls; Communication technologies; D,Automation; Control systems; Domestic appliances;,Location based services},
pages = {44--47},
title = {{A micro-location based dynamic device-oriented control system for iOT applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028572180{\&}doi=10.1109{\%}2FICASI.2017.7988341{\&}partnerID=40{\&}md5=5959fab623f9688dad0857700fbfd5a1},
year = {2017}
}
@inproceedings{Nishimura2007295,
abstract = {This paper proposes a new capture method for an indoor interactive workshop with facilitators and attendees working collaboratively on creation of original works. A simple audio recorder and audio player for every user and artifact in the workshop enables the system to estimate the user location history as well as recording the audio scenery. Each audio signal captured by a recorder is analyzed and identified as a specific sound emitted from a corresponding audio player. The locations and orientations of all users are estimated by collecting all the information in the vicinity of each attendee. Users can re-experience the workshop audially and visually using a map of the workshop room and attendees' locations and orientations.},
annote = {cited By 0},
author = {Nishimura, T and Nakamura, Y and Tomobe, H and Kurata, T and Okuma, T and Matsuo, Y},
booktitle = {4th International Conference on Networked Sensing Systems, INSS},
doi = {10.1109/INSS.2007.4297437},
keywords = {Audio acoustics,Audio signals; International conferences; Locatio,Estimation; Location; Sensors},
pages = {295},
title = {{Location estimation using auditory signal emitted and received by all objects}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-47149088826{\&}doi=10.1109{\%}2FINSS.2007.4297437{\&}partnerID=40{\&}md5=2ea280594780c0981eddde799f3e5539},
year = {2007}
}
@article{Recio2009914,
abstract = {This paper describes the design and implementation of an object tracking service for indoor environments. First, the wireless indoor location estimation technology is overviewed presenting advantages and disadvantages. Second, the methodology of the study is presented. To estimate the position we use clues inserted by location clue injectors of the system. In our architecture one of these injectors is a ZigBee sensor network. As location algorithm we have developed a method combining statistical techniques (particle filter) and proximity sensing (nearest neighbour) to get better efficiency. The results obtained show that a good precision and reliability can be achieved with a low-cost solution. {\textcopyright} 2009 Springer Berlin Heidelberg.},
annote = {cited By 2},
author = {Recio, I and Moya, J M and Araujo, {\'{A}} and Vallejo, J C and Malag{\'{o}}n, P},
doi = {10.1007/978-3-642-02481-8_139},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Assisted living; Distributed computer systems; Loc,Design and implementations; Indoor; Intelligent e,Tracking (position)},
number = {PART 2},
pages = {914--921},
title = {{Analysis and design of an object tracking service for intelligent environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952566504{\&}doi=10.1007{\%}2F978-3-642-02481-8{\_}139{\&}partnerID=40{\&}md5=d8a7a3686625f812f2c7674217960960},
volume = {5518 LNCS},
year = {2009}
}
@article{Hedau2010224,
abstract = {In this paper we show that a geometric representation of an object occurring in indoor scenes, along with rich scene structure can be used to produce a detector for that object in a single image. Using perspective cues from the global scene geometry, we first develop a 3D based object detector. This detector is competitive with an image based detector built using state-of-the-art methods; however, combining the two produces a notably improved detector, because it unifies contextual and geometric information. We then use a probabilistic model that explicitly uses constraints imposed by spatial layout - the locations of walls and floor in the image - to refine the 3D object estimates. We use an existing approach to compute spatial layout [1], and use constraints such as objects are supported by floor and can not stick through the walls. The resulting detector (a) has significantly improved accuracy when compared to the state-of-the-art 2D detectors and (b) gives a 3D interpretation of the location of the object, derived from a 2D image. We evaluate the detector on beds, for which we give extensive quantitative results derived from images of real scenes. {\textcopyright} 2010 Springer-Verlag.},
annote = {cited By 83},
author = {Hedau, V and Hoiem, D and Forsyth, D},
doi = {10.1007/978-3-642-15567-3_17},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 6},
pages = {224--237},
title = {{Thinking inside the box: Using appearance models and context based on room geometry}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78149294425{\&}doi=10.1007{\%}2F978-3-642-15567-3{\_}17{\&}partnerID=40{\&}md5=d2a4f63dd563d95d5eb022f026caa516},
volume = {6316 LNCS},
year = {2010}
}
@inproceedings{Kowalczuk20161082,
abstract = {The paper describes a system of 3D mapping of data collected with due regard for variable baseline. This solution constitute an extension to a VisRobot sub-system developed as a subsystem necessary for implementing the generic idea of using mobile robots to explore an indoor static environment. This subsystem is to acquire stereo images, calculate the depth in the images and construct the sought 3D map. Stereo images are obtained at various stereo baselines, resulting in enhanced resolution of depth, especially for distant objects. The length of each baseline is obtained by currently measuring the actual location and angular pose of robotic carrier of camera. Measurement errors bring about inaccuracies in depth. Therefore, we propose an innovative procedure that combine the depth maps gained at variable baselines. The paper presents the resulting improved 3D-map visualization in terms of higher precision, considering two cases: static and cumulative localization errors. {\textcopyright} 2016 IEEE.},
annote = {cited By 1},
author = {Kowalczuk, Z and Merta, T},
booktitle = {2016 21st International Conference on Methods and Models in Automation and Robotics, MMAR 2016},
doi = {10.1109/MMAR.2016.7575288},
keywords = {Enhanced resolutions; Localization errors; Map vi,Mapping; Robotics; Three dimensional computer grap,Stereo image processing},
pages = {1082--1087},
title = {{Three-dimensional mapping for data collected using variable stereo baseline}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991766088{\&}doi=10.1109{\%}2FMMAR.2016.7575288{\&}partnerID=40{\&}md5=1587473cc0edac41f70b7fc0b5022b57},
year = {2016}
}
@inproceedings{Men2012,
abstract = {Improvements are presented for the radio frequency identification (RFID) location technology based on received signal strength indication (RSSI) in this paper. A semi-active tag with RSSI is designed, which increases the circuit of measuring the signal strength between the rectifier modules and digital modules, thus tags can measure the signal strength. This paper theoretically analyzes the method of signal received by tags to reduce the reflection interference. The method of bi-directional RSSI is proposed, which gets signal by tags and readers, and the spatial diversity technique is introduced, which can be utilized to compensate channel uncertainties such as multipath fading. The method of bi-directional RSSI is that tags and the reader can locate each other, and is a special spatial diversity technique. In this paper, spatial diversity is exploited for locating stationary and mobile objects in the indoor environment. Space diversity technique is introduced for small scale motion and temporal variation compensation of received signal strength and it is demonstrated analytically that it enhances location accuracy. The three common linear combining approaches are selection combining (SC), maximal ratio combining (MRC) and equal gain combining (EGC). Taking into account the ease of implementation, SC is adopted in the paper. It is theoretically analyzed that the method of bi-directional RSSI can be effectively against multipath fading, improve signal reception gain, and enhance the communication quality. {\textcopyright} 2012 IEEE.},
annote = {cited By 1},
author = {Men, C and Mao, L and Wu, L},
booktitle = {2012 International Conference on Wireless Communications, Networking and Mobile Computing, WiCOM 2012},
doi = {10.1109/WiCOM.2012.6478718},
keywords = {Diversity reception; Electric rectifiers; Mobile,Interference suppression,Localization; Maximal ratio combining (MRC); Recei},
title = {{The research of RFID localization technology based on bi-directional RSSI}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876060826{\&}doi=10.1109{\%}2FWiCOM.2012.6478718{\&}partnerID=40{\&}md5=095fee16889ac0fd35803eb8a6bd52c5},
year = {2012}
}
@inproceedings{Lee2014410,
abstract = {This paper addresses the challenge of mobile robot navigation in indoor environments. There is a critical need for cost-effective, reliable, and fairly accurate solutions to meet the demands of indoor robotic applications. Currently, researchers are exploring various approaches for this problem. The one we are presenting in this paper is based on QR (Quick Response) codes to provide location references for mobile robots. The mobile robot is equipped with a Smartphone that is programmed to detect and read information on QR codes that are strategically placed in the operating environment of the robot. The mobile robot can perform the autonomous run throughout the guide route by using real-time QR code recognition. The lab information on QR code is played to the visitors using Text-to-Speech provided through Android device. Ultrasonic range sensors which can detect objects and measure distances with high accuracy are used to implement the wall-following and obstacle-avoidance behaviors. The collected sonar range information by ultrasonic range sensors is processed by a microcontroller that autonomously controls a tour guide robot. An algorithm based on a proportional-integral-derivative (PID) control is applied to the tour guide robot to perform more accurate robot motion control. A Bluetooth technology is used to send stored information on QR codes from the Smartphone to the tour guide robot wirelessly. The experimental setup of the tour guide robot along with the successful implementation of the efficient method for a navigation technique is presented. {\textcopyright} 2014 IEEE.},
annote = {cited By 13},
author = {Lee, S J and Lim, J and Tewolde, G and Kwon, J},
booktitle = {IEEE International Conference on Electro Information Technology},
doi = {10.1109/EIT.2014.6871799},
keywords = {Bar codes; Bluetooth; Mobile robots; Signal encodi,Bluetooth technology; Landmark; QR codes; Robot n,Navigation},
pages = {410--415},
title = {{Autonomous tour guide robot by using ultrasonic range sensors and QR code recognition in indoor environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906572093{\&}doi=10.1109{\%}2FEIT.2014.6871799{\&}partnerID=40{\&}md5=205bfc816c1cdfb76857ecdc9107e760},
year = {2014}
}
@article{Khoury2009483,
abstract = {This paper presents research that investigated algorithms for high-precision identification of contextual information in location-aware engineering applications. The primary contribution of the presented work is the design and implementation of a dynamic user-viewpoint tracking scheme in which mobile users' spatial context is defined not only by their position (i.e., location), but also by their three-dimensional head orientation (i.e., line of sight). This allows the identification of objects and artifacts visible in a mobile user's field of view with much higher accuracy than was possible by tracking position alone. For outdoor applications, a georeferencing based algorithm has been developed using the Global Positioning System (GPS) and magnetic orientation tracking devices [5] to track a user's dynamic viewpoint. For indoor applications, this study explored the applicability of wireless technologies, in particular Indoor GPS, for dynamic user position tracking in situations where GPS is unavailable. The objectives of this paper are to describe the details of the three-stage-algorithm that has been designed and implemented, and to demonstrate the extent to which positioning technologies such as GPS and Indoor GPS can be used together with high-precision orientation trackers to accurately interpret the fully-qualified spatial context of a mobile user in challenging environments such as those found on construction sites. The obtained results highlight the potential of using location-aware technologies for rapidly identifying and retrieving contextual information in engineering applications. {\textcopyright} 2009 Elsevier Ltd. All rights reserved.},
annote = {cited By 27},
author = {Khoury, H M and Kamat, V R},
doi = {10.1016/j.aei.2009.04.002},
journal = {Advanced Engineering Informatics},
keywords = {Applications; Global positioning system; Global s,Construction sites; Contextual information; Engine,Tracking (position)},
number = {4},
pages = {483--496},
title = {{High-precision identification of contextual information in location-aware engineering applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349188274{\&}doi=10.1016{\%}2Fj.aei.2009.04.002{\&}partnerID=40{\&}md5=6758556a9b767f8c64efa927fd9b31b0},
volume = {23},
year = {2009}
}
@inproceedings{Liu201689,
abstract = {Millions of people in the world suffer from vision impairment or even vision loss. Guide sticks and dogs have been deployed to lead them around various obstacles. However, both of them are not capable of interacting with human users who normally rely on conceptual knowledge or semantic contents of the environment. This paper first builds a 3D semantic indoor environment map with an RGB-D sensor. Then, the map is used for room recognition during the revisits based on appearance by applying a convolutional neural network. Representative objects extracted from the semantic map are used to diagnose and eliminate errors during room recognition. The proposed method result in a 97.8{\%} accuracy even with lighting condition and small object location changes. {\textcopyright} 2016 Chinese Automation and Computing Society.},
annote = {cited By 3},
author = {Liu, Q and Li, R and Hu, H and Gu, D},
booktitle = {2016 22nd International Conference on Automation and Computing, ICAC 2016: Tackling the New Challenges in Automation and Computing},
doi = {10.1109/IConAC.2016.7604900},
keywords = {Automation; Convolution; Neural networks,Conceptual knowledge; Convolutional neural networ,Semantics},
pages = {89--94},
title = {{Using semantic maps for room recognition to aid visually impaired people}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998636627{\&}doi=10.1109{\%}2FIConAC.2016.7604900{\&}partnerID=40{\&}md5=d49af27e247a25032df80f344fd201af},
year = {2016}
}
@inproceedings{Liu201525,
abstract = {In this paper, we present a new approach of 3D indoor scenes modeling on single image. With a single input indoor image (including sofa, tea table, etc.), a 3D scene can be reconstructed using existing model library in two stages: image analysis and model retrieval. In the image analysis stage, we obtain the object information from input image using geometric reasoning technology combined with image segmentation method. In the model retrieval stage, line drawings are extracted from 2D objects and 3D models by using different line rendering methods. We exploit various tokens to represent local features and then organize them together as a star-graph to show a global description. Finally, by comparing similarity among the encoded line drawings, models are retrieved from the model library and then the scene is reconstructed. Experimental results show that, driven by the given model library, indoor scenes modeling from a single image could be achieved automatically and efficiently. Copyright held by authors.},
annote = {cited By 12},
author = {Liu, Z and Zhang, Y and Wu, W and Liu, K and Sun, Z},
booktitle = {Proceedings - Graphics Interface},
keywords = {Computational geometry; Computer graphics; Image a,Geometric reasoning; I.3.5 [computer graphics]: c,Three dimensional computer graphics},
pages = {25--32},
title = {{Model-driven indoor scenes modeling from a single image}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025458224{\&}partnerID=40{\&}md5=a05f94179147d45e1d6c9b967c0ee8af},
volume = {2015-June},
year = {2015}
}
@inproceedings{Yu20133714,
abstract = {A device just like Harry Potter's Marauder's Map, which pinpoints the location of each person-of-interest at all times, provides invaluable information for analysis of surveillance videos. To make this device real, a system would be required to perform robust person localization and tracking in real world surveillance scenarios, especially for complex indoor environments with many walls causing occlusion and long corridors with sparse surveillance camera coverage. We propose a tracking-by-detection approach with nonnegative discretization to tackle this problem. Given a set of person detection outputs, our framework takes advantage of all important cues such as color, person detection, face recognition and non-background information to perform tracking. Local learning approaches are used to uncover the manifold structure in the appearance space with spatio-temporal constraints. Nonnegative discretization is used to enforce the mutual exclusion constraint, which guarantees a person detection output to only belong to exactly one individual. Experiments show that our algorithm performs robust localization and tracking of persons-of-interest not only in outdoor scenes, but also in a complex indoor real-world nursing home environment. {\textcopyright} 2013 IEEE.},
annote = {cited By 30},
author = {Yu, S.-I. and Yang, Y and Hauptmann, A},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2013.476},
keywords = {Face recognition; Monitoring; Supervised learning,Localization and tracking; Manifold structures; Mu,Security systems},
pages = {3714--3720},
title = {{Harry potter's marauder's map: Localizing and tracking multiple persons-of-interest by nonnegative discretization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887373086{\&}doi=10.1109{\%}2FCVPR.2013.476{\&}partnerID=40{\&}md5=a6f440d72e9067725ed866bf084d115d},
year = {2013}
}
@inproceedings{Hauschildt2010879,
abstract = {Exploiting the natural thermal infrared radiation of humans is a promising approach for an accurate, comfortable and inexpensive indoor localization system. However, different sources of disturbancemake the development challenging. In order to provide valid sensor data for various scenarios an adequate simulation environment is needed. In this paper we present a real-time scene simulator that allows the simulation of dynamic indoor environments and the resulting output signals of infrared sensors. The composition of such environments is simplified by using an object and sensor database. In order to enable real-time processing, OpenGL and hardware acceleration is applied. Evaluations show that the accuracy of the chosen approach is sufficient to develop algorithms for a Thermal Infrared Localization System (ThILo). Furthermore, it can be shown that real-time processing is possible for a complete location system in typical indoor environments. {\textcopyright}2010 IEEE.},
annote = {cited By 4},
author = {Hauschildt, D and Kemper, J and Kirchhof, N and Juretko, B and Linde, H},
booktitle = {Proceedings - Winter Simulation Conference},
doi = {10.1109/WSC.2010.5679101},
keywords = {A-thermal; Hardware acceleration; Indoor environme,Infrared radiation; Sensors,Tracking (position)},
pages = {879--890},
title = {{Real-time scene simulator for thermal infrared localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951660388{\&}doi=10.1109{\%}2FWSC.2010.5679101{\&}partnerID=40{\&}md5=a3c2b4ac9335f7eb417509e00ea23901},
year = {2010}
}
@inproceedings{Ma2016,
abstract = {Extremely low-cost passive RFID tags have become key components for the Internet of Things (IoT), where ubiquitous object locating is one of the most important functions. Although the number of tags in indoor environment continues growing fast, objects cannot be always assumed tagged, whether intentionally or unintentionally. Compared to tagged objects, a tagless target which neither emits nor modulates signal is much more difficult to locate, especially when the size is small. In this paper, we achieve accurate tagless object locating through a dense and wide non-uniform sampling in the Fourier domain of target reflectivity with the help of ambient passive RFID tags as landmarks. Unlike conventional RFID systems, we leverage nonlinearity in passive tags to backscatter second harmonic signals. The frequency separation of uplink and downlink in harmonic RFID allows ready interference cancellation. We embrace spatial diversity enabled by ambient tags and frequency diversity by broadband harmonic backscattering to improve accuracy and robustness. We present the fundamental theory and a prototype system to verify the proposed approach. {\textcopyright} 2016 IEEE.},
annote = {cited By 1},
author = {Ma, Y and Kan, E C},
booktitle = {Proceedings - IEEE INFOCOM},
doi = {10.1109/INFOCOM.2016.7524577},
keywords = {Backscattering; Interference suppression; Internet,Frequency separation; Harmonic; Indoor locating;,Harmonic analysis},
title = {{Ubiquitous tagless object locating with ambient harmonic tags}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983325934{\&}doi=10.1109{\%}2FINFOCOM.2016.7524577{\&}partnerID=40{\&}md5=f538d080f481eeaaec159db7ea962918},
volume = {2016-July},
year = {2016}
}
@article{Guo200881,
abstract = {A new system named Home-Explorer that searches and finds physical artifacts in a smart indoor environment is proposed. The view on which it is based is artifact-centered and uses sensors attached to the everyday artifacts (called smart objects) in the real world. This paper makes two main contributions: First, it addresses, the robustness of the embedded sensors, which is seldom discussed in previous smart artifact research. Because sensors may sometimes be broken or fail to work under certain conditions, smart objects become hidden ones. However, current systems provide no mechanism to detect and manage objects when this problem occurs. Second, there is no common context infrastructure for building smart artifact systems, which makes it difficult for separately developed applications to interact with each other and uneasy for them to share and reuse knowledge. Unlike previous systems, Home-Explorer builds on an ontology-based knowledge infrastructure named Sixth-Sense, which makes it easy for the system to interact with other applications or agents also based on this ontology. The hidden object problem is also reflected in our ontology, which enables Home-Explorer to deal with both smart objects and hidden objects. A set of rules for deducing an object's status or location information and for locating hidden objects are described and evaluated. {\textcopyright} 2008 - IOS Press and the authors.},
annote = {cited By 24},
author = {Guo, B and Satake, S and Imai, M},
doi = {10.1155/2008/463787},
journal = {Mobile Information Systems},
number = {2},
pages = {81--103},
title = {{Home-Explorer: Ontology-based physical artifact search and hidden object detection system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013575868{\&}doi=10.1155{\%}2F2008{\%}2F463787{\&}partnerID=40{\&}md5=f9be0ab3feceeeca3868fc69cbafb87c},
volume = {4},
year = {2008}
}
@inproceedings{Wang20166,
abstract = {Device-free localization of people and objects indoors not equipped with radios is playing a critical role in many emerging applications. This paper presents a novel channel state information (CSI) pre-processing scheme that enables accurate device-free localization indoors. The basic idea is simple: CSI is sensitive to a target's location and by modelling the CSI measurements of multiple wireless links as a set of power fading based equations, the target location can be determined. However, due to rich multipaths in indoor environment, the received signal strength (RSS) or even the fine-grained CSI can not be easily modelled. We observe that even in a rich multipath environment, not all subcarriers are equally affected by multipath reflections. Our preprocessing scheme tries to identify the subcarriers not affected by multipath. Thus, CSIs on the "clean" subcarriers can be modelled and utilized for accurate localization. Extensive experiments demonstrate the effectiveness of the proposed pre-processing scheme. {\textcopyright} 2016 ACM.},
annote = {cited By 3},
author = {Wang, J and Zhang, L and Wang, X and Xiong, J and Chen, X and Fang, D},
booktitle = {Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM},
doi = {10.1145/2987354.2987361},
keywords = {Channel state information,Device-free localizations; Emerging applications;,Education; Fading (radio); Indoor positioning syst},
pages = {6--8},
title = {{A novel CSI pre-processing scheme for device-free localization indoors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994134205{\&}doi=10.1145{\%}2F2987354.2987361{\&}partnerID=40{\&}md5=22cd4a2ad232b253a2dc8b639866d4d9},
volume = {03-07-Octo},
year = {2016}
}
@inproceedings{Vieira2015,
abstract = {Indoor Location has been studied for some time and has become a very popular topic recently. Although many techniques for indoor positioning exist, the right choice depends on the context. The context is composed of many factors, for example, the service provided, cost, maintenance, etc. Moreover, new techniques for indoor positioning are still being developed. This paper applies the Architecture Trade-off Analysis Method (ATAM) in a joint scenario for indoor location, presenting how architectural decisions influence the quality attributes for the system. Finally, the paper proposes a generic object-oriented model for indoor location, making it trivial to exchange between techniques, algorithms and sensors within a mobile application during the localization process. {\textcopyright} 2015 ACM.},
annote = {cited By 0},
author = {Vieira, E B and Leal, A G},
booktitle = {Proceedings of the 5th International Workshop on Mobile Entity Localization and Tracking in GPS-Less Environments, MELT 2015},
doi = {10.1145/2830571.2830577},
keywords = {Architectural decision; ATAM; Indoor locations; M,Economic and social effects; Global positioning sy,Quality control},
title = {{Applying ATAM to evaluate indoor location systems for smartphones}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976904123{\&}doi=10.1145{\%}2F2830571.2830577{\&}partnerID=40{\&}md5=f3e71bc12606ebc11919aa64a1f92b18},
year = {2015}
}
@inproceedings{Schmid2016,
abstract = {The Internet of Things (IoT) envisions that many devices can connect to a network. Visible Light Communication (VLC) based on Light Emitting Diodes (LEDs) is an attractive communication fabric for the IoT, as LEDs are readily available and can serve as transmitters as well as receivers. LED light bulbs, enhanced with photodiodes, provide an attractive path to extend device-to-device communication to room area networking. This paper describes a VLC system, called EnLighting, based on light bulbs that support an embedded Linux version (and its complete networking stack). These programmable light bulbs can both send and receive; they can communicate with objects in a room as well as with other light bulbs nearby. Bidirectional communication allows a light bulb to actively participate in networking and simplifies deployment, maintenance, configuration, and controllability of indoor lighting installations and services. EnLighting supports low-bandwidth communication services in a room (and via a gateway, beyond the room), which provide the base for other applications, e.g., a location service. This paper includes an initial evaluation of a room area communication and localization network based on prototype Linux-enabled light bulbs, reporting the performance for different network traffic types, and shows the benefits obtained from bidirectional communication. This proof-of- concept system illustrates that simple devices can provide an attractive solution to future communication challenges in the saturated radio spectrum. {\textcopyright} 2016 IEEE.},
annote = {cited By 11},
author = {Schmid, S and Richner, T and Mangold, S and Gross, T R},
booktitle = {2016 13th Annual IEEE International Conference on Sensing, Communication, and Networking, SECON 2016},
doi = {10.1109/SAHCN.2016.7732989},
keywords = {Attractive solutions; Bi-directional communicatio,Computer operating systems; Gateways (computer net,Light emitting diodes},
title = {{EnLighting: An indoor visible light communication system based on networked light bulbs}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85001076405{\&}doi=10.1109{\%}2FSAHCN.2016.7732989{\&}partnerID=40{\&}md5=3ca5bebfcbbff999b814679cbb823273},
year = {2016}
}
@inproceedings{Song2007,
abstract = {We present a novel framework for tracking of a long sequence of human activities, including the time instances of change from one activity to the next, using a closed-loop, non-linear dynamical feedback system. A composite feature vector describing the shape, color and motion of the objects, and a non-linear, piecewise stationary, stochastic dynamical model describing its spatio-temporal evolution, are used for tracking. The tracking error or expected log likelihood, which serves as a feedback signal, is used to automatically detect changes and switch between activities happening one after another in a long video sequence. Whenever a change is detected, the tracker is reinitialized automatically by comparing the input image with learned models of the activities. Unlike some other approaches that can track a sequence of activities, we do not need to know the transition probabilities between the activities, which can be difficult to estimate in many application scenarios. We demonstrate the effectiveness of the method on multiple indoor and outdoor real-life videos and analyze its performance. {\textcopyright} 2007 IEEE.},
annote = {cited By 5},
author = {Song, B and Vaswani, N and Roy-Chowdhury, A K},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2007.383243},
keywords = {Change detection; Dynamical feedback systems; Fea,Dynamical systems; Error analysis; Feature extract,Gesture recognition},
title = {{Closed-loop tracking and change detection in multi-activity sequences}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34948822823{\&}doi=10.1109{\%}2FCVPR.2007.383243{\&}partnerID=40{\&}md5=eab8fb3bfb8d688c1509d807475c77a8},
year = {2007}
}
@inproceedings{Pirkl2012431,
abstract = {We describe the design, implementation, and evaluation of an indoor positioning system based on resonant magnetic coupling. The system has an accuracy of less than 1 m 2 and, because of the underlying physical principle, is robust with respect to disturbances such as people moving around or changes in room configuration. It consists of 16x16x16 cm transmitter coils, each able to cover an area of up to 50 m 2, and provides location information to an arbitrary number of mobile receivers with an update rate of up to 30Hz. We evaluate the actual accuracy of the positioning with a robotic arm and show quantitatively that even large metallic objects have little effect on the signal. We then present an elaborate study of the performance of our system for the recognition of abstract locations such as "at the table", "in front of a cabinet". It comprises four different sites with a total of 100 individual locations some as little as 50 cm apart. Copyright 2012 ACM.},
annote = {cited By 30},
author = {Pirkl, G and Lukowicz, P},
booktitle = {UbiComp'12 - Proceedings of the 2012 ACM Conference on Ubiquitous Computing},
doi = {10.1145/2370216.2370281},
keywords = {Arbitrary number; Indoor positioning; Indoor posit,Magnetic couplings; Scheduling; Sensor networks,Ubiquitous computing},
pages = {431--440},
title = {{Robust, low cost indoor positioning using magnetic resonant coupling}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867471585{\&}doi=10.1145{\%}2F2370216.2370281{\&}partnerID=40{\&}md5=09fd23ccaa7ac745085e5d41199adaee},
year = {2012}
}
@inproceedings{Yu2013263,
abstract = {People spend a significant amount of time in indoor spaces (e.g., office buildings, subway systems, etc.) in their daily lives. Therefore, it is important to develop efficient indoor spatial query algorithms for supporting various location-based applications. However, indoor spaces differ from outdoor spaces because users have to follow the indoor floor plan for their movements. In addition, positioning in indoor environments is mainly based on sensing devices (e.g., RFID readers) rather than GPS devices. Consequently, we cannot apply existing spatial query evaluation techniques devised for outdoor environments for this new challenge. Because particle filters can be employed to estimate the state of a system that changes over time using a sequence of noisy measurements made on the system, in this research, we propose the particle filter-based location inference method as the basis for evaluating indoor spatial queries with noisy RFID raw data. Furthermore, two novel models, indoor walking graph model and anchor point indexing model, are created for tracking object locations in indoor environments. Based on the inference method and tracking models, we develop innovative indoor range and k nearest neighbor (kNN) query algorithms. We validate our solution through extensive simulations with real-world parameters. Our experimental results show that the proposed algorithms can evaluate indoor spatial queries effectively and efficiently. {\textcopyright} 2013 ACM.},
annote = {cited By 17},
author = {Yu, J and Ku, W.-S. and Sun, M.-T. and Lu, H},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/2452376.2452408},
keywords = {Algorithms; Database systems; Distributed compute,Extensive simulations; Indoor environment; K neare,Query processing},
pages = {263--274},
title = {{An RFID and particle filter-based indoor spatial query evaluation system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876785917{\&}doi=10.1145{\%}2F2452376.2452408{\&}partnerID=40{\&}md5=1a9d26397baa06b7903339759f564760},
year = {2013}
}
@article{Chen2013657,
abstract = {Many localization algorithms and systems have been developed by means of wireless sensor networks for both indoor and outdoor environments. To achieve higher localization accuracy, extra hardware equipments are utilized by most of the existing localization solutions, which increase the cost and considerably limit the location-based applications. The Internet of Things (IOT) integrates many technologies, such as Internet, Zigbee, Bluetooth, infrared, WiFi, GPRS, 3G, etc., which can enable different ways to obtain the location information of various objects. Location-based service is a primary service of the IOT, while localization accuracy is a key issue. In this paper, a higher accuracy localization scheme is proposed which can effectively satisfy diverse requirements for many indoor and outdoor location services. The proposed scheme composes of two phases: (1) the partition phase, in which the target region is split into small grids; (2) the localization refinement phase, in which a higher accuracy of localization can be obtained by applying an algorithm designed in the paper. A trial system is set up to verify correctness of the proposed scheme and furthermore to illustrate its feasibility and availability. The experimental results show that the proposed scheme can improve the localization accuracy. {\textcopyright} 2011 Springer Science+Business Media, LLC.},
annote = {cited By 42},
author = {Chen, Z and Xia, F and Huang, T and Bu, F and Wang, H},
doi = {10.1007/s11227-011-0693-2},
journal = {Journal of Supercomputing},
keywords = {Algorithms; Encoding (symbols); Internet; Knowled,Indoor and outdoor locations; Internet of thing (I,Telecommunication systems},
number = {3},
pages = {657--674},
title = {{A localization method for the Internet of Things}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886718938{\&}doi=10.1007{\%}2Fs11227-011-0693-2{\&}partnerID=40{\&}md5=f6e349be5ce864bffb31d52cff534aee},
volume = {63},
year = {2013}
}
@inproceedings{Gracia-Roche2005484,
abstract = {In this paper we address the problem of real time object tracking in complex scenes under dynamically changing lighting conditions. This problem affects video-surveillance applications where object location must be known at any time. We are interested in locating and tracking people in video sequences for access control and advanced user interface applications. Here we present a real time tracking method suitable for human faces. A Skin Probability Image (SPI) is generated by applying a skin hue model to the input frame. Targets are located by applying a modified mean-shift algorithm. To obtain their spatial extent, error ellipses are fitted to the probability distributions representing them. The hue model is unique for each target and it is updated each frame to cope with lighting variations. This technique has been applied to human face tracking in indoor environments to test its performance in different situations. {\textcopyright} Springer-Verlag Berlin Heidelberg 2005.},
annote = {cited By 0},
author = {Gracia-Roche, J J and Orrite, C and Bernu{\'{e}}s, E and Herrero, J E},
booktitle = {Lecture Notes in Computer Science},
keywords = {Algorithms; Color image processing; Mathematical m,Face recognition,Face tracking; Object location; Object tracking;},
number = {I},
pages = {484--491},
title = {{Color distribution tracking for facial analysis}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-25144434991{\&}partnerID=40{\&}md5=06ee8cbe9184772896b4fe8a84dead1f},
volume = {3522},
year = {2005}
}
@inproceedings{Lee2018224,
abstract = {With the development of sensing technologies, various spatial applications have been expanding into indoor spaces. For smooth spatial services, grasping indoor space information is most essential task. However, the indoor spaces is not only becoming increasingly complex, but also frequently changed than outdoor spaces. This makes it hard to provide an accurate location based service in an indoor space. This paper propose a way of managing a dynamic indoor environment by defining a multi-layered indoor model in terms of an object mobility. It allows an indoor space to be managed more elaborate and realistic than up-to-date indoor models which only consider an indoor floor plan. We firstly define a classification of indoor objects based on their characteristic to frequently change location, and propose three-layers indoor model followed by the classified objects with its mobility. Secondly, we design and implement an autonomous scanning system to understand changes of indoor situation quickly and automatically. The system is made up of a combination of IoT devices, including a programmable robot, lidar scanner and single-board computer. Finally, we demonstrate an implementation of the system with constructing the proposed model from a real indoor environment. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Lee, J and Seo, M and Kim, J and Hwang, S and Kim, T and Kim, K.-S.},
booktitle = {Proceedings - 2018 1st IEEE International Conference on Artificial Intelligence and Knowledge Engineering, AIKE 2018},
doi = {10.1109/AIKE.2018.00051},
keywords = {Autonomous driving; Indoor environment; Iot devic,Imaging systems; Internet of things; Knowledge eng,Location based services},
pages = {224--227},
title = {{Management of Subdivided Dynamic Indoor Environments by Autonomous Scanning System}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058245475{\&}doi=10.1109{\%}2FAIKE.2018.00051{\&}partnerID=40{\&}md5=d722ecf098c36b9df851d6d96c848cc9},
year = {2018}
}
@article{Wu2012245,
abstract = {In the current (Internet of Things) trend, the identification capability of RFID is integrated for the identification and applications of all objects, and this trend reveals the future demand for RFID wireless communication and localization. Therefore, this paper investigates the influences of RSSI and the distance to RFID and analyzes the common indoor localization algorithms, including range-based algorithms and range-free algorithms. However, there are too many interference factors in the indoor environment that easily lead to localization inaccuracy. To improve the RF-mapping technique in RFID that requires much time for initiation and lots of calculations, this paper proposes a GA-based (Genetic Algorithms, GA) localization algorithm to estimate the locations of unknown nodes and avoid the influence of environmental factors by preestablishing the pattern. The designed scenarios and reference nodes in this paper are used to train our proposed algorithm and obtain the patents of the scenarios, which are adopted for RFID nodes to further compare and decrease errors. Therefore, as long as the algorithm is trained in advance with the scenarios and then include the patents in the new environment, the errors and the training time can be greatly reduced. Moreover, our proposed algorithm needs only little information about reference nodes to preestablish the pattern. {\textcopyright} Springer-Verlag London Limited 2011.},
annote = {cited By 16},
author = {Wu, T.-Y. and Liaw, G.-H. and Huang, S.-W. and Lee, W.-T. and Wu, C.-C.},
doi = {10.1007/s00779-011-0398-9},
journal = {Personal and Ubiquitous Computing},
keywords = {Environmental factors; Indoor environment; Indoor,Errors; Internet; Patents and inventions; Radio f,Genetic algorithms},
number = {3},
pages = {245--258},
title = {{A GA-based mobile RFID localization scheme for internet of things}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860889798{\&}doi=10.1007{\%}2Fs00779-011-0398-9{\&}partnerID=40{\&}md5=97b2c7122febca730ce5d55ab8162b14},
volume = {16},
year = {2012}
}
@inproceedings{Lee2010,
abstract = {Indoor localization is becoming an important application for wireless sensor networks. In order to determine sensors location, ranging packets need to be transmitted. Therefore, a good scheduling scheme is needed in order to avoid collision during packet transmission. Current wireless cellular network allows sensors inside the network to transmit without packet collision by using frequency reuse method or assigning different orthogonal code sequences to every individual sensor so that they can transmit at the same time. One of the drawbacks in the earlier method is the requirement for a large frequency band that must be wide enough to allocate frequencies to all the sensors inside a network. For the latter method, there is a limited number of code sequences that can be assigned to all the sensors inside the network. Therefore in this paper, we first proposed a time scheduling method for ranging packet transmission to avoid packet collision in order to locate a large number of people or objects inside an indoor environment at the same time. The proposed method allows sensors to transmit at different time slot. They are able to use the same frequency across the entire network and interference between neighboring cells is avoided. In addition, frequency guard band is no longer required, therefore, it is bandwidth saving. This makes the system to be scalable to large network coverage, low cost and simple to operate. Secondly, we modified our localization method to suit this time scheduling scheme so that it can perform both offline and online localization for a multi-cell indoor environment. {\textcopyright} 2010 IEEE.},
annote = {cited By 0},
author = {Lee, J X and Chin, F and Lin, Z W},
booktitle = {IEEE Vehicular Technology Conference},
doi = {10.1109/VETECS.2010.5493646},
keywords = {Bandwidth savings; Code sequences; Frequency re-us,Cellular neural networks; Codes (symbols); Freque,Wireless sensor networks},
title = {{A time scheduling scheme used for multi-cells indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954910228{\&}doi=10.1109{\%}2FVETECS.2010.5493646{\&}partnerID=40{\&}md5=fb52ef57992c4f941f93298b2f0da5ad},
year = {2010}
}
@inproceedings{Panta2016332,
abstract = {GPS is the reference for outdoor positioning, implementing direct connection between satellite and receiver device. Indoor positioning raises challenges, locating target devices requiring wireless sensors networks and other technologies. Sensor networks deployed in buildings are commonly used for many applications based on location: surveillance, detection, navigation, etc. These indoor locating sensors generate data related to tracking information. Exploiting this information for investigation issues remains a relevant purpose. This paper context is related to indoor locations systems based on wireless cell, ICCARD sensors and video surveillance cameras. In this context, as no global reference system similar to GPS is available, the location information issued from various devices have neither standards nor common formats, and remain heterogeneous. This paper presents a contribution to extend our framework [24] to information generated by location sensor networks deployed in an indoor environment. The use case is illustrated in a forensic application [1].},
annote = {cited By 1},
author = {Panta, F J and S{\`{e}}des, F},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3007120.3007154},
keywords = {Forensic; Forensic applications; Global reference,Global positioning system,Location; Mobile computing; Security systems; Sens},
pages = {332--336},
title = {{Mobile objects in indoor environment: Trajectories reconstruction}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015016478{\&}doi=10.1145{\%}2F3007120.3007154{\&}partnerID=40{\&}md5=82a728ec079ed442d05545aae470a15f},
year = {2016}
}
@inproceedings{Enfu20171,
abstract = {Map retrieval, the problem of similarity search over a large collection of 2D pointset maps previously built by mobile robots, is crucial for autonomous navigation in indoor and outdoor environments. Bag-of-words (BoW) methods constitute a popular approach to map retrieval; however, these methods have extremely limited descriptive ability because they ignore the spatial layout information of the local features. The main contribution of this paper is an extension of the bag-of-words map retrieval method to enable the use of spatial information from local features. Our strategy is to explicitly model a unique viewpoint of an input local map; the pose of the local feature is defined with respect to this unique viewpoint, and can be viewed as an additional invariant feature for discriminative map retrieval. Specifically, we wish to determine a unique viewpoint that is invariant to moving objects, clutter, occlusions, and actual viewpoints. Hence, we perform scene parsing to analyze the scene structure, and consider the "center" of the scene structure to be the unique viewpoint. Our scene parsing is based on a Manhattan world grammar that imposes a quasi-Manhattan world constraint to enable the robust detection of a scene structure that is invariant to clutter and moving objects. Experimental results using the publicly available radish dataset validate the efficacy of the proposed approach. {\textcopyright} 2017 IEEE.},
annote = {cited By 1},
author = {Enfu, L and Kanji, T and Xiaoxiao, F},
booktitle = {2017 International Conference on Indoor Positioning and Indoor Navigation, IPIN 2017},
doi = {10.1109/IPIN.2017.8115884},
keywords = {Autonomous navigation; Invariant features; Manhat,Clutter (information theory); Mobile robots; Navig,Formal languages},
pages = {1--8},
title = {{Grammar-based map parsing for view invariant map descriptor}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043497749{\&}doi=10.1109{\%}2FIPIN.2017.8115884{\&}partnerID=40{\&}md5=01a59539c9f584aa5e4c1f5c31b681a7},
volume = {2017-Janua},
year = {2017}
}
@inproceedings{Zhou20112824,
abstract = {Knowledge acquisition from the Internet for robotic applications has received widespread attention recently. It has turned out to be an important supplementary or even a complete replacement to conventional robotic perception. In this paper, we investigate state-of-the-art online knowledge acquisition systems for robotic vision applications and present a framework for further fusion and tighter integration. Bootstrapped by an interconnected process wherein modules for object detection and supporting structure detection co-operate to extract cross-correlated information, a web text mining technique using sequential pattern retrieval is introduced for linking the search of objects with their potential localities. Experiments using an indoor mobile robot for an Active Visual Search (AVS) task demonstrate the benefits of our coherent framework for visual representation and knowledge acquisition from the Internet. {\textcopyright} 2011 IEEE.},
annote = {cited By 2},
author = {Zhou, K and Varadarajan, K M and Zillich, M and Vincze, M},
booktitle = {2011 IEEE International Conference on Robotics and Biomimetics, ROBIO 2011},
doi = {10.1109/ROBIO.2011.6181733},
keywords = {Biomimetics; Data mining; Internet; Knowledge acq,Coherent frameworks; Indoor mobile robots; Object,Object recognition},
pages = {2824--2829},
title = {{Web mining driven semantic scene understanding and object localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860771449{\&}doi=10.1109{\%}2FROBIO.2011.6181733{\&}partnerID=40{\&}md5=fa5ca0db5b9ce0285842f80ef4fb2411},
year = {2011}
}
@article{Pannuto2018,
abstract = {We introduce Harmonium, a novel ultra wideband (UWB) RF localization architecture that achieves decimeter-scale accuracy indoors. Harmonium strikes a balance between tag simplicity and processing complexity to provide fast and accurate indoor location estimates. Harmonium uses only commodity components and consists of a small, inexpensive, lightweight, and FCC-compliant UWB transmitter or tag, fixed infrastructure anchors with known locations, and centralized processing that calculates the tag's position. Anchors employ a new frequency-stepped narrowband receiver architecture that rejects narrowband interferers and extracts high-resolution timing information without the cost or complexity of traditional UWB approaches. In a complex indoor environment, 90{\%} of position estimates obtained with Harmonium exhibit less than 31 cm of error with an average of 9 cm of inter-sample noise. In non-line-of-sight conditions (i.e., through-wall), 90{\%} of position error is less than 42 cm. The tag draws 75 mW when actively transmitting, or 3.9 mJ per location fix at the 19 Hz update rate. Tags weigh 3 g and cost {\$}4.50 USD at modest volumes. Furthermore, VLSI-based design concepts are identified for a simple, low-power realization of the Harmonium tag to offer a roadmap for the realization of Harmonium concepts in future integrated systems. Harmonium introduces a new design point for indoor localization and enables localization of small, fast objects such as micro quadrotors, devices previously restricted to expensive optical motion capture systems. {\textcopyright} 2018 Copyright is held by the owner/author(s).},
annote = {cited By 0},
author = {Pannuto, P and Kempke, B and Chuo, L.-X. and Blaauw, D and Dutta, P},
doi = {10.1145/3185752},
journal = {ACM Transactions on Sensor Networks},
keywords = {Anchors; Indoor positioning systems; Location,Bandstitching; Centralized processing; Indoor loc,Ultra-wideband (UWB)},
number = {2},
title = {{Harmonium: Ultra wideband pulse generation with bandstitched recovery for fast, accurate, and robust indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053473109{\&}doi=10.1145{\%}2F3185752{\&}partnerID=40{\&}md5=83ac1db17c2eb58e5809b1b57cb53ea2},
volume = {14},
year = {2018}
}
@article{Liu2015305,
abstract = {With increasingly large location data sets, improvements in query efficiency and reductions in location update costs have become important issues. For indoor evacuation, due to the different characteristics of indoor and outdoor environments, it is not easy to monitor and query evacuation objects using existing methods. Therefore, in this study, a geographical information system (GIS)-oriented location model called the velocity range and marked cell (VRMC) model is established, which includes three processes: (1) the generation of indoor geometric spaces called indoor marked cells (IMCs) and two auxiliary structures, the connection matrix and the tendency cells, oriented by GIS; (2) the construction of a VRMC-tree index based on Equation (1) for efficiently supporting new emergency queries; and (3) usage of the interaction between the objects' velocities and the IMCs as an update strategy to filter the indoor positioning results. As demonstrated by simulative and real positioning data sets, the proposed model improves the query efficiency for evacuation objects, compared with existing indoor indexes and update strategies, and makes further progress toward resolving the trade-off between emergency query precision and server-side update costs. {\textcopyright} 2014 Taylor {\&} Francis.},
annote = {cited By 4},
author = {Liu, T and Chi, T and Li, H and Rui, X and Lin, H},
doi = {10.1080/13658816.2014.969271},
journal = {International Journal of Geographical Information Science},
keywords = {data set; equation; geometry; GIS; matrix; numeric},
number = {2},
pages = {305--326},
title = {{A GIS-oriented location model for supporting indoor evacuation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925623169{\&}doi=10.1080{\%}2F13658816.2014.969271{\&}partnerID=40{\&}md5=212a17b6e7c84e12f53c412600ce7abc},
volume = {29},
year = {2015}
}
@inproceedings{Panta201844,
abstract = {The use of mobile devices and the development of geo-positioning technologies make applications that use location-based services very attractive and useful. These applications are composed of sensors that generate various and heterogeneous spatio-temporal data. Exploiting this spatio-temporal data to support video surveillance systems remains a relevant purpose for video content filtering. Since the data processed in such a context are heterogeneous (indoor and outdoor environment, various position types and reference systems, various data format), interoperability and management of these data remains a problem to be solved. In this paper, we define an approach that integrates camera location and field of view metadata, mobile objects trajectories, and metadata from video content analysis algorithms (e.g. detection and movement of mobile objects) to address problems related to processing of huge amount of data (big data) generated by CCTV systems. We propose a new generic trajectory based query in order to handle trajectory segment's heterogeneity for both environments (indoor and outdoor). The proposed data model integrate multi-source metadata and enable to handle interoperability issue of data. Our querying mechanism enable to automatically retrieve video segments that could contain relevant information for the CCTV operator (suspects, trajectories, etc.). We provide an experimental evaluation demonstrating the utility of our approach in a real-world case. Results show that the proposed approach enhances the efficiency of investigators by reducing the search space, as the operator will analyze only the relevant data, therefore he needs less time for video processing (video reviewing). {\textcopyright} 2018 Association for Computing Machinery.},
annote = {cited By 0},
author = {Panta, F J and Qodseya, M and S{\`{e}}des, F and P{\'{e}}ninou, A},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3282353.3282368},
keywords = {Experimental evaluation; Indoor/outdoor; Mobiles,Image segmentation; Interoperability; Location; Lo,Information management},
pages = {44--52},
title = {{Management of mobile objects location for video content filtering}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060948309{\&}doi=10.1145{\%}2F3282353.3282368{\&}partnerID=40{\&}md5=21507f7833f21332fb649f261b88234a},
year = {2018}
}
@inproceedings{Bekkali2007,
abstract = {Indoor tracking and localization is a crucial ingredient in many ubiquitous computing applications and robotics. In many applications there is the need to know the location of the objects. While in the near future everything will be tagged with Radio Frequency Identification (RFID) tags, the localization of these tags in their environment is becoming an important feature for the RFID based ubiquitous computing applications. Due to its lower cost and its technical capabilities, RFID Tagged object tracking can have a wide diverse variety of applications including scientific, military, and public safety. In this paper we propose a tracking algorithm for objects attached by UHF RFID tags by means of two RFID antennas and landmarks to reduce the localization cost and environment complexity. This algorithm uses RFID map made from passive or active references tags with known location (landmarks) to locate any unknown tag detected by the RFID Reader antennas. It measures the distances between the readers and the common detected tags using the large scale path loss propagation model, and calculates the distance between the unknown tag and all the detected landmarks (Inter-tags distance). With the multilateration technique the system is able to estimate the position of the unknown tag. The location estimation of the target will be independent to the reader's position. The research challenge corresponds to achieve an accurate indoor tracking system using two mobile RFID Readers taking in consideration the limitation of RFID technology. This tracking algorithm is based on Received Signal Strength (RSS) measurement to measure the reader-tags distance and target-landmarks distance to estimate the target location. To minimize the effect of the RSS and the process measurement noises on the position estimation, Maximum Likelihood Estimator (MLE), Map Matching and Kalman filter are applied. Here, we investigate the use of Kalman filter to improve the precision and RFID map matching to improve the accuracy. Results obtained after simulations demonstrate the validity and suitability of the proposed algorithm to provide high performance level in terms of accuracy and scalability. {\textcopyright}2007 IEEE.},
annote = {cited By 8},
author = {Bekkali, A and Matsumoto, M},
booktitle = {2007 Wireless Telecommunications Symposium, WTS 2007},
doi = {10.1109/WTS.2007.4563343},
keywords = {Antennas; Applications; Boolean functions; Compute,Conformal mapping,Indoor tracking; Tracking algorithms},
title = {{RFID indoor tracking based on inter-tags distance measurement}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-51749095079{\&}doi=10.1109{\%}2FWTS.2007.4563343{\&}partnerID=40{\&}md5=9f6578a80504744a862b1aa71d7fd199},
year = {2007}
}
@inproceedings{Hatthasin20091,
abstract = {The proliferation of mobile computing devices and wireless positioning networks has fostered a growing interest in location-aware systems and devices. Most technologies such as Radio Frequency IDentification (RFID), RADAR, etc, use at least three Base Station (BS) for calculating position of target objects. This paper describes an improvement of the previous OneBS algorithm [13]. The proposed system uses only one BS based on the RFID infrastructure for positioning target tags amid the clutter of indoor interference environments. We proposed to fuse the Round-trip Time of Flight (RTOF) and the Received Signal Strength (RSS) in the positioning algorithm. Both information are kept in an intersection Box (iBox). The RTOF information is used to focus a target tag's position among groups of four-nearestneighbor reference tags kept within iBox. Then, the RSS information is weighted using the weighted center of gravity technique to estimate a location of the target tags. Our experiments are based on Three Dimension (3D) materials within interference environments. The interference environments are simulated based on Uniform Geometrical Theory of Diffraction (UTD), for measuring signals in each specific area. Our proposed algorithm gains 50 percents better average distance error compared to the OneBS algorithm. {\textcopyright} 2009 IEEE.},
annote = {cited By 10},
author = {Hatthasin, U and Thainimit, S and Vibhatavanij, K and Premasathian, N and Worasawate, D},
booktitle = {2009 6th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology, ECTI-CON 2009},
doi = {10.1109/ECTICON.2009.5137182},
keywords = {Base stations; Computation theory; Electromagnetic,Interference environments; Locating system; Mobil,Radio frequency identification (RFID)},
pages = {1--4},
title = {{An improvement of an RFID indoor positioning system using one base station}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856491355{\&}doi=10.1109{\%}2FECTICON.2009.5137182{\&}partnerID=40{\&}md5=ba625707b07fa54e7cd1f9bd6a446d72},
volume = {2009-Janua},
year = {2009}
}
@article{Wagner2013392,
abstract = {Indoor localization based on signal strength fingerprinting has received significant attention from the community. This method is attractive because it does not require complex hardware beyond off-the-shelf radio transceivers. However, its main limitation is the inaccuracy caused by the variability of the signal strength. When applied to the localization of people, the signal variability can be attributed to three main sources: environmental dynamics (movement of people or objects), movement of transceiver (changes in the position and/or orientation of the transceivers) and body effects (distortion of the wireless signal due to body absorption). Our work focuses on the impact of the last two sources and provides two important contributions. First, we present an analysis to quantify the effects of antenna disorientation and transceiver misplacement. For the RFID system used in our work, these effects can decrease the localization accuracy by up to 50{\%}. Motivated by these results, we identify parts of the human body where tags are less affected by unintentional movements and describe how multiple transceivers can be used to overcome the absorption effects of the human body. We validate our findings through an extensive set of measurements gathered in a home environment. Our tests indicate that by following a set of simple guidelines, we can increase the localization accuracy (the percentage of correct location estimations) by a factor of four (from 20{\%} to 88{\%}), and reduce the maximum localization error (from 7 to 4 m). {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
annote = {cited By 5},
author = {Wagner, S and Handte, M and Zuniga, M and Marr{\'{o}}n, P J},
doi = {10.1016/j.pmcj.2012.12.002},
journal = {Pervasive and Mobile Computing},
keywords = {Antennas; Heat radiation; Radio frequency identifi,Environmental dynamics; Indoor localization; Loca,Indoor positioning systems},
number = {3},
pages = {392--405},
title = {{Enhancing the performance of indoor localization using multiple steady tags}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876667420{\&}doi=10.1016{\%}2Fj.pmcj.2012.12.002{\&}partnerID=40{\&}md5=50c4fae973dec94f39de6abe367291ce},
volume = {9},
year = {2013}
}
@inproceedings{Zhou201021,
abstract = {The automatic video content analysis is an important step to provide the content-based video coding, indexing and retrieval. It is also a key issue to the event analysis in video surveillance. In this paper, an automatic event analysis approach is presented. It is based on our previous method of Multi-object Particle Filter Tracking with Dual Consistency Check. The multiple non-rigid objects are first tracked individually in parallel by multi-resolution technique and particle filter method. The events including object presence and occlusion identification are then detected and analyzed by measuring the Goodness-of-Fit Coefficient based on Schwartz's inequality and the Backward Projection. The method is then tested in different indoor and outdoor environments with cluttered background. The experimental results show the robustness and the effectiveness of the method.},
annote = {cited By 4},
author = {Zhou, Y and Benois-Pineau, J and Nicolas, H},
booktitle = {ARTEMIS'10 - Proceedings of the 1st ACM Workshop on Analysis and Retrieval of Tracked Events and Motion in Imagery Streams, Co-located with ACM Multimedia 2010},
doi = {10.1145/1877868.1877876},
keywords = {Backward projection; Consistency checks; Content-b,Nonlinear filtering,Security systems; Tracking (position)},
pages = {21--26},
title = {{Multi-object particle filter tracking with automatic event analysis}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650468918{\&}doi=10.1145{\%}2F1877868.1877876{\&}partnerID=40{\&}md5=c4722ec5840d89319cf26585406fe120},
year = {2010}
}
@inproceedings{Kim2016,
abstract = {With the advance in the indoor positioning systems such as RFID, WIFI, and Bluetooth, the locations of moving objects constitute a significant factor for many applications. Many researches have verified that most people spend their time in an indoor environment. In this paper, we propose two novel index structures, called Split Grid Index (SGI) and N-Density Split Grid Index (N-DSGI) for indexing moving objects in an indoor environment. SGI divides the grid into a set of cells when a new moving object enters. In particular, if a moving object moves into a grid cell, it is recursively divided into a set of smaller cells until each grid cell includes only one moving object. On the other hand, in N-DSGI, the grid is divided into a set of cells when (i) a new moving object enters the grid cell R and (ii) the number of moving objects in R exceeds the threshold value N. Through simulations, we verify that SGI and N-DSGI save CPU time while providing clients the valuable information. {\textcopyright} 2016 ACM.},
annote = {cited By 1},
author = {Kim, Y and Jung, H and Jang, J and Kim, U.-M.},
booktitle = {ACM IMCOM 2016: Proceedings of the 10th International Conference on Ubiquitous Information Management and Communication},
doi = {10.1145/2857546.2857606},
keywords = {Cells; Information management,Cytology,Grid cells; Grid index; Index structure; Indexing},
title = {{An efficient grid index for moving objects in indoor environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965034975{\&}doi=10.1145{\%}2F2857546.2857606{\&}partnerID=40{\&}md5=2f775e4b3f8c78c0200b96a080e0dd11},
year = {2016}
}
@inproceedings{Yuuto20131629,
abstract = {We consider the task of long-term visual SLAM, i.e., simultaneous localization and mapping, in a partially changing environment (SLAM-PCE). The main problem we face is how to obtain discriminative and compact visual landmarks, which are necessary to cope with changes in appearance in an environment and with a large amount of visual information. We address this issue by proposing the use of common object patterns, which are inherent in typical environments (e.g., indoor, street, forests, suburban, etc.), as visual landmarks for a SLAM-PCE task. In our contributions, we describe our approach, 'part-based SLAM', and validate its effectiveness within a standard problem of view image retrieval. The main novelty of this approach lies in that the common landmark objects are extracted in an unsupervised manner via common pattern discovery, and can be used for compact characterization and efficient retrieval of view images. Our method is also innovative in its use of traditional bounding box-based part annotation: an image is represented in a compact form, 'bag-of-bounding-boxes (BoBB)' and then, the scene matching can be solved efficiently as a low dimensional problem of matching bounding boxes. The results of challenging experiments show that it is possible to have high retrieval performance with compact image representation with only 16 words per image. {\textcopyright} 2013 IEEE.},
annote = {cited By 1},
author = {Yuuto, C and Kanji, T and Masatoshi, A},
booktitle = {2013 IEEE International Conference on Robotics and Biomimetics, ROBIO 2013},
doi = {10.1109/ROBIO.2013.6739700},
keywords = {Biomimetics; Image retrieval; Mathematical techniq,Changing environment; Image representations; Patt,Robotics},
pages = {1629--1634},
title = {{Part-based SLAM for partially changing environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898806812{\&}doi=10.1109{\%}2FROBIO.2013.6739700{\&}partnerID=40{\&}md5=ad2dd11083f39b923c7cd1c0956464af},
year = {2013}
}
@inproceedings{Kulkarni2013,
abstract = {Autrebot; indoor trash detection and collection system using autonomously directed robotic exploration algorithm is presented. The algorithm has linear time complexity and is developed using two ultrasonic sensors. The key feature of this algorithm is the acquisition of object location based on the sensor output. The two sensor interface is specially implemented for intelligent decision making and proper identification of the object of interest, ignoring stray mobile objects or walls. Pneumatic actuators are used for the pickup and disposal of trash once it has been successfully located. Experiments with the algorithm have been conducted in static as well as dynamic environments and its performance analyzed for multiple scenarios. The algorithm can be thus extended for locating a particular object of interest based on its physical attributes. {\textcopyright} 2013 IEEE.},
annote = {cited By 4},
author = {Kulkarni, S and Junghare, S},
booktitle = {CARE 2013 - 2013 IEEE International Conference on Control, Automation, Robotics and Embedded Systems, Proceedings},
doi = {10.1109/CARE.2013.6733698},
keywords = {Algorithms; Embedded systems; Sensors; Ultrasonic,Detection algorithm; Detection and collection syst,Robotics},
title = {{Robot based indoor autonomous trash detection algorithm using ultrasonic sensors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896800550{\&}doi=10.1109{\%}2FCARE.2013.6733698{\&}partnerID=40{\&}md5=78e5cfc40cf7034291d3bd259247dd34},
year = {2013}
}
@inproceedings{Tseng201763,
abstract = {This paper proposes the capturing of IoT data andtheir embedding as metadata in digital snapshots, includingphotos, audios, and videos. Specifically, we focus on IoT devicesbased on Bluetooth Low Energy (BLE) Technology, whichis used for not only data communication but also proximitysensing and is ubiquitous in wearables, smartphones, personaltags, indoor-navigation beacons, and home-automation devices. The IoT metadata can cover different levels, from the radiosignal strength and the media-access controller (MAC) addressto device name, indoor location, temperature, humidity, airquality, and advertising messages. These IoT data can readilyaugment metadata such as timestamp, GPS location, and camerasettings already captured by today's cameras and saved indigital photo files. With such IoT metadata, the user will havemuch richer ways to understand the subject and environmentof the scene being captured by the photo or media, such as thesubject's fitness condition, the advertised events, and the taggedpersonal items at the scene. These metadata will enable newways of searching, querying, and organizing the photos and theassociated objects. Moreover, a novel mechanism we proposeis the ability to pair with a remote device whose identity androuting information is captured as IoT metadata, so that anauthorized user can then pair with it at a later time remotely. We contend that IoT metadata capturing can bring significantbenefits to the users. {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Tseng, H.-Y. and Lee, C.-T. and Lin, C.-A. and Chou, P H},
booktitle = {Proceedings - 11th IEEE International Symposium on Service-Oriented System Engineering, SOSE 2017},
doi = {10.1109/SOSE.2017.18},
keywords = {Bluetooth low energies (BLE); Data-communication;,Bluetooth; Computer graphics; Humidity control; Me,Internet of things},
pages = {63--68},
title = {{IoT Metadata Creation System for Mobile Images and Its Applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85022198777{\&}doi=10.1109{\%}2FSOSE.2017.18{\&}partnerID=40{\&}md5=c4593fe408474b77a826e0b2fc7eb919},
year = {2017}
}
@article{Zou2019143,
abstract = {One major goal of vision is to infer physical models of objects, surfaces, and their layout from sensors. In this paper, we aim to interpret indoor scenes from one RGBD image. Our representation encodes the layout of orthogonal walls and the extent of objects, modeled with CAD-like 3D shapes. We parse both the visible and occluded portions of the scene and all observable objects, producing a complete 3D parse. Such a scene interpretation is useful for robotics and visual reasoning, but difficult to produce due to the well-known challenge of segmentation, the high degree of occlusion, and the diversity of objects in indoor scenes. We take a data-driven approach, generating sets of potential object regions, matching to regions in training images, and transferring and aligning associated 3D models while encouraging fit to observations and spatial consistency. We use support inference to aid interpretation and propose a retrieval scheme that uses convolutional neural networks to classify regions and retrieve objects with similar shapes. We demonstrate the performance of our method on our newly annotated NYUd v2 dataset (Silberman et al., in: Computer vision-ECCV, 2012, pp 746760, 2012) with detailed 3D shapes. {\textcopyright} 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
annote = {cited By 0},
author = {Zou, C and Guo, R and Li, Z and Hoiem, D},
doi = {10.1007/s11263-018-1133-z},
journal = {International Journal of Computer Vision},
keywords = {3D parsing; Convolutional neural network; Data-dr,Computer aided design; Neural networks,Image reconstruction},
number = {2},
pages = {143--162},
title = {{Complete 3D Scene Parsing from an RGBD Image}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057089423{\&}doi=10.1007{\%}2Fs11263-018-1133-z{\&}partnerID=40{\&}md5=2e9384f70fa35fc9d9e06a7f9d79c1b9},
volume = {127},
year = {2019}
}
@inproceedings{Ren2018937,
abstract = {We develop a 3D object detection algorithm that uses latent support surfaces to capture contextual relationships in indoor scenes. Existing 3D representations for RGB-D images capture the local shape and appearance of object categories, but have limited power to represent objects with different visual styles. The detection of small objects is also challenging because the search space is very large in 3D scenes. However, we observe that much of the shape variation within 3D object categories can be explained by the location of a latent support surface, and smaller objects are often supported by larger objects. Therefore, we explicitly use latent support surfaces to better represent the 3D appearance of large objects, and provide contextual cues to improve the detection of small objects. We evaluate our model with 19 object categories from the SUN RGB-D database, and demonstrate state-of-the-art performance. {\textcopyright} 2018 IEEE.},
annote = {cited By 1},
author = {Ren, Z and Sudderth, E B},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2018.00104},
keywords = {3d representations; Contextual cue; Contextual re,Computer vision; Object recognition,Object detection},
pages = {937--946},
title = {{3D Object Detection with Latent Support Surfaces}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054803694{\&}doi=10.1109{\%}2FCVPR.2018.00104{\&}partnerID=40{\&}md5=79707e21649237c8ce019fc8d0df0f1e},
year = {2018}
}
@article{Alamri2014287,
abstract = {With the currently available indoor positioning devices such as RFID, Bluetooth and WI-FI, the locations of moving objects constitute an important foundation for a variety of applications such as the tracking of moving objects, security and way finding. Many studies have proven that most individuals spend their lives in indoor environments. Therefore, in this paper, we propose a new index structure for moving objects in cellular space. The index is based on the connectivity (adjacency) between the indoor environment cells and can effectively respond to the spatial indoor queries and enable efficient updates of the location of a moving object in indoor space. An empirical performance study suggests that the proposed indoor-tree in terms of measurements and performance is effective, efficient and robust. {\textcopyright} 2013 Springer-Verlag London.},
annote = {cited By 16},
author = {Alamri, S and Taniar, D and Safar, M and Al-Khalidi, H},
doi = {10.1007/s00779-013-0645-3},
journal = {Personal and Ubiquitous Computing},
keywords = {Cellular space; Connectivity indices; Empirical pe,Information services,Radio frequency identification (RFID)},
number = {2},
pages = {287--301},
title = {{A connectivity index for moving objects in an indoor cellular space}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897644591{\&}doi=10.1007{\%}2Fs00779-013-0645-3{\&}partnerID=40{\&}md5=46a64e6759dcff17a99a1e2ab8ff76cf},
volume = {18},
year = {2014}
}
@inproceedings{Sankar2016233,
abstract = {We present an interactive system to capture CAD-like 3D models of indoor scenes, on a mobile device. To overcome sensory and computational limitations of the mobile platform, we employ an in situ, semi-automated approach and harness the user's high-level knowledge of the scene to assist the reconstruction and modeling algorithms. The modeling proceeds in two stages: (1) The user captures the 3D shape and dimensions of the room. (2) The user then uses voice commands and an augmented reality sketching interface to insert objects of interest, such as furniture, artwork, doors and windows. Our system recognizes the sketches and add a corresponding 3D model into the scene at the appropriate location. The key contributions of this work are the design of a multi-modal user interface to effectively capture the user's semantic understanding of the scene and the underlying algorithms that process the input to produce useful reconstructions. {\textcopyright} 2016 ACM.},
annote = {cited By 5},
author = {Sankar, A and Seitz, S M},
booktitle = {Proceedings of the 18th International Conference on Human-Computer Interaction with Mobile Devices and Services, MobileHCI 2016},
doi = {10.1145/2935334.2935337},
keywords = {Algorithms; Augmented reality; Computer aided desi,Computational limitations; High level knowledge;,Human computer interaction},
pages = {233--243},
title = {{In situ CAD capture}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991047339{\&}doi=10.1145{\%}2F2935334.2935337{\&}partnerID=40{\&}md5=54712ae530747637a804f0860d3e69b6},
year = {2016}
}
@inproceedings{Afyouni2012329,
abstract = {Continuous location-dependent queries can be considered as key elements for the development of different categories of location-based and context-aware services. However, most work on location-dependent query processing has been mainly oriented towards outdoor environments. This paper studies location-dependent and context-aware queries over moving objects in indoor environments (e.g., houses, commercial malls, etc.), with a special focus on navigation-related queries (i.e., mainly path search and range queries). A hierarchical and context-dependent spatial data model is firstly presented, which leads to the consideration of other contextual dimensions besides the location of the involved entities, such as time and user profiles. Two algorithms for continuous processing of path and range queries on top of this modelling approach are introduced. The former performs a hierarchical and incremental path search for the continuous processing of path queries, and applied to both static and moving objects. The latter presents an incremental approach for continuous range queries, which performs a hierarchical network expansion around the initial query point and implements a mechanism to update the initial search tree based on user's movements. {\textcopyright} 2012 ACM.},
annote = {cited By 6},
author = {Afyouni, I and Ray, C and Ilarri, S and Claramunt, C},
booktitle = {GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems},
doi = {10.1145/2424321.2424363},
keywords = {Algorithms; Information services; Models; Query p,Continuous processing; Indoor navigation; Location,Geographic information systems},
pages = {329--338},
title = {{Algorithms for continuous location-dependent and context-aware queries in indoor environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872338659{\&}doi=10.1145{\%}2F2424321.2424363{\&}partnerID=40{\&}md5=8a035743addc2b1403fe1332d761343c},
year = {2012}
}
@inproceedings{Delmerico20124806,
abstract = {Many robotics platforms are capable of ascending stairways, but all existing approaches for autonomous stair climbing use stairway detection as a trigger for immediate traversal. In the broader context of autonomous exploration, the ability to travel between floors of a building should be compatible with path planning, such that the robot can traverse a stairway at a time that is appropriate to its navigation goals. No system yet presented is capable of both localizing stairways on a map and estimating their properties, functions that in combination would enable stairways to be considered as traversable terrain in a path planning algorithm. We propose a method for modeling stairways as objects and localizing them on a map, such that they can be subsequently traversed if they are of dimensions that the robotic platform is capable of climbing. Our system consists of two parts: a computationally efficient detector that leverages geometric cues from depth imagery to detect sets of ascending stairs, and a stairway modeler that uses multiple detections to infer the location and parameters of a stairway that is discovered during exploration. This video demonstrates the performance of the system in a number of real-world situations, modeling and localizing a variety of stairway types in both indoor and outdoor environments. {\textcopyright} 2012 IEEE.},
annote = {cited By 4},
author = {Delmerico, J A and Corso, J J and Baran, D and David, P and Ryde, J},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2012.6386283},
keywords = {Autonomous exploration; Autonomous stair climbing;,Detectors; Floors; Intelligent systems; Motion pl,Robots},
pages = {4806--4807},
title = {{Ascending stairway modeling: A first step toward autonomous multi-floor exploration}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872329625{\&}doi=10.1109{\%}2FIROS.2012.6386283{\&}partnerID=40{\&}md5=464fca54871f25f5c2940303b115d488},
year = {2012}
}
@inproceedings{Amer2002945,
abstract = {The significant increase of video data in various domains requires effective ways to represent video by its semantic content. This paper proposes a system to extract useful events defined by approximate but efficient world models, independently of context. Changes and the behavior of low-level features of the scene's objects are continually monitored. When certain conditions are met, events related to these conditions are detected. Proposed events are sufficiently broad to assist surveillance and retrieval of video shots. Extensive experimentations on more than 10 indoor and outdoor video shots containing a total of 6371 images including sequences with noise and coding artifacts have demonstrated the reliability and the real-time response (up to 10 frames per second) of the proposed system. {\textcopyright} 2002 IEEE.},
annote = {cited By 5},
author = {Amer, A and Dubois, E and Mitiche, A},
booktitle = {Proceedings - International Conference on Pattern Recognition},
keywords = {Context independent; Frames per seconds; Image ex,Feature extraction; Image coding; Image reconstruc,Low-level features; Video datas; Video shots,Pattern recognition; Pattern recognition},
number = {2},
pages = {945--947},
title = {{Context-independent real-time event recognition: Application to key-image extraction}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33751576002{\&}partnerID=40{\&}md5=b0df6055d2c83ee650836f50c3ff85f6},
volume = {16},
year = {2002}
}
@article{Tapu201711771,
abstract = {In this paper, we introduce a novel computer vision-based perception system, dedicated to the autonomous navigation of visually impaired people. A first feature concerns the real-time detection and recognition of obstacles and moving objects present in potentially cluttered urban scenes. To this purpose, a motion-based, real-time object detection and classification method is proposed. The method requires no a priori information about the obstacle type, size, position or location. In order to enhance the navigation/positioning capabilities offered by traditional GPS-based approaches, which are often unreliably in urban environments, a building/landmark recognition approach is also proposed. Finally, for the specific case of indoor applications, the system has the possibility to learn a set of user-defined objects of interest. Here, multi-object identification and tracking is applied in order to guide the user to localize such objects of interest. The feedback is presented to user by audio warnings/alerts/indications. Bone conduction headphones are employed in order to allow visually impaired to hear the systems warnings without obstructing the sounds from the environment. At the hardware level, the system is totally integrated on an android smartphone which makes it easy to wear, non-invasive and low-cost. {\textcopyright} 2016, Springer Science+Business Media New York.},
annote = {cited By 2},
author = {Tapu, R and Mocanu, B and Zaharia, T},
doi = {10.1007/s11042-016-3617-6},
journal = {Multimedia Tools and Applications},
keywords = {Air navigation; Obstacle detectors,Computer vision,Descriptors; Image representations; Obstacle dete},
number = {9},
pages = {11771--11807},
title = {{A computer vision-based perception system for visually impaired}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971011011{\&}doi=10.1007{\%}2Fs11042-016-3617-6{\&}partnerID=40{\&}md5=cc9c7810f480caf433c3de70890a3616},
volume = {76},
year = {2017}
}
@inproceedings{Jms2010,
abstract = {In the current paper, we describe a three dimensional indoor positioning system for the metal industry. The developed system consists of a three dimensional map-based user interface scanned with Leica ScanStation 2, Chirp Spread Spectrum modulation (CSS) indoor positioning technology, and a used positioning algorithm. The system development process described in this paper includes three phases. Firstly, the modelling of three dimensional virtual environments with an accuracy of 2 centimeters required the use of point cloud processing software and 3D content creation. The next phase was to find reliable indoor positioning technology for harsh industrial conditions. The results reported in this paper show that a reliable positioning system using CSS could be created. Finally, location information provided by CSS was shown in the three dimensional map-based user interface. The user interface was based on CENTRIA's Locawe platform. The process described in this paper shows that moving objects such as mobile robots, autonomous transporters or working machines can be tracked in a three dimensional virtual environment. {\textcopyright} 2010 IEEE.},
annote = {cited By 10},
author = {J{\"{a}}ms{\"{a}}, J and Luimula, M and Piesk{\"{a}}, S and Brax, V and Saukko, O and Verronen, P},
booktitle = {2010 Ubiquitous Positioning Indoor Navigation and Location Based Service, UPINLBS 2010},
doi = {10.1109/UPINLBS.2010.5653563},
keywords = {3D content; Chirp spread spectrum; Indoor position,Chirp modulation; Industry; Metallurgy; Navigatio,Three dimensional},
title = {{Indoor positioning with laser scanned models in the metal industry}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651439823{\&}doi=10.1109{\%}2FUPINLBS.2010.5653563{\&}partnerID=40{\&}md5=52aee50ec9b02cd70b679d77651bf186},
year = {2010}
}
@inproceedings{Curran201225,
abstract = {Indoor Positioning Systems (IPS) track objects in buildings. Examples of tagged objects are patients or equipment in a hospital whilst discovered objects could be people in burning buildings or soldiers on a battlefield. Ultra Wide Band (UWB) location determination aims at delivering high positional accuracy in harsh industrial environments that cause problems for traditional systems due to electromagnetic interference. UWB systems can calculate the location of tags which are designed to be mounted on assets or worn by a person. They transmit UWB signals that are received by sensors which contain an array of antenna and ultra-wideband radio receivers. The data from these sensors combined with dedicated software uses algorithms to work out the angle of arrival (AOA) of the UWB signal from the tag which is then compared to the time difference of arrival (TDOA). The robotics industry can benefit from advanced location detection systems. We examine here the use of ultra wide band technology in tracking items such as mobile robots. {\textcopyright} 2012 IEEE.},
annote = {cited By 1},
author = {Curran, K and Condell, J and Knox, J},
booktitle = {2012 IEEE Conference on Technologies for Practical Robot Applications, TePRA 2012},
doi = {10.1109/TePRA.2012.6215649},
keywords = {Angle of arrival; Burning buildings; In-buildings;,Electromagnetic pulse; Radio; Radio receivers; Ro,Ultra-wideband (UWB)},
pages = {25--30},
title = {{Guiding robots through wireless location positioning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863702013{\&}doi=10.1109{\%}2FTePRA.2012.6215649{\&}partnerID=40{\&}md5=b8d0444856011f0f73d75c34f7b160aa},
year = {2012}
}
@inproceedings{Guo2018,
abstract = {Indoor localization is an important problem with a wide range of applications such as indoor navigation, robot mapping, especially augmented reality(AR). One of most important tasks in AR technology is to estimate the target objects' position information in real environment. The existed AR systems mostly utilize specialized marker to locate, some AR systems track real 3D object in real environment but need to get the the position information of index points in environment in advance. The above methods are not efficiency and limit the application of AR system, so that solving indoor localization problem has significant meaning for the development of AR technology. The development of computer vision (CV) techniques and the ubiquity of intelligent devices with cameras provides the foundation for offering accurate localization services. However, pure CV-based solutions usually involve hundreds of photos and pre-calibration to construct an densely sampled 3D model, which is a labor-intensive overhead for practical deployment. And a large amount of computation cost is difficult to satisfy the requirement for efficiency in mobile device. In this paper, we present iStart, a lightweight, easy deployed, image-based indoor localization system, which can be run on smart phone and VR/AR devices like HTC Vive, Google Glasses and so on. With core techniques rooted in data hierarchy scheme of WiFi fingerprints and photos, iStart also acquires user localization with a single photo of surroundings with high accuracy and short delay. Extensive experiments in various environments show that 90 percentile location deviations are less than 1 m, and 60 percentile location deviations are less than 0.5 m. {\textcopyright} 2018 Association for Computing Machinery.},
annote = {cited By 0},
author = {Guo, J and Zhang, S and Zhao, W and Peng, J},
booktitle = {Proceedings - VRCAI 2018: 16th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and its Applications in Industry},
doi = {10.1145/3284398.3284401},
keywords = {Augmented reality; Efficiency; Interactive compute,C-v models; Image-based localizations; Indoor loc,Indoor positioning systems},
title = {{Fusion of WiFi and vision based on smart devices for indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061818875{\&}doi=10.1145{\%}2F3284398.3284401{\&}partnerID=40{\&}md5=8f7dad8460fb4628d138f77d585cb30d},
year = {2018}
}
@article{Kim2017250,
abstract = {The extensive growth of mobile communications and the increasing use of smart devices has drawn significant research attention to location-based services (LBS). One of most important issues related to the application of LBS is the accurate position estimation of a mobile object. Focusing on an image sensor deployed in smart devices, we develop a visual light communication (VLC)-based location data transferal method. A light emitting diode (LED) generates a specific light signal, which is easily detected by image sensors. The algorithmic procedure of light signal recognition is implemented by using the image processing functions of smart devices. The image extracted from the light signal can be interpreted as unique location data. The proposed method can strengthen the advantages of the indoor applicability of VLC. The applicability of VLC is additionally reinforced by the concept of software defined light network reconfiguration. All data were harvested using actual measurements in indoor areas. The experimental results verify the practical usefulness of the proposed method. {\textcopyright} 2016 Elsevier B.V.},
annote = {cited By 1},
author = {Kim, J.-H. and Kang, S.-Y. and Lee, S.-T.},
doi = {10.1016/j.osn.2016.04.003},
journal = {Optical Switching and Networking},
keywords = {Actual measurements; Algorithmic procedure; Image,Image processing; Image sensors; Location; Locatio,Light emitting diodes},
pages = {250--258},
title = {{VLC-based location data transferal for smart devices}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964255610{\&}doi=10.1016{\%}2Fj.osn.2016.04.003{\&}partnerID=40{\&}md5=985a808f2ed1669bb9519ecb2ac11c4f},
volume = {23},
year = {2017}
}
@article{Zhang2016179,
abstract = {Properly incorporating location-uncertainties  which is, fully considering their impact when processing queries of interest  is a paramount in any application dealing with spatio-temporal data. Typically, the location-uncertainty is a consequence of the fact that objects cannot be tracked continuously and the inherent imprecision of localization devices. Although there is a large body of works tackling various aspects of efficient management of uncertainty in spatio-temporal data  the settings consider homogeneous localization devices, e.g., either a Global Positioning System (GPS), or different sensors (roadside, indoor, etc.).In this work, we take a first step towards combining the uncertain location data  i.e., fusing the uncertainty of moving objects location  obtained from both GPS devices and roadside sensors. We develop a formal model for capturing the whereabouts in time in this setting and propose the Fused Bead (FB) model, extending the bead model based solely on GPS locations. We also present algorithms for answering traditional spatio-temporal range queries, as well as a special variant pertaining to objects locations with respect to lanes on road segments  augmenting the conventional graph based road network with the width attribute. In addition, pruning techniques are proposed in order to expedite the query processing. We evaluated the benefits of the proposed approach on both real (Beijing taxi) and synthetic (generated from a customized trajectory generator) data. Our experiments demonstrate that the proposed method of fusing the uncertainties may eliminate up to 26 {\%} of the false positives in the Beijing taxi data, and up to 40 {\%} of the false positives in the larger synthetic dataset, when compared to using the traditional bead uncertainty models. {\textcopyright} 2015, Springer Science+Business Media New York.},
annote = {cited By 3},
author = {Zhang, B and Trajcevski, G and Liu, L},
doi = {10.1007/s10707-015-0238-6},
journal = {GeoInformatica},
keywords = {Beads; Efficient managements; Heterogeneous sourc,Beijing [Beijing (ADS)]; Beijing [China]; China,Global positioning system; Graphic methods; Locati,Information management,algorithm; data set; GPS; heterogeneity; precisio},
number = {2},
pages = {179--212},
title = {{Towards fusing uncertain location data from heterogeneous sources}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946781196{\&}doi=10.1007{\%}2Fs10707-015-0238-6{\&}partnerID=40{\&}md5=e1573a04f9c4cbebe50121ec3a49c93b},
volume = {20},
year = {2016}
}
@inproceedings{Barfeh201789,
abstract = {In this study, the authors design and implement a real time system as an autonomous robot-camera to capture many targets in the scene. The robot has only one camera, but it is capable of capturing more than one moving object through proper movement. The system uses Gaussian Filtering for motion detection and then performs partitioning to grab location of all targets in the scene. Due to partitioning, the scene has three major regions while each of which has different sub-regions. Based on the partitioning and position of all targets, the system might be in three states of unsafe state, safe state, and over-safe state. In each state regarding specific regions or sub-regions, the system picks appropriate movement not only to be capable of capturing all moving objects, but also to give equal chance of capturing to new targets entering to the scene from different direction. The system is tested in both of indoor and outdoor with different values for different parameters such as resolutions, fps (frame-per-second), minimum number of motion frames, and minimum areas of motion.},
annote = {cited By 0},
author = {Barfeh, D P Y and Bustamante, R V and Jose, E C and Lansigan, F P and Mendoza, E R and Mariano, V Y},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3175516.3175534},
keywords = {Cameras; Computer vision; Image processing; Intera,Gaussian filtering; Motion detection; Moving obje,Target tracking},
pages = {89--93},
title = {{Real time multi target capturing using partitioning in robot vision}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045480310{\&}doi=10.1145{\%}2F3175516.3175534{\&}partnerID=40{\&}md5=a44b329448f86724e86a70848501e876},
year = {2017}
}
@inproceedings{Nakamura2007,
abstract = {In this paper, we present a method for estimation of objects' positions and orientations in an indoor environment. For ubiquitous computing, it is important to realize provision of a location-aware information service for humans. Especially, orientation information can reflect a more detailed context than that obtained merely according to a location: people standing face-to-face or back-to-back have vastly different contexts. We are tackling indoor location and orientation estimation using a new approach called topological estimation, which specifically examines relative relationships of humans rather than their absolute positions. In the initial implementation of topological estimation, we have used infrared tags as sensors to collect real-world related information. This paper describes an ultrasonic and radio device system to collect objects' local relationships. {\textcopyright}2007 IEEE.},
annote = {cited By 0},
author = {Nakamura, Y and Kobayashi, R and Minami, M and Nishimura, T},
booktitle = {2007 IEEE Internatonal Conference on Mobile Adhoc and Sensor Systems, MASS},
doi = {10.1109/MOBHOC.2007.4428691},
keywords = {Device system; Indoor environments; Location-awar,Estimation; Information services; Sensors; Topolog,Ubiquitous computing},
title = {{Topological estimation using ultrasonic and radio}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-50249118281{\&}doi=10.1109{\%}2FMOBHOC.2007.4428691{\&}partnerID=40{\&}md5=8a79b3ae78715ea33491ba2e09c3e570},
year = {2007}
}
@inproceedings{Weng2009239,
abstract = {Augmented Reality systems often require the tracking of a user's pose in a large area to implement the registration between virtual object and the real world. To solve such a problem, this paper proposes a novel tracking system based on invisible projected markers which are created with an infrared projector. To enlarge the tracking area using only a limited number of markers, the system adopts a primary-secondary marker deployment solution, in which the primary marker uses an improved two-dimensional barcode and can be identified uniquely. The secondary marker is a simple light-spot, whose code is identified through the location relationship with the nearby primary markers and is used for the pose calculation. The system tracks the invisible markers using an IR (Infrared) camera, which means that it works in a way similar to a robust marker-less tracking system. A prototype is built to demonstrate the feasibility of the proposed tracking system, experimental result shows that the proposed system meets the requirements of accuracy for large-area tracking. Copyright {\textcopyright} 2009 by the Association for Computing Machinery, Inc.},
annote = {cited By 6},
author = {Weng, D and Huang, Y and Liu, Y and Wang, Y},
booktitle = {Proceedings - VRCAI 2009: 8th International Conference on Virtual Reality Continuum and its Applications in Industry},
doi = {10.1145/1670252.1670302},
keywords = {Augmented reality systems; Indoor tracking; Infrar,Augmented reality; Imaging systems; Infrared imag,Navigation},
pages = {239--245},
title = {{Study on an indoor tracking system with infrared projected markers for large-area applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-76749139059{\&}doi=10.1145{\%}2F1670252.1670302{\&}partnerID=40{\&}md5=4a68a13df21f3e0c5d41d710401df891},
year = {2009}
}
@inproceedings{Liu20103457,
abstract = {Background subtraction is an important step used to segment moving regions in surveillance videos. However, cast shadows are often falsely labeled as foreground objects, which may severely degrade the accuracy of object localization and detection. Effective shadow detection is necessary for accurate foreground segmentation, especially for outdoor scenes. Based on the characteristics of shadows, such as luminance reduction, chromaticity invariance and texture invariance, we introduce a nonparametric framework for modeling surface behavior under cast shadows. To each pixel, we assign a potential shadow value with a confidence weight, indicating the probability that the pixel location is an actual shadow point. Given an observed RGB value for a pixel in a new frame, we use its recent spatio-temporal context to compute an expected shadow RGB value. The similarity between the observed and the expected shadow RGB values determines whether a pixel position is a true shadow. Experimental results show the performance of the proposed method on a suite of standard indoor and outdoor video sequences. {\textcopyright} 2010 IEEE.},
annote = {cited By 2},
author = {Liu, Y and Adjeroh, D},
booktitle = {Proceedings - International Conference on Image Processing, ICIP},
doi = {10.1109/ICIP.2010.5653764},
keywords = {Background segmentation; Chromaticity; Shadow dete,Image segmentation,Imaging systems; Monitoring; Object recognition;},
pages = {3457--3460},
title = {{A statistical approach for shadow detection using spatio-temporal contexts}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651095026{\&}doi=10.1109{\%}2FICIP.2010.5653764{\&}partnerID=40{\&}md5=9ce7ead89eb8a9d4880e2994967a978a},
year = {2010}
}
@inproceedings{SyedAriffin2010383,
abstract = {Ubiquitous computing for context aware system collects information from many static and moving devices as well as sensor integrated objects. To provide valuable services, it is necessary to track the location of the users or objects. There are many possible applications that can apply location-assisted service such as child tracking, supermarket trolley alert system, firefighter tracking and many more. This paper proposed an indoor location assisted device switching for Voice over Internet Protocol (VoIP) application using session initiated protocol (SIP) for Wireless Local Area Network (WLAN) based. We present real test-bed measurements for indoor environment giving the results of the system operation as well as the system performance. The system performance shows excellent accuracy of 1m. {\textcopyright}2010 IEEE.},
annote = {cited By 1},
author = {{Syed Ariffin}, S H and {Abdul Wahab}, N H and Fisal, N and Latiff, L A and Choong, K.-N. and Raj, M A and Mohamed, R and Abbas, M},
booktitle = {2010 16th Asia-Pacific Conference on Communications, APCC 2010},
doi = {10.1109/APCC.2010.5679700},
keywords = {Component; Device switching; Location assisted sys,Environmental testing; Internet protocols; Intern,Wireless local area networks (WLAN)},
pages = {383--388},
title = {{Indoor location-assisted device switching system for VoIP application}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79251544322{\&}doi=10.1109{\%}2FAPCC.2010.5679700{\&}partnerID=40{\&}md5=e101e9662d1ab73dce69295d675fa6ca},
year = {2010}
}
@inproceedings{Bouman20172289,
abstract = {We show that walls, and other obstructions with edges, can be exploited as naturally-occurring 'cameras' that reveal the hidden scenes beyond them. In particular, we demonstrate methods for using the subtle spatio-temporal radiance variations that arise on the ground at the base of a wall's edge to construct a one-dimensional video of the hidden scene behind the wall. The resulting technique can be used for a variety of applications in diverse physical settings. From standard RGB video recordings, we use edge cameras to recover 1-D videos that reveal the number and trajectories of people moving in an occluded scene. We further show that adjacent wall edges, such as those that arise in the case of an open doorway, yield a stereo camera from which the 2-D location of hidden, moving objects can be recovered. We demonstrate our technique in a number of indoor and outdoor environments involving varied floor surfaces and illumination conditions. {\textcopyright} 2017 IEEE.},
annote = {cited By 9},
author = {Bouman, K L and Ye, V and Yedidia, A B and Durand, F and Wornell, G W and Torralba, A and Freeman, W T},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2017.249},
keywords = {Cameras,Computer vision; One dimensional; Stereo image pro,Floor surface; Illumination conditions; Moving ob},
pages = {2289--2297},
title = {{Turning Corners into Cameras: Principles and Methods}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041916662{\&}doi=10.1109{\%}2FICCV.2017.249{\&}partnerID=40{\&}md5=a257ed381871020abd557c579233b252},
volume = {2017-Octob},
year = {2017}
}
@inproceedings{Chrysikos2015,
abstract = {This paper presents a validation of indoor path loss models as well as a characterization of large-scale fading for an office propagation topology, based on measurements conducted at 3.5 GHz. The intrinsic channel characteristics and the impact of shadow fading on the reliability of signal prediction were taken into consideration. The mean relative error was calculated to prove the limitations of area-mean, distance-dependent path loss modeling. The distribution of the local mean values of the received power was investigated. Losses from walls and other objects were measured and compared to respective values for the indoor 2.4 GHz channel. Results confirm the impact of obstacle losses on the reliable estimation of shadow depth, as well as their dependence on frequency. {\textcopyright} 2015 IEEE.},
annote = {cited By 4},
author = {Chrysikos, T and Papadakos, C and Kotsopoulos, S},
booktitle = {Wireless Telecommunications Symposium},
doi = {10.1109/WTS.2015.7117285},
keywords = {Frequency estimation,Indoor propagation; Large-scale fading; Log-norma,Topology},
title = {{Wireless channel measurements and modeling for an office topology at 3.5 GHz}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940421861{\&}doi=10.1109{\%}2FWTS.2015.7117285{\&}partnerID=40{\&}md5=a5ac84f096fcc34a689ee04d969f3ef9},
volume = {2015-Janua},
year = {2015}
}
@article{Jin2016181,
abstract = {In this paper, we propose a new approach to measuring the similarity among indoor moving-object trajectories. Particularly, we propose to measure indoor trajectory similarity based on spatial similarity and semantic pattern similarity. For spatial similarity, we propose to detect the critical points in trajectories and then use them to determine spatial similarity. This approach can lower the computational costs of similarity search. Moreover, it helps achieve a more effective measure of spatial similarity because it removes noisy points. For semantic pattern similarity, we propose to construct a hierarchical semantic pattern to capture the semantics of trajectories. This method makes it possible to capture the implicit semantic similarity among different semantic labels of locations, and enables more meaningful measures of semantic similarity among indoor trajectories. We conduct experiments on indoor trajectories, comparing our proposal with several popular methods. The results suggest that our proposal is effective and represents an improvement over existing methods. {\textcopyright} Springer International Publishing Switzerland 2016.},
annote = {cited By 4},
author = {Jin, P and Cui, T and Wang, Q and Jensen, C S},
doi = {10.1007/978-3-319-32049-6_12},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Computational costs; Effective measures; Implicit,Database systems; Semantics,Trajectories},
pages = {181--197},
title = {{Effective similarity search on indoor moving-object trajectories}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962447607{\&}doi=10.1007{\%}2F978-3-319-32049-6{\_}12{\&}partnerID=40{\&}md5=507f6c4e58332bdb74f08e6d5362f377},
volume = {9643},
year = {2016}
}
@inproceedings{Takagi2009524,
abstract = {We have been developing a Universal Mobile robot for Assistive tasks (UMA). The aim of UMA is to assist elderly and disabled person in an indoor location. UMA is able to transport daily use objects by following the user. This paper presents an early construction of UMA and experimental result of following a user using visual tracking as a first step. {\textcopyright}2009 IEEE.},
annote = {cited By 2},
author = {Takagi, M and Takahashi, Y and Komeda, T},
booktitle = {2009 IEEE International Conference on Rehabilitation Robotics, ICORR 2009},
doi = {10.1109/ICORR.2009.5209602},
keywords = {Assistive; Daily use; Disabled persons; Visual Tra,Mobile robots; Patient rehabilitation,Robotics},
pages = {524--528},
title = {{A universal mobile robot for assistive tasks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449371565{\&}doi=10.1109{\%}2FICORR.2009.5209602{\&}partnerID=40{\&}md5=f01e396e558b9fb9f6b7d3fef7276e80},
year = {2009}
}
@inproceedings{Desingh2012,
abstract = {We present a probabilistic method of finding the next best viewpoint that maximizes the chances of finding an object in a known environment for an indoor mobile robot. We make use of the information that is available to a robot in the form of potential locations to search for an object. Extraction of these potential locations and their representation for exploration is explained. This work primarily focuses on placing the robot at its best location in the environment to detect, recognize an object and hence do object search. With experiments done on the exploration, object recognition individually we show the robustness of this approach for object search task. We analyse and compare our method with two other strategies for localizing the object empirically and show unequivocally that the strategy based on the probabilistic formalism in general performs better than the other two. {\textcopyright} 2012 ACM.},
annote = {cited By 0},
author = {Desingh, K and Nagariya, A and Krishna, K M},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/2425333.2425351},
keywords = {Computer vision,Image segmentation; Object recognition; Robotics,Indoor environment; Indoor mobile robots; Known en},
title = {{Viewpoint based mobile robotic exploration aiding object search in indoor environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872814603{\&}doi=10.1145{\%}2F2425333.2425351{\&}partnerID=40{\&}md5=54b83884438752dddbf0011dad757703},
year = {2012}
}
@inproceedings{Liu20141593,
abstract = {Advances in real-time location system (RTLS) solutions have enabled us to collect massive amounts of fine-grained semantically rich location traces, which provide unparalleled opportunities for understanding human activities and discovering useful knowledge. This, in turn, delivers intelligence for real-time decision making in various fields, such as workflow management. Indeed, it is a new paradigm for workflow modeling by the knowledge discovery in location traces. To that end, in this paper, we provide a focused study of workflow modeling by the integrated analysis of indoor location traces in the hospital environment. In comparison with conventional workflow modeling based on passive workflow logs, one salient feature of our approach is that it can proactively unravel the workflow patterns hidden in the location traces, by automatically constructing the workflow states and estimating parameters describing the transition patterns of moving objects. Specifically, to determine a meaningful granularity for the model, the workflow states are first constructed as regions associated with specific healthcare activities. Then, we transform the original indoor location traces to the sequences of workflow states and model the workflow transition patterns by finite state machines. Furthermore, we leverage the correlations in the location traces between related types of medical devices to reinforce the modeling performance and enable more applications. The results show that the proposed framework can not only model the workflow patterns effectively, but also have managerial applications in workflow monitoring, auditing, and inspection of workflow compliance, which are critical in the healthcare industry. {\textcopyright} 2014 ACM.},
annote = {cited By 7},
author = {Liu, C and Ge, Y and Xiong, H and Xiao, K and Geng, W and Perkins, M},
booktitle = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
doi = {10.1145/2623330.2623363},
pages = {1593--1602},
title = {{Proactive workflow modeling by stochastic processes with application to healthcare operation and management}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907028479{\&}doi=10.1145{\%}2F2623330.2623363{\&}partnerID=40{\&}md5=6a78e4160370e2798b8b140835b3b83c},
year = {2014}
}
@inproceedings{Lee201019,
abstract = {In this paper, we introduce a u-SPACE service robot, designed to help children who may be left alone while their caregivers are away from home. In order to protect children from indoor dangers, this service robot provides customized guiding messages taking into account the location information and behavioral patterns of a child, after the detection of dangerous objects and situations. And these guiding messages are vocalized by our emotional speech generation system. This emotional speech generation system is also being put to use in reading fairy tales to a child, as a part of a home education service. The outward appearance of the u-SPACE service robot is modeled on a teddy bear, in order to provide a safe and comforting environment for children. Two touch sensors designed for basic interactions between a child and the robot are installed on each hand of the robot, and an RFID tag is placed inside the body. A PDA with a Wi-Fi communication module, a touch screen, and a speaker is used as a main operating device of this u-SPACE service robot. {\textcopyright}2010 IEEE.},
annote = {cited By 1},
author = {Lee, H.-J. and Park, J C},
booktitle = {Proceedings of IEEE Workshop on Advanced Robotics and its Social Impacts, ARSO},
doi = {10.1109/ARSO.2010.5679634},
keywords = {Behavioral patterns; Emotional speech; Location in,Education,Mobile robots; Radio navigation; Robotics; Speech},
pages = {19--23},
title = {{A ubiquitous smart parenting and customized education service robot}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870051300{\&}doi=10.1109{\%}2FARSO.2010.5679634{\&}partnerID=40{\&}md5=7e17dd6022440adba5a395277dd3bed7},
year = {2010}
}
@inproceedings{Gmez2014346,
abstract = {This paper presents a service concept that enables the virtual augmentation of physical objects through a mobile device. Each object is linked to a tree of virtual resources (e.g. digital contents). Resources are organized in levels-of-detail that depend on the user's distance and orientation towards the object itself (i.e. user's attitude). The root node of the content tree hosts a set of items that can be retrieved from the most distant position to the object; each depth level in the tree is associated to the observer's attitude towards the object, thus the structure facilitates 'spatial browsing' of information. On this concept, we have implemented an indoor sensor-based Augmented Reality system that relies on a RFID positioning mat for positioning. To complete the attitude calculation and to adjust the service interface, we have handled typical indoor problems such as compass calibration and its bias management. The service has been instantiated to augment a TV set to spatially browse geography contents; the content tree is organized in continent, country and city levels and delivers synchronized resources to the mobile interface and to the TV, depending on the user's attitude and its previous interactions. Results of a limited user test show that the service concept is acceptable to the users and underline the need to get better control of resources representation. Although the chosen object for demonstration is a media one, the concept is applicable to any kind of object. {\textcopyright} 2014 IEEE.},
annote = {cited By 1},
author = {G{\'{o}}mez, D and Bernardos, A M and Casar, J R},
booktitle = {Proceedings - 2014 8th International Conference on Innovative Mobile and Internet Services in Ubiquitous Computing, IMIS 2014},
doi = {10.1109/IMIS.2014.47},
keywords = {Augmented reality; Forestry; Internet; Mobile devi,Computation; Information Retrieval,Interaction; Level of detail; Media management; P,Web services},
pages = {346--351},
title = {{A system to enable level-of-detail mobile interaction with augmented media objects}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938676754{\&}doi=10.1109{\%}2FIMIS.2014.47{\&}partnerID=40{\&}md5=07794802b569d020fa27e6759c618ea7},
year = {2014}
}
@inproceedings{Ouyang20164828,
abstract = {To understand the utilization of clinical resources and improve the efficiency of healthcare, it is often necessary to accurately locate patients and doctors in a healthcare facility. However, existing tracking methods, such as GPS, Wi-Fi and RFID, have technological drawbacks or impose significant costs, thus limiting their applications in many clinical environments, especially those with indoor enclosures. This paper proposes a low-cost and flexible tracking system that is well suited for operating in an indoor environment. Based on readily available RF transceivers and microcontrollers, our wearable sensor system can facilitate locating users (e.g., patients or doctors) or objects (e.g., medical devices) in a building. The strategic construction of the sensor system, along with a suitably designed tracking algorithm, together provide for reliability and dispatch in localization performance. For demonstration purposes, several simplified experiments, with different configurations of the system, are implemented in two testing rooms to assess the baseline performance. From the obtained results, our system exhibits immense promise in acquiring a user location and corresponding time-stamp, with high accuracy and rapid response. This capability is conducive to both short- and long-term data analytics, which are crucial for improving healthcare management. {\textcopyright} 2016 IEEE.},
annote = {cited By 1},
author = {Ouyang, Y and Shan, K and Bui, F M},
booktitle = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
doi = {10.1109/EMBC.2016.7591808},
keywords = {Algorithms; Biomedical Technology; Equipment Desi,algorithm; devices; equipment design; evaluation s},
pages = {4828--4831},
title = {{An RF-based wearable sensor system for indoor tracking to facilitate efficient healthcare management}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009067439{\&}doi=10.1109{\%}2FEMBC.2016.7591808{\&}partnerID=40{\&}md5=67498cd559232e1c500244a8df4b9811},
volume = {2016-Octob},
year = {2016}
}
@inproceedings{Berz2017331,
abstract = {In order to optimize the user experience and solve logistical and security issues, many systems require the physical location information from objects and people. Indoor positioning systems (IPSs) based on more than one technology can improve localization performance by leveraging the advantages of different technologies. This work proposes a hybrid IPS able to estimate the item-level location of stationary objects using off-the-shelf equipment. By using RFID technology, machine learning approaches based on artificial neural networks (ANNs) and support vector regression (SVR) are proposed. A k-means technique is also applied to improve accuracy. A computer vision (CV) subsystem detects visual markers in the scenario to enhance RFID localization. To combine the RFID and CV subsystems, a fusion method based on region of interest (ROI) is proposed. We have implemented our system and evaluated it using real experiments. The localization error is between 9 and 29cm in the range of 1 and 2.2m scenarios. In a machine learning approach comparison, ANN performed 31{\%} better than SVR approach. {\textcopyright} 2017 IEEE.},
annote = {cited By 2},
author = {Berz, E L and Tesch, D A and Hessel, F P},
booktitle = {Proceedings - International Symposium on Quality Electronic Design, ISQED},
doi = {10.1109/ISQED.2017.7918337},
keywords = {Artificial intelligence; Engineering education; Im,Localization errors; Localization performance; Ma,Radio frequency identification (RFID)},
pages = {331--336},
title = {{A hybrid RFID and CV system for item-level localization of stationary objects}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019602282{\&}doi=10.1109{\%}2FISQED.2017.7918337{\&}partnerID=40{\&}md5=0d63615dbee60e8d734545c24ee5618c},
year = {2017}
}
@inproceedings{Wei2017194,
abstract = {Indoor positioning enables location-based services for a wide range of commercial applications [4]. Existing visible light positioning (VLP) systems [5, 7] leverage the high image resolution of a receiving camera to support high positioning accuracy. However, power-hungry cameras are not desirable in many scenarios, e.g., smart factories, where small objects need to be accurately located and tracked. In this demo, we introduce CELLI, an indoor VLP system that only uses a single luminary as the transmitter and requires only a simple light sensor to achieve high accuracy with centimeter-level error. The key idea is to provide the spatial resolution capability from the transmitter instead of the receiver, so that the complexity of the receiver can be minimized. In particular, a small Liquid Crystal Display (LCD) is installed at the transmitter to project a large number of narrow and interference-free polarized light beams to different spatial cells. A receiving light sensor identifies its located cell by detecting the unique polarization-modulated signals projected to that cell, as shown in Fig. 1. CELLI further incorporates several novel designs to overcome the technical challenges such as reducing the positioning latency, which is typically limited by the long optical response time of an LCD, and transforming a cell coordinate to the global 3D position using only a single light. We have prototyped our design using off-the-shelf optical and electronic components, and experimentally shown that CELLI achieves a median 3D positioning error less than 12 cm and a median 2D error less than 2.7 cm. {\textcopyright} 2017 Copyright held by the owner/author(s).},
annote = {cited By 0},
author = {Wei, Y.-L. and Huang, C.-J. and Tsai, H.-M. and Lin, K.C.-J.},
booktitle = {MobiSys 2017 - Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
doi = {10.1145/3081333.3089339},
keywords = {Cameras; Cells; Cytology; Errors; Image resolution,Commercial applications; Electronic component; In,Light},
pages = {194},
title = {{Demo: CELLI - Indoor positioning using polarized sweeping light beams}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026206479{\&}doi=10.1145{\%}2F3081333.3089339{\&}partnerID=40{\&}md5=33e49f253bc919f79c2525b94b7067c5},
year = {2017}
}
@inproceedings{Radhakrishnan2018312,
abstract = {We espouse the vision of a smart object/campus architecture where sensors attached to smart objects use BLE as communication interface, and where smartphones act as opportunistic relays to transfer the data. We explore the feasibility of the vision with real-world Wi-Fi based location traces from our university campus. Our feasibility studies establish that redundancy exists in user movement within the indoor spaces, and that this redundancy can be exploited for collecting sensor data in an opportunistic, yet fair manner. We develop a couple of alternative heuristics that address the BLE energy asymmetry challenge by intelligently duty-cycling the scanning actions of individual devices. We evaluate the efficacy and tradeoffs of the proposed approaches by simulation experiments with real-world location traces. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Radhakrishnan, M and Sen, S and Misra, A and Lee, Y and Balan, R K},
booktitle = {2018 10th International Conference on Communication Systems and Networks, COMSNETS 2018},
doi = {10.1109/COMSNETS.2018.8328213},
keywords = {Communication interface; Feasibility studies; Ind,Human computer interaction,Redundancy},
pages = {312--319},
title = {{Smart monitoring via participatory BLE relaying}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050917461{\&}doi=10.1109{\%}2FCOMSNETS.2018.8328213{\&}partnerID=40{\&}md5=4e68daea32a20f27c53bbd71332619aa},
volume = {2018-Janua},
year = {2018}
}
@inproceedings{Pishdad201277,
abstract = {Particle filters have been widely used in positioning problems, to post-process the noisy location sensor measurements. In this paper, instead of the commonly used Prior Importance Function for particle filtering, we have formulated and applied the Optimal Importance Function. Unlike other importance functions, the Optimal Importance Function minimizes the variance of particle weights and thus resolves the degeneracy problem of particle filters. In this work, we have derived a closed form formula for the Optimal Importance Function using map-independent random walk velocity motion model and a GMM sensor error. Due to the generality of the proposed method, it can be used for a wide range of moving objects in different environments. Simulation results support the validity of modeling assumptions and the advantage of applying an Optimal Importance Function in indoor localization and positioning. {\textcopyright} 2012 IEEE.},
annote = {cited By 2},
author = {Pishdad, L and Labeau, F},
booktitle = {WPNC'12 - Proceedings of the 2012 9th Workshop on Positioning, Navigation and Communication},
doi = {10.1109/WPNC.2012.6268742},
keywords = {Closed-form formulae; Degeneracy problems; Importa,Communication; Monte Carlo methods; Signal filter,Optimization},
pages = {77--82},
title = {{Indoor positioning using particle filters with optimal importance function}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867002379{\&}doi=10.1109{\%}2FWPNC.2012.6268742{\&}partnerID=40{\&}md5=f530c194eaa5a269fe98db14e56cc592},
year = {2012}
}
@inproceedings{Lu2011816,
abstract = {To facilitate a variety of applications, positioning systems are deployed in indoor settings. For example, Bluetooth and RFID positioning are deployed in airports to support real-time monitoring of delays as well as off-line flow and space usage analyses. Such deployments generate large collections of tracking data. Like in other data management applications, joins are indispensable in this setting. However, joins on indoor tracking data call for novel techniques that take into account the limited capabilities of the positioning systems as well as the specifics of indoor spaces. This paper proposes and studies probabilistic, spatio-temporal joins on historical indoor tracking data. Two meaningful types of join are defined. They return object pairs that satisfy spatial join predicates either at a time point or during a time interval. The predicates considered include same X, where X is a semantic region such as a room or hallway. Based on an analysis on the uncertainty inherent to indoor tracking data, effective join probabilities are formalized and evaluated for object pairs. Efficient two-phase hash-based algorithms are proposed for the point and interval joins. In a filter-and-refine framework, an R-tree variant is proposed that facilitates the retrieval of join candidates, and pruning rules are supplied that eliminate candidate pairs that do not qualify. An empirical study on both synthetic and real data shows that the proposed techniques are efficient and scalable. {\textcopyright} 2011 IEEE.},
annote = {cited By 19},
author = {Lu, H and Yang, B and Jensen, C S},
booktitle = {Proceedings - International Conference on Data Engineering},
doi = {10.1109/ICDE.2011.5767902},
keywords = {Data management; Empirical studies; Indoor space;,Decision trees; Information management; Navigatio,Uncertainty analysis},
pages = {816--827},
title = {{Spatio-temporal joins on symbolic indoor tracking data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957822670{\&}doi=10.1109{\%}2FICDE.2011.5767902{\&}partnerID=40{\&}md5=f535f50445657ec049623529a773bf25},
year = {2011}
}
@inproceedings{Kanezaki20114026,
abstract = {Realizing automatic object search by robots in an indoor environment is one of the most important and challenging topics in mobile robot research. If the target object does not exist in a nearby area, the obvious strategy is to go to the area in which it was last observed. We have developed a robot system that collects 3D-scene data in an indoor environment during automatic routine crawling, and also detects objects quickly through a global search of the collected 3D-scene data. The 3D-scene data can be obtained automatically by transforming color images and range images into a set of color voxel data using self-location information. To detect an object, the system moves the bounding box of the target object by a certain step in the color voxel data, extracts 3D features in each box region, and computes the similarity between these features and the target object's features, using an appropriate feature projection learned beforehand. Taking advantage of the additive property of our 3D features, both feature extraction and similarity calculation are considerably accelerated. In the object learning process, the system obtains the feature-projection matrix by weighting unique features of the target object rather than its common features, resulting in reducing object detection errors. {\textcopyright} 2011 IEEE.},
annote = {cited By 13},
author = {Kanezaki, A and Suzuki, T and Harada, T and Kuniyoshi, Y},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2011.5980129},
keywords = {Bounding box; Color images; Feature projection; Gl,Color; Feature extraction; Metadata; Object recog,Search engines},
pages = {4026--4033},
title = {{Fast object detection for robots in a cluttered indoor environment using integral 3D feature table}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867949589{\&}doi=10.1109{\%}2FICRA.2011.5980129{\&}partnerID=40{\&}md5=dd4095748df69123bd5ae7a6b9b25aac},
year = {2011}
}
@inproceedings{Viswanathan20111,
abstract = {Places in an environment are locations where activities occur, and can be described by the objects they contain. This paper discusses the completely automated integration of object detection and global image properties for place classification. We first determine object counts in various place types based on Label Me images, which contain annotations of places and segmented objects. We then train object detectors on some of the most frequently occurring objects. Finally, we use object detection scores as well as global image properties to perform place classification of images. We show that our object-centric method is superior and more generalizable when compared to using global properties in indoor scenes. In addition, we show enhanced performance by combining both methods. We also discuss areas for improvement and the application of this work to informed visual search. Finally, through this work we display the performance of a state-of-the-art technique trained using automatically-acquired labeled object instances (i.e., bounding boxes) to perform place classification of realistic indoor scenes. {\textcopyright} 2011 IEEE.},
annote = {cited By 12},
author = {Viswanathan, P and Southey, T and Little, J and Mackworth, A},
booktitle = {Proceedings - 2011 Canadian Conference on Computer and Robot Vision, CRV 2011},
doi = {10.1109/CRV.2011.8},
keywords = {Bounding box; Enhanced performance; Global informa,Computer vision; Detectors,Object recognition},
pages = {1--7},
title = {{Place classification using visual object categorization and global information}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051821089{\&}doi=10.1109{\%}2FCRV.2011.8{\&}partnerID=40{\&}md5=cf1672cd639354c15ebcabd559086b90},
year = {2011}
}
@inproceedings{Chawla2013,
abstract = {New computing paradigms have underscored the need to locate objects in an environment, motivating several object localization approaches targeting competing technologies and specific applications. While RFID technology recently emerged as a viable platform for locating objects, several unresolved key challenges precluded higher performance and wider applicability. We present an RFID-based real-time location system that uses Received Signal Strength (RSS) to better model the distance-decaying behavior of radio signals in an orientation-agnostic manner.We experimentally leverage the proposed robust models to simultaneously locate several stationary and mobile objects tagged with passive tags in a realistically noisy indoor environment, with an average accuracy of 0.6 meters. A more general conclusion of this work is that contrary to common belief, RSS can indeed serve as reliable metric for a variety of select applications, including localization. {\textcopyright} 2013 IEEE.},
annote = {cited By 21},
author = {Chawla, K and McFarland, C and Robins, G and Shope, C},
booktitle = {2013 International Conference on Localization and GNSS, ICL-GNSS 2013},
doi = {10.1109/ICL-GNSS.2013.6577259},
keywords = {Competing technologies; Computing paradigm; Indoor,Object recognition; Telecommunication networks,RSS},
title = {{Real-time RFID localization using RSS}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884616401{\&}doi=10.1109{\%}2FICL-GNSS.2013.6577259{\&}partnerID=40{\&}md5=ce7559359c11497daba265bde2cb3ee9},
year = {2013}
}
@inproceedings{Shen2018429,
abstract = {A rich body of work has focused on motion tracking techniques using inertial sensors, namely accelerometers, gyroscopes, and magnetometers. Applications of these techniques are in indoor localization, gesture recognition, inventory tracking, vehicular motion, and many others. This paper identifies room for improvement over today's motion tracking techniques. The core observation is that conventional systems have trusted gravity more than the magnetic North to infer the 3D orientation of the object. We find that the reverse is more effective, especially when the object is in continuous fast motion. We leverage this opportunity to design MUSE, a magnetometer-centric sensor fusion algorithm for orientation tracking. Moreover, when the object's motion is somewhat restricted (e.g., human-arm motion restricted by elbow and shoulder joints), we find new methods of sensor fusion to fully leverage the restrictions. Real experiments across a wide range of uncontrolled scenarios show consistent improvement in orientation and location accuracy, without requiring any training or machine learning. We believe this is an important progress in the otherwise mature field of IMU-based motion tracking. {\textcopyright} 2018 Association for Computing Machinery.},
annote = {cited By 1},
author = {Shen, S and Gowda, M and Choudhury, R R},
booktitle = {Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM},
doi = {10.1145/3241539.3241582},
keywords = {Accelerometers; Crystal orientation; Gyroscopes; L,Conventional systems; Dead reckoning; Indoor loca,Motion analysis},
pages = {429--444},
title = {{Closing the gaps in inertial motion tracking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055326634{\&}doi=10.1145{\%}2F3241539.3241582{\&}partnerID=40{\&}md5=6c96a318e5ea41893a9abaad78cdaa99},
year = {2018}
}
@inproceedings{Takatsuka2015,
abstract = {This paper proposes a unified locating service, KULOCS, which horizontally integrates the heterogeneous locating services. Focusing on technology-independent elements [when], [where] and [who] in location queries, KULOCS integrates data and operations of the existing locating services. In the data integration, we propose a method where the time representation, the locations, the namespace are consolidated by Unix time, the location labels and the alias table, respectively. Based on possible combinations of the three elements, we then derive API for the operation integration. In this paper, we also implement KULOCS as a Java Web service and integrate two locating services: GPS-based outdoor locating service and BLE-based indoor locating service. On top of the implementation, we develop application services: Umbrella Reminder Service and Stay Areas Visualization Service. Experimental evaluation shows the practical feasibility by comparing cases with or without KULOCS. Since KULOCS works as a seamless f{\c{a}}cade to the underlying locating services, the users and applications consume location information easily and efficiently, without knowing concrete services actually locating target objects. {\textcopyright} 2015 ACM.},
annote = {cited By 1},
author = {Takatsuka, H and Tokunaga, S and Saiki, S and Matsumoto, S and Nakamura, M},
booktitle = {17th International Conference on Information Integration and Web-Based Applications and Services, iiWAS 2015 - Proceedings},
doi = {10.1145/2837185.2837229},
keywords = {Application services; Concrete service; Experimen,Data integration; Indoor positioning systems; Info,Location based services},
title = {{Integrating heterogeneous locating services for efficient development of location-based services}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84967321361{\&}doi=10.1145{\%}2F2837185.2837229{\&}partnerID=40{\&}md5=ca4a8dd9a566607c5d531c8441cbde30},
year = {2015}
}
@article{Wang201213,
abstract = {This paper presents a novel method to generate semantic-based trajectories for indoor moving objects. Indoor moving objects management has been a research focus in recent years. In order to get the trajectory data of indoor moving objects, we have to deply numerous positioning equipments, such as RFID readers and tags. In addition, it is a very complex and costly process to construct different environment settings for various indoor applications. To solve those problems, we propose to use virtual positioning equipments, e.g. RFID readers and tags, to simulate indoor environment. Furthermore, we present a semantic-based approach to generating trajectories for indoor moving objects, which takes into account the type of moving objects, the relationship between moving objects and locations, and the distribution of the trajectories. Compared with previous approaches, our method is more realistic for the simulation of indoor scenarios, and can provide useful trajectory data for further indoor data management analysis. Finally, we design and implement a tool for the generation of semantic-based trajectories for indoor moving objects, and conduct a case study to demonstrate its effectiveness. The results show that it can generate semantic-based trajectories for indoor moving objects according to different parameters and semantic settings. {\textcopyright} 2012 Springer-Verlag.},
annote = {cited By 3},
author = {Wang, H and Jin, P and Zhao, L and Zhang, L and Yue, L},
doi = {10.1007/978-3-642-28635-3_2},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Indoor applications; Indoor environment; Indoor sp,Information management; Semantic Web; Semantics;,Trajectories},
pages = {13--25},
title = {{Generating semantic-based trajectories for indoor moving objects}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859125176{\&}doi=10.1007{\%}2F978-3-642-28635-3{\_}2{\&}partnerID=40{\&}md5=fad6ebff4d0240612407490fc32519c0},
volume = {7142 LNCS},
year = {2012}
}
@inproceedings{Bauer20138,
abstract = {We address a specific, particularly difficult class of activity recognition problems defined by (1) subtle, and hardly discriminative hand motions such as a short press or pull, (2) large, ill defined NULL class (any other hand motion a person may express during normal life), and (3) difficulty of collecting sufficient training data, that generalizes well from one to multiple users. In essence we intend to spot activities such as opening a cupboard, pressing a button, or taking an object from a shelve in a large data stream that contains typical every day activity. We focus on body-worn sensors without instrumenting objects, we exploit available infrastructure information, and we perform a one-to-many-users training scheme for minimal training effort. We demonstrate that a state of the art motion sensors based approach performs poorly under such conditions (Equal Error Rate of 18{\%} in our experiments). We present and evaluate a new multi modal system based on a combination of indoor location with a wrist mounted proximity sensor, camera and inertial sensor that raises the EER to 79{\%}. {\textcopyright} 2013 IEEE.},
annote = {cited By 1},
author = {Bauer, G and Blanke, U and Lukowicz, P and Schiele, B},
booktitle = {2013 IEEE International Conference on Pervasive Computing and Communications Workshops, PerCom Workshops 2013},
doi = {10.1109/PerComW.2013.6529448},
keywords = {Activity recognition; ADL; Body-worn sensors; Mult,Cameras; Sensors,Ubiquitous computing},
pages = {8--13},
title = {{User independent, multi-modal spotting of subtle arm actions with minimal training data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881500453{\&}doi=10.1109{\%}2FPerComW.2013.6529448{\&}partnerID=40{\&}md5=db423f048a6ebc4ee74fad0fbb17d7e6},
year = {2013}
}
@inproceedings{Durucan2000,
abstract = {The subject of this paper is to provide an illumination invariant moving object detector for indoor surveillance applications. Furthermore we want to treat the illumination change as a mathematical/physical transformation procedure on images. Therefore the intention to this paper could also be defined as to provide an operator, which is invariant to transformations. The proposed detector relies on a model assigning a vector to every pixel location of the reference and the current image. The vector represents information on the neighborhood region of that pixel. Based on the above definition, the theorem of linear dependence of vectors is used to describe an operator for the detection of objects. For the purpose of an objective evaluation, the proposed technique is compared to the state-of-the-art Statistical Change Detection method. The proposed operator proved to be robust to noise as well as global illumination changes and local shadows and reflections. {\textcopyright} 2000 EUSIPCO.},
annote = {cited By 13},
author = {Durucan, E and Ebrahimi, T},
booktitle = {European Signal Processing Conference},
keywords = {Global illumination change; Illumination changes;,Image recognition; Mathematical transformations; O,Signal detection},
number = {March},
title = {{Robust and illumination invariant change detection based on linear dependence for surveillance application}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937057303{\&}partnerID=40{\&}md5=d1976d5e74d99fb337c17d7c0b2d5628},
volume = {2015-March},
year = {2000}
}
@inproceedings{Mainetti20151065,
abstract = {Smart Objects and Smart Environments are expected to become two of the leaders of the future Internet of Things. In this context, the Smart Homes are getting more and more attention, since people are very attracted by the idea of a home environment able to automatically meet their needs. However, the heterogeneity of the smart devices, the difficulty in automating the user-home interaction, and the poor involvement of the users in the development process of new services and applications still represent very debated issues. So, in this paper, we propose an architecture able to overcome the heterogeneity of smart devices and that can be easily extended to new future technologies. To maximize the User Experience, the proposed architecture automatically manages the environment basing on users-defined rules and on people movements, by exploiting an indoor location service based on Bluetooth Low Energy. Finally, the system also provides a simplified development tool that allows even common users to develop new services for Smart Homes and mobile applications to directly interact with the home environment. As a proof-of-concept, the first development steps are described in this paper. {\textcopyright} 2015 IEEE.},
annote = {cited By 14},
author = {Mainetti, L and Mighali, V and Patrono, L},
booktitle = {Proceedings of the 2015 IFIP/IEEE International Symposium on Integrated Network Management, IM 2015},
doi = {10.1109/INM.2015.7140434},
keywords = {Automation; Intelligent buildings; Middleware; Net,Bluetooth low energies (BTLE); Building automatio,Location based services},
pages = {1065--1070},
title = {{A location-aware architecture for heterogeneous building automation systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942568374{\&}doi=10.1109{\%}2FINM.2015.7140434{\&}partnerID=40{\&}md5=5b4bd98395ea2297d738f66403985a8e},
year = {2015}
}
@article{Chianese2015209,
abstract = {The relationship between cultural heritage domain and new technologies has always been complex, dialectical and often inspired by the human desire to induce these spaces not created for that purpose, to pursue technological trends, eventually offering to the end-users devices and innovative technologies that could become a dead weight' during their cultural experiences. However, by means of innovative technological applications and location-based services it is possible to shorten the distance between cultural spaces and their visitors, nowadays determined by the purely aesthetic and essentially passive fruition of cultural objects. This paper presents the design and implementation of a novel multipurpose system for creating single smart spaces ((Formula presented.)), a new concept of intelligent environment, that relies on innovative sensors board named smart crickets and an ad hoc proximity strategy; by following the Internet of Things paradigm the proposed system is able to transform a cultural space in a smart cultural environment to enhance the enjoyment and satisfaction of the involved people. To assess the effectiveness of our solution, we have experienced two real case studies, the first one situated within an art exhibition (indoor), and the second one concerning an historical building (outdoor). In this way, technology can become a mediator between visitors and fruition, an instrument of connection between people, objects and spaces to create new social, economic and cultural opportunities. {\textcopyright} 2015 Taylor {\&} Francis.},
annote = {cited By 50},
author = {Chianese, A and Piccialli, F and Valente, I},
doi = {10.1080/17489725.2015.1099752},
journal = {Journal of Location Based Services},
keywords = {Cultural environment; Cultural heritages; Design,Internet; Internet of things; Social sciences; Tel,Location based services},
number = {3},
pages = {209--234},
title = {{Smart environments and Cultural Heritage: a novel approach to create intelligent cultural spaces}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946541214{\&}doi=10.1080{\%}2F17489725.2015.1099752{\&}partnerID=40{\&}md5=51491841777a4f5028cb20325f0e010b},
volume = {9},
year = {2015}
}
@inproceedings{Marchesotti200399,
abstract = {This paper presents an agent-based architecture designed to functionally combine data from an homogeneous network of sensors for tracking purposes. The system has been developed in a video surveillance context to detect, classify and track moving objects in a scene of interest. Although single camera systems could perform the tasks outlined above, they would not be able to deal with topologically complex environments such as corridor, corners and indoor locations in general. The multi-sensor approach has been used to overcome these problems, nevertheless issues arise such as data fusion, synchronization and camera calibration. The sensor fusion approach here purposed uses autonomous software agents to negotiate the combination of data and the fusion is carried out by appropriate signal processing algorithms. The system has been tested with indoor video sequences to show the system's ability to preserve identity and of correct trajectory estimation of the tracked object. {\textcopyright} 2003 IEEE.},
annote = {cited By 10},
author = {Marchesotti, L and Piva, S and Regazzoni, C},
booktitle = {Proceedings - 12th International Conference on Image Analysis and Processing, ICIAP 2003},
doi = {10.1109/ICIAP.2003.1234033},
keywords = {Agent-based approach; Agent-based architecture; Au,Data fusion; Image analysis; Security systems; Se,Target tracking},
pages = {99--102},
title = {{An agent-based approach for tracking people in indoor complex environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750472252{\&}doi=10.1109{\%}2FICIAP.2003.1234033{\&}partnerID=40{\&}md5=eeccd4bd3e7c410b3cfe23038691dfeb},
year = {2003}
}
@inproceedings{Bulten2016211,
abstract = {The indoor localisation problem is more complex than just finding whereabouts of users. Finding positions of users relative to the devices of a smart space is even more important. Unfortunately, configuring such systems manually is a tedious process, requires expert knowledge, and is sensitive to changes in the environment. Moreover, many existing solutions do not take user privacy into account. We propose a new system, called Simultaneous Localisation and Configuration (SLAC), to address the problem of locating devices and users relative to those devices, and combine this problem into a single estimation problem. The SLAC algorithm, based on FastSLAM, is able to locate devices using the received signal strength indicator (RSSI) of devices and motion data from users. Simulations have been used to show the performance in a controlled environment and the effect of the amount of RSSI updates on the localisation error. Live tests in non-trivial environments showed that we can achieve room level accuracy and that the localisation can be performed in real time. This is all done locally, i.e. running on a user's device, with respect for privacy and without using any prior information of the environment or device locations. Although promising, more work is required to increase accuracy in larger environments and to make the algorithm more robust for environment noise caused by walls and other objects. Existing techniques, e.g. map fusing, can alleviate these problems. {\textcopyright} 2016 IEEE.},
annote = {cited By 3},
author = {Bulten, W and {Van Rossum}, A C and Haselager, W F G},
booktitle = {Proceedings - 2016 IEEE 1st International Conference on Internet-of-Things Design and Implementation, IoTDI 2016},
doi = {10.1109/IoTDI.2015.19},
keywords = {Automation; Complex networks; Data privacy; Intell,Controlled environment; Estimation problem; Exper,Indoor positioning systems},
pages = {211--222},
title = {{Human SLAM, indoor localisation of devices and users}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977615151{\&}doi=10.1109{\%}2FIoTDI.2015.19{\&}partnerID=40{\&}md5=80bab104452668eeb1526a72b0747843},
year = {2016}
}
@article{Zhou20041491,
abstract = {We present an approach that incorporates appearance-adaptive models in a particle filter to realize robust visual tracking and recognition algorithms. Tracking needs modeling interframe motion and appearance changes, whereas recognition needs modeling appearance changes between frames and gallery images. In conventional tracking algorithms, the appearance model is either fixed or rapidly changing, and the motion model is simply a random walk with fixed noise variance. Also, the number of particles is typically fixed. All these factors make the visual tracker unstable. To stabilize the tracker, we propose the following modifications: an observation model arising from an adaptive appearance model, an adaptive velocity motion model with adaptive noise variance, and an adaptive number of particles. The adaptive-velocity model is derived using a first-order linear predictor based on the appearance difference between the incoming observation and the previous particle configuration. Occlusion analysis is implemented using robust statistics. Experimental results on tracking visual objects in long outdoor and indoor video sequences demonstrate the effectiveness and robustness of our tracking algorithm. We then perform simultaneous tracking and recognition by embedding them in a particle filter. For recognition purposes, we model the appearance changes between frames and gallery images by constructing the intra- and extrapersonal spaces. Accurate recognition is achieved when confronted by pose and view variations. {\textcopyright} 2004 IEEE.},
annote = {cited By 566},
author = {Zhou, S K and Chellappa, R and Moghaddam, B},
doi = {10.1109/TIP.2004.836152},
journal = {IEEE Transactions on Image Processing},
keywords = {Algorithms; Artificial Intelligence; Cluster Anal,Algorithms; Digital filters; Mathematical models;,Appearance adaptive model; Occlusion; Particle fi,Automated; Reproducibility of Results; Sensitivit,Biological; Models,Computer-Assisted; Information Storage and Retrie,Computer-Assisted; Pattern Recognition,Computer-Assisted; Subtraction Technique,Face recognition,Statistical; Motion; Movement; Numerical Analysis,algorithm; article; artificial intelligence; auto},
number = {11},
pages = {1491--1506},
title = {{Visual tracking and recognition using appearance-adaptive models in particle filters}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-7444266896{\&}doi=10.1109{\%}2FTIP.2004.836152{\&}partnerID=40{\&}md5=d70c3ef33dcd1c6befb2e69f88515507},
volume = {13},
year = {2004}
}
@inproceedings{Zou2013,
abstract = {In recent years, applying RFID technology to develop an Indoor Positioning System (IPS) has become a hot research topic. The most prominent advantage of active RFID IPS comes from its unique identification of different objects in indoor environment. However, certain drawbacks of existing RFID IPSs, such as high cost of RFID readers and active tags, as well as heavy dependence on the density of reference tags to provide the location based service, largely limit the applications of active RFID IPS. In order to overcome these drawbacks, we develop a cost-efficient RFID IPS by using cheaper active RFID tags, sensors and reader. In addition, one localization algorithm: integrated Weighted Path Loss (WPL) - Extreme Learning Machine (ELM) which combines the fast estimation of WPL and the high localization accuracy of ELM is proposed. According to the algorithm, an indoor environment is divided into small zones firstly and an ELM model is developed for each zone during the offline phase. During the online phase, the WPL approach is used to determine the zone of the target primarily, then the ELM model of that zone is deployed to provide the final estimated location of the target. Based on our experimental result, this integrated algorithm provides a higher localization efficiency and accuracy than existing approaches. {\textcopyright} 2013 IEEE.},
annote = {cited By 12},
author = {Zou, H and Xie, L and Jia, Q.-S. and Wang, H},
booktitle = {2013 International Conference on Indoor Positioning and Indoor Navigation, IPIN 2013},
doi = {10.1109/IPIN.2013.6817858},
keywords = {Extreme learning machine; Hot research topics; In,Internet of things; Knowledge acquisition; Learnin,Radio frequency identification (RFID)},
title = {{An integrative weighted path loss and extreme learning machine approach to Rfid based indoor positioning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902130198{\&}doi=10.1109{\%}2FIPIN.2013.6817858{\&}partnerID=40{\&}md5=4f9a03288d46b018865a0cececcad9bf},
year = {2013}
}
@inproceedings{Zhao2014255,
abstract = {Indoor object localization can enable many ubicomp applications, such as asset tracking and object-related activity recognition. Most location and tracking systems rely on either battery-powered devices which create cost and maintenance issues or cameras which have accuracy and privacy issues. This paper introduces a system that is able to detect the 3D position and motion of a battery-free RFID tag embedded with an ultrasound detector and an accelerometer. Combining tags' acceleration with location improves the system's power management and supports activity recognition. We characterize the system's localization performance in open space as well as implement it in a smart wet lab application. The system is used to track real-time location and motion of the tags in the wet lab as well as recognize pouring actions performed on the objects to which the tag is attached. The median localization accuracy is 7.6cm - (3.1, 5, 1.9)cm for each (x, y, z) axis - with max update rates of 15 Sample/s using single RFID reader antenna. Copyright {\textcopyright} 2014 by the Association for Computing Machinery, Inc. (ACM).},
annote = {cited By 8},
author = {Zhao, Y and Lamarca, A and Smith, J R},
booktitle = {UbiComp 2014 - Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
doi = {10.1145/2632048.2632078},
keywords = {Activity recognition; Battery powered devices; Lo,Electric batteries; Object recognition; Ubiquitous,Radio frequency identification (RFID)},
pages = {255--259},
title = {{A battery-free object localization and motion sensing platform}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908594275{\&}doi=10.1145{\%}2F2632048.2632078{\&}partnerID=40{\&}md5=cf06e24e7885ea4d6643a0c0a464e224},
year = {2014}
}
@article{Bouguet1999129,
abstract = {A simple and inexpensive approach for extracting the three-dimensional shape of objects is presented. It is based on `weak structured lighting'. It requires very little hardware besides the camera: a light source (a desk-lamp or the sun), a stick and a checkerboard. The object, illuminated by the light source, is placed on a stage composed of a ground plane and a back plane; the camera faces the object. The user moves the stick in front of the light source, casting a moving shadow on the scene. The 3D shape of the object is extracted from the spatial and temporal location of the observed shadow. Experimental results are presented on five different scenes (indoor with a desk lamp and outdoor with the sun) demonstrating that the error in reconstructing the surface is less than 0.5{\%} of the size of the object. A mathematical formalism is proposed that simplifies the notation and keep the algebra compact. A real-time implementation of the system is also presented.},
annote = {cited By 44},
author = {Bouguet, J.-Y. and Perona, P},
doi = {10.1023/A:1008124523456},
journal = {International Journal of Computer Vision},
keywords = {Computational geometry; Feature extraction; Lighti,Dual-space geometry,Photography},
number = {2},
pages = {129--149},
title = {{3D photography using shadows in dual-space geometry}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033220998{\&}doi=10.1023{\%}2FA{\%}3A1008124523456{\&}partnerID=40{\&}md5=ed1e74d24242be7fcf6c98688e732594},
volume = {35},
year = {1999}
}
@article{Deng2017127,
abstract = {In this paper, we present a novel unsupervised framework for automatically generating bottom up class independent object candidates for detection and recognition in cluttered indoor environments. Utilizing raw depth map from active sensors such as Kinect, we propose a novel plane segmentation algorithm for dividing an indoor scene into predominant planar regions and non-planar regions. Based on this partition, we are able to effectively predict object locations and their spatial extensions. Our approach automatically generates object proposals considering five different aspects: Non-planar Regions (NPR), Planar Regions (PR), Detected Planes (DP), Merged Detected Planes (MDP) and Hierarchical Clustering (HC) of 3D point clouds. Object region proposals include both bounding boxes and instance segments. Our approach achieves very competitive results and is even able to outperform supervised state-of-the-art algorithms on the challenging NYU-v2 RGB-Depth dataset. In addition, we apply our approach to the most recently released large scale RGB-Depth dataset from Princeton University  SUN RGBD, which utilizes four different depth sensors. Its consistent performance demonstrates a general applicability of our approach. {\textcopyright} 2016 Elsevier Inc.},
annote = {cited By 5},
author = {Deng, Z and Todorovic, S and {Jan Latecki}, L},
doi = {10.1016/j.cviu.2016.07.005},
journal = {Computer Vision and Image Understanding},
keywords = {Consistent performance; Hierarchical Clustering;,Image segmentation,Object detection},
pages = {127--136},
title = {{Unsupervised object region proposals for RGB-D indoor scenes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979680942{\&}doi=10.1016{\%}2Fj.cviu.2016.07.005{\&}partnerID=40{\&}md5=684c6f8a5516ac72a00391b6c8cec790},
volume = {154},
year = {2017}
}
@inproceedings{Biocca20061115,
abstract = {The attention funnel is a general purpose AR interface technique that interactively guides the attention of a user to any object, person, or place in space. The technique utilizes dynamic perceptual affordances to draw user attention "down" the funnel to the target location. Attention funnel can be used to cue objects completely out of sight including objects behind the user, or occluded by other objects or walls. An experiment evaluating user performance with the attention funnel and other conventional AR attention directing techniques found that the attention funnel increased the consistency of the user's search by 65{\%}, increased search speed by 22{\%}, and decreased mental workload by 18{\%}. The attention funnel has potential applicability as a general 3D cursor or cue in a wide array of spatially enabled mobile and AR systems, and for applications where systems can support users in visual search, object awareness, and emergency warning in indoor and outdoor spaces. Copyright 2006 ACM.},
annote = {cited By 64},
author = {Biocca, F and Tang, A and Owen, C and Xiao, F},
booktitle = {Conference on Human Factors in Computing Systems - Proceedings},
keywords = {Alarm systems; Human computer interaction; Online,Attention funnel; Augmented Reality(AR) attention,Mobile computing},
pages = {1115--1122},
title = {{Attention funnel: Omnidirectional 3D cursor for mobile augmented reality platforms}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745833423{\&}partnerID=40{\&}md5=0290e7b79cf889c6e894d42a0151775c},
volume = {2},
year = {2006}
}
@article{Dwiyasa2017867,
abstract = {With the rapid growing market of wireless devices, positioning systems that make use of the signal strength of wireless devices are gaining more interest nowadays. Being able to track the location of a Wi-Fi or Radio Frequency Identification device could improve the quality of services in various sectors, including security, warehouse, logistic management, and healthcare. As compared with outdoor environment, positioning systems face a greater challenge in indoor environment because wireless signal is significantly influenced by building layout and surrounding objects, for which a location fingerprinting approach is needed. Moreover, the signal strength of a wireless device may also change over time, which is known as temporal variation, and therefore a reliable location estimation system must have the ability to learn and adapt with temporal changes. However, if the learning process is highly complex and requires long processing time, deploying the system into a larger scale would not be feasible. In recent years, Extreme Learning Machine (ELM) has surfaced as a viable alternative that challenged the norm of iterative and progressive learning. ELM has also been considered as a solution for indoor location fingerprinting. However, there has not been a comprehensive review on how the ELM-based approaches are linked with existing location fingerprinting techniques. Here we discuss some major location fingerprinting techniques, which are nearest-neighbor, LANDMARC, and LEMT, and formulate a new framework for systematically translating the techniques into ELM-based methods. {\textcopyright} 2016, Springer Science+Business Media New York.},
annote = {cited By 3},
author = {Dwiyasa, F and Lim, M.-H. and Ong, Y.-S. and Panigrahi, B},
doi = {10.1007/s11045-016-0409-0},
journal = {Multidimensional Systems and Signal Processing},
keywords = {Building signal systems; Iterative methods; Knowle,Extreme learning machine; Location estimation; Lo,Mobile computing},
number = {3},
pages = {867--883},
title = {{Extreme learning machine for indoor location fingerprinting}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963636167{\&}doi=10.1007{\%}2Fs11045-016-0409-0{\&}partnerID=40{\&}md5=c25511dc296aed32e1bfc01d301f6ec6},
volume = {28},
year = {2017}
}
@article{Zhang2013975,
abstract = {Key challenges to widespread deployment of mobile robots include collaboration and the ability to tailor sensing and information processing to the task at hand. Partially observable Markov decision processes (POMDPs), which are an instance of probabilistic sequential decision-making, can be used to address these challenges in domains characterized by partial observability and nondeterministic action outcomes. However, such formulations tend to be computationally intractable for domains that have large complex state spaces and require robots to respond to dynamic changes. This paper presents a hierarchical decomposition of POMDPs that incorporates adaptive observation functions, constrained convolutional policies, and automatic belief propagation, enabling robots to retain capabilities for different tasks, direct sensing to relevant locations, and determine the sequence of sensing and processing algorithms best suited to any given task. A communication layer is added to the POMDP hierarchy for belief sharing and collaboration in a team of robots. All algorithms are evaluated in simulation and on physical robots, localizing target objects in dynamic indoor domains. {\textcopyright} 2004-2012 IEEE.},
annote = {cited By 11},
author = {Zhang, S and Sridharan, M and Washington, C},
doi = {10.1109/TRO.2013.2252252},
journal = {IEEE Transactions on Robotics},
keywords = {Algorithms; Bayesian networks; Computer vision; D,Bayesian methods; Communication layers; Hierarchic,Robot programming},
number = {4},
pages = {975--985},
title = {{Active visual planning for mobile robot teams using hierarchical pomdps}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84882456074{\&}doi=10.1109{\%}2FTRO.2013.2252252{\&}partnerID=40{\&}md5=be5079e965a07916d3b9a6bcb747a3b3},
volume = {29},
year = {2013}
}
@inproceedings{Im2016445,
abstract = {Semantic localization refers to the process of finding one's location with respect to visible or identifiable objects in the scene instead of finding position coordinates. In this research, we use textual signs and their geographical relationships inside a building as semantic signatures to design an infrastructureless indoor navigation system without a site survey. We propose a computer vision-based approach, which takes as an input a oor plan image and automatically infers the oor graph. The constructed graph is then used to estimate the shortest path, which is a sequence of store names, that the user needs to pass to reach her destination. {\textcopyright} 2016 Copyright held by the owner/author(s).},
annote = {cited By 0},
author = {Im, T and De, P},
booktitle = {Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM},
doi = {10.1145/2973750.2985270},
keywords = {Air navigation; Computer vision; Graph theory; Nav,Android applications; In-door navigations; Indoor,Indoor positioning systems},
number = {1},
pages = {445--446},
title = {{Poster: An infrastructureless and self-deployable indoor navigation approach using semantic signatures}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994102676{\&}doi=10.1145{\%}2F2973750.2985270{\&}partnerID=40{\&}md5=87fee140dc7f1f306370c209d85cb8c4},
volume = {0},
year = {2016}
}
@inproceedings{Xiao20101091,
abstract = {3D reconstruction has been widely used in many important applications. While extensive research has been done in 3D reconstruction, several key issues are still open and the precision of the recovered regions is still far from satisfaction. In this paper, we propose a novel approach to selecting regions of interest in video frames by analyzing multiple spatio-temporal characteristics and reconstructing 3D objects based on the selected regions. Firstly, the static, location and motion attention are extracted from video frames to generate saliency maps. Then, all the video frames are clustered and a candidate set of key frames is extracted based on the saliency maps, where the key frames are extracted according to the constraints in terms of geometry and visibility. Finally, the 3D structure of the attention region is recovered using the selected key frames and the generated saliency maps. The experiments on realworld indoor and outdoor scenes demonstrate that the proposed approach is both more accurate (better attention regions) and computationally more efficient. {\textcopyright} 2010 IEEE.},
annote = {cited By 11},
author = {Xiao, X and Xu, C and Rui, Y},
booktitle = {2010 IEEE International Conference on Multimedia and Expo, ICME 2010},
doi = {10.1109/ICME.2010.5582982},
keywords = {3D object; 3D reconstruction; 3D Structure; Key fr,Three dimensional},
pages = {1091--1096},
title = {{Video based 3D reconstruction using spatio-temporal attention analysis}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78349245896{\&}doi=10.1109{\%}2FICME.2010.5582982{\&}partnerID=40{\&}md5=8cc8dd092238e4c2bd2b979a354bda76},
year = {2010}
}
@article{Marias2006,
abstract = {Enabling the pervasive paradigm requires the incorporation of location information. Retrieving location data has been a field of ongoing research for both the outdoor and indoor wireless systems. The results in the cellular scenario are already mature and location architectures have been standardized. Recent research is ongoing for indoor-positioning mechanisms, resulting in implementations that vary. A platform that enables the deployment of location-based services in heterogeneous indoor and WLAN-based communication systems will address difficulties in cooperating with different positioning systems. For that purpose, we have designed a novel entity, called Gateway WLAN Location Center (GWLC), which hides the heterogeneous functions of the indoor positioning architectures, incorporating a unified framework for retrieving location data of users and objects. The GWLC platform has been designed to meet objectives such as modularity, scalability, as well as portability, and to facilitate open interfaces. In this contribution, we elaborate on the design principles and the functionality of GWLC. We also provide performance results, obtained through real experiments. Copyright {\textcopyright} 2006 Hindawi Publishing Corporation. All rights reserved.},
annote = {cited By 3},
author = {Marias, G F and Papazafeiropoulos, G and Priggouris, N and Hadjiefthymiades, S and Merakos, L},
doi = {10.1155/ASP/2006/81714},
journal = {Eurasip Journal on Applied Signal Processing},
keywords = {Computer architecture; Information retrieval; Log,Gateway WLAN Location Center (GWLC); Indoor positi,Gateways (computer networks)},
title = {{An innovative gateway for indoor positioning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646393544{\&}doi=10.1155{\%}2FASP{\%}2F2006{\%}2F81714{\&}partnerID=40{\&}md5=50e25169f9419262ebd00f30e4efdef9},
volume = {2006},
year = {2006}
}
@inproceedings{Alamri201238,
abstract = {Researchers have proven that most individuals spend most of their lives indoors. With the current appropriate indoor positioning devices such as Bluetooth and RFID, WIFI, the locations of moving objects will be an important foundation for a variety of applications such as the tracking moving objects, way finding, and security. Many studies have considered the moving object in outdoor environments such as TPR-Tree and its successors. In this paper, we propose a new index tree for moving objects in cellular space. The Index will be based on the connectivity (adjacency) between the indoor environment cells. The development index can support and enable efficient query processing and efficient updates of moving objects in indoor space. {\textcopyright} 2012 IEEE.},
annote = {cited By 19},
author = {Alamri, S and Taniar, D and Safar, M},
booktitle = {Proceedings of the 2012 15th International Conference on Network-Based Information Systems, NBIS 2012},
doi = {10.1109/NBiS.2012.17},
keywords = {Cellular space; Index structure; Indexing moving o,Data Processing; Information Retrieval; Tags,Forestry,Information systems; Query processing; Radio freq},
pages = {38--44},
title = {{Indexing moving objects in indoor cellular space}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870804883{\&}doi=10.1109{\%}2FNBiS.2012.17{\&}partnerID=40{\&}md5=273a848ec5d91863741952fd07fc36a5},
year = {2012}
}
@inproceedings{Zhou2017,
abstract = {Continuous tracking of the device location in 3D space is a popular form of user input, especially for virtual/augmented reality (VR/AR), video games and health rehabilitation. Conventional inertial based approaches are well known for inaccuracy caused by large error drifts. Computer vision approaches can produce accuracy tracking but have privacy concerns and are subject to lighting conditions and computation complexity. Recent work exploits accurate acoustic distance measurements for high precision tracking. However, they require additional hardware (e.g., multiple external speakers), which adds to the costs and installation efforts, thus limiting the convenience and usability. In this paper, we propose BatTracker, which incorporates inertial and acoustic data for robust, high precision and infrastructure-free tracking in indoor environments. BatTracker leverages echoes from nearby objects and uses distance measurements from them to correct error accumulation in inertial based device position prediction. It incorporates Doppler shifts and echo amplitudes to reliably identify the association between echoes and objects despite noisy signals from multi-path reflection and cluttered environment. A probabilistic algorithm creates, prunes and evolves multiple hypotheses based on measurement evidences to accommodate uncertainty in device position. Experiments in real environments show that BatTracker can track a mobile device's movements in 3D space at sub-cm level accuracy, comparable to the state-of-the-art infrastructure based approaches, while eliminating the needs of any additional hardware. {\textcopyright} 2017 Association for Computing Machinery.},
annote = {cited By 3},
author = {Zhou, B and Gao, R and Elbadry, M and Ye, F},
booktitle = {SenSys 2017 - Proceedings of the 15th ACM Conference on Embedded Networked Sensor Systems},
doi = {10.1145/3131672.3131689},
keywords = {Acoustics; Computer hardware; Computer privacy; Em,Cluttered environments; Computation complexity; D,Mobile devices},
title = {{Battracker: High precision infrastructure-free mobile device tracking in indoor environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045316674{\&}doi=10.1145{\%}2F3131672.3131689{\&}partnerID=40{\&}md5=466622352d8101d776742b39b30d6022},
volume = {2017-Janua},
year = {2017}
}
@inproceedings{Uddin2011523,
abstract = {LED-ID wireless communication channel suffers from much impairment such as shadowing, rapid movement of reader in the home environment. In a LED-ID network environment, multiple propagation paths often exist from a Tag to a reader due to scattering by different objects. Signal copies following different paths can undergo different attenuation, distortions, delays and phase shifts. So, this is necessary to reduce the problem of fading, but not at the cost of extra power or additional bandwidth. One effective solution is proposed for LED-ID system named diversity, without the requirement of power or extra bandwidth. LED-ID system typically needs line of sight (LOS) to support narrow FOV transceivers links to achieve high data rate with sacrifice the coverage. In indoor case link blockage can happen due to the people or other obstacle. Site diversity is one of the solutions to handle this kind of shadowing. In this paper we propose a location based reconfigurable cell site diversity technique for LED-ID system. {\textcopyright} 2011 IEEE.},
annote = {cited By 2},
author = {Uddin, M S and Jang, Y M},
booktitle = {2011 International Conference on ICT Convergence, ICTC 2011},
doi = {10.1109/ICTC.2011.6082653},
keywords = {Bandwidth; Cells; Wireless telecommunication syst,FOV; LED-ID system; Location based; MRC; Site dive,Satellite communication systems},
pages = {523--526},
title = {{Location based reconfigurable cell site diversity techniques for LED-ID system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-83755172677{\&}doi=10.1109{\%}2FICTC.2011.6082653{\&}partnerID=40{\&}md5=e28e17eea5244b7f09091fd6164d1c73},
year = {2011}
}
@inproceedings{Politis19982801,
abstract = {Ultrasonic sensors have been widely used as time-of-flight range finding systems in mobile robots. Different variations of this scheme lead to robust identification of simple reflector types, like walls, corners and edges. In this paper an alternative approach is attempted, able not only to locate and identify simple reflectors, but to detect and recognize more complicated objects. A more sophisticated sensor, the CTFM sonar, produces an image which corresponds to a range map. The image provides information about the location and type of the reflector. A reflectivity model for planes, corners, and edges is presented and compared with some experimental results. A method to distinguish well structured reflectors from complex objects is then described and the application of the system in a room mapping task is demonstrated.},
annote = {cited By 9},
author = {Politis, Zafiris and Probert, Penny},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
keywords = {Acoustic imaging; Sensors; Sonar,Mobile robots,Sonar imaging},
pages = {2801--2806},
title = {{Perception of an indoor robot workspace by using CTFM sonar imaging}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031645820{\&}partnerID=40{\&}md5=4ed81092191ef4c8df04b4b9c25e1873},
volume = {4},
year = {1998}
}
@inproceedings{Zeng2016,
abstract = {There has been a growing interest in equipping the objects and environment surrounding the user with sensing capabilities. Smart indoor spaces such as smart homes and offices can implement the sensing and processing functionality, relieving users from the need of wearing or carrying smart devices. Enabling such smart spaces requires device-free effortless sensing of user's identity and activities. Device-free sensing using WiFi has shown great potential in such scenarios, however, fundamental questions such as person identification have remained unsolved. In this paper, we present WiWho, a framework that can identify a person from a small group of people in a device-free manner using WiFi. We show that Channel State Information (CSI) used in recent WiFi can identify a person's steps and walking gait. The walking gait being distinguishing characteristics for different people, WiWho uses CSI-based gait for person identification. We demonstrate how step and walk analysis can be used to identify a person's walking gait from CSI, and how this information can be used to identify a person. WiWho does not require a person to carry any device and is effortless since it only requires the person to walk for a few steps (e.g. entering a home or an office). We evaluate WiWho using experiments at multiple locations with a total of 20 volunteers, and show that it can identify a person with average accuracy of 92{\%} to 80{\%} from a group of 2 to 6 people. We also show that in most cases walking as few as 2-3 meters is sufficient to recognize a person's gait and identify the person. We discuss the potential and challenges of WiFi- based person identification with respect to smart space applications. {\textcopyright} 2016 IEEE.},
annote = {cited By 53},
author = {Zeng, Y and Pathak, P H and Mohapatra, P},
booktitle = {2016 15th ACM/IEEE International Conference on Information Processing in Sensor Networks, IPSN 2016 - Proceedings},
doi = {10.1109/IPSN.2016.7460727},
keywords = {Automation; Information science; Intelligent build,Channel state information,Indoor space; Person identification; Processing f},
title = {{WiWho: WiFi-Based Person Identification in Smart Spaces}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971265256{\&}doi=10.1109{\%}2FIPSN.2016.7460727{\&}partnerID=40{\&}md5=43a2982c3f5da8dae572994f0f2f9510},
year = {2016}
}
@inproceedings{Stringa1999274,
abstract = {In this paper, a joint video-shot and layer indexing technique is presented with applications to automatic surveillance of indoor environments. A video-based surveillance system has been developed that simultaneously tracks moving objects and detects the presence of abandoned objects. Whenever an abandoned object is detected, the system is able to determine the video-shot in which a particular object (layer) appears in the guarded environment, from the first frame in which that object enters in the scene to the frame in which the object has been left. The semantic information related on both the dangerous object and the person who left it, allows the system to perform the video-shot detection and indexing tasks. What is important in a video-shot is the information related to the dangerous object present in it. For this reason a video-shot has a two level indexing: the first one is related to the characteristics of the video-shot and the second one is related to the characteristics of a particular layer.},
annote = {cited By 3},
author = {Stringa, E and Soldatini, F and Regazzoni, C S},
booktitle = {IEEE International Conference on Image Processing},
keywords = {Image analysis,Indexing (of information); Information retrieval,Video shots; Video-based surveillance systems},
pages = {274--278},
title = {{Joint video-shot and layer indexing in video-surveillance application}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033352927{\&}partnerID=40{\&}md5=8de590c16e06d0c3386526d9aacaad7c},
volume = {3},
year = {1999}
}
@article{Ma2018175,
abstract = {Advances in small and low power electronics have created new opportunities for the Internet of Things (IoT), leading to an explosion of physical objects being connected to the Internet. However, there still lacks an indoor localization solution that can answer the needs of various location-based IoT applications with desired simplicity, robustness, accuracy, and responsiveness. We introduce Foglight, a visible light enabled indoor localization system for IoT devices that relies on unique spatial encoding produced when mechanical mirrors inside a projector are flipped based on gray-coded binary images. Foglight employs simple off-the-shelf light sensors that can be easily coupled with existing IoT devices-such as thermometers, gas meters, or light switches-making their location discoverable. Our sensor unit is computation efficient; it can perform high-accuracy localization with minimum signal processing overhead, allowing any low-power IoT device on which it rests to be able to locate itself. Additionally, results from our evaluation reveal that Foglight can locate a target device with an average accuracy of 1.7 mm and average refresh rate of 84 Hz with minimal latency, 31.46 ms on Wi-Fi and 23.2 ms on serial communication. Two example applications are developed to demonstrate possible scenarios as proof of concept. We also discuss limitations, how they could be overcome, and propose next steps. {\textcopyright} 2014 IEEE.},
annote = {cited By 6},
author = {Ma, S and Liu, Q and Sheu, P.C.-Y.},
doi = {10.1109/JIOT.2017.2776964},
journal = {IEEE Internet of Things Journal},
keywords = {Binary images; Image coding; Indoor positioning sy,Fingerprint Recognition; Indoor localization; Vis,Internet of things},
number = {1},
pages = {175--185},
title = {{Foglight: Visible Light-Enabled Indoor Localization System for Low-Power IoT Devices}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85035793406{\&}doi=10.1109{\%}2FJIOT.2017.2776964{\&}partnerID=40{\&}md5=d4081a301541b54f85a262a848377b7b},
volume = {5},
year = {2018}
}
@article{Shou2010,
abstract = {We present in this paper a modified independent component analysis (mICA) based on the conditional entropy to discriminate unsorted independent components. We make use of the conditional entropy to select an appropriate subset of the ICA features with superior capability in classification and apply support vector machine (SVM) to recognizing patterns of human and nonhuman. Moreover, we use the models of background images based on Gaussian mixture model (GMM) to handle images with complicated backgrounds. Also, the color-based shadow elimination and head models in ellipse shapes are combined to improve the performance of moving objects extraction and recognition in our system. Our proposed tracking mechanism monitors the movement of humans, animals, or vehicles within a surveillance area and keeps tracking the moving pedestrians by using the color information in HSV domain. Our tracking mechanism uses the Kalman filter to predict locations of moving objects for the conditions in lack of color information of detected objects. Finally, our experimental results show that our proposed approach can perform well for real-time applications in both indoor and outdoor environments. Copyright {\textcopyright} 2010 Chin-Teng Lin et al.},
annote = {cited By 4},
author = {Shou, Y.-W. and Lin, C.-T. and Siana, L and Shen, T.-K.},
doi = {10.1155/2010/468329},
journal = {Eurasip Journal on Advances in Signal Processing},
keywords = {Animals; Blind source separation; Color; Entropy;,Background image; Color information; Complicated b,Independent component analysis},
title = {{A conditional entropy-based independent component analysis for applications in human detection and tracking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956835745{\&}doi=10.1155{\%}2F2010{\%}2F468329{\&}partnerID=40{\&}md5=6f7f948987daf078bd9c02e7b3cac8c0},
volume = {2010},
year = {2010}
}
@article{Xu2013125,
abstract = {Moving objects databases should be able to manage trips that pass through several real world environments, e. g., road network, indoor. However, the current data models only deal with the movement in one situation and cannot represent comprehensive trips for humans who can move inside a building, walk on the pavement, drive on the road, take the public vehicles (bus or train), etc. As a result, existing queries are solely limited to one environment. In this paper, we design a data model that is able to represent moving objects in multiple environments in order to support novel queries on trips in different surroundings and various transportation modes (e. g., Car, Walk, Bus). A generic and precise location representation is proposed that can apply in all environments. The idea is to let the space for moving objects be covered by a set of so-called infrastructures each of which corresponds to an environment and defines the available places for moving objects. Then, the location is represented by referencing to the infrastructure. We formulate the concept of space and infrastructure and propose the methodology to represent moving objects in different environments with the integration of precise transportation modes. Due to different infrastructure characteristics, a set of novel data types is defined to represent infrastructure components. To efficiently support new queries, we design a group of operators to access the data. We present how such a data model is implemented in a database system and report the experimental results. The new model is designed with attention to the data models of previous work for free space and road networks to have a consistent type system and framework of operators. In this way, a powerful set of generic query operations is available for querying, together with those dealing with infrastructures and transportation modes. We demonstrate these capabilities by formulating a set of sophisticated queries across all infrastructures. {\textcopyright} 2012 Springer Science+Business Media, LLC.},
annote = {cited By 31},
author = {Xu, J and G{\"{u}}ting, R H},
doi = {10.1007/s10707-012-0158-7},
journal = {GeoInformatica},
keywords = {Current data; Data type; Free spaces; Generic data,Data structures; Database systems; Digital storag,Models,data processing; database; modeling; spatial anal},
number = {1},
pages = {125--172},
title = {{A generic data model for moving objects}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872275067{\&}doi=10.1007{\%}2Fs10707-012-0158-7{\&}partnerID=40{\&}md5=9dd36274612984f5ad4ffb55e1adb93d},
volume = {17},
year = {2013}
}
@inproceedings{Qiu2016,
abstract = {Many pervasive computing applications depend upon maps for navigation and support of location based services. Maps are commonly available for outdoor pervasive applications from a variety of sources. An individual can determine their location outdoors on these maps via GPS. Indoor pervasive applications may also need to know the layout of rooms, doorways and hallways of buildings, and the objects and obstacles within them, however indoor maps of buildings are less prevalent. Moreover, indoor maps may need to be dynamic and updated regularly since the layout changes when objects and obstacles are added or removed by people within the building. In this paper, we present iFrame, a dynamic approach that leverages existing mobile sensing capabilities for constructing indoor floor plans. We explore how iFrame users may collaborate and contribute to constructing 2-dimensional indoor maps by merely carrying smartphones or other mobile devices, and to allow their mobile devices to share information with other users' devices. The iFrame approach consists of four steps: 1) Abstract the unknown indoor map as a matrix; 2) Leverage collaborating mobile devices that incorporate three mobile sensing technologies - accelerometers to support dead reckoning, Bluetooth RSSI detection, and WiFi RSSI detection; 3) Combine the three methods by Curve Fit Fusion (CFF), and 4) Extend iFrame from one room to a whole building by shadow rates and anchor points analysis. We conducted a deployment study that shows iFrame is a light-weight and unattended approach that provides a skeleton map of a real building effectively and automatically. The layouts of 12 rooms are reconstructed within 5-10 minutes. Changes of layout in indoor maps can be detected and the resolution of the reconstructed indoor floor plans can be improved when there is an increase in the number of cooperating users. {\textcopyright} 2016 IEEE.},
annote = {cited By 12},
author = {Qiu, C and Mutka, M W},
booktitle = {2016 IEEE International Conference on Pervasive Computing and Communications, PerCom 2016},
doi = {10.1109/PERCOM.2016.7456500},
keywords = {Anchor point; Dead reckoning; Dynamic approaches;,Buildings; Curve fitting; Floors; Mobile devices;,Location based services},
title = {{IFrame: Dynamic indoor map construction through automatic mobile sensing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969185737{\&}doi=10.1109{\%}2FPERCOM.2016.7456500{\&}partnerID=40{\&}md5=efebb66565c903eea1abcd7c56962d51},
year = {2016}
}
@inproceedings{Zelek2010,
abstract = {Computer vision (i.e., image understanding) involves understanding the 3D scene creating the image. Computer vision is challenging because it is the computer that decides how to act based on an understanding of the image. Key image understanding tasks include depth computation, as well as object detection, localization, recognition and tracking. Techniques up to now have not been able to perform any of these tasks robustly with the precision and accuracy demanded by many real-world applications. Additional complications include operational and environmental factors. For humans, visual recognition is fast and accurate, yet robust against occlusion, clutter, viewpoint variations, and changes in lighting conditions. Moreover, learning new categories requires minimal supervision and a very small set of exemplars. Achieving this level of performance in a wearable portable system would enable a great number of useful applications especially for enhancing mobile cell phone and camera operation. We demonstrate some of the computer vision techniques that we have developed and tested in real environments for applications in the field of automotive navigation, personal navigation, assistive devices and augmented reality. Some of the techniques include object detection and recognition, depth from motion, context recognition and the general task of mapping and localization. Our object detection techniques have shown to have performance close to 100{\%}. We have actually shown that we can triangulate based on objects in the environment using only a camera; which can aid when GPS drops out such as in urban canyons and indoor environments. We argue that all of this potential can be packaged within a smart phone like an iphone. A category with the (minimum) three required fields {\textcopyright} 2010 ACM.},
annote = {cited By 1},
author = {Zelek, J and Fazl, E and Asmar, D and Fakih, A},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/1823854.1823906},
keywords = {3D scenes; Assistive devices; Computer vision tech,Augmented reality; Cameras; Computer vision; Imag,Object recognition},
title = {{Computer vision geo-location, awareness {\&} detail}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955150212{\&}doi=10.1145{\%}2F1823854.1823906{\&}partnerID=40{\&}md5=9abcda38f0929163f718418772dfafe9},
year = {2010}
}
@article{Tsai200981,
abstract = {Due to the popularity of location-based services, determining the location of a device at all times has become a subject of great interests. Although many GPS-based applications have been developed and successfully deployed in various fields, their applicabilities are hindered by the obstruction of the objects in the environment. Essentially, as satellite signals cannot penetrate the walls of buildings, the coverage of GPS systems is limited to outdoor environments. To fully exploit the benefit of location-based services, approaches that determine the location of a device in indoor environments need to be established. This study presents a novel location determination mechanism that uses an indoor WLAN and back-propagation neural network (BPN). A museum is taken as the context of the example indoor environment. Location determination is achieved using the combined strengths of 802.11b wireless access signals. With a significant number of access points (APs) installed in the museum, hand-held devices can sense the strengths of the signals from all APs to which the devices can connect. Using a back-propagation network, device locations can be estimated with sufficient accuracy. A novel adaptive algorithm is implemented for enhancing the accuracy of the estimation. {\textcopyright} Springer-Verlag London Limited 2008.},
annote = {cited By 15},
author = {Tsai, C.-Y. and Chou, S.-Y. and Lin, S.-W. and Wang, W.-H.},
doi = {10.1007/s10115-008-0154-2},
journal = {Knowledge and Information Systems},
number = {1},
pages = {81--93},
title = {{Location determination of mobile devices for an indoor WLAN application using a neural network}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-67650003712{\&}doi=10.1007{\%}2Fs10115-008-0154-2{\&}partnerID=40{\&}md5=8b60e83e01b9f2bc80ae62d6a2c83ff4},
volume = {20},
year = {2009}
}
@inproceedings{Kunze20124385,
abstract = {Many of today's mobile robots are supposed to perform everyday manipulation tasks autonomously. However, in large-scale environments, a task-related object might be out of the robot's reach. Hence, the robot first has to search for the object in its environment before it can perform the task. In this paper, we present a decision-theoretic approach for searching objects in large-scale environments using probabilistic environment models and utilities associated with object locations. We demonstrate the feasibility of our approach by integrating it into a robot system and by conducting experiments where the robot is supposed to search different objects with various strategies in the context of fetch-and-delivery tasks within a multi-level building. {\textcopyright} 2012 IEEE.},
annote = {cited By 24},
author = {Kunze, L and Beetz, M and Saito, M and Azuma, H and Okada, K and Inaba, M},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2012.6224965},
keywords = {Decision theoretic approach; Delivery task; Envir,Robotics,Robots},
pages = {4385--4390},
title = {{Searching objects in large-scale indoor environments: A decision-theoretic approach}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864418987{\&}doi=10.1109{\%}2FICRA.2012.6224965{\&}partnerID=40{\&}md5=a04d6b9c1aba92cae8087e6ebaf917bd},
year = {2012}
}
@inproceedings{Hueting201645,
abstract = {Understanding indoor scene structure from a single RGB image is useful for a wide variety of applications ranging from the editing of scenes to the mining of statistics about space utilization. Most efforts in scene understanding focus on extraction of either dense information such as pixel-level depth or semantic labels, or very sparse information such as bounding boxes obtained through object detection. In this paper we propose the concept of a scene map, a coarse scene representation, which describes the locations of the objects present in the scene from a top-down view (i.e., as they are positioned on the floor), as well as a pipeline to extract such a map from a single RGB image. To this end, we use a synthetic rendering pipeline, which supplies an adapted CNN with virtually unlimited training data. We quantitatively evaluate our results, showing that we clearly outperform a dense baseline approach, and argue that scene maps provide a useful representation for abstract indoor scene understanding. {\textcopyright} 2016 The Author(s) Eurographics Proceedings {\textcopyright} 2016 The Eurographics Association.},
annote = {cited By 2},
author = {Hueting, M and Ptrucean, V and Ovsjanikov, M and Mitra, N J},
booktitle = {VMV 2016 - Vision, Modeling and Visualization},
doi = {10.2312/vmv.20161341},
keywords = {Color image processing,Image processing; Object detection; Pipelines; Sem,MAP estimation; Scene representation; Scene struc},
pages = {45--52},
title = {{Scene structure inference through scene map estimation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019629086{\&}doi=10.2312{\%}2Fvmv.20161341{\&}partnerID=40{\&}md5=bec4c2f9daac6af3fd73ae0efc3905d1},
year = {2016}
}
@inproceedings{Kumar2014229,
abstract = {In this paper we discuss our attempt to solve the problem of Indoor Localization for a game intended to enhance learning among children by involving them in 'learning' along with 'play'. The first part of the paper describes our methodology towards the construction of the Augmented Reality Game for enhancing astronomy learning in children, emphasizing the experiential nature of tangible interactions and the remote dimension which the game can take, due to the available social media tools, by bringing people into a virtual 3D space to interact with each other. To keep the game simple and less complicated, we employ Single Access Point based Indoor Localization technique for tracking players. In the latter part of the paper we discuss the Indoor Localization system being implemented to track real time location of the player in his/her physical environment and the same being mapped on a virtual game arena for facilitating remote play dimension. Technologies used for early prototype: - basic optics for creating a device that gives 3D illusion of celestial objects appearing on 2D screen, a Kinect-sensor environment, and potentiometer for interactions. Technologies for the game being currently developed: augmented and virtual reality elements, indoor position tracking using Kalman filter implemented inertial navigation system, with Wi-Fi RSSI data, onboard sensory data, geo-tagging. {\textcopyright} 2014 IEEE.},
annote = {cited By 7},
author = {Kumar, C P and Poovaiah, R and Sen, A and Ganadas, P},
booktitle = {IEEE TechSym 2014 - 2014 IEEE Students' Technology Symposium},
doi = {10.1109/TechSym.2014.6808052},
keywords = {Augmented reality; Beam plasma interactions; Depth,Experiential; Gestural; Intuitive; Play and learn,Tracking (position)},
pages = {229--232},
title = {{Single access point based indoor localization technique for augmented reality gaming for children}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901746089{\&}doi=10.1109{\%}2FTechSym.2014.6808052{\&}partnerID=40{\&}md5=d4efac5e6be2678483a0cb17810898a9},
year = {2014}
}
@article{Lpez-de-Ipia2007266,
abstract = {Context-aware systems allow users to access services and multimedia data according to their current context (location, identity, preferences). Web 2.0 fosters user contribution and presents the web as an application programming platform where third parties can create new applications (mash-ups) mixing the functionality offered by others. We deem that applying Web 2.0 principles to the development of middleware support for context-aware systems could result into a wider adoption of AmI. This work provides a platform which combines social context-aware annotation of objects and spatial regions with sentient mobile devices enabling multi-modal human to environment interaction in order to enable advanced context-aware data and service discovery, filtering and consumption within both indoor and outdoor environments. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
annote = {cited By 11},
author = {L{\'{o}}pez-de-Ipi{\~{n}}a, D and Vazquez, J I and Abaitua, J},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Computer programming; Data acquisition; Middleware,Context-aware systems; Human to environment inter,Web services},
pages = {266--286},
title = {{A Web 2.0 platform to enable context-a ware mobile mash-ups}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-38149072491{\&}partnerID=40{\&}md5=5cbcc6b0666fa1c3ba885ce92e2f88f1},
volume = {4794 LNCS},
year = {2007}
}
@inproceedings{Jeevarathnam2018,
abstract = {Passive ultra-high frequency (UHF) radio frequency identification (RFID) systems have gained immense popularity due to groundbreaking advances in wireless devices and technologies for their wide-scale industrial applications in inventory tracking and management. In this study, we explore the potential of passive RFID systems for indoor localization by developing a grid-based experimental framework using two standard and easily measurable performance metrics: Received signal strength indicator (RSSI) and tag read count (TRC). We create scenarios imitating real life challenges such as placing metal objects and other RFID tags in two different read fields (symmetric and asymmetric) to analyze their impacts on location accuracy. We study the prediction potential of RSSI and TRC both independently and collaboratively. In the end, we demonstrate that both signal metrics can be used for localization with sufficient accuracy whereas the best performance is obtained when both metrics are used together for prediction on an artificial neural network especially for more challenging scenarios. Experimental results show an average error of as low as 0.286 (where consecutive grid distance is defined as unity) which satisfies the grid-based localization benchmark of less than 0.5. {\textcopyright} 2018 IEEE.},
annote = {cited By 1},
author = {Jeevarathnam, N G and Uysal, I},
booktitle = {Proceedings of the International Joint Conference on Neural Networks},
doi = {10.1109/IJCNN.2018.8489596},
keywords = {Forecasting; Indoor positioning systems; Neural ne,Localization; Performance metrics; Received; Rece,Radio frequency identification (RFID)},
title = {{Grid-Based RFID Localization Using Tag Read Count and Received Signal Strength}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056489838{\&}doi=10.1109{\%}2FIJCNN.2018.8489596{\&}partnerID=40{\&}md5=99a9824238d6c796555d17a6acc6988a},
volume = {2018-July},
year = {2018}
}
@article{Rahman2010,
abstract = {Interaction with the physical environment using mobile phones has become increasingly desirable and feasible. Nowadays mobile phones are being used to control different devices and access information/services related to those devices. To facilitate such interaction, devices are usually marked with RFID tags or visual markers, which are read by a mobile phone equipped with an integrated RFID reader or camera to fetch related information about those objects and initiate further actions. This article contributes in this domain of mobile physical interaction; however, using a spatial-geometric approach for interacting with indoor physical objects and artifacts instead of RFID based solutions. Using this approach, a mobile phone can point from a distance to an annotated object or a spatial subregion of that object for the purpose of interaction. The pointing direction and location is determined based on the fusion of IR camera and accelerometer data, where the IR cameras are used to calculate the 3D position of the mobile phone users and the accelerometer in the phone provides its tilting and orientation information. The annotation of objects and their subregions with which the mobile phone interacts is performed by specifying their geometric coordinates and associating related information or services with them.We perform experiment in a technology-augmented smart space and show the applicability and potential of the proposed approach. {\textcopyright} 2010 ACM.},
annote = {cited By 9},
author = {Rahman, A.S.M.M. and Hossain, M A and Saddik, A E},
doi = {10.1145/1865106.1865112},
journal = {ACM Transactions on Multimedia Computing, Communications and Applications},
keywords = {Accelerometers; Cameras; Geometry; Mobile devices,Indoor position; Mobile interaction; Multimedia ob,Mobile phones},
number = {4},
title = {{Spatial-geometric approach to physical mobile interaction based on accelerometer and IR sensory data fusion}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649627436{\&}doi=10.1145{\%}2F1865106.1865112{\&}partnerID=40{\&}md5=fb05c8f555b638a2e81954460554a32a},
volume = {6},
year = {2010}
}
@inproceedings{Murshed2011355,
abstract = {We propose an edge segment based moving object tracking algorithm using a static camera. The recognition of object from a sequence image is difficult due to the change in object's shape, orientation, motion and size between frames. Objects may contain several parts with motion variation. Moving objects show a wide range of color variation due to the angle of view, illumination change, and reflectance from neighbor objects. Thus, to overcome these limitations, we make efficient use of edge-segments utilizing a Canny edge detector. Moving edge-segments are grouped by means of a iterative k-means clustering algorithm and the group is used in the Generalized Hough Transform based shape matching algorithm due to its robustness to utilize partial information. A Kalman filter is then used to predict the location of each group in future frames. Experiments with outdoor and indoor image sequences show encouraging result under varying illumination conditions with partial occlusion. {\textcopyright} 2011 IEEE.},
annote = {cited By 2},
author = {Murshed, M and Morshed, M and Chae, O},
booktitle = {14th International Conference on Computer and Information Technology, ICCIT 2011},
doi = {10.1109/ICCITechn.2011.6164813},
keywords = {Algorithms; Content based retrieval; Information,Canny edge detectors; Color variations; Edge Segme,Image matching},
pages = {355--359},
title = {{Moving edge matching for moving object tacking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860012244{\&}doi=10.1109{\%}2FICCITechn.2011.6164813{\&}partnerID=40{\&}md5=4ef4c5a03e27280fea04b57611a59b64},
year = {2011}
}
@inproceedings{Soltani2013,
abstract = {Indoor/outdoor localization has gained importance as it has the potential to improve various processes related to the resource management of construction projects and to deliver personalized and location-based services (LBS). Radio Frequency Identification (RFID) based systems, have been widely used in different applications in construction and maintenance. This paper investigates the usage of active RFID technology for the localization of movable objects (e.g. material, equipment, tools, and assets) equipped with RFID tags using handheld readers. The method builds on Cluster-based Movable Tag Localization (CMTL) technique which uses k-Nearest Neighbor (k-NN) algorithm. CMTL uses multidimensional clustering technique that considers signal pattern similarity between target and reference tags together with spatial distribution of reference tags for detecting the region where the target tag is located. This paper proposes applying an irregular bilinear interpolation method to form a grid of virtual reference tags within the selected cluster of real reference tags. Moreover, the proposed method uses artificial neural networks (ANN) for positioning the target tag, as opposed to empirical weighted averaging formulas used in similar k-NN based methods. Comparative analysis is performed to quantify the improvement of the proposed method over similar k-NN-based methods using a simulation environment. A case study is performed to analyze the performance of the proposed method. {\textcopyright} 2013 IEEE.},
annote = {cited By 5},
author = {Soltani, M M and Motamedi, A and Hammad, A},
booktitle = {2013 International Conference on Indoor Positioning and Indoor Navigation, IPIN 2013},
doi = {10.1109/IPIN.2013.6817886},
keywords = {Clustering; Indoor positioning; k-NN; RF-ID tags;,Internet of things,Location based services; Neural networks; Radio fr},
title = {{Enhancing cluster-based RFID tag localization using artificial neural networks and virtual reference tags}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902185391{\&}doi=10.1109{\%}2FIPIN.2013.6817886{\&}partnerID=40{\&}md5=5dad3ed27d9553012a215687287ba887},
year = {2013}
}
@inproceedings{Farahiyah2018181,
abstract = {Indoor localization becomes more popular along with the rapid growth of technology dan information system. The research has been conducted in many areas, especially in algorithm. Based on the need for knowledge of training data, Fingerprinting algorithm is categorized as the one that works with it. Training data is then computed with the machine learning approach, Na{\"{i}}ve Bayes. Na{\"{i}}ve Bayes is a simple and efficient classifier to estimate location. This study conducted an experiment with Na{\"{i}}ve Bayes in order to classify unknown location of object based on the signal strength of Bluetooth low energy. It required 2 processes, collecting training data and evaluating test data. The result of the analysis with Na{\"{i}}ve Bayes showed that the algorithm works well to estimate the right position of an object regarding its class. {\textcopyright} 2018 Association for Computing Machinery.},
annote = {cited By 0},
author = {Farahiyah, D and Romadhoni, R M and Pratomo, S W},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3299819.3299842},
keywords = {Artificial intelligence; Bluetooth; Cloud computin,Bayes Classifier; Bluetooth low energies (BTLE);,Indoor positioning systems},
pages = {181--185},
title = {{Na{\"{i}}ve bayes classifier for indoor positioning using bluetooth low energy}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062988801{\&}doi=10.1145{\%}2F3299819.3299842{\&}partnerID=40{\&}md5=6ebb4145711a423d75939af36b57842c},
year = {2018}
}
@inproceedings{Yan2012375,
abstract = {RFID (radio frequency identification) technology has been widely used for object tracking in many real-life applications, such as inventory monitoring and product flow tracking. These applications usually rely on passive RFID technologies rather than active ones, since passive RFID tags are more attractive than active ones in many aspects, such as lower tag cost and simpler maintenance. RFID technology is also important for indoor location tracking systems that require high degree of accuracy. However, most existing systems estimate object locations by using active RFID tags, which usually incur localization error of more than one meter. Although recent studies begin to investigate the application of passive tags for indoor location tracking, these methods are far from deployable and research of this application is still in its infancy. In this paper, we propose a new indoor location tracking system, named PassTrack, which relies on the read rates of passive RFID tags for location estimation. PassTrack is designed to tolerate noise arising from external environmental factors, by probabilistically modeling the relationship between tag read rate and tag-reader distance, and updating the model parameters based on the current readings of reference tags. Besides tolerance of noise, PassTrack is also outstanding in terms of localization accuracy and efficiency. Several new approaches for location inference are supported by PassTrack, and the best one incurs an average error of around 30 cm, and is able to carry out over 7500 location estimations per second on an ordinary machine. Furthermore, as a result of using passive RFID tags, PassTrack also enjoys the many other benefits of passive RFID tags mentioned before. We have conducted extensive experiments on both real and synthetic datasets, which demonstrate that our PassTrack system outperforms the previous localization approaches in localization accuracy, tracking efficiency and space applicability. {\textcopyright} 2012 ACM.},
annote = {cited By 4},
author = {Yan, D and Zhao, Z and Ng, W},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/2396761.2396811},
keywords = {Active rfid tags; Average errors; Environmental fa,Estimation; Knowledge management; Radio frequency,Tracking (position)},
pages = {375--384},
title = {{Leveraging read rates of passive RFID tags for real-time indoor location tracking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871076518{\&}doi=10.1145{\%}2F2396761.2396811{\&}partnerID=40{\&}md5=7c75e52b15adf141dbbedc4e9e207178},
year = {2012}
}
@article{Xiao201712165,
abstract = {Target tracking across lenses is a popular research topic for video surveillance recently. This paper presents a method of target tracking across lenses with overlap regions. First, the target detection and tracking are completed with a single camera. Second, in order to obtain the location-invariant feature of the same target in the images with various cameras, the camera calibration is completed based on a three-dimension (3D) model. After that, for all images via multiple cameras, the coordinates of the 3D model are unified. Finally, referring to the assumption of spatial and temporal consistency of the target location across multiple cameras, the association among detected objects for the same target with different cameras is established. And a feature pool is built which contains perspective and scale features. Thus the same target is continuously tracked across multiple lenses. At last, the performance of the proposed approach is compared with KSP and PABC and demonstrated with indoor and outdoor experiments. {\textcopyright} 2015, Springer Science+Business Media New York.},
annote = {cited By 0},
author = {Xiao, J and Liu, Z and Yang, H and Hu, X},
doi = {10.1007/s11042-015-3067-6},
journal = {Multimedia Tools and Applications},
keywords = {Camera calibration; Feature pool; Invariant featu,Cameras; Clutter (information theory); Security sy,Target tracking},
number = {10},
pages = {12165--12179},
title = {{The invariant features-based target tracking across multiple cameras}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947081090{\&}doi=10.1007{\%}2Fs11042-015-3067-6{\&}partnerID=40{\&}md5=b76797bd8430955ac57e1d9005a5d03c},
volume = {76},
year = {2017}
}
@inproceedings{Cheng2016392,
abstract = {Radio Frequency Identification technology (RFID) is the key technology to realize the Internet of things. Currently, using RFID to locate objects indoor is a hot topic in the research on the application of RFID. In this paper, we propose an RFID system based on RFID technology and Wi-Fi wireless communication technology. And we design a corresponding handheld device client software to realize a visual book search and management system. This system can not only greatly improve the efficiency of book search and management but also save the manpower and material resources to a large extent, which has a practical application value. {\textcopyright} 2016 IEEE.},
annote = {cited By 9},
author = {Cheng, H and Huang, L and Xu, H and Hu, Y and Wang, X A},
booktitle = {Proceedings - 2016 International Conference on Intelligent Networking and Collaborative Systems, IEEE INCoS 2016},
doi = {10.1109/INCoS.2016.35},
keywords = {Design and implementations; Indoor locations; Lib,Intelligent networks; Wi-Fi; Wireless local area n,Radio frequency identification (RFID)},
pages = {392--397},
title = {{Design and implementation of library books search and management system using RFID technology}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998678956{\&}doi=10.1109{\%}2FINCoS.2016.35{\&}partnerID=40{\&}md5=2759033171eeed009c62d0dc80895992},
year = {2016}
}
@inproceedings{Mitra2018267,
abstract = {Discovering 3D arrangements of objects from single indoor images is important given its many applications such as interior design and content creation for virtual environments. Although heavily researched in the recent years, existing approaches break down under medium to heavy occlusion as the core image-space region detection module fails in absence of directly visible cues. Instead, we take into account holistic contextual 3D information, exploiting the fact that objects in indoor scenes co-occur mostly in typical configurations. First, we use a neural network trained on real indoor annotated images to extract 2D keypoints, and feed them to a 3D candidate object generation stage. Then, we solve a global selection problem among these candidates using pairwise co-occurrence statistics discovered from a large 3D scene database. We iterate the process allowing for candidates with low keypoint response to be incrementally detected based on the location of the already discovered nearby objects. We demonstrate significant performance improvement over combinations of state-of-the-art methods, especially for scenes with moderately to severely occluded objects. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Mitra, N and Kim, V and Yumer, E and Hueting, M and Carr, N and Reddy, P},
booktitle = {Proceedings - 2018 International Conference on 3D Vision, 3DV 2018},
doi = {10.1109/3DV.2018.00039},
keywords = {Architectural design,Co-occurrence statistics; Content creation; Globa,Virtual reality},
pages = {267--276},
title = {{SeeThrough: Finding objects in heavily occluded indoor scene images}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056760098{\&}doi=10.1109{\%}2F3DV.2018.00039{\&}partnerID=40{\&}md5=47d651f7b72b3deece63a3225f2f7a5f},
year = {2018}
}
@article{Wang2000360,
abstract = {We present here SIMPLIcity (Semantics-sensitive Integrated Matching for Picture LIbraries), an image retrieval system using semantics classification and integrated region matching (IRM) based upon image segmentation. The SIMPLIcity system represents an image by a set of regions, roughly corresponding to objects, which are characterized by color, texture, shape, and location. The system classifies images into categories which are intended to distinguish semantically meaningful difierences, such as textured versus nontextured, indoor versus outdoor, and graph versus photograph. Retrieval is enhanced by narrowing down the searching range in a database to a particular category and exploiting semantically-adaptive searching methods. A measure for the overall similarity between images, the IRM distance, is defined by a region-matching scheme that integrates properties of all the regions in the images. This overall similarity approach reduces the adverse effect of inaccurate segmentation, helps to clarify the semantics of a particular region, and enables a simple querying interface for region-based image retrieval systems. The application of SIMPLIcity to a database of about 200,000 general-purpose images demonstrates accurate retrieval at high speed. The system is also robust to image alterations. {\textcopyright} Springer-Verlag Berlin Heidelberg 2000.},
annote = {cited By 22},
author = {Wang, J Z and Li, J and Wiederholdy, G},
doi = {10.1007/3-540-40053-2_32},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Adverse effect; High Speed; Image retrieval syste,Image matching; Image retrieval; Image segmentatio,Search engines},
pages = {360--371},
title = {{SIMPLIcity: Semantics-sensitive integrated matching for picture libraries?}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959046617{\&}doi=10.1007{\%}2F3-540-40053-2{\_}32{\&}partnerID=40{\&}md5=45cf49d7672a400a1270501d5775a85e},
volume = {1929},
year = {2000}
}
@article{Chen2006383,
abstract = {Locations of moving or missing objects are getting important information for context-aware applications which try to get the locality of an object, and then provide services pertaining to the object. To position an object, most systems use a predefined coordinate to compute object location while sensing the appearance of the target object. Usually, it is troublesome and costs much to define the base coordinate in advance for most object positioning systems, especially when the target object is locating in an unknown environment. To reduce the cost and complexity of object locating system and improve the accuracy of location, this paper proposed an Object Finding System based on RFID technology to identify the localities of target objects in buildings. In this paper, we introduce the design concepts of the proposed system as well as the algorithms used to calculate the object locations. In addition, the experimental results show that it is a feasibility study. {\textcopyright} Springer-Verlag Berlin Heidelberg 2005.},
annote = {cited By 5},
author = {Chen, L.-C. and Sheu, R.-K. and Lu, H.-C. and Lo, W.-T. and Chu, Y.-P.},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Algorithms; Computation theory; Identification (co,Context-aware applications; Object finding system,Object recognition},
pages = {383--396},
title = {{Object finding system based on RFID technology}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745649624{\&}partnerID=40{\&}md5=6958abff374c204c98b717a7676531a0},
volume = {3842 LNCS},
year = {2006}
}
@inproceedings{DeVita201889,
abstract = {Nowadays, smart environments are becoming an integral part of our everyday lives. Objects are becoming smarter and the number of applications where they are involved increases day by day. In such a context, indoor localization is a key aspect for the development of smart services which are strictly related to the user position inside an environment. In this paper, we present a deep learning approach to estimate the indoor user location starting from its Wi-Fi fingerprint composed by those signals perceived in the environment. We show some experimental results that demonstrate the feasibility of the proposed approach. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {{De Vita}, F and Bruneo, D},
booktitle = {Proceedings - 2018 IEEE International Conference on Smart Computing, SMARTCOMP 2018},
doi = {10.1109/SMARTCOMP.2018.00078},
keywords = {Deep learning,Indoor localization; Integral part; Learning appr,Indoor positioning systems; Learning systems},
pages = {89--96},
title = {{A deep learning approach for indoor user localization in smart environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051458988{\&}doi=10.1109{\%}2FSMARTCOMP.2018.00078{\&}partnerID=40{\&}md5=711a152dc1ad2418fbd39cef2201c8a5},
year = {2018}
}
@article{Molyneaux2012197,
abstract = {This paper presents two novel handheld projector systems for indoor pervasive computing spaces. These projection-based devices are "aware" of their environment in ways not demonstrated previously. They offer both spatial awareness, where the system infers location and orientation of the device in 3D space, and geometry awareness, where the system constructs the 3D structure of the world around it, which can encompass the user as well as other physical objects, such as furniture and walls. Previous work in this area has predominantly focused on infrastructure-based spatial-aware handheld projection and interaction. Our prototypes offer greater levels of environment awareness, but achieve this using two opposing approaches; the first infrastructure-based and the other infrastructure-less sensing. We highlight a series of interactions including direct touch, as well as in-air gestures, which leverage the shadow of the user for interaction. We describe the technical challenges in realizing these novel systems; and compare them directly by quantifying their location tracking and input sensing capabilities. {\textcopyright} 2012 Springer-Verlag Berlin Heidelberg.},
annote = {cited By 45},
author = {Molyneaux, D and Izadi, S and Kim, D and Hilliges, O and Hodges, S and Cao, X and Butler, A and Gellersen, H},
doi = {10.1007/978-3-642-31205-2_13},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {3-D space; 3D Structure; Environment awareness; Ha,Optical projectors; Three dimensional,Ubiquitous computing},
pages = {197--215},
title = {{Interactive environment-aware handheld projectors for pervasive computing spaces}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864252202{\&}doi=10.1007{\%}2F978-3-642-31205-2{\_}13{\&}partnerID=40{\&}md5=7ad9af27f028468a1adb3a8004bac63a},
volume = {7319 LNCS},
year = {2012}
}
@inproceedings{Tateno2017321,
abstract = {In the traditional indoor positioning systems, because of high cost or various environmental interferences, most existing technology such as GPS, Bluetooth and RFID are not so useful. Pedestrian Dead-Reckoning (PDR) is a kind of low-cost location positioning technique that can get high accuracy by estimating the heading angle of target from acceleration, gyro and compass data. Usually, researchers use compass data to estimate heading angle. However, the compass data is easily affected by external environment, such as electrical equipment or some objects made by iron or steel. On the other hand, the calculation results by the obtained data of acceleration and gyro usually have accumulated error with time. When time comes longer, the bigger error often appears. Some researchers use Wi-Fi based on received signal strength indicator (RSSI) to assist PDR for correction. However, some Wi-Fi Access Points (APs) cannot be used because RSSI can be affected by external factors, such as people moving, wall. In this paper, a novel method that can improve PDR by heading correction is proposed. In this method, heading angle is estimated by calculating the yaw angle with Quaternion from acceleration and gyro data, and optimal APs selection method is used to select suitable RSSI for getting high accuracy. {\textcopyright} 2017 The Society of Instrument and Control Engineers - SICE.},
annote = {cited By 2},
author = {Tateno, S and Cho, Y and Li, D and Tian, H and Hsiao, P},
booktitle = {2017 56th Annual Conference of the Society of Instrument and Control Engineers of Japan, SICE 2017},
doi = {10.23919/SICE.2017.8105775},
keywords = {AP selection; Environmental interference; Indoor,Environmental technology; Indoor positioning syste,Gyroscopes},
pages = {321--326},
title = {{Improvement of pedestrian dead reckoning by heading correction based on optimal access points selection method}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044204703{\&}doi=10.23919{\%}2FSICE.2017.8105775{\&}partnerID=40{\&}md5=64526a0a51591d099aeab70ad765fbd5},
volume = {2017-Novem},
year = {2017}
}
@article{Wang2006413,
abstract = {This paper presents a novel coarse-to-fine global localization approach inspired by object recognition and text retrieval techniques. Harris-Laplace interest points characterized by scale-invariant transformation feature descriptors are used as natural landmarks. They are indexed into two databases: a location vector space model (LVSM) and a location database. The localization process consists of two stages: coarse localization and fine localization. Coarse localization from the LVSM is fast, but not accurate enough, whereas localization from the location database using a voting algorithm is relatively slow, but more accurate. The integration of coarse and fine stages makes fast and reliable localization possible. If necessary, the localization result can be verified by epipolar geometry between the representative view in the database and the view to be localized. In addition, the localization system recovers the position of the camera by essential matrix decomposition. The localization system has been tested in indoor and outdoor environments. The results show that our approach is efficient and reliable. {\textcopyright} 2006 IEEE.},
annote = {cited By 103},
author = {Wang, J and Zha, H and Cipolla, R},
doi = {10.1109/TSMCB.2005.859085},
journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics},
keywords = {Algorithms; Artificial Intelligence; Image Enhanc,Algorithms; Computer vision; Mathematical models;,Automated; Reproducibility of Results; Sensitivit,Coarse-to-fine localization; Indexing scale-invar,Computer-Assisted; Information Storage and Retrie,Mobile robots,algorithm; article; artificial intelligence; auto},
number = {2},
pages = {413--422},
title = {{Coarse-to-fine vision-based localization by indexing scale-invariant features}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33644994583{\&}doi=10.1109{\%}2FTSMCB.2005.859085{\&}partnerID=40{\&}md5=b3943765157df2da5325293e0f63e978},
volume = {36},
year = {2006}
}
@article{Huang2017671,
abstract = {Object proposal detection is an effective way of accelerating object recognition. Existing proposal methods are mostly based on detecting object boundaries, which may not be effective for cluttered backgrounds. In this paper, we leverage stereopsis as a robust and effective solution for generating object proposals. We first obtain a set of candidate bounding boxes through adaptive transformation, which fits the bounding boxes tightly to object boundaries detected by rough depth and color information. A two-level hierarchy composed of proposal and cluster levels is then constructed to estimate object locations in an efficient and accurate manner. Three stereo-based cues 'exactness,' 'focus,' and 'distribution' are proposed for objectness estimation. Two-level hierarchical ranking is proposed to accurately obtain ranked object proposals. A stereo data set with 400 labeled stereo image pairs is constructed to evaluate the performance of the proposed method in both indoor and outdoor scenes. Extensive experimental evaluations show that the proposed stereo-based approach achieves a better performance than the state of the arts with either a small or a large number of object proposals. As stereopsis can be a complement to the color information, the proposed method can be integrated with existing proposal methods to obtain superior results. {\textcopyright} 1992-2012 IEEE.},
annote = {cited By 1},
author = {Huang, S and Wang, W and He, S and Lau, R W H},
doi = {10.1109/TIP.2016.2627819},
journal = {IEEE Transactions on Image Processing},
keywords = {Adaptive transformations; Cluttered backgrounds;,Object detection,Object recognition; Stereo image processing},
number = {2},
pages = {671--683},
title = {{Stereo Object Proposals}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012885900{\&}doi=10.1109{\%}2FTIP.2016.2627819{\&}partnerID=40{\&}md5=9493441818acc598deb6dbe28b3e8ae4},
volume = {26},
year = {2017}
}
@inproceedings{Christensen2015687,
abstract = {Increasingly, streaming positions from moving objects in blended indoor/outdoor spaces are used to deliver new types of real-time location-based services. To support such scenarios, this paper presents the Searchlight Graph (SLG) model and the associated Searchlight Continuous Query Processing Framework (CQPF) for (predictive) Continuous Query Processing (CQP) in symbolic indoor/outdoor spaces. The model captures both actual and predicted object movement, object-specific edge costs, and location/object context annotation with keywords, enabling context-aware (predictive) querying of both locations and objects. Furthermore, the paper proposes several types of continuous spatio-temporal queries, expressed in the declarative Searchlight Query Language (SLQL), along with novel query processing algorithms, and describes their implementation in the Searchlight CQPF. Finally, a novel location prediction algorithm is proposed. Extensive experimental studies show that Searchlight is scalable, efficient, and outperforms its main competitor. {\textcopyright} 2015 IEEE.},
annote = {cited By 3},
author = {Christensen, K F and Christiansen, L L and Pedersen, T B and Pihl, J},
booktitle = {Proceedings - International Conference on Data Engineering},
doi = {10.1109/ICDE.2015.7113325},
keywords = {Algorithms; Location; Query languages; Query proce,Context annotation; Continuous query processing;,Location based services},
pages = {687--698},
title = {{Searchlight: Context-aware predictive Continuous Querying of moving objects in symbolic space}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940858606{\&}doi=10.1109{\%}2FICDE.2015.7113325{\&}partnerID=40{\&}md5=3de130270e588c8fe831f160192c087b},
volume = {2015-May},
year = {2015}
}
@inproceedings{Wan2010,
abstract = {Methods for indoor tracking typically require a person to carry some type of a body worn tag. A novel tag-free solution is presented that utilizes low cost wall-mounted ultrasonic transducers. The active ultrasonic transducers capture analog echoes, which are then digitized and analyzed in order to calculate the 1-D range of the moving person. The tracking algorithm utilizes a number of signal processing techniques including band-pass filtering, Hilbert transformation, and back-ground subtraction to remove interference from other objects in the room. The range data from multiple sensors are treated as observations in a Bayesian framework using the sigma-point Kalman smoother (SPKS) to determine a person's 2-D position and velocity. The SPKS also performs "self-calibration" or simultaneous localization and mapping (SLAM) to determine the location of the wall-mounted transducers. The indoor tracking accuracy of the tag-free system is better than 0.5 meters. {\textcopyright} 2010 IEEE.},
annote = {cited By 13},
author = {Wan, E A and Paul, A S},
booktitle = {2010 International Conference on Indoor Positioning and Indoor Navigation, IPIN 2010 - Conference Proceedings},
doi = {10.1109/IPIN.2010.5648178},
keywords = {Band pass filtering; Bayesian frameworks; Free sol,Mathematical techniques; Navigation; Signal proce,Transducers},
title = {{A tag-free solution to unobtrusive indoor tracking using wall-mounted ultrasonic transducers}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650756597{\&}doi=10.1109{\%}2FIPIN.2010.5648178{\&}partnerID=40{\&}md5=70a67a7456eb90dd7121bfb664b9fdd3},
year = {2010}
}
@inproceedings{Jain2014346,
abstract = {We propose an augmented reality system on off-the-shelves smartphones which allows random physical object tagging. At later times, such tags could be retrieved from different locations and orientations. Our approach does not require any additional infrastructure support, localization scheme, specialized camera, or modification to smartphone's operating system. Designed and developed for current generation smartphones, our application shows promising initial results with retrieval accuracy of 82{\%} in indoor environment without noticeable impact on the user experience. If made commercially available, such system could be used in city tourism, infrastructure maintenance, and enabling new kind of social interactions. {\textcopyright} 2014 Authors.},
annote = {cited By 0},
author = {Jain, P and {Roy Choudhury}, R},
booktitle = {MobiSys 2014 - Proceedings of the 12th Annual International Conference on Mobile Systems, Applications, and Services},
doi = {10.1145/2594368.2601472},
keywords = {Augmented reality,Augmented reality systems; Current generation; In,Smartphones},
pages = {346},
title = {{Demo: Real-time object tagging and retrieval}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903179103{\&}doi=10.1145{\%}2F2594368.2601472{\&}partnerID=40{\&}md5=e9f98b5b8b53c2312038eafb22f3f3a4},
year = {2014}
}
@inproceedings{Patil2015,
abstract = {In automated video surveillance applications, detection of suspicious human behaviour is of great practical importance. However due to random nature of human movements, reliable classification of suspicious human movements can be very difficult. Defining an approach to the problem of automatically tracking people and detecting unusual or suspicious movements in Closed Circuit TV (CCTV) videos is our primary aim. We are proposing a system that works for surveillance systems installed in indoor environments like entrances/exits of buildings, corridors, etc. Our work presents a framework that processes video data obtained from a CCTV camera fixed at a particular location. First, we obtain the foreground objects by using background subtraction. These foreground objects are then classified into people and inanimate objects (luggage). These objects are tracked using a real-time blob matching technique. Using temporal and spatial properties of these blobs, activities are classified using semantics-based approach. {\textcopyright} 2015 IEEE.},
annote = {cited By 4},
author = {Patil, S and Talele, K},
booktitle = {Proceedings - 2015 International Conference on Communication, Information and Computing Technology, ICCICT 2015},
doi = {10.1109/ICCICT.2015.7045698},
keywords = {Automated video surveillance; Automatically track,Behavioral research; Electronic circuit tracking;,Target tracking},
title = {{Suspicious movement detection and tracking based on color histogram}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925624092{\&}doi=10.1109{\%}2FICCICT.2015.7045698{\&}partnerID=40{\&}md5=7293a43b25c50581329d9094d2145523},
year = {2015}
}
@article{Xia2015333,
abstract = {Image-based object recognition is employed widely in many computer vision applications such as image semantic annotation and object location. However, traditional object recognition algorithms based on the 2D features of RGB data have difficulty when objects overlap and image occlusion occurs. At present, RGB-D cameras are being used more widely and the RGB-D depth data can provide auxiliary information to address these challenges. In this study, we propose a deep learning approach for the efficient recognition of 3D objects with occlusion. First, this approach constructs a multi-view shape model based on 3D objects by using an encode-decode deep learning network to represent the features. Next, 3D object recognition in indoor scenes is performed using random forests. The application of deep learning to RGB-D data is beneficial for recovering missing information due to image occlusion. Our experimental results demonstrate that this approach can significantly improve the efficiency of feature representation and the performance of object recognition with occlusion. {\textcopyright} 2015 Elsevier Inc. All rights reserved.},
annote = {cited By 7},
author = {Xia, Y and Zhang, L and Xu, W and Shan, Z and Liu, Y},
doi = {10.1016/j.ins.2015.01.038},
journal = {Information Sciences},
keywords = {Computer vision applications; Deep learning; Dept,Computer vision; Decision trees; Optical character,Object recognition},
pages = {333--345},
title = {{Recognizing multi-view objects with occlusions using a deep architecture}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937512497{\&}doi=10.1016{\%}2Fj.ins.2015.01.038{\&}partnerID=40{\&}md5=98cd8cb2cda6cdf1b0219bf215f67f78},
volume = {320},
year = {2015}
}
@article{Sunaga201131,
abstract = {This paper describes new concepts and techniques for an indoor positioning system that uses ultrasonic signals to enhance practicability. This indoor positioning system can be applied to the location detection of a moving object such as a person or a goods trolley over a wide indoor area. The proposed system works by means of ultrasonic signals. This makes it easy to avoid multipath effects because the propagation velocity of ultrasonic signals is much slower than that of radio waves. In addition, ultrasonic signals are not restricted by radio regulations that may differ from country to country. The main feature of our system, developed and presented last year, is that it does not require synchronization between the transmitting and receiving units. This paper describes a system for accommodating multiple moving objects and expanding positioning area. Two techniques, the allocation of a specific ID to each positioning object and the use of a virtual receiving point for ultrasonic signals, were investigated in order to realize the required functions and make the proposed system more practical. The effectiveness of these techniques was confirmed by experiments carried out using ultrasonic sensors installed in the ceiling and model railway trains acting as moving objects on the floor below. {\textcopyright} 2011 Springer-Verlag.},
annote = {cited By 1},
author = {Sunaga, H and Hada, T and Akiyama, M and Ioroi, S and Tanaka, H},
doi = {10.1007/978-3-642-25167-2_4},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Artificial intelligence; Field programmable gate,Indoor positioning; Indoor positioning systems; Lo,Ultrasonic testing},
pages = {31--40},
title = {{Discrimination of multiple objects and expanding positioning area for indoor positioning systems using ultrasonic sensors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-81855212574{\&}doi=10.1007{\%}2F978-3-642-25167-2{\_}4{\&}partnerID=40{\&}md5=131946de1618179ee60ab8cd10d31a36},
volume = {7040 LNCS},
year = {2011}
}
@inproceedings{Zhu2007,
abstract = {Our goal is to create a visual odometry system for robots and wearable systems such that localization accuracies of centimeters can be obtained for hundreds of meters of distance traveled. Existing systems have achieved approximately a 1{\%} to 5{\%} localization error rate whereas our proposed system achieves close to 0.1{\%} error rate, a ten-fold reduction. Traditional visual odometry systems drift over time as the frame-to-frame errors accumulate. In this paper, we propose to improve visual odometry using visual landmarks in the scene. First, a dynamic local landmark tracking technique is proposed to track a set of local landmarks across image frames and select an optimal set of tracked local landmarks for pose computation. As a result, the error associated with each pose computation is minimized to reduce the drift significantly. Second, a global landmark based drift correction technique is proposed to recognize previously visited locations and use them to correct drift accumulated during motion. At each visited location along the route, a set of distinctive visual landmarks is automatically extracted and inserted into a landmark database dynamically. We integrate the landmark based approach into a navigation system with 2 stereo pairs and a low-cost Inertial Measurement Unit (IMU) for increased robustness. We demonstrate that a real-time visual odometry system using local and global landmarks can precisely locate a user within 1 meter over 1000 meters in unknown indoor/outdoor environments with challenging situations such as climbing stairs, opening doors, moving foreground objects etc.. {\textcopyright}2007 IEEE.},
annote = {cited By 33},
author = {Zhu, Z and Oskiper, T and Samarasekera, S and Kumar, R and Sawhney, H S},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2007.4409062},
keywords = {Artificial intelligence; Computer networks; Compu,Computer systems,Visual odometry},
title = {{Ten-fold improvement in visual odometry using landmark matching}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-50649083083{\&}doi=10.1109{\%}2FICCV.2007.4409062{\&}partnerID=40{\&}md5=d80452963691e87b62c144d4413d4d81},
year = {2007}
}
@article{Bento2007108,
abstract = {Location is an important topic on Ambient Intelligence. Different techniques are used, alone or together, to determine the position of people and objects. One aspect of this problem concerns to indoor location. Various authors propose the analysis of Radio Frequency (RF) signatures as a solution for this challenge. An approach for indoor location is the use of RF signals acquired from a Global System for Mobile Communications (GSM) by Mobile Units(MU). In this paper we make a study based on around 485.000 signatures gathered from four buildings. We present our conclusions on the suitability and limitations of this approach for indoor location. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
annote = {cited By 4},
author = {Bento, C and Soares, T and Veloso, M and Baptista, B},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Ambient Intelligence; Radio Frequency signatures,Electronic document identification systems,Global system for mobile communications; Object r},
pages = {108--123},
title = {{A study on the suitability of GSM signatures for indoor location}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-38149013156{\&}partnerID=40{\&}md5=45534f031aba3dce1b7afb16cacecc6f},
volume = {4794 LNCS},
year = {2007}
}
@article{Rao2016,
abstract = {The process of generating schematic maps of salient objects from a set of pictures of an indoor environment is challenging. It has been an active area of research as it is crucial to a wide range of context- And locationaware services, as well as for general scene understanding. Although many automated systems have been developed to solve the problem, most of them either require predefining labels or expensive equipment, such as RGBD sensors or lasers, to scan the environment. In this article, we introduce a prototype system to show how human computations can be utilized to generate schematic maps from a set of pictures, without making strong assumptions or demanding extra devices. The system requires humans (crowd workers from Amazon Mechanical Turks) to do simple spatial mapping tasks in various conditions, and their data are aggregated by filtering and clustering techniques that allow salient cues to be identified in the pictures and their spatial relations to be inferred and projected on a two-dimensional map. In particular, we tested and demonstrated the effectiveness of two methods that improved the quality of the generated schematic map: (1) We encouraged humans to adopt an allocentric representations of salient objects by guiding them to perform mental rotations of these objects and (2) we sensitized human perception by guided arrows superimposed on the imagery to improve the accuracy of depth and width estimation. We demonstrated the feasibility of our system by evaluating the results of schematic maps generated from indoor pictures taken from an office building. By calculating Riemannian shape distances between the generated maps to the ground truth, we found that the generated schematic maps captured the spatial relations well. Our results showed that the combination of human computations and machine clustering could lead to more-accurate schematized maps from imagery.We also discuss how our approach may have important insights on methods that leverage human computations in other areas. {\textcopyright} 2016 ACM.},
annote = {cited By 0},
author = {Rao, H and Huang, S.-W. and Fu, W.-T.},
doi = {10.1145/2873065},
journal = {ACM Transactions on Intelligent Systems and Technology},
keywords = {Allocentric representations; Amazon mechanical tu,Automation,Crowdsourcing; Office buildings},
number = {4},
title = {{Leveraging human computations to improve schematization of spatial relations from imagery}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964777781{\&}doi=10.1145{\%}2F2873065{\&}partnerID=40{\&}md5=c83658ae678b2291bd9ddcf0944efb71},
volume = {7},
year = {2016}
}
@inproceedings{Liu2010,
abstract = {Positioning of real world objects (e.g., people) in indoor environment will facilitate location dependent or context-aware applications. Due to severe multi-path fading effect in indoor wireless environment, received signal strength indicator (RSSI) based indoor positioning systems usually require a great amount of human intervention for data measurement during the system initiation. This paper proposes a novel two-phase positioning technique that has been implemented and tested in real environment. Experiment results show that our method can significantly cut down the requirements on data acquisition and achieve satisfactory performance in terms of error distance. {\textcopyright}2010 IEEE.},
annote = {cited By 4},
author = {Liu, W and Gong, S and Zhou, Y and Wang, P},
booktitle = {IEEE International Conference on Communications},
doi = {10.1109/ICC.2010.5502140},
keywords = {Context aware applications; Data measurements; Err},
title = {{Two-phase indoor positioning technique in wireless networking environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955373020{\&}doi=10.1109{\%}2FICC.2010.5502140{\&}partnerID=40{\&}md5=dfcd782d37b84b3b180daf0e5f7c4afb},
year = {2010}
}
@inproceedings{Pratkanis20131248,
abstract = {We describe our development of an autonomous robotic system that safely navigates through an unmodified campus environment to purchase and deliver a cup of coffee. To accomplish this task, the robot navigates through indoor and outdoor environments, opens heavy spring-loaded doors, calls, enters, and exits an elevator, waits in line with other customers, interacts with coffee shop employees to purchase beverages, and returns to its original location to deliver the beverages. This paper makes four contributions: a robust infrastructure for unifying multiple 2D navigation maps; a process for detecting and opening transparent, heavy spring-loaded doors; algorithms for operating elevators; and software that enables the intuitive passing of objects to and from untrained humans. {\textcopyright} 2013 IEEE.},
annote = {cited By 6},
author = {Pratkanis, A and Leeper, A E and Salisbury, K},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2013.6630731},
keywords = {Autonomous robotic systems; Coffee shops; Mobile m,Beverages; Elevators; Sales,Robotics},
pages = {1248--1253},
title = {{Replacing the office intern: An autonomous coffee run with a mobile manipulator}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887270848{\&}doi=10.1109{\%}2FICRA.2013.6630731{\&}partnerID=40{\&}md5=78ba3432b94b02a204cfc26bcf8052e4},
year = {2013}
}
@inproceedings{Bagci2009235,
abstract = {To provide valuable services in ubiquitous and pervasive computing, it is necessary to estimate the location of users or objects in the environment. The Global Positioning System (GPS) has supported many applications using outdoor location estimation, but there is still a need for alternative technologies in buildings. Assuming that multiple wireless sensors will be attached to ubiquitous environments, they could also support location estimation and tracking. This paper presents optimizations for an indoor location tracking system using wireless sensors, called Loc-Sens. LocSens works with a minimum number of sensor nodes. It is established and tested in a real indoor scenario over multiple rooms. LocSens could be improved by optimizing algorithms and using more precise sensor boards. Results confirm improved accuracy in location estimation and tracking of moving objects. {\textcopyright}2009 IEEE.},
annote = {cited By 0},
author = {Bagci, F and Kluge, F and Satzger, B and Ungerer, T},
booktitle = {WISP 2009 - 6th IEEE International Symposium on Intelligent Signal Processing - Proceedings},
doi = {10.1109/WISP.2009.5286560},
keywords = {Alternative technologies; In-buildings; Location e,Estimation; Global positioning system; Power cont,Ubiquitous computing},
pages = {235--240},
title = {{Towards indoor location estimation and tracking with wireless sensors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-71249116609{\&}doi=10.1109{\%}2FWISP.2009.5286560{\&}partnerID=40{\&}md5=0c512cc3c87e712a82efc85698d11d3d},
year = {2009}
}
@inproceedings{Jimnez2018,
abstract = {In ambient assistive living (AAL) it is of a paramount importance to be able to detect, localize and estimate the activities of persons living at their homes. Specially, estimating an accurate person's localization and detailed movement patterns in everyday activities, are very valuable for health monitoring and safety assessment. The indoor positioning and navigation (IPIN) research community mainly concentrates on the use of radio beaconing for trilateration with WiFi, Bluetooth or UWB, acoustic beaconing, inertial pedestrian dead-reckoning, and the fusion of several approaches, using fingerprinting or Bayesian estimators. In the area of activity recognition (AR) authors use different kind of sensors such as smart floors, binary sensors attached to common objects, or infer the proximity to objects using Bluetooth beacons. In this paper we want to join these two different field approaches (IPIN and AR) by proposing an indoor localization method that make use of smart floor information, binary sensors, and the signal strength received at a smartwatch coming from BLE beacons deployed in a smarlab. We use the smart floor as a ground truth in order to estimate location accuracy of persons in a totally unobtrusive way. The localization results, for a person moving in the smart livinglab during 10 days, showing accuracies below 1.5 meter in 80{\%} of the cases. The proposed approach can help the tracking of multiple persons living together and also serve as a complement to improve the performance of location-aware activity recognition algorithms, {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Jim{\'{e}}nez, A R and Seco, F and Peltola, P and Espinilla, M},
booktitle = {IPIN 2018 - 9th International Conference on Indoor Positioning and Indoor Navigation},
doi = {10.1109/IPIN.2018.8533714},
keywords = {Ble beacons; Indoor localization; Particle filter,Bluetooth; Floors; Location; Pattern recognition;,Indoor positioning systems},
title = {{Location of Persons Using Binary Sensors and BLE Beacons for Ambient Assitive Living}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059088491{\&}doi=10.1109{\%}2FIPIN.2018.8533714{\&}partnerID=40{\&}md5=b6f65442b71f480129f9ca4e2eaaafc3},
year = {2018}
}
@inproceedings{Alqahtani2018,
abstract = {Indoor navigation systems are increasingly needed for smart cities, robots, and visually impaired people. Although Global Positioning System (GPS) is widely used for navigation in numerous applications, it cannot be used for indoor navigation systems as the signals cannot be absorbed by the walls of buildings. As a result, other methods including Wi-Fi, Bluetooth and sensors must be used for navigation. This paper analyses the various algorithms used to find the location of objects and algorithms to navigate using the shortest path in an indoor environment. The first section introduces indoor navigation systems, the problem statement of this paper, and the background of such systems. Then, a comprehensive literature review is included that reviews previous research studies conducted in this area. After that, a discussion and analysis of the literature review has been done to classify and compare between the algorithms and techniques studied. Finally, the paper provides directions for future work in the field of indoor navigation. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Alqahtani, E J and Alshamrani, F H and Syed, H F and Alhaidari, F A},
booktitle = {21st Saudi Computer Society National Computer Conference, NCC 2018},
doi = {10.1109/NCG.2018.8593096},
keywords = {Best paths; Dijkstra's algorithms; In-door naviga,Global positioning system; Graph theory; Robots,Indoor positioning systems},
title = {{Survey on Algorithms and Techniques for Indoor Navigation Systems.}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061485768{\&}doi=10.1109{\%}2FNCG.2018.8593096{\&}partnerID=40{\&}md5=bb4de616cfffaa32ed7adce4c23785bd},
year = {2018}
}
@article{Raychoudhury20152208,
abstract = {Recent advances in smartphones and location-aware services necessitate identifying logical locations of users, in terms of their surroundings, instead of raw location coordinates. In this paper, we have proposed CROWD-PAN-360 (CP360), a novel smartphone-based system to generate 360-degree panoramic map of a querying user for his unfamiliar surrounding using crowd-sourced images. The objects (logical locations) appearing in the images are identified using manually or automatically generated tags. The system is context-aware and it intelligently associates user location coordinates with several smartphone contexts, like acceleration and orientation. CP360 can significantly reduce GPS positional errors for even cheap low-end smartphones and can identify the user surroundings very efficiently. We extensively tested the system in both indoor and outdoor environments of IIT Roorkee campus using Android smartphones over a dataset of more than 6,000 crowd-sourced images of nearly 70 objects (departments, hostels, cafeteria, etc.) and CP360 generates the panoramic map with an average accuracy of 92.2 percent. {\textcopyright} 1990-2012 IEEE.},
annote = {cited By 9},
author = {Raychoudhury, V and Shrivastav, S and Sandha, S S and Cao, J},
doi = {10.1109/TPDS.2014.2345067},
journal = {IEEE Transactions on Parallel and Distributed Systems},
keywords = {Automatically generated; Context-Aware; Crowd sou,Location based services,Location; Signal encoding; Smartphones; Telecommun},
number = {8},
pages = {2208--2219},
title = {{CROWD-PAN-360: Crowdsourcing Based Context-Aware Panoramic Map Generation for Smartphone Users}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937485173{\&}doi=10.1109{\%}2FTPDS.2014.2345067{\&}partnerID=40{\&}md5=1848b21798a04bdf1556d4641d8a47f7},
volume = {26},
year = {2015}
}
@article{Kim2012,
abstract = {Large-scale acquisition of exterior urban environments is by now a well-established technology, supporting many applications in search, navigation, and commerce. The same is, however, not the case for indoor environments, where access is often restricted and the spaces are cluttered. Further, such environments typically contain a high density of repeated objects (e.g., tables, chairs, monitors, etc.) in regular or non-regular arrangements with significant pose variations and articulations. In this paper, we exploit the special structure of indoor environments to accelerate their 3D acquisition and recognition with a low-end handheld scanner. Our approach runs in two phases: (i) a learning phase wherein we acquire 3D models of frequently occurring objects and capture their variability modes from only a few scans, and (ii) a recognition phase wherein from a single scan of a new area, we identify previously seen objects but in different poses and locations at an average recognition time of 200ms/model. We evaluate the robustness and limits of the proposed recognition system using a range of synthetic and real world scans under challenging settings. {\textcopyright} 2012 ACM.},
annote = {cited By 104},
author = {Kim, Y M and Mitra, N J and Yan, D.-M. and Guibas, L},
doi = {10.1145/2366145.2366157},
journal = {ACM Transactions on Graphics},
keywords = {3D acquisition; 3D models; Acquisition; Hand-held,Face recognition,Mergers and acquisitions},
number = {6},
title = {{Acquiring 3D indoor environments with variability and repetition}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870233124{\&}doi=10.1145{\%}2F2366145.2366157{\&}partnerID=40{\&}md5=51d7ea1a941396e3e01b090de032ae11},
volume = {31},
year = {2012}
}
@inproceedings{Inada201142,
abstract = {RFID (Radio Frequency IDentification) systems have become meaningful as a new identification source that is applicable in ubiquitous environments. Each RFID tag has a unique ID, and is attached to an object. A user reads the unique ID of an RFID tag with RFID readers and obtains the information of the object. One of the most important technologies that use the RFID system is the position estimation of RFID tags. The position estimation means to estimates the location of the object with the RFID tag. It is very useful to acquire the location information of RFID tag. If a user understands the position of the RFID tag, a new navigation system for persons in complex buildings. In this paper, we propose a new method for accurate indoor position estimation of passive RFID systems named as the Sliding-Typed CRR method. In this method, the position of an RFID tag is estimated by using S-CRR (Swift Communication Range Recognition) method. The proposed method is capable of accurate position estimation in any directions of RFID tags. {\textcopyright} 2011 IEEE.},
annote = {cited By 2},
author = {Inada, A and Oda, Y and Nakamori, E and Fujimoto, M and Wada, T and Mutsuura, K and Okada, H},
booktitle = {Proceedings of the International Conference on Parallel Processing Workshops},
doi = {10.1109/ICPPW.2011.29},
keywords = {Attenuator; Communication area; Communication rang,Communication; Cryptography; Estimation; Frequenc,Radio frequency identification (RFID)},
pages = {42--49},
title = {{Sliding-Typed Communication Range Recognition method for indoor position estimation in passive RFID systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80155194965{\&}doi=10.1109{\%}2FICPPW.2011.29{\&}partnerID=40{\&}md5=878d174c654303d8a022b7d49baf4a66},
year = {2011}
}
@inproceedings{Maesen2013101,
abstract = {In this paper we present a novel approach for tracking the movement of a user in a large indoor environment. Many studies show that natural walking in virtual environments increases the feeling of immersion by the users. However, most tracking systems suffer from a limited working area or are expensive to scale up to a reasonable size for navigation. Our system is designed to be easily scalable both in working area and number of simultaneous users using inexpensive off-the-shelf components. To accomplish this, the system determines the 6 DOF pose using passive LED strips, mounted to the ceiling, which are spatially encoded using De Bruijn codes. A camera mounted to the head of the user records these patterns. The camera can determine its own pose independently, so no restriction on the number of tracked objects is required. The system is accurate to a few millimeters in location and less than a degree in orientation. The accuracy of the tracker is furthermore independent of the size of the working area which makes it scalable to enormous installations. To provide a realistic feeling of immersion, the system is developed to be realtime and is only limited by the framerate of the camera, currently at 60Hz.},
annote = {cited By 4},
author = {Maesen, S and Goorts, P and Bekaert, P},
booktitle = {Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST},
doi = {10.1145/2503713.2503733},
keywords = {Cameras,Indoor environment; Large virtual environments; Lo,Virtual reality},
pages = {101--110},
title = {{Scalable optical tracking for navigating large virtual environments using spatially encoded markers}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887176865{\&}doi=10.1145{\%}2F2503713.2503733{\&}partnerID=40{\&}md5=201206463903fa45aad313bd2dba10cd},
year = {2013}
}
@article{Liu2018,
abstract = {We propose a new method for modeling the indoor scene from a single image. With our system, the user only needs to drag a few bounding boxes surrounding the objects of interest. Our system then automatically finds the most similar models from the ShapeNet repository and aligns them with the corresponding objects of interest. To achieve this, each 3D model is represented as a group of view-dependent representations generated from a set of synthesized views. We iteratively conduct object segmentation and 3D model retrieval, based on the observation that good segmentation of the objects of interest can significantly improve the accuracy of model retrieval and make it robust to cluttered background and occlusion, and in turn, the retrieved models can be used to assist with segmentation. Segmentation of all objects of interest is achieved simultaneously under a unified multi-labeling framework which fully utilizes the correspondences between the objects and retrieved model images. Besides, we propose a new method to estimate the scene layout of the input image, which helps compose the resulting scene and further improves the modeling result. We verify the effectiveness of our approach through experimenting with a variety of indoor images and comparing against the relevant methods. IEEE},
annote = {cited By 0; Article in Press},
author = {Liu, M and Zhang, K and Zhu, J and Wang, J and Guo, J and Guo, Y},
doi = {10.1109/TVCG.2018.2880737},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Color image processing; Image enhancement; Image r,Computational model; Data driven; Layout; Object,Image segmentation},
title = {{Data-driven Indoor Scene Modeling from a Single Color Image with Iterative Object Segmentation and Model Retrieval}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056308085{\&}doi=10.1109{\%}2FTVCG.2018.2880737{\&}partnerID=40{\&}md5=efff458942d68c0be7c1016c4318f542},
year = {2018}
}
@article{Nguyen2015133,
abstract = {Indoor localisation is the state-of-the-art to identify and observe a moving human or an object inside a building. However, because of the harsh indoor conditions, current indoor localisation systems remain either too expensive or not accurate enough. In this paper, we tackle the latter issue in a different direction, with a new conformal prediction algorithm to enhance the accuracy of the prediction. We handle the common indoor signal attenuation issue, which introduces errors into the training database, with a reliability measurement for our prediction. We show why our approach performs better than other solutions through empirical studies with two testbeds. To the best of our knowledge, we are the first to apply conformal prediction for the localisation purpose in general, and for the indoor localisation in particular. {\textcopyright} 2013, Springer Science+Business Media Dordrecht.},
annote = {cited By 2},
author = {Nguyen, K A and Luo, Z},
doi = {10.1007/s10472-013-9384-4},
journal = {Annals of Mathematics and Artificial Intelligence},
number = {1-2},
pages = {133--153},
title = {{Reliable indoor location prediction using conformal prediction}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930415578{\&}doi=10.1007{\%}2Fs10472-013-9384-4{\&}partnerID=40{\&}md5=d122c1f620b440d2676ae2c0cd9a85a2},
volume = {74},
year = {2015}
}
@article{Li2018,
abstract = {Knowing popular indoor locations can benefit many applications like exhibition planning and location-based advertising, among others. In this work, we use uncertain historical indoor mobility data to find the top-k popular indoor semantic locations with the highest flow values. In the data we use, an object positioning report contains a set of samples, each consisting of an indoor location and a corresponding probability. The problem is challenging due to the difficulty in obtaining reliable flow values and the heavy computational workload on probabilistic samples for large numbers of objects. To address the first challenge, we propose an indoor flow definition that takes into account both data uncertainty and indoor topology. To efficiently compute flows for individual indoor semantic locations, we design data structures for facilitating accessing the relevant data, a data reduction method that reduces the intermediate data to process, and an overall flow computing algorithm. Furthermore, we design search algorithms for finding the top-k popular indoor semantic locations. All proposals are evaluated extensively on real and synthetic data. The evaluation results show that our data reduction method significantly reduces the data volume in computing, our search algorithms are efficient and scalable, and the top-k popular semantic locations returned are in good accord with ground truth. IEEE},
annote = {cited By 0; Article in Press},
author = {Li, H and Lu, H and Shou, L and Chen, G and Chen, K},
doi = {10.1109/TKDE.2018.2875096},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Data reduction,Data structures; Learning algorithms; Location; Re,Indoor flows; Indoor mobility; Indoor space; Unce},
title = {{Finding Most Popular Indoor Semantic Locations Using Uncertain Mobility Data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054686043{\&}doi=10.1109{\%}2FTKDE.2018.2875096{\&}partnerID=40{\&}md5=3279bf0c8299ee48527dc9fd9ef35e1d},
year = {2018}
}
@inproceedings{Bouguet1998,
abstract = {A simple and inexpensive approach for extracting the three- dimensional shape of objects is presented. It is based on 'weak structured lighting;' and requires little hardware besides the cam-era: A light source (a desk-lamp or the sun), a stick and a checkerboard. The object, illuminated by the light source, is placed on a stage composed of a ground plane and a back plane; the camera faces the object. The user moves the stick in front of the light source, casting a moving shadow on the scene. The 3D shape of the object is extracted from the spatial and temporal location of the observed shadow. Experimental results are presented on three different scenes (indoor with a desk lamp and outdoor with the sun) demonstrating that the error in reconstructing the surface is less than 0.5{\%} of the size of the object.},
annote = {cited By 0},
author = {Bouguet, J.-Y. and Perona, P},
booktitle = {European Signal Processing Conference},
keywords = {3-D shape; 3D photography; Ground planes; Structu,Light sources,Signal processing},
title = {{3D photography using shadows}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019566487{\&}partnerID=40{\&}md5=6a756984402fef5abe737e48d2ad51dc},
volume = {1998-Janua},
year = {1998}
}
@inproceedings{Meng2012,
abstract = {The University of Nottingham has purchased a set of more than 20 Ultra Wideband (UWB) sensors from Thales (UK) to enhance its ubiquitous positioning and navigation capacity. A scalable indoor testing facility has been set up recently and one of these testing scenarios consists of 8 fixed base stations and a few rover units onboard the moving objects, to simulate different applications. Two tests that lasted one week each have been carried out to identify the UWB error sources, develop and test the newly developed processing algorithms, assess the achievable positioning and navigation performance that include kinematic positioning accuracy, continuity and system robustness. This paper presents the initial research results and findings and compares the advantages and disadvantages of UWB indoor positioning and navigation with other methods. Lessons learnt from organizing these tests are also presented and the future research exploration is briefly discussed. {\textcopyright} 2012 IEEE.},
annote = {cited By 7},
author = {Meng, X and Gao, Y and Kwok, K.-H. and Zhao, H},
booktitle = {2012 Ubiquitous Positioning, Indoor Navigation, and Location Based Service, UPINLBS 2012},
doi = {10.1109/UPINLBS.2012.6409783},
keywords = {Error analysis; Location based services; Navigati,Error sources; Indoor positioning; Indoor testing;,Ultra-wideband (UWB)},
title = {{Assessment of UWB for ubiquitous positioning and navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873975074{\&}doi=10.1109{\%}2FUPINLBS.2012.6409783{\&}partnerID=40{\&}md5=2fd2616a7726a3e7dddaaa1f86516c1a},
year = {2012}
}
@inproceedings{Lo2018220,
abstract = {Intelligent mobile robots have recently become able to operate aut onomously in large-scale indoor environments for extended periods of time. Task planning in such environments involves sequencing the robot's high-level goals and subgoals, and typically requires reasoning about the locations of people, rooms, and objects in the environment, and their interactions to achieve a goal. One of the prerequisites for optimal task planning that is often overlooked is having an accurate estimate of the actual distance (or time) a robot needs to navigate from one location to another. Stateof-ihe-art mot ion planners, though often computationally complex, are designed exactly for this pUrpose of finding routes through constrained spaces. In this work, we focus on integrating task and motion planning (TMP) to achieve task-level optimal planning for robot navigation while maintaining manageable computational efficiency. To this end, we introduce TMP algorithm PETLON (Planning Efficiently for Task-Level-Optimal Navigation) for everyday service tasks using a mobile robot. PETLON is more efficient than planning approaches that pre-compute motion costs of all possible navigation actions, while still producing plans that are optimal at the task level. {\textcopyright} 2018 International Foundation for Autonomous Agents and Multiagent Systems.},
annote = {cited By 0},
author = {Lo, S.-Y. and Zhang, S and Stone, P},
booktitle = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
keywords = {Actual distance; Constrained space; High-level go,Autonomous agents; Computational efficiency; Intel,Robot programming},
pages = {220--228},
title = {{PETLON: Planning efficiently for task-level-optimal navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055313834{\&}partnerID=40{\&}md5=2a2af8594ec914ea478e9a8d8a6e85cf},
volume = {1},
year = {2018}
}
@article{Xu2014,
abstract = {We introduce focal points for characterizing, comparing, and organizing collections of complex and heterogeneous data and apply the concepts and algorithms developed to collections of 3D indoor scenes. We represent each scene by a graph of its constituent objects and define focal points as representative substructures in a scene collection. To organize a heterogeneous scene collection, we cluster the scenes based on a set of extracted focal points: scenes in a cluster are closely connected when viewed from the perspective of the representative focal points of that cluster. The key concept of representativity requires that the focal points occur frequently in the cluster and that they result in a compact cluster. Hence, the problem of focal point extraction is intermixed with the problem of clustering groups of scenes based on their representative focal points. We present a co-analysis algorithm which interleaves frequent pattern mining and subspace clustering to extract a set of contextual focal points which guide the clustering of the scene collection. We demonstrate advantages of focal-centric scene comparison and organization over existing approaches, particularly in dealing with hybrid scenes, scenes consisting of elements which suggest membership in different semantic categories. Copyright {\textcopyright} ACM.},
annote = {cited By 27},
author = {Xu, K and Ma, R and Zhang, H and Zhu, C and Shamir, A and Cohen-Or, D and Huang, H},
doi = {10.1145/2601097.2601109},
journal = {ACM Transactions on Graphics},
keywords = {3D indoor scenes; Focal points; Frequent pattern,Clustering algorithms; Natural resources explorati,Interactive computer graphics},
number = {4},
title = {{Organizing heterogeneous scene collections through contextual focal points}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905740389{\&}doi=10.1145{\%}2F2601097.2601109{\&}partnerID=40{\&}md5=75f6a195e2ee532df4aa4880b622fc25},
volume = {33},
year = {2014}
}
@inproceedings{Xia2015,
abstract = {Energy-efficiency and location accuracy are two important performance metrics for indoor localization systems. However, typical indoor localization schemes based on WLAN cut gravely down smart device lifetime due to large energy consumption of scanning around wireless access points. In this paper, for the purpose of decreasing the amount of energy consumption while guaranteeing localization accuracy, a novel indoor localization framework based on heterogeneous network (HetNet) by fusing WLAN and WPAN under group-based mobility mode is proposed, whose localization method is relied on the fusion of fingerprint matching and trilateration. Moreover, we develop a novel energy-accuracy tradeoff scheme including objects clustering and dynamic multiple cluster header smart devices selection scheme during the localization process based on the proposed HetNet-based indoor localization framework. Simulation results indicate that the proposed scheme extends the smart device lifetime, maintains the fairness of smart devices and provides a well-balanced energy consumption and location accuracy compared to a previous proposed scheme, namely, LEACH scheme. {\textcopyright} 2015 IEEE.},
annote = {cited By 0},
author = {Xia, J and Xu, C and Liu, Z and Yu, H},
booktitle = {2015 International Conference on Wireless Communications and Signal Processing, WCSP 2015},
doi = {10.1109/WCSP.2015.7341283},
keywords = {Energy accuracy tradeoff; Fingerprint matching; H,Energy efficiency; Energy utilization; Heterogeneo,Indoor positioning systems},
title = {{DMCHS: An energy-accuracy tradeoff scheme for HetNet-based indoor localization framework}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975746893{\&}doi=10.1109{\%}2FWCSP.2015.7341283{\&}partnerID=40{\&}md5=be3082daac424eb7c3b26c1a41e70965},
year = {2015}
}
@inproceedings{Al-Nuaimi201531,
abstract = {In this paper we show that indoor location retrieval can be posed as a part-in-whole matching problem of Kinect-Fusion (KinFu) query scans in large-scale target indoor point clouds. We tackle the problem with a local shape feature-based 3D Object Retrieval (3DOR) system. We specifically show that the KinFu queries suffer from artifacts stemming from the non-linear depth distortion and noise characteristics of Kinect-like sensors that are accentuated by the relative largeness of the queries. We furthermore show that proper calibration of the Kinect sensor using the CLAMS technique (Calibrating, Localizing, and Mapping, Simultaneously) proposed by Teichman et al. effectively reduces the artifacts in the generated KinFu scan and leads to a substantial retrieval performance boost. Throughout the paper we use queries and target point clouds obtained at the world's largest technical museum. The target point clouds cover floor spaces of up to 3500m2. We achieve an average localization accuracy of 6cm although the KinFu query scans make up only a tiny fraction of the target point clouds. {\textcopyright} The Eurographics Association 2015.},
annote = {cited By 5},
author = {Al-Nuaimi, A and Piccolrovazzi, M and Gedikli, S and Steinbach, E and Schroth, G},
booktitle = {Eurographics Workshop on 3D Object Retrieval, EG 3DOR},
doi = {10.2312/3DOR.20151052},
keywords = {3D object retrieval; Indoor locations; Kinect sens,Object recognition},
pages = {31--38},
title = {{Indoor location retrieval using shape matching of kinectfusion scans to large-scale indoor point clouds}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971632243{\&}doi=10.2312{\%}2F3DOR.20151052{\&}partnerID=40{\&}md5=8bb971f091e6e8f05432181bb7bc182c},
year = {2015}
}
@article{Gentile2008,
abstract = {Fine time resolution enables ultrawideband (UWB) ranging systems to extract the first multipath arrival corresponding to the range between a transmitter and receiver, even when attenuated in strength compared to later arrivals. Bearing systems alone lack any notion of time and in general select the strongest arrival which is rarely the first one in nonline-of-sight conditions. Complementing UWB ranging systems with bearing capabilities allows indexing the arrivals as a function of both time and angle in order to isolate the first, providing precision range and angle. However, that precision degrades with the increasing presence of walls and other objects which distort the properties of the first arrival. In order to gauge the physical limits of the joint UWB system, we design and assemble a spatial-temporal channel sounder using a vector network analyzer coupled to a virtual antenna array, and conduct 200 experiments to measure the time- and angle-of-flight. The experiments are carried out in both line-of-sight and nonline-of-sight conditions up to an unprecedented 45 meters throughout four separate buildings with dominant wall material varying from sheet rock to steel. In addition, we report performance for varying bandwidth and center frequency of the system. We find that operating at a bandwidth of 4GHz suffices in resolving multipath in most buildings and in excess shows virtually no improvement. While the range error decreases at lower center frequencies, the higher frequencies offer better angular resolution and so smaller angle error.},
annote = {cited By 8},
author = {Gentile, C and Braga, A J and Kik, A},
doi = {10.1155/2008/248509},
journal = {Eurasip Journal on Wireless Communications and Networking},
keywords = {Angle estimations; Angular resolutions; Bearing c,Antenna arrays; Bearings (structural); Broadband n,Telecommunication systems},
title = {{A comprehensive evaluation of joint range and angle estimation in indoor ultrawideband location systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-59849112566{\&}doi=10.1155{\%}2F2008{\%}2F248509{\&}partnerID=40{\&}md5=fcfb76f98ece6b8acbf8c589ea56b67a},
volume = {2008},
year = {2008}
}
@inproceedings{Yang20101087,
abstract = {Independent travel is a well known challenge for blind or visually impaired persons. In this paper, we propose a computer vision-based indoor wayfinding system for assisting blind people to independently access unfamiliar buildings. In order to find different rooms (i.e. an office, a lab, or a bathroom) and other building amenities (i.e. an exit or an elevator), we incorporate door detection with text recognition. First we develop a robust and efficient algorithm to detect doors and elevators based on general geometric shape, by combining edges and corners. The algorithm is generic enough to handle large intra-class variations of the object model among different indoor environments, as well as small inter-class differences between different objects such as doors and elevators. Next, to distinguish an office door from a bathroom door, we extract and recognize the text information associated with the detected objects. We first extract text regions from indoor signs with multiple colors. Then text character localization and layout analysis of text strings are applied to filter out background interference. The extracted text is recognized by using off-the-shelf optical character recognition (OCR) software products. The object type, orientation, and location can be displayed as speech for blind travelers. {\textcopyright} 2010 ACM.},
annote = {cited By 14},
author = {Yang, X and Tian, Y and Yi, C and Arditi, A},
booktitle = {MM'10 - Proceedings of the ACM Multimedia 2010 International Conference},
doi = {10.1145/1873951.1874156},
keywords = {Algorithms; Computer vision; Doors; Elevators; Fe,Blind people; Blind person; blind/visually impaire,Handicapped persons},
pages = {1087--1090},
title = {{Context-based indoor object detection as an aid to blind persons accessing unfamiliar environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650985002{\&}doi=10.1145{\%}2F1873951.1874156{\&}partnerID=40{\&}md5=95d939c147db6c1c350d2a86e38facb1},
year = {2010}
}
@inproceedings{Gao2014249,
abstract = {The lack of floor plans is a critical reason behind the current sporadic availability of indoor localization service. Service providers have to go through effort-intensive and timeconsuming business negotiations with building operators, or hire dedicated personnel to gather such data. In this paper, we propose Jigsaw, a floor plan reconstruction system that leverages crowdsensed data from mobile users. It extracts the position, size and orientation information of individual landmark objects from images taken by users. It also obtains the spatial relation between adjacent landmark objects from inertial sensor data, then computes the coordinates and orientations of these objects on an initial floor plan. By combining user mobility traces and locations where images are taken, it produces complete floor plans with hallway connectivity, room sizes and shapes. Our experiments on 3 stories of 2 large shopping malls show that the 90-percentile errors of positions and orientations of landmark objects are about 1  2m and 5  9, while the hallway connectivity is 100{\%} correct. Copyright {\textcopyright} 2014 by the Association for Computing Machinery, Inc. (ACM).},
annote = {cited By 116},
author = {Gao, R and Zhao, M and Ye, T and Ye, F and Wang, Y and Bian, K and Wang, T and Li, X},
booktitle = {Proceedings of the Annual International Conference on Mobile Computing and Networking, MOBICOM},
doi = {10.1145/2639108.2639134},
keywords = {Floorplans; Mobile crowdsensing},
pages = {249--260},
title = {{Jigsaw: Indoor floor plan reconstruction via mobile crowdsensing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907860017{\&}doi=10.1145{\%}2F2639108.2639134{\&}partnerID=40{\&}md5=ec1ca5d9eb803a4ad8ed52b67fed1089},
year = {2014}
}
@inproceedings{Kawsar20071624,
abstract = {Our approach towards context awareness is to use sensor augmented daily life objects surrounding us for extracting context information and for providing ambient services. Some of these artefacts are static in nature and have designated location, like a bed in the bedroom, a refrigerator in the kitchen, etc. Utilizing this characteristics, we present "Spreha", a light weight hierarchical location model where static artefacts are used as reference points for identifying mobile artefacts like a chair, a watch, a lamp, etc. The model is organized in a tree structure representing the containment relationship and is independent of underlying sensing infrastructure. A prototype implementation of the model has been constructed as a pluggable module of a generic middleware using Bluetooth technology. This paper discusses about the design, architecture and findings of the prototype implementation. Copyright 2007 ACM.},
annote = {cited By 8},
author = {Kawsar, F and Fujinami, K and Nakajima, T},
booktitle = {Proceedings of the ACM Symposium on Applied Computing},
doi = {10.1145/1244002.1244347},
keywords = {Bluetooth; Context free languages; Data structures,Context awareness; Hierarchical location model; I,Virtual reality},
pages = {1624--1631},
title = {{A lightweight indoor location model for sentient artefacts using sentient artefacts}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-35248841984{\&}doi=10.1145{\%}2F1244002.1244347{\&}partnerID=40{\&}md5=335929e49363237776fb51bb4a98a9f7},
year = {2007}
}
@article{Nur201530,
abstract = {RFID can be used to obtain information about objects present in a physical space, including their approximate location. Handheld RFID readers, smart shelves, zenithal antennas, and autonomous robots can obtain additional information with varying time and space resolutions. The authors present a system that projects this information on a panoramic view of a retail store, allowing users to virtually navigate the space and obtain quasi-real-time information about the products as they actually are in the store. For example, when a user clicks on the image of a shelf in the panorama, product information appears at or near that position from the last RFID-based inventory, which could be as recent as a few seconds ago. {\textcopyright} 2001-2011 IEEE.},
annote = {cited By 8},
author = {Nur, K and Morenza-Cinos, M and Carreras, A and Pous, R},
doi = {10.1109/MIS.2015.90},
journal = {IEEE Intelligent Systems},
keywords = {Google; Panoramic views; Product information; Rea,Navigation; Radio frequency identification (RFID);,Retail stores},
number = {6},
pages = {30--37},
title = {{Projection of RFID-obtained product information on a retail stores indoor panoramas}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960964324{\&}doi=10.1109{\%}2FMIS.2015.90{\&}partnerID=40{\&}md5=dc417cc60cad07e63f72937cb2e7dd5d},
volume = {30},
year = {2015}
}
@inproceedings{Zhou20071087,
abstract = {Trajectories of moving objects provide crucial clues for video event analysis especially in surveillance applications. In this paper, we study the problem of detecting anomalous events by analyzing the motion trajectories in videos. Different trajectories of the same category may have varying relative velocities, in addition to the variations and noises in location samples; hence the core of the problem is to provide a robust and accurate function for measuring the similarities of trajectory pairs. We propose a novel learning based algorithm for estimating the similarities of the multi-dimensional sequence pairs, and then an anomaly detection framework is presented to detect anomalous motion trajectories in surveillance videos. Our proposed algorithm offers several advantages over the traditional algorithms for dealing with the trajectories of moving objects. First, the similarity measurement is robust against data imperfections such as noise, algorithmic error and etc. Second, we introduce a learning algorithm which allows the similarity function to be adapted to the particular problems being solved. Third, the proposed anomaly detection framework is fully automatic and without parametric distribution assumption on the data. The experiments on both outdoor and indoor surveillance videos validate the effectiveness of our proposed framework in detecting anomalous trajectories. {\textcopyright} 2007 IEEE.},
annote = {cited By 52},
author = {Zhou, Y and Yan, S and Huang, T S},
booktitle = {Proceedings of the 2007 IEEE International Conference on Multimedia and Expo, ICME 2007},
keywords = {Anomalous events; Anomaly detections; Indoor surv,Boolean functions; Diesel engines; Exhibitions; Fu,Security systems},
pages = {1087--1090},
title = {{Detecting anomaly in videos from trajectory similarity analysis}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-46449086514{\&}partnerID=40{\&}md5=99422aa16d43b5e7aef765838acba4d2},
year = {2007}
}
@inproceedings{Zhao20173331,
abstract = {We propose a system for indoor localization using intensity-controllable LED light fixtures and light sensors mounted on the ceiling. While providing accurate location estimates, our approach preserves user privacy and is robust to ambient light conditions. We develop a LASSO algorithm and a localized ridge regression algorithm for locating a single object. In synthetic experiments, our localized ridge regression algorithm achieves an average localization error ranging from 0.24in to 1.39in, for different object sizes, in a 712-foot room. The localized ridge regression algorithm also shows the ability to locate multiple objects in experiments with a real-world occupancy scenario. {\textcopyright} 2017 IEEE.},
annote = {cited By 1},
author = {Zhao, J and Ishwar, P and Konrad, J},
booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
doi = {10.1109/ICASSP.2017.7952773},
pages = {3331--3335},
title = {{Privacy-preserving indoor localization via light transport analysis}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023771103{\&}doi=10.1109{\%}2FICASSP.2017.7952773{\&}partnerID=40{\&}md5=be88f85b0ca10ba2d19b942ebbe40238},
year = {2017}
}
@inproceedings{Chriki20171144,
abstract = {The need to locate objects and to be situated in the space, whether inside or outside, has long been the focus of a substantial amount of research. Especially in Wireless Sensor Networks, indoor localization has become an important issue in many fields of applications. In this paper, we propose an indoor location solution based on Support Vector Machine (SVM). SVM is a class of learning algorithms defined to resolve discrimination and regression problems. In fact, with many works, it turned out that it is very difficult to properly locate a target with only the RSSI measurements. Thus, the idea is to use multi-class SVM with RSSI measurements to propose a zoning localization approach. The performed experiments using different datasets, collected from two real world environments in both a hospital and a laboratory building, and the comparison with Artificial Neural Networks (ANN) confirm the effectiveness of our SVM-based localization proposal. Experimental results show that the system achieves a correct classification rate of around 90{\%} with misclassification is in rooms where there is no wall separating them. {\textcopyright} 2017 IEEE.},
annote = {cited By 7},
author = {Chriki, A and Touati, H and Snoussi, H},
booktitle = {2017 13th International Wireless Communications and Mobile Computing Conference, IWCMC 2017},
doi = {10.1109/IWCMC.2017.7986446},
keywords = {Classification (of information); Indoor positionin,Classification rates; Experimentation; Indoor loc,Wireless sensor networks},
pages = {1144--1149},
title = {{SVM-based indoor localization in Wireless Sensor Networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027886310{\&}doi=10.1109{\%}2FIWCMC.2017.7986446{\&}partnerID=40{\&}md5=21db9b50b17a1fd6ba89c84e7951ecb0},
year = {2017}
}
@article{Papapostolou2011902,
abstract = {Radio Frequency IDentification (RFID) is a rapidly developing wireless technology with key features which anticipate its outstanding position in the upcoming era of pervasive computing. Even though object identification is its primary objective, it is generally accepted that RFID systems can revolutionize various commercial applications. Despite its promising benefits, however, there are some technological challenges that should be addressed in order to exploit the full potential of RFID. Admittedly, the interference problem among its components and from non-conductive materials is the main shortcoming of RFID. The main goal of this paper is exploring its applicability for indoor location sensing, an important feature for the realization of ubiquitous computing applications. To that end, we study the impact of several interference types on its performance. Focusing on the case of determining the location of mobile terminals with reader extension by relying on a deployment of tags, we consider three RFID positioning schemes which are easily implemented but differ in their memory and computation requirements. Mathematical models are derived for describing the main interference types and their influence on the accuracy and time response of these schemes. Finally, extensive simulation analysis is conducted for exploring the practicality and efficacy of RFID for the localization of single or multiple users under different levels of environmental harshness. Numerical results validate the potential of RFID in location sensing but also the requirement for careful design of RFID-based positioning systems. {\textcopyright} 2010 Elsevier Ltd. All rights reserved.},
annote = {cited By 39},
author = {Papapostolou, A and Chaouchi, H},
doi = {10.1016/j.jnca.2010.04.009},
journal = {Journal of Network and Computer Applications},
keywords = {Commercial applications; Computing applications; E,Conductive materials; Cryptography; Mathematical,Radio frequency identification (RFID)},
number = {3},
pages = {902--913},
title = {{RFID-assisted indoor localization and the impact of interference on its performance}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952451098{\&}doi=10.1016{\%}2Fj.jnca.2010.04.009{\&}partnerID=40{\&}md5=7ca6d443f952c97a9a902b44e0766d31},
volume = {34},
year = {2011}
}
@inproceedings{Hepeng20081179,
abstract = {Ubiquitous Location-Based Services that can detect the location of objects or people anytime and anywhere, and use this as a basis for providing useful services, are emerging important services. Location tracking services are applicable in a wide variety of fields such as logistics, security, industrial autonomy, wireless sensor networks and military tracking. There are various location detection systems using different methods such as infrared, ultrasonic, RFID, UWB and signal strength. This thesis will examine the performance and practical uses of indoor location system which uses RFID and ultrasonic sensors as detection nodes. {\textcopyright} 2008 IEEE.},
annote = {cited By 7},
author = {Hepeng, D and Donglin, S},
booktitle = {ISAPE 2008 - The 8th International Symposium on Antennas, Propagation and EM Theory Proceedings},
doi = {10.1109/ISAPE.2008.4735437},
keywords = {Antennas; Ubiquitous computing; Ultrasonic sensors,Indoor location systems; Location detections; Loc,Wireless sensor networks},
pages = {1179--1181},
title = {{Indoor Location system using RFID and ultrasonic sensors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-63549091022{\&}doi=10.1109{\%}2FISAPE.2008.4735437{\&}partnerID=40{\&}md5=779f7dea8e9d3304e98cbff123409fb6},
year = {2008}
}
@inproceedings{Tapu2013444,
abstract = {In this paper we introduce a real-time obstacle detection and classification system designed to assist visually impaired people to navigate safely, in indoor and outdoor environments, by handling a smartphone device. We start by selecting a set of interest points extracted from an image grid and tracked using the multiscale Lucas - Kanade algorithm. Then, we estimate the camera and background motion through a set of homographic transforms. Other types of movements are identified using an agglomerative clustering technique. Obstacles are marked as urgent or normal based on their distance to the subject and the associated motion vector orientation. Following, the detected obstacles are fed/sent to an object classifier. We incorporate HOG descriptor into the Bag of Visual Words (BoVW) retrieval framework and demonstrate how this combination may be used for obstacle classification in video streams. The experimental results demonstrate that our approach is effective in image sequences with significant camera motion and achieves high accuracy rates, while being computational efficient. {\textcopyright} 2013 IEEE.},
annote = {cited By 57},
author = {Tapu, R and Mocanu, B and Bursuc, A and Zaharia, T},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCVW.2013.65},
keywords = {Agglomerative clustering; Classification system;,Cameras; Computer vision; Object recognition; Obst,Smartphones},
pages = {444--451},
title = {{A smartphone-based obstacle detection and classification system for assisting visually impaired people}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897491638{\&}doi=10.1109{\%}2FICCVW.2013.65{\&}partnerID=40{\&}md5=caa0d28cda6b9d51887dd5915dfa52c9},
year = {2013}
}
@article{Wu2009546,
abstract = {A novel approach to location estimation by omni-directional vision for autonomous vehicle navigation in indoor environments using circular landmark information is proposed. A circular-shaped landmark is attached on a ceiling and an omni-directional camera is equipped on a vehicle to take upward-looking omni-directional images of the landmark. This way of image taking reduces possible landmark shape occlusion and image noise creation, which come from the existence of nearby objects or humans surrounding the vehicle. It is shown that the perspective shape of the circular landmark in the omni-directional image may be approximated by an ellipse by analytic formulas with good shape-fitting effect and fast computation speed. The parameters of the ellipse are then used for estimating the location of the vehicle with good precision for navigation guidance. Both simulated and real images were tested and good experimental results confirm the feasibility of the proposed approach. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
annote = {cited By 37},
author = {Wu, C.-J. and Tsai, W.-H.},
doi = {10.1016/j.robot.2008.10.001},
journal = {Robotics and Autonomous Systems},
keywords = {Autonomous land vehicle; Circular-shaped landmark,Cameras; Ceilings; Estimation; Navigation; Navigat,Vehicles},
number = {5},
pages = {546--555},
title = {{Location estimation for indoor autonomous vehicle navigation by omni-directional vision using circular landmarks on ceilings}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-63149179151{\&}doi=10.1016{\%}2Fj.robot.2008.10.001{\&}partnerID=40{\&}md5=937e12af91356edc83713f02cf63da8f},
volume = {57},
year = {2009}
}
@article{Bonani200911,
abstract = {We present a novel approach to mobile object manipulation for service in indoor environments. Current research in service robotics focus on single robots able to move, manipulate objects, and transport them to various locations. Our approach differs by taking a collective robotics perspective: different types of small robots perform different tasks and exploit complementarity by collaborating together. We propose a robot design to solve one of these tasks: climbing vertical structures and manipulating objects. Our robot embeds two manipulators that can grasp both objects or structures. To help climbing, it uses a rope to compensate for the gravity force. This allows it to free one of its manipulators to interact with an object while the other grasps a part of a structure for stabilization. Our robot can launch and retrieve the rope autonomously, allowing multiple ascents. We show the design and the implementation of our robot and demonstrate the successful autonomous retrieval of a book from a shelf. {\textcopyright} 2009 Springer-Verlag Berlin Heidelberg.},
annote = {cited By 23},
author = {Bonani, M and Magnenat, S and R{\'{e}}tornaz, P and Mondada, F},
doi = {10.1007/978-3-642-10817-4_2},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Collective robotics; Gravity forces; Indoor enviro,Machine design; Manipulators; Robotics; Rope,Robots},
pages = {11--22},
title = {{The hand-bot, a robot design for simultaneous climbing and manipulation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-76649085873{\&}doi=10.1007{\%}2F978-3-642-10817-4{\_}2{\&}partnerID=40{\&}md5=216ce03336b57d98c4c87c58825d6036},
volume = {5928 LNAI},
year = {2009}
}
@inproceedings{Zhang2014529,
abstract = {Transceiver-free object localization is essential for emerging location-based service, e.g., the safe guard system and asset security. It can track indoor target without carrying any device and has attracted many research effort. Among these technologies, Radio Signal Strength (RSS) based approaches are very popular because of their low-cost and wide applicability. In such work, usually a large number of reference nodes have to be deployed. However, if in a very large area, many labor work to measure the positions of the reference nodes have to be performed, result in not practical in real scenario. In this paper, we propose Double Free, which can accurately track transceiver-free object without measuring the positions of the reference nodes. Users may randomly deploy nodes in a 2D area, e.g., the ceiling of the floor. Our Double Free contains two steps: reference node localization and target localization. The key to achieve the first step is to utilize the RSS difference in different channel to distinguish the Line-Of-Sight (LOS) signal from combined multiple paths' signal. Thus, the reference nodes can be accurately localized without additional hardware. In the second step, we propose two algorithms: Influential Link {\&} Node (ILN) and MultiPath Distinguishing (MD). ILN is simple to implement, while MD can accurately model the additional signal caused by the target, then accurately localize the target. To implement this idea, 16 TelosB nodes are placed randomly in a 2510m2 laboratory. The experiment results show, the average localization error is only round 2 meters without requiring to measure the positions of reference nodes in advance. It shows enormous potential in those localization areas, where manual measurement is hard to perform, or hard labor work want to be saved. {\textcopyright} 2014 IEEE.},
annote = {cited By 3},
author = {Zhang, D and Jiang, X and Ni, L M},
booktitle = {Proceedings of the International Conference on Parallel Processing},
doi = {10.1109/ICPP.2014.62},
keywords = {Free Localization; Indoor localization; Line of s,Location based services; RSS; Telecommunication se,Radio transceivers},
number = {November},
pages = {529--538},
title = {{Double Free: Measurement-Free Localization for Transceiver-Free Object}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932614649{\&}doi=10.1109{\%}2FICPP.2014.62{\&}partnerID=40{\&}md5=9bca40498b6c9a9d729c7f96be0871d7},
volume = {2014-Novem},
year = {2014}
}
@inproceedings{Maneerat2015244,
abstract = {Among different Wireless Indoor Positioning Systems (WIPS) that utilize radio frequency signal to estimation an object location, the system that uses Received Signal Strength (RSS) of the wireless transceiver, such as the fingerprinting approach, has gained lot of attention and been deployed widely. This paper presents a novel wireless indoor positioning approaches based on fingerprinting technique called Fusion parameter technique with temperature level (FUSTL). The proposed technique takes into account an environmental data in conjunction with RSS information in the fingerprinting database. The environmental data, such as room temperature and humidity, is used to classify different zones of the service areas. This information could help facilitate the RSS matching process of the fingerprinting technique. The performance of the proposed algorithm is compared with those of different indoor positioning techniques in literature. The experimental results shows that the proposed technique outperformed the other techniques and can provide the highest of accuracy and precision performance at the lowest computational complexity. Specifically, the positioning accuracy of our proposed technique is 15-27{\%} higher than those of the other techniques whereas the computational complexity of our technique is 12-36{\%} lower than those of the other techniques. {\textcopyright} 2015 IEEE.},
annote = {cited By 1},
author = {Maneerat, K and Prommak, C},
booktitle = {25th International Telecommunication Networks and Applications Conference, ITNAC 2015},
doi = {10.1109/ATNAC.2015.7366820},
keywords = {Accuracy and precision; fingerprinting; Fingerpri,Complex networks; Computational complexity; Freque,Indoor positioning systems},
pages = {244--249},
title = {{Low complexity Wireless Indoor Positioning approaches based on fingerprinting techniques}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963771219{\&}doi=10.1109{\%}2FATNAC.2015.7366820{\&}partnerID=40{\&}md5=aaadb8340987c2d81662902098893466},
year = {2015}
}
@article{Kuo2008678,
abstract = {Signal strength fluctuation is one of the major problems in a fingerprint-based localization system. To alleviate this problem, we propose a scrambling method to exploit temporal diversity and spatial dependency of collected signal samples. We present methods on how these properties can be applied to enhance the positioning accuracy of several existing schemes. Simulation studies and experimental results show that the scrambling method can greatly improve positioning accuracy, especially when the tracked object has some degree of mobility. {\textcopyright} 2007 IEEE.},
annote = {cited By 73},
author = {Kuo, S.-P. and Tseng, Y.-C.},
doi = {10.1109/TKDE.2007.190730},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Computer science; Encoding (symbols); Power contr,Context Awareness; Indoor Positioning; Location Tr,Sensor networks},
number = {5},
pages = {678--684},
title = {{A scrambling method for fingerprint positioning based on temporal diversity and spatial dependency}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-52349106204{\&}doi=10.1109{\%}2FTKDE.2007.190730{\&}partnerID=40{\&}md5=e9f99e27001f99378b8247cb67d523e0},
volume = {20},
year = {2008}
}
@inproceedings{Liu20183658,
abstract = {We propose a single image-based 3D model retrieval method for indoor scenes. By simulating the scene context of the input image, our method is able to handle several challenging scenarios featuring cluttered backgrounds and severe occlusions. To use our system, the user only needs to drag a few semantic bounding boxes for the query objects. The proposed approach then retrieves the most similar 3D models from the ShapeNet model repository, and aligns them with the corresponding objects automatically. This requires that the 3D models are represented by calibrated view-dependent visual elements learned from the rendered views. With the estimated occlusion relationships, the rendered model images are stacked at the corresponding locations to simulate the scene context. By conducting matching between these synthesized scenes and the input image, the most similar 3D models under the approximate poses are retrieved. Moreover, we show that the retrieving time can be significantly reduced based on a novel greedy algorithm. Experimental results demonstrate the effectiveness of our proposed method. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Liu, M and Zhang, Y and He, J and Guo, J and Guo, Y},
booktitle = {Proceedings - International Conference on Image Processing, ICIP},
doi = {10.1109/ICIP.2018.8451547},
keywords = {3 d model retrievals; 3D model retrieval methods;,3D modeling; Image retrieval; Rendering (computer,Image processing},
pages = {3658--3662},
title = {{Image-Based 3D Model Retrieval for Indoor Scenes by Simulating Scene Context}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062923439{\&}doi=10.1109{\%}2FICIP.2018.8451547{\&}partnerID=40{\&}md5=98079de8f33299960247e4acd1e9673a},
year = {2018}
}
@inproceedings{Shen2011253,
abstract = {Ultra-wideband (UWB) radios offer highly accurate ranging, i.e., measurement of signal travel time. This is important for positioning (localization), in particular in indoor environments, where GPS is not available. This paper considers UWB-based positioning of passive objects, where one transmitter and multiple, distributed, receivers are employed. We consider the case where the transmitter and receivers can be synchronized, so that time-of-arrival (TOA) instead of time-difference-of-arrival (TDOA) information can be utilized. Assuming Gaussian errors for the range estimates, we propose a novel, Two-Step, Expectation Maximization (TSEM) based algorithm for the localization of the passive object. This algorithm achieves the Cramer-Rao Lower Bound (CRLB) of TOA algorithms. Simulation results show that the error variance of TSEM is much lower (often 30 dB) than that of the existing, TDOA-based, algorithms. {\textcopyright} 2011 IEEE.},
annote = {cited By 11},
author = {Shen, J and Molisch, A F},
booktitle = {Proceedings - IEEE International Conference on Ultra-Wideband},
doi = {10.1109/ICUWB.2011.6058839},
keywords = {Algorithms; Cramer-Rao bounds; Estimation; Transm,Cramer-rao lower bound; CRLB; Error variance; Expe,Ultra-wideband (UWB)},
pages = {253--257},
title = {{Passive location estimation using TOA measurements}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-82455164459{\&}doi=10.1109{\%}2FICUWB.2011.6058839{\&}partnerID=40{\&}md5=43f086f5319bfc0b895183b11560963d},
year = {2011}
}
@inproceedings{Chenning2018,
abstract = {This study presents a novel method that utilizes Region-based Convolution Neural Network (R-CNN) for identifying objects in an image, and then, localizes the image using a pre-stored map of these objects. The algorithm follows the next steps. First, an image, taken by a smart phone, is uploaded to the server, where a pre-trained R-CNN and template images are combined to identify the objects in the image. In the second step, the location of the image is derived according to the spatial relationships of the objects in the image with a prior knowledge of the objects location in a digital map. Finally, if more than one location solutions are obtained from the previous step, a range-based localization method is utilized to eliminate the wrong results. To prove the concept, a test is conducted in typical yet challenging indoor environment. Selected objects were labeled in 600 images, taken randomly around the test environment, to train the R-CNN and used for template matching. Another 42 images, with known capture locations, were utilized to assess the performance of the method. The proposed object-based indoor localization method detected 81.7{\%} of the objects in the images, and provided 59.5{\%} success rate with 1-5 m accuracy. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Chenning, L and Ting, Y and Qian, Z and Haowei, X},
booktitle = {2018 IEEE International Conference on Signal Processing, Communications and Computing, ICSPCC 2018},
doi = {10.1109/ICSPCC.2018.8567795},
keywords = {Convolution neural network; Convolutional neural,Convolution; Environmental testing; Location; Neur,Indoor positioning systems},
title = {{Object-based Indoor Localization using Region-based Convolutional Neural Networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060480563{\&}doi=10.1109{\%}2FICSPCC.2018.8567795{\&}partnerID=40{\&}md5=7a36a88de331b288815ccba014a62631},
year = {2018}
}
@inproceedings{Li20181,
abstract = {This paper describes the structure, design and implementation of a building/environment data and information system, called BeDIS for short. It is designed to support fine-scale, location-specific services provided by smart devices and mobile applications in large smart buildings. Structured as a fog, it remains responsive when overloaded and degrades gracefully when network connection is disrupted and parts of it damaged. During normal times, it enables hundreds and thousands of people to locate themselves sufficiently accurately and navigate amidst dense crowd and moving objects via their mobile phones. When triggered by a disaster/emergency alert from responsible government agencies or the building safety system, BeDIS functions as a system of micro data servers for delivering location- and situation-specific emergency response instructions to people and decision support data to active smart devices and applications within fractions of a second to seconds. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Li, C C and Wu, P and Wang, H and Chu, E T H and Liu, J W S},
booktitle = {2018 IEEE 2nd International Conference on Fog and Edge Computing, ICFEC 2018 - In conjunction with 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing, IEEE/ACM CCGrid 2018},
doi = {10.1109/CFEC.2018.8358731},
keywords = {Cluster computing; Decision support systems; Edge,Data and information; Decision supports; Design a,Emergency services},
pages = {1--8},
title = {{Building/environment Data/information System for Fine-Scale Indoor Location Specific Services}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048113019{\&}doi=10.1109{\%}2FCFEC.2018.8358731{\&}partnerID=40{\&}md5=d1b87a2212bada6fca7c601f5df9018c},
year = {2018}
}
@article{Talebi201826219,
abstract = {Doors are a significant object for the visually impaired and robots to enter and exit buildings. Although the accuracy of door detection is reported high in indoor scenes, it has become a difficult problem in outdoor scenes in computer vision. The reason may lie in the fact that such properties of a simple ordinary door such as handles, corners, and the gap between the door and the ground may not be visible due to the great variety of doors in outdoor environments. In this paper, we present a vision-based method for detecting building entrances in outdoor images. After extracting the lines and deleting the extra ones, regions between the vertical lines are specified and the features including height, width, location, color, texture and the number of lines inside the regions are obtained. Finally, some additional knowledge such as door existence at the bottom of the image, a reasonable height and width of a door, the difference between color and texture of the doors and those of the neighboring regions, and numerous lines on doors is used to decide on door detection. The method was tested on the eTRIMS dataset, door images from the ImageNet dataset, and our own dataset including doors of houses, apartments, and stores leading to acceptable results. The obtained results show that our approach outperforms comparable state-of-the-art approaches. {\textcopyright} 2018, Springer Science+Business Media, LLC, part of Springer Nature.},
annote = {cited By 0},
author = {Talebi, M and Vafaei, A and Monadjemi, A},
doi = {10.1007/s11042-018-5846-3},
journal = {Multimedia Tools and Applications},
keywords = {Additional knowledge; Color and textures; Door de,Color; Image processing; Image texture; Textures,Doors},
number = {20},
pages = {26219--26238},
title = {{Vision-based entrance detection in outdoor scenes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052739428{\&}doi=10.1007{\%}2Fs11042-018-5846-3{\&}partnerID=40{\&}md5=316a834ab2e0bd06f8bd4e098e9397ae},
volume = {77},
year = {2018}
}
@inproceedings{Hedley201292,
abstract = {In this paper we present a practical system for indoor tracking that is low-cost, quick and simple to setup, and accurate. The system consists of three types of nodes, GPS referenced anchor nodes, static nodes placed at fixed locations within a building, and mobile tags that are attached to objects to be tracked. The network of anchor and static nodes must be setup to be globally rigid which allows a unique determination of the location of the static nodes using cooperative localization. The static and anchor nodes are then used as the reference for tracking the mobile tags. We describe a technique to identify static nodes that cannot be uniquely solved so that they can be augmented or removed, and then present a fast and distributed algorithm for determining the locations of the rigid static nodes. We also present an algorithm based on particle filters for tracking the tags that utilizes the knowledge of the range error distribution. Finally we present results obtained using our WASP (Wireless Ad-hoc System for Positioning) platform in an indoor office environment. {\textcopyright} 2012 IEEE.},
annote = {cited By 1},
author = {Hedley, M and Sathyan, T},
booktitle = {Record - IEEE PLANS, Position Location and Navigation Symposium},
doi = {10.1109/PLANS.2012.6236869},
keywords = {Ad hoc systems; Anchor nodes; Cooperative localiza,Algorithms,Distributed computer systems; Nonlinear filtering},
pages = {92--97},
title = {{Rapid mesh network setup for indoor RF tracking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866240626{\&}doi=10.1109{\%}2FPLANS.2012.6236869{\&}partnerID=40{\&}md5=754c463faa6acbeb1c09cc85c1da3beb},
year = {2012}
}
@inproceedings{Djaja-Josko201795,
abstract = {Nowadays, indoor localization systems gain more and more attention, as demand for the services employing data on the indoor position of the objects and people is growing. There are many techniques used for position calculation. The most popular rely on measurements of radio wave propagation times. Most of the systems' architectures consist of localized tags and fixed-positioned anchor nodes. Knowledge on the precise localization of the nodes is often crucial for correct calculation of the tags' positions. Therefore, for robust system's exploitation a method for evaluating and correcting shifted anchor's position is necessary. Such method is presented in the paper, along with the explanation of the proposed algorithm and experimental results. {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Djaja-Josko, V and Kolakowski, J},
booktitle = {2017 IEEE International Conference on RFID Technology and Application, RFID-TA 2017},
doi = {10.1109/RFID-TA.2017.8098887},
keywords = {Anchor nodes; Indoor localization; Indoor localiz,Broadband networks; Radio waves; Ultra-wideband (U,Indoor positioning systems},
pages = {95--99},
title = {{A new method for shifted anchor coordinates retrieval in UWB positioning system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040743050{\&}doi=10.1109{\%}2FRFID-TA.2017.8098887{\&}partnerID=40{\&}md5=d1024cf5c11337e35e10046e1dd20314},
year = {2017}
}
@inproceedings{Schelkshorn2008172,
abstract = {Nowadays knowledge about the position of persons indoors is relevant for a huge number of problems. An increasing number of modern applications and services is based on information refering to the users actual position and in some cases also on its velocity. In addition to these location based services also safety and security relevant tasks require these informations, e. g. critical infrastructure (CI) or small area surveillance. In outdoor scenarios the GPS-System is often used, but not all of the already existing wireless infrastructure is capable of providing the position information needed, especially in indoor environments. For this case several approaches can be found in the literature. Most of them adopt the GPS-principle thus needing additional infrastructure and objects actively participating in the position finding task. We will present a system that is based on doppler measurement and only analyses a relative distance information between the object to be detected and four very basic sensors. Therefore no cooperation of the object is needed which is very important for the mentioned security relevant applications. The design of a 4-channel demonstration system will be shown and practical results obtained with this demonstration system will be given. {\textcopyright} 2008 EuMA.},
annote = {cited By 1},
author = {Schelkshorn, S and Detlefsen, J},
booktitle = {2008 5th European Radar Conference Proceedings, EuRAD 2008},
keywords = {Critical infrastructures; Doppler measurements; D,Global positioning system; Radar,Sensors},
pages = {172--175},
title = {{Position finding based on multiple doppler sensors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-63149132603{\&}partnerID=40{\&}md5=379fef9ea703f57ef02e57bb067f59b7},
year = {2008}
}
@article{Passarinho2011466,
abstract = {This paper proposes a method combining local SVM classifiers and a Kalman filter to track faces in color video sequences, which is referred to as the Dynamic Local Support Vector Tracker (DLSVT). The adjacent locations of the target point are predicted in a search window, reducing the number of image regions that are candidates to be faces. Thus, the method can predict the object motion more accurately. The architecture presented good results for both indoor and outdoor unconstrained videos, considering multi-view scenes containing partial occlusion and bad illumination. Moreover, the reduction of the image area in which the face is searched for results in a method that is faster, besides being precise. {\textcopyright} 2011 Springer-Verlag.},
annote = {cited By 0},
author = {Passarinho, C J P and Salles, E O T and Sarcinelli-Filho, M},
doi = {10.1007/978-3-642-24031-7_47},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Color video; Detection and tracking; Image regions},
number = {PART 2},
pages = {466--475},
title = {{Detection and tracking faces in unconstrained color video streams}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053346299{\&}doi=10.1007{\%}2F978-3-642-24031-7{\_}47{\&}partnerID=40{\&}md5=a07efef09655addee4b4a7fdbecdea79},
volume = {6939 LNCS},
year = {2011}
}
@inproceedings{Abdat2010,
abstract = {Indoor positioning remains a challenging research area to be explored. Various kind of indoor positioning systems (IPSs) have been developed based on different techniques and technologies. Parameters such as distance, objects and location of access points can greatly affect the power of received signal strength. In this paper we discuss several existing IPSs and the techniques used with their unique strengths as well as its weaknesses. In addition, this paper elaborates the need of adaptive systems which can be the solution where other systems are unable to accomplish. Finally the reviewed techniques will be evaluated based on its complexity, accuracy and deployment cost to determine its capability in addressing issues in indoor wireless positioning. {\textcopyright} 2010 University Sains Malaysia.},
annote = {cited By 8},
author = {Abdat, M and Wan, T.-C. and Supramaniam, S},
booktitle = {2010 International Conference on Distributed Frameworks for Multimedia Applications, DFmA 2010},
keywords = {Access points; Deployment costs; Indoor positionin,Adaptive systems,Navigation systems},
title = {{Survey on indoor wireless positioning techniques: Towards adaptive systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052019960{\&}partnerID=40{\&}md5=6bf1dbb0ecfe3c227747c10699d4e7d7},
year = {2010}
}
@inproceedings{Malekpour2008488,
abstract = {In recent years, the employment of IEEE 802.11 radio signals for location determination in an indoor environment has drawn great attention. The basis of this technique is that the location of an object is estimated using an estimation algorithm and the radio frequency (RF) fingerprint database as a reference. The main target of this paper is to find an optimum strategy for the construction of the RF map and a decent estimation algorithm. By obtaining statistical data from several signal strength measurements, we investigate and identify three influential factors on the RSSI behavior. With this knowledge, we propose improvement to the existing deterministic algorithm. An algorithm for detection of and dealing with the aliasing problem is also suggested. Test results show that our proposed combinational deterministic method and the anti aliasing technique improves the system performance by up to 33{\%} compared to other deterministic method using single scalar values. {\textcopyright} 2008 IEEE.},
annote = {cited By 18},
author = {Malekpour, A and Ling, T C and Lim, W C},
booktitle = {Proceedings of the 6th Annual Communication Networks and Services Research Conference, CNSR 2008},
doi = {10.1109/CNSR.2008.32},
keywords = {Algorithms; Conformal mapping; Estimation; Radio w,Aliasing; Aliasing problems; Antialiasing; Commun,Frequency estimation},
pages = {488--495},
title = {{Location determination using radio frequency RSSI and deterministic algorithm}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-49649090826{\&}doi=10.1109{\%}2FCNSR.2008.32{\&}partnerID=40{\&}md5=8a1bcc40c3711776ee00e8ef814bd115},
year = {2008}
}
@inproceedings{Lin2013,
abstract = {Wireless sensor networks have been widely used in many applications. One of them is indoor guiding service for emergency evacuation whose goal is to assist moving objects in escaping a hazardous region safely and quickly when an emergency occurs. In this paper, we propose a distributed and adaptive guiding protocol that takes several factors such as hazardous regions, distance to exits, width of exits, and congestion degree of each location into consideration. This protocol guides moving objects with load balancing among multiple navigation paths to multiple exits and avoids congestion to reduce the evacuation time. Simulation results show that the proposed protocol can guide moving objects (e.g., people) to exits in shorter time and have higher survival rate in comparison to those without balancing the traffic load on navigation paths and exits. {\textcopyright} 2013 IEEE.},
annote = {cited By 3},
author = {Lin, C.-H. and Chen, P.-Y. and Chen, W.-T.},
booktitle = {IEEE Vehicular Technology Conference},
doi = {10.1109/VTCSpring.2013.6691867},
keywords = {Crowd evacuation; Emergency evacuation; Emergency,Navigation,Wireless sensor networks},
title = {{An adaptive guiding protocol for crowd evacuation based on wireless sensor networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893584982{\&}doi=10.1109{\%}2FVTCSpring.2013.6691867{\&}partnerID=40{\&}md5=3ef5f91b2fb3f9d4f8f940d628b41045},
year = {2013}
}
@inproceedings{Feng20061132,
abstract = {Augmented reality system is well suited for Computer Supported Cooperative Work. For achieving Visual realism, correctly handling and representing occlusion between virtual and real objects in Augmented Reality scene is essential. Here, we present an approach for realizing multilayer occlusion. Differing qualitatively from previous work in AR occlusion, our algorithm realizes multilayer occlusion, and its application domain involves indoor-field occluded objects, which are several meters distant from the viewer. Previous related work has focused on monolayer occlusion, and near-field occluded objects, which are within or just beyond arm's reach. We designed a special scene graph tree comprised of sume special nodes, namely EMO nodes. According to the location of real moving object, different FMO node will be activated in real-time, consequently realizing the multilayer occlusion. Experimental results are provided to demonstrate the multilayer indoor-field occlusion. {\textcopyright} 2006 IEEE.},
annote = {cited By 5},
author = {Feng, Y and Du, W and Guan, X and Gao, F and Chen, Y},
booktitle = {Proceedings - 2006 10th International Conference on Computer Supported Cooperative Work in Design, CSCWD 2006},
doi = {10.1109/CSCWD.2006.253124},
keywords = {Algorithms; Computer supported cooperative work; G,Alpha channels; EMO node; Multilayer occlusion; S,Virtual reality},
pages = {1132--1136},
title = {{Realization of multilayer occlusion between real and virtual scenes in augmented reality}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547660409{\&}doi=10.1109{\%}2FCSCWD.2006.253124{\&}partnerID=40{\&}md5=68211fe3edfaf8de8ba2051f704b1502},
year = {2006}
}
@article{Cupec2015674,
abstract = {This paper considers the potential of using three-dimensional (3D) planar surfaces and line segments detected in depth images for place recognition. A place recognition method is presented that is based on matching sets of surface and line features extracted from depth images provided by a 3D camera to features of the same type contained in a previously created environment model. The considered environment model consists of a set of local models representing particular locations in the modeled environment. Each local model consists of planar surface segments and line segments representing the edges of objects in the environment. The presented method is designed for indoor and urban environments. A computationally efficient pose hypothesis generation approach is proposed that ranks the features according to their potential contribution to the pose information, thereby reducing the time needed for obtaining accurate pose estimation. Furthermore, a robust probabilistic method for selecting the best pose hypothesis is proposed that allows matching of partially overlapping point clouds with gross outliers. The proposed approach is experimentally tested on a benchmark dataset containing depth images acquired in the indoor environment with changes in lighting conditions and the presence of moving objects. A comparison of the proposed method to FAB-MAP and DLoopDetector is reported. {\textcopyright} The Author(s) 2015.},
annote = {cited By 7},
author = {Cupec, R and Nyarko, E K and Filko, D and Kitanov, A and Petrovi, I},
doi = {10.1177/0278364914548708},
journal = {International Journal of Robotics Research},
keywords = {Cameras,Computer vision,Line segment; Place recognition; Planar surface;},
number = {4-5},
pages = {674--704},
title = {{Place recognition based on matching of planar surfaces and line segments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928004833{\&}doi=10.1177{\%}2F0278364914548708{\&}partnerID=40{\&}md5=10ba8d5d956027236e34828698aa877d},
volume = {34},
year = {2015}
}
@article{Yi2009747,
abstract = {This paper proposes a cognitive representation and Bayesian model for spatial relations among objects that can be constructed with perception data acquired by a single consumer-grade camera. We first suggest a cognitive representation to be shared by humans and robots consisting of perceived objects and their spatial relations. We then develop Bayesian models to support our cognitive representation with which the location of a robot can be estimated sufficiently well to allow the robot to navigate in an indoor environment. Based on extensive localization experiments in an indoor environment, we show that our cognitive representation is valid in the sense that the localization accuracy improves whenever new objects and their spatial relations are detected and instantiated. {\textcopyright} 2009 Springer Berlin Heidelberg.},
annote = {cited By 3},
author = {Yi, C and Suh, I H and Lim, G H and Jeong, S and Choi, B.-U.},
doi = {10.1007/978-3-642-02490-0_91},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Bayesian model; Indoor environment; Localization a,Bayesian networks; Data processing; Robot applica,Robots},
number = {PART 1},
pages = {747--754},
title = {{Cognitive representation and bayeisan model of spatial object contexts for robot localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349109188{\&}doi=10.1007{\%}2F978-3-642-02490-0{\_}91{\&}partnerID=40{\&}md5=112615de54226452c8559de98880a3b4},
volume = {5506 LNCS},
year = {2009}
}
@article{Khan20161,
abstract = {Inexpensive structured light sensors can capture rich information from indoor scenes, and scene labeling problems provide a compelling opportunity to make use of this information. In this paper we present a novel conditional random field (CRF) model to effectively utilize depth information for semantic labeling of indoor scenes. At the core of the model, we propose a novel and efficient plane detection algorithm which is robust to erroneous depth maps. Our CRF formulation defines local, pairwise and higher order interactions between image pixels. At the local level, we propose a novel scheme to combine energies derived from appearance, depth and geometry-based cues. The proposed local energy also encodes the location of each object class by considering the approximate geometry of a scene. For the pairwise interactions, we learn a boundary measure which defines the spatial discontinuity of object classes across an image. To model higher-order interactions, the proposed energy treats smooth surfaces as cliques and encourages all the pixels on a surface to take the same label. We show that the proposed higher-order energies can be decomposed into pairwise sub-modular energies and efficient inference can be made using the graph-cuts algorithm. We follow a systematic approach which uses structured learning to fine-tune the model parameters. We rigorously test our approach on SUN3D and both versions of the NYU-Depth database. Experimental results show that our work achieves superior performance to state-of-the-art scene labeling techniques. {\textcopyright} 2015, Springer Science+Business Media New York.},
annote = {cited By 13},
author = {Khan, S H and Bennamoun, M and Sohel, F and Togneri, R and Naseem, I},
doi = {10.1007/s11263-015-0843-8},
journal = {International Journal of Computer Vision},
keywords = {Approximate geometries; Conditional random field;,Geometry; Graphic methods; Inference engines; Pixe,Image segmentation},
number = {1},
pages = {1--20},
title = {{Integrating Geometrical Context for Semantic Labeling of Indoor Scenes using RGBD Images}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960385363{\&}doi=10.1007{\%}2Fs11263-015-0843-8{\&}partnerID=40{\&}md5=d9c5ade8ec43813268922facc7a042bc},
volume = {117},
year = {2016}
}
@inproceedings{Xu2011760,
abstract = {Localization is of great importance in mobile and wireless network applications. TDOA is one of the widely used localization schemes, in which a to-be-located object emits a signal and a number of receivers record the arriving time of the signal. By calculating the time difference of different receivers, the location of the object is estimated. In such a scheme, receivers must be precisely synchronized; even slight noises are completely unacceptable for centimeter-level localization. Previous studies have shown that existing time synchronization approaches for low-cost devices are insufficiently accurate and basically infeasible for high accuracy localization. In our scheme (called Whistle), several asynchronous receivers record a target signal and a successive signal that is generated artificially. By two-signal sensing and sample counting techniques, high time resolution can be achieved. This design fundamentally changes TDOA in the sense of releasing the synchronization requirement and avoiding many sources of inaccuracy. We implement Whistle on commercial off-the-shelf (COTS) cell phones. Through extensive real-world experiments in indoor and outdoor, quiet and noisy environments, the mean error is 1020 centimeters in a 9  9  4m 3 3D space. {\textcopyright} 2011 IEEE.},
annote = {cited By 26},
author = {Xu, B and Yu, R and Sun, G and Yang, Z},
booktitle = {Proceedings - International Conference on Distributed Computing Systems},
doi = {10.1109/ICDCS.2011.30},
keywords = {3-D space; Cell phone; Commercial-off-the-shelf; H,Distributed computer systems; Synchronization,Signal receivers},
pages = {760--769},
title = {{Whistle: Synchronization-free TDOA for localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051900314{\&}doi=10.1109{\%}2FICDCS.2011.30{\&}partnerID=40{\&}md5=68b995c55008c7345892accfecc45dfb},
year = {2011}
}
@article{Reza200967,
abstract = {One of the biggest challenges in RFID (radio frequency identification) large scale deployment, such as in warehouse RFID deployment, is the positioning of RFID reader antennas to efficiently locate all the tagged objects distributed at RFID reader environment. This paper has investigated a novel location sensing system based on geometric grid covering algorithm that can use any passive or active RFID standard for positioning or tracking objects inside buildings. This study involves design of RFID reader antenna network which focuses on placing the reader antennas on a grid to cover all the tags distributed at two dimensional planes and position calculation using statistical averages algorithm. The statistical averages algorithm simply computes the location coordinates of the tagged object by statistical average of the reader antenna's location. The proposed grid of reader antennas can assist in minimizing the actual number of reader antennas required for RFID large scale deployment. The proposed prototype system is a simpler positioning system which presents the solution of placement pattern of RFID reader antennas, gives less complicated mathematical calculation, and is able to provide a high degree of accuracy. The obtained results show that the proposed location sensing system can achieve better positioning accuracy as compared to existing positioning system and in some cases accuracy improvement of about 50{\%} can be reached. {\textcopyright} 2008 Springer Science+Business Media, LLC.},
annote = {cited By 34},
author = {Reza, A W and Geok, T K},
doi = {10.1007/s11277-008-9556-4},
journal = {Wireless Personal Communications},
keywords = {Accuracy Improvement; Active RFID; Covering algori,Algorithms; Radio frequency identification (RFID),Antennas},
number = {1},
pages = {67--80},
title = {{Investigation of indoor location sensing via RFID reader network utilizing grid covering algorithm}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77649184510{\&}doi=10.1007{\%}2Fs11277-008-9556-4{\&}partnerID=40{\&}md5=2943277a03b2867c32d03f829d79a4d0},
volume = {49},
year = {2009}
}
@inproceedings{Chianese2013,
abstract = {In this paper, we present an ongoing project developed within DATABENC, a high technology district for Cultural Heritage management. In particular, the project aims at exploiting several location-based services and technologies to realize a smart multimedia guide system able to detect user position and make objects of a museum exhibition able to "talk" during tourists' visit and capable of automatically telling their story using multimedia facilities. Moreover, we have deployed in the museum rooms a particular Wireless Sensor Network (WSN) that, using Bluetooth technology, is able to sense the surrounding area for detecting user devices' presence. Once a device has been detected, the related MAC address is retrieved and multimedia contents of the closest museum artworks are delivered to user using proper multimedia delivery techniques to facilitate and make more stimulating the visit. As case of study, we show an example of "talking" museum as a smart multimedia guide of sculptures' art exhibition within the Maschio Angioino castle, in Naples (Italy). {\textcopyright} 2013 IEEE.},
annote = {cited By 27},
author = {Chianese, A and Marulli, F and Moscato, V and Piccialli, F},
booktitle = {2013 International Conference on Indoor Positioning and Indoor Navigation, IPIN 2013},
doi = {10.1109/IPIN.2013.6851448},
keywords = {Bluetooth technology; Contextual navigation; Cult,Exhibitions,Location based services; Museums; Navigation; Wire},
title = {{A "smart" multimedia guide for indoor contextual navigation in Cultural Heritage applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904581677{\&}doi=10.1109{\%}2FIPIN.2013.6851448{\&}partnerID=40{\&}md5=a2ed7ba365db19484e6bc1a3ddf8332a},
year = {2013}
}
@inproceedings{Tabibiazar20111986,
abstract = {Location based services in wireless sensor networks are quite demanding applications especially in indoors, such that accurate localization of objects and people in indoor environments has long been considered as one of important building blocks in wireless systems. In this paper, we investigate sensor location estimation problem where a target sensor measures inconsistent signals as received-signal-strength or time-of-arrival from anchor sensors with known locations, whereas target sensor location must be estimated. We know that even in large scale wireless sensor networks, information are relatively sparse compared with the number of sensors. In such networks, the localization problem can be recast as a sparse signal recovery problem in the discrete spatial domain from a small number of linear measurements by solving an under-determined linear system. By exploiting the compressive sensing theory, sparse signals can be recovered from far fewer samples than Nyquist sampling rate. Our approach uses a few number of inconsistent measurements to find the wireless device location over a non-symmetric spatial grid. In this method, an  1-norm minimization program is used to recover the wireless user location. The performance of the proposed method is evaluated through simulations with synthetic and real measurements. {\textcopyright} 2011 IEEE.},
annote = {cited By 13},
author = {Tabibiazar, A and Basir, O},
booktitle = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
doi = {10.1109/ICSMC.2011.6083963},
keywords = {Building blockes; compressive sensing; Indoor envi,Cybernetics; Linear systems; Recovery; Sensors; S,Wireless sensor networks},
pages = {1986--1991},
title = {{Compressive sensing indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-83755225491{\&}doi=10.1109{\%}2FICSMC.2011.6083963{\&}partnerID=40{\&}md5=5ded3910afb7d8328ce7d4475cbb5d4f},
year = {2011}
}
@inproceedings{Headley2007105,
abstract = {In this paper, we propose an indoor location positioning method for non-active objects (that is, objects that do not transmit radio waves) using ultra-wideband radios and a fingerprinting-like algorithm. This proposed method is based on pattern matching of the changes to the multipath intensity profile caused by the object to be located. Experimental results are reported, and the performance of the proposed method is evaluated. It is shown that the location of a non-active object can be determined with a very good degree of reliability by using commercial off-the-shelf ultra-wideband radios. The applications for this proposed method are numerous, especially in areas such as public safety and asset tracking. {\textcopyright}2007 IEEE.},
annote = {cited By 14},
author = {Headley, W C and {Da Silva}, C.R.C.M. and Buehrer, R M},
booktitle = {Proceedings - 2007 IEEE Radio and Wireless Symposium, RWS},
doi = {10.1109/RWS.2007.351743},
keywords = {Accident prevention; Algorithms; Electronic circui,Fingerprinting-like algorithm; Indoor positioning,Radio},
pages = {105--108},
title = {{Indoor location positioning of non-active objects using ultra-wideband radios}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548137407{\&}doi=10.1109{\%}2FRWS.2007.351743{\&}partnerID=40{\&}md5=876dc3daea128ef7be5a7735fec3be0d},
year = {2007}
}
@article{Ren201726,
abstract = {The existing three-dimensional (3D) object layout methods are focused mainly on indoor scenes and they are limited for outdoor applications. In this study, we propose a data-driven method for outdoor scene modeling by using fast retrieval and automatic optimization layout techniques. Unlike the current methods, we first employ an improved manifold ranking algorithm in the sketch-based 3D model retrieval stage, which achieves higher accuracy. Next, according to the particular properties of outdoor architectures, specialized constraints are then proposed to define an energy function, which meets both the functional and aesthetic requirements. Finally, we cast the auto-arrangement as a combinatorial optimization problem, which we solve using an optimization algorithm. In contrast to the earlier version of this method, which was presented at Cyberworlds 2016, this extended version combines simulated annealing and particle swarm optimization algorithms, which have the advantages of rapid convergence and avoiding becoming trapped by local minima. Our experimental results demonstrate that the proposed method is more intuitive and effective for modeling 3D scenes, and can be employed in the actual development of game scenes. {\textcopyright} 2017 Elsevier Ltd},
annote = {cited By 1},
author = {Ren, P and Fan, Y and Zhou, M and Wang, Z and Du, G and Qian, L},
doi = {10.1016/j.cag.2017.02.003},
journal = {Computers and Graphics (Pergamon)},
keywords = {Automatic layout; Combinatorial optimization prob,Combinatorial optimization; Image retrieval; Optim,Three dimensional computer graphics},
pages = {26--36},
title = {{Rapid three-dimensional scene modeling by sketch retrieval and auto-arrangement}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013996091{\&}doi=10.1016{\%}2Fj.cag.2017.02.003{\&}partnerID=40{\&}md5=ce6050ef999cc32a97b2528d369c7ebe},
volume = {64},
year = {2017}
}
@inproceedings{Hara2003560,
abstract = {Several techniques have been developed for recovering reflectance properties of real surfaces under unknown illumination conditions. However, in most cases, those techniques assume that the light sources are located at infinity, which cannot be applied to, for example, photometric modeling of indoor environments. In this paper, we propose two methods to estimate the surface reflectance property of an object, as well as the position of a light source from a single image without the distant illumination assumption. Given a color image of an object with specular reflection as an input, the first method estimates the light source position by fitting to the Lambertian diffuse component, while separating the specular and diffuse components by using an iterative relaxation scheme. Moreover, we extend the above method by using a single specular image as an input, thus removing its constraints on the diffuse reflectance property and the number of light sources. This method simultaneously recovers the reflectance properties and the light source positions by optimizing the linearity of a log-transformed Torrance-Sparrow model. By estimating the object's reflectance property and the light source position, we can freely generate synthetic images of the target object under arbitrary source directions and source-surface distances.},
annote = {cited By 21},
author = {Hara, K and Nishino, K and Ikeuchi, K},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
keywords = {H -infinity controls; Indoor environment; Optical,Image analysis; Source separation,Lambertian diffuse component; Surface reflectance,Light sources; Lighting; Mathematical models; Phot},
pages = {560--567},
title = {{Determining reflectance and light position from a single image without distant illumination assumption}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0345414062{\&}partnerID=40{\&}md5=6d4f93f73945bc57b955cadfb1afd330},
volume = {1},
year = {2003}
}
@inproceedings{Zhang2012,
abstract = {Network operators have a keen interest on knowledge about the coverage of their network in indoor environments. Mobile users use the mobile network indoors about 80{\%} of their time compared to outdoor. To identify coverage gaps it requires precise knowledge about the environment itself and the whereabout of the mobile terminal. This knowledge is lacking for two reasons. First the network driven time-based location solutions of the user is rather inaccurate for reasons like multi-path propagation or inaccurate synchronization. Furthermore, the indoor environment itself remains normally unknown for the network operators. However, the high density of users in indoor environments invites to explicitly use the potential peer-to-peer links between mobile terminals themselves. This would allow to position the mobile terminals relatively to each other. Positioning by using the peer-to-peer link is called cooperative positioning. This paper investigates the behavior of a distributed particle filter using nomadic movement behavior of the tracking objects. {\textcopyright} 2012 IEEE.},
annote = {cited By 2},
author = {Zhang, S and Raulefs, R},
booktitle = {5th International Symposium on Communications Control and Signal Processing, ISCCSP 2012},
doi = {10.1109/ISCCSP.2012.6217874},
keywords = {Computer terminals; Distributed computer systems;,Coverage gaps; Distributed particle filter; High d,Mobile phones},
title = {{Improved particle filtering by exploring nomadic movements}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864146525{\&}doi=10.1109{\%}2FISCCSP.2012.6217874{\&}partnerID=40{\&}md5=895f802e0aeca1ae696e35891ed1a365},
year = {2012}
}
@inproceedings{Antic20151251,
abstract = {Object, action, or scene representations that are corrupted by noise significantly impair the performance of visual recognition. Typically, partial occlusion, clutter, or excessive articulation affects only a subset of all feature dimensions and, most importantly, different dimensions are corrupted in different samples. Nevertheless, the common approach to this problem in feature selection and kernel methods is to down-weight or eliminate entire training samples or the same dimensions of all samples. Thus, valuable signal is lost, resulting in suboptimal classification. Our goal is, therefore, to adjust the contribution of individual feature dimensions when comparing any two samples and computing their similarity. Consequently, per-sample selection of informative dimensions is directly integrated into kernel computation. The interrelated problems of learning the parameters of a kernel classifier and determining the informative components of each sample are then addressed in a joint objective function. The approach can be integrated into the learning stage of any kernel-based visual recognition problem and it does not affect the computational performance in the retrieval phase. Experiments on diverse challenges of action recognition in videos and indoor scene classification show the general applicability of the approach and its ability to improve learning of visual representations. {\textcopyright} 2015 IEEE.},
annote = {cited By 4},
author = {Antic, B and Ommer, B},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.2015.148},
keywords = {Computational performance; Feature dimensions; In,Computer science; Computers; Electrical engineerin,Computer vision},
pages = {1251--1259},
title = {{Per-sample kernel adaptation for visual recognition and grouping}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973931771{\&}doi=10.1109{\%}2FICCV.2015.148{\&}partnerID=40{\&}md5=bc6315d130d26cbe4197023efcae1950},
volume = {2015 Inter},
year = {2015}
}
@article{Murillo2008512,
abstract = {An important component of human-robot interaction is the capability to associate semantic concepts with encountered locations and objects. This functionality is essential for visually guided navigation as well as location and object recognition. In this paper we focus on the problem of door detection using visual information only. Doors are frequently encountered in structured man-made environments and function as transitions between different places. We adopt a probabilistic approach for door detection, by defining the likelihood of various features for generated door hypotheses. Differing from previous approaches, the proposed model captures both the shape and appearance of the door. This is learned from a few training examples, exploiting additional assumptions about the structure of indoor environments. After the learning stage, we describe a hypothesis generation process and several approaches to evaluate the likelihood of the generated hypotheses. The approach is tested on numerous examples of indoor environment. It shows a good performance provided that the door extent in the images is sufficiently large and well supported by low level feature measurements. {\textcopyright} 2008 Elsevier B.V. All rights reserved.},
annote = {cited By 52},
author = {Murillo, A C and Ko{\v{s}}eck{\'{a}}, J and Guerrero, J J and Sag{\"{u}}{\'{e}}s, C},
doi = {10.1016/j.robot.2008.03.003},
journal = {Robotics and Autonomous Systems},
keywords = {Door detection; Generative models; Indoor object,Human computer interaction; Mathematical models; N,Object recognition},
number = {6},
pages = {512--521},
title = {{Visual door detection integrating appearance and shape cues}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-44249097243{\&}doi=10.1016{\%}2Fj.robot.2008.03.003{\&}partnerID=40{\&}md5=58ab5ae3fb5ee7a197dcc84983fd13f0},
volume = {56},
year = {2008}
}
@article{Powell20041964,
abstract = {We present a methodology for correcting color images taken in practical indoor environments, such as laboratories, factories, and studios, that explicitly models illuminant location, surface reflectance and geometry, and camera responsivity. We explicitly model surfaces by taking our color images with corresponding registered three-dimensional (3-D) range images, which provide surface orientation and location information for every point in the scene. We automatically detect regions where color correction should not be applied, such as specularities, coarse texture regions, and jump edges. This correction results in objective color measures of the imaged surfaces. This kind of integrated, comprehensive system of color correction has not existed until now. i.e., it is the first of its kind in computer vision. We demonstrate results of applying this methodology to real images for applications in photorealistic rerendering, skin lesion detection, burn scar color measurement, and general color image enhancement. We also have tested the method under different lighting configurations and with three different range scanners. {\textcopyright} 2004 IEEE.},
annote = {cited By 12},
author = {Powell, M W and Sarkar, S and Goldgof, D B and Ivanov, K},
doi = {10.1109/TSMCB.2004.832177},
journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics},
keywords = {Algorithms; Artificial Intelligence; Burns; Color,Algorithms; Cameras; Computational complexity; Com,Automated; Signal Processing,Burn scars; Color calibration; Color correction;,Color image processing,Computer-Assisted; Imaging,Computer-Assisted; Skin,Three-Dimensional; Pattern Recognition,algorithm; article; artificial intelligence; auto},
number = {5},
pages = {1964--1978},
title = {{A methodology for extracting objective color from images}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-4844231203{\&}doi=10.1109{\%}2FTSMCB.2004.832177{\&}partnerID=40{\&}md5=5723ecdf704611257000dc9f11539c10},
volume = {34},
year = {2004}
}
@inproceedings{Xie2015582,
abstract = {This paper focuses on a RFID-Based dynamic positioning scheme, aiming to locate an object by using a moving RFID reader and reference tags without recording any measurement data, e.g., the time of arrival (TOA) of the signal, or the received signal strength indication (RSSI). To address the problem of blindness of location path, a RFID-based positioning scheme with MATLAB GUI, is proposed based on the theory of the original dynamic positioning method. The status of all the tags read by moving reader can be monitored whenever necessary. Moreover, a power-adjustable method of location path is proposed for saving positioning time. Results of experiments indicate that the proposed dynamic positioning scheme is user-friendly control and can positioning accurately with low cost, which would be applied in localization of warehouse management in the future. {\textcopyright} 2015 IEEE.},
annote = {cited By 0},
author = {Xie, M and Wang, M and Liu, Z},
booktitle = {Proceedings - 2015 2nd International Conference on Information Science and Control Engineering, ICISCE 2015},
doi = {10.1109/ICISCE.2015.135},
keywords = {Control theory; Graphical user interfaces; Informa,Dynamic positioning,Indoor positioning; MATLAB GUI; Measurement data;},
pages = {582--586},
title = {{An RFID-based dynamic positioning scheme with MATLAB GUI}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938810565{\&}doi=10.1109{\%}2FICISCE.2015.135{\&}partnerID=40{\&}md5=5803aaccd834e9119a132c6a186c34aa},
year = {2015}
}
@inproceedings{Aizawa2010369,
abstract = {In this paper, we present our ongoing research on capture and processing of location logs of visitors in museum. We introduce importance of logging visitors' locations in museum, and comparisons of various localization techniques developed so far. Among the techniques potentially available, we focus on image-based localization: the visitor capture images of the objects in museum which is of his/her interest, then the images are compared to the image dataset which includes location tags, and find the possible locations of the user. We will present our preliminary experiments of the results of the image-based localization, which we have done in the Railway Museum of Japan. Capturing images during the visit finally results in the location logs of the visitor which benefit each individual and the museum. Copyright {\textcopyright} 2010 by the Association for Computing Machinery, Inc.},
annote = {cited By 1},
author = {Aizawa, K and Yamasaki, T and Kawaji, H and Kawamura, S},
booktitle = {Proceedings - VRCAI 2010, ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Application to Industry},
doi = {10.1145/1900179.1900256},
keywords = {Cameras; Image processing; Imaging systems; Indus,Capture images; Image datasets; Image-based; Indoo,Museums},
pages = {369--372},
title = {{Location identification for visitor behavior log in museum}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951831206{\&}doi=10.1145{\%}2F1900179.1900256{\&}partnerID=40{\&}md5=079d691ab6c744b9c305c7ebeaec2ed7},
year = {2010}
}
@inproceedings{Yang2014553,
abstract = {With the explosive growth of web-based cameras and mobile devices, billions of photographs are uploaded to the internet. We can trivially collect a huge number of photo streams for various goals, such as 3D scene reconstruction and other big data applications. However, this is not an easy task due to the fact the retrieved photos are neither aligned nor calibrated. Furthermore, with the occlusion of unexpected foreground objects like people, vehicles, it is even more challenging to find feature correspondences and reconstruct realistic scenes. In this paper, we propose a structure-based image completion algorithm for object removal that produces visually plausible content with consistent structure and scene texture. We use an edge matching technique to infer the potential structure of the unknown region. Driven by the estimated structure, texture synthesis is performed automatically along the estimated curves. We evaluate the proposed method on different types of images: from highly structured indoor environment to the natural scenes. Our experimental results demonstrate satisfactory performance that can be potentially used for subsequent big data processing: 3D scene reconstruction and location recognition. {\textcopyright} 2014 IEEE.},
annote = {cited By 11},
author = {Yang, J and Hua, K and Wang, Y and Wang, W and Wang, H and Shen, J},
booktitle = {Proceedings - IEEE INFOCOM},
doi = {10.1109/INFCOMW.2014.6849291},
keywords = {Big data,Computer graphics; Image reconstruction; Mobile de,Image completion; Object removal; Online Photos;},
pages = {553--558},
title = {{Automatic objects removal for scene completion}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904463970{\&}doi=10.1109{\%}2FINFCOMW.2014.6849291{\&}partnerID=40{\&}md5=2067a7c7cb260d5da4b8d53d2ebff8fc},
year = {2014}
}
@inproceedings{Lee2015404,
abstract = {This paper presents a location method for the mobile robots moving in the indoor environment by using the multi- projected texture stereo (PTS) cameras and a Wi-Fi Receiver. The proposed method is divided into three processes. First, a modulation of the multi-PTS cameras is registering three PTS cameras to measure the wide 3D depth and color images corresponding to the objects surrounding the robot. Second, the measurements of the Wi-Fi receiver and the multi-PTS cameras can be used for building a radio map and a gird-based map. Last, the localization method consisting of a fingerprint and a particle filter algorithms can find the broad and the exact positions of the robot sequentially by matching the real-time measurements of sensors and the maps. To verify the feasibility of the proposed method, we performed the experiment with a real robot in an indoor office environment. And we confirmed that the proposed localization method can be applied to the actual robot practically. Finally, we remark the conclusion and plan the future works to enhance the proposed localization method. {\textcopyright} 2015 IEEE.},
annote = {cited By 0},
author = {Lee, Y.-C.},
booktitle = {2015 12th International Conference on Ubiquitous Robots and Ambient Intelligence, URAI 2015},
doi = {10.1109/URAI.2015.7358885},
keywords = {Artificial intelligence; Cameras; Image matching;,Fingerprint; Indoor environment; Localization met,Intelligent robots},
pages = {404--407},
title = {{Robot localization method using multi-PTS cameras and Wi-Fi receiver}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962725513{\&}doi=10.1109{\%}2FURAI.2015.7358885{\&}partnerID=40{\&}md5=229e3b35686d42ee49efbcaa2452ea02},
year = {2015}
}
@article{Tsechpenakis200084,
abstract = {Main mobile object detection and localization is a task of major importance in the fields of video understanding, object-based coding and numerous related applications, such as content-based retrieval, remote surveillance and object recognition. The present work revisits the algorithm proposed in [13] for mobile object localization in both indoor and outdoor sequences when either a static or a mobile camera is utilized. The proposed approach greatly improves the trade-off between accuracy and time-performance leading to satisfactory results with a considerably low amount of computations. Moreover, based on the point gatherings extracted in [13], the bounding polygon and the direction of movement are estimated for each mobile object; thus yielding an adequate representation in the MPEG-7 sense. Experimental results over a number of distinct natural sequences have been included to illustrate the performance of the proposed approach. {\textcopyright} Springer-Verlag Berlin Heidelberg 2000.},
annote = {cited By 1},
author = {Tsechpenakis, G and Xirouhakis, Y and Delopoulos, A},
doi = {10.1007/3-540-40053-2_8},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Bounding polygons; Mobile camera; Mobile objects;,Content based retrieval; Economic and social effec,Object recognition},
pages = {84--95},
title = {{Main mobile object detection and localization in video sequences}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33645161589{\&}doi=10.1007{\%}2F3-540-40053-2{\_}8{\&}partnerID=40{\&}md5=44fc3e475342a5bc0d9dcb9e82ed1bf3},
volume = {1929},
year = {2000}
}
@inproceedings{Marques2012,
abstract = {Fingerprint is one of the most widely used methods for locating devices in indoor wireless environments and we have witnessed the emergence of several positioning systems aimed for indoor environments based on this approach. However, additional efforts are required in order to improve the performance of these systems so that applications that are highly dependent on user location can provide better services to its users. In this work we discuss some improvements to the positioning accuracy of the fingerprint-based systems. Our algorithm ranks the information about the location in a hierarchical way by identifying the building, the floor, the room and the geometric position. The proposed fingerprint method uses a previously stored map of the signal strength at several positions and determines the position using similarity functions and majority rules. In particular, we compare different similarity functions to understand their impact on the accuracy of the positioning system. The experimental results confirm the possibility of correctly determining the building, the floor and the room where the persons or the objects are at with high rates, and with an average error around 3 meters. Moreover, detailed statistics about the errors are provided, showing that the average error metric, often used by many authors, hides many aspects on the system performance. {\textcopyright} 2012 IEEE.},
annote = {cited By 39},
author = {Marques, N and Meneses, F and Moreira, A},
booktitle = {2012 International Conference on Indoor Positioning and Indoor Navigation, IPIN 2012 - Conference Proceedings},
doi = {10.1109/IPIN.2012.6418937},
keywords = {Average errors; Fingerprint method; fingerprinting,Error statistics; Floors,Mobile computing},
title = {{Combining similarity functions and majority rules for multi-building, multi-floor, WiFi positioning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874271633{\&}doi=10.1109{\%}2FIPIN.2012.6418937{\&}partnerID=40{\&}md5=041c955be07ae820a60e148c5ca178c2},
year = {2012}
}
@inproceedings{Ahmed2013462,
abstract = {Finding the hotspots in large indoor spaces is very important for getting overloaded locations, security, crowd management, indoor navigation and guidance. The tracking data coming from indoor tracking are huge in volume and not readily available for finding hotspots. This paper presents a graph-based model for constrained indoor movement that can map the tracking records into mapping records which represent the entry and exit times of an object in a particular location. Then it discusses the hotspots extraction technique from the mapping records. {\textcopyright} 2013 Authors.},
annote = {cited By 7},
author = {Ahmed, T and Pedersen, T B and Lu, H},
booktitle = {GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems},
doi = {10.1145/2525314.2525463},
keywords = {Crowd managements; Extraction techniques; Graph-ba,Geographic information systems,Graphic methods; Radio frequency identification (},
pages = {462--465},
title = {{Capturing hotspots for constrained indoor movement}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893460717{\&}doi=10.1145{\%}2F2525314.2525463{\&}partnerID=40{\&}md5=f1c30e6bc95e1769131e4acd9cc3bc73},
year = {2013}
}
@article{Frintrop2003202,
abstract = {In this paper we present experimental results on a novel application of visual attention mechanisms for the selection of points of interest in an arbitrary scene. The imaging sensor used is a multi-modal 3D laser scanner. In a single 3D scan pass, it is capable of providing range data as well as a gray-scale intensity image. The scanner is mounted on top of an autonomous mobile robot and serves control purposes. We present results achieved by applying the visual attention system of Itti et al. [8] to recorded scans of indoor and outdoor scenes. The vast majority of the primary attended locations pointed to scene objects of potential interest for navigation and object detection tasks. Moreover, both sensor modalities complement each other, resulting in a greater variety of points of interest than one modality alone can provide. {\textcopyright} Springer-Verlag Berlin Heidelberg 2003.},
annote = {cited By 7},
author = {Frintrop, S and Rome, E and N{\"{u}}chter, A and Surmann, H},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {3D laser scanners; Autonomous Mobile Robot; Intens,Object recognition,Scanning; Three dimensional},
pages = {202--211},
title = {{An attentive, multi-modal laser "eye"}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84886603460{\&}partnerID=40{\&}md5=ae5a1fd2bb26cf4121aa50aac47ad985},
volume = {2626},
year = {2003}
}
@inproceedings{Duan2017,
abstract = {In recent years, both the RFID and computer vision technologies have been widely employed in indoor scenarios aimed at different goals while faced with respective limitations. For example, the RFID-based EAS system is useful in quickly identifying tagged objects but the accompanying false alarm problem is troublesome and hard to tackle with except that the accurate trajectory of the target tag can be easily acquired. On the other side, the CV system performs fairly well in tracking multiple moving objects precisely while finding it difficult to screen out the specific target among them. To overcome the above limitations, we present TagVision, a hybrid RFID and computer vision system for fine-grained localization and tracking of tagged objects. A fusion algorithm is proposed to organically combine the position information given by the CV subsystem, and phase data output by the RFID subsystem. In addition, we employ the probabilistic model to eliminate the measurement error caused by thermal noise and device diversity. We have implemented TagVision with COTS camera and RFID devices and evaluated it extensively in our lab environment. Experimental results show that TagVision can achieve 98{\%} blob matching accuracy and 10.33mm location tracking precision. {\textcopyright} 2017 IEEE.},
annote = {cited By 4},
author = {Duan, C and Rao, X and Yang, L and Liu, Y},
booktitle = {Proceedings - IEEE INFOCOM},
doi = {10.1109/INFOCOM.2017.8057161},
keywords = {Computer vision,Computer vision system; Computer vision technolog,Image processing; Radio frequency identification (},
title = {{Fusing RFID and computer vision for fine-grained object tracking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034048631{\&}doi=10.1109{\%}2FINFOCOM.2017.8057161{\&}partnerID=40{\&}md5=485f06466cf423da2980f4c35de15f3b},
year = {2017}
}
@article{Yim201115075,
abstract = {A moving object database (MODB), a database representing information on moving objects, has many uses in a wide range of applications, such as the digital battlefield and transportation systems. In the transportation system, an MODB processes queries such as "How long should I wait until the next bus arrives here?" Therefore, location information on moving objects reflects the most important data the MODB has to manipulate. Most moving objects are equipped with a GPS (Global Positioning System) unit that sends location information to the MODB. However, GPS signals are usually very weak inside enclosed structures; thus, locating indoor moving objects requires more than the GPS. In this regard, indoor positioning for location-based services (LBSs) has been an important research topic for the last decade. There are many other differences between indoor and outdoor MODBs. For examples, the area where the indoor moving objects are moving around is much smaller than where the outdoor moving objects are moving around, and the speed of indoor moving objects is much slower than that of outdoor ones. Therefore, the indoor moving object database (IMODB) should be studied separately from the outdoor MODB or the MODB. One of the most important problems that the MODB has to solve is the updating problem. In this regard, this paper proposes an updating method of IMODBs for location-based services. Our method applies the Kalman filter to the most recently collected series of measured positions to estimate the moving object's position and velocity at the last moment of the series of the measurements and extrapolates the current position with the estimated position and velocity. If the difference between the extrapolated current position and the measured current position is less than the threshold, that is, if the two positions are close, we skip updating the IMODB. When the IMODB requires information on the moving object's position at a certain moment T, it applies the Kalman filter to the series of the recorded measurements at the moments before T and extrapolates the position at T with the Kalman filter in the same manner as the updating process described earlier. To verify the efficiency of our updating method, we applied our method to a series of measured positions obtained by employing the fingerprinting indoor positioning method while we walked through the test bed. We then analyzed the test results to calculate savings of communication cost and error. {\textcopyright} 2011 Elsevier Ltd. All rights reserved.},
annote = {cited By 8},
author = {Yim, J and Joo, J and Park, C},
doi = {10.1016/j.eswa.2011.05.037},
journal = {Expert Systems with Applications},
keywords = {Communication cost; GPS signals; Indoor positionin,Database systems; Encoding (symbols); Equipment t,Global positioning system},
number = {12},
pages = {15075--15083},
title = {{A Kalman filter updating method for the indoor moving object database}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052036557{\&}doi=10.1016{\%}2Fj.eswa.2011.05.037{\&}partnerID=40{\&}md5=c2e35aaa9e80a5566a94b1b46052b2eb},
volume = {38},
year = {2011}
}
@inproceedings{Wang2015,
abstract = {Image recognition techniques have been widely used in positioning systems in recent years. By recognizing the objects targeted by users' camera, one can decide the users' location. In this paper, a mobile indoor positioning system based on the image recognition techniques is implemented for shopping malls. We recognize the stores by their logos, and then use the location of the stores to locate the users. The image recognition method includes extracting local features from the image, calculating the Bag-of-Word structure through a pre-trained hierarchical clustering tree, and using cosine similarity to make the comparison between the training images and the query images. Though SIFT and SURF are the most extensively used local feature detectors and descriptors in the field, the limitations of mobile devices make them infeasible due to their high computational complexity. Moreover, both SIFT and SURF are patent-protected and are not free modules in OpenCV4Android, which will cause additional cost. Therefore, in this paper, we attempt to adopt features that exclude SIFT and SURF. By analyzing the precision and speed of pairwise mashup of feature detectors and descriptors, we target to find the most suitable pair of algorithms to be used on mobile devices. In this paper, the Global Mall at Hsinchu, Taiwan, is used as a scenario for the actual test. {\textcopyright} 2015 ACM.},
annote = {cited By 0},
author = {Wang, S.-S. and Tsai, P.-H. and Li, W.-S.},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/2818869.2818930},
keywords = {Additional costs; Cosine similarity; Hier-archica,Feature extraction,Image recognition; Indoor positioning systems; Mob},
title = {{Logo recognition for image-based indoor positioning systems on mobile devices}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960080013{\&}doi=10.1145{\%}2F2818869.2818930{\&}partnerID=40{\&}md5=5c2504c4bee9c58d60b453c6b6daac1a},
volume = {07-09-Ocob},
year = {2015}
}
@article{Arias-De-reyna201385,
abstract = {This paper deals with range-based localization in ultra wideband sensor networks, allowing for the possibility of large range measurement errors because of a failure to detect the direct paths between some nodes. A novel algorithm is proposed that uses only partial knowledge of the service area topology, particularly of the positions of objects which are capable of causing undetected direct path (UDP) propagation conditions. Although the spirit of the proposed approach, because of the lack of information on the range error statistics, is to remove measurements performed under UDP conditions from the computation of the location estimate, these measurements are used implicitly by the algorithm to contribute to the erroneous trial locations being discarded. A cooperative stage is included that allows the probability of localization of a target with an insufficient initial number of accurate range measurements to increase. The proposed algorithm outperforms a variety of alternative positioning techniques, and thus illustrates the capability of this topology knowledge to mitigate the UDP problem, even in the absence of any knowledge about the range error statistics. {\textcopyright} Springer Science+Business Media New York 2013.},
annote = {cited By 7},
author = {Arias-De-reyna, E},
doi = {10.1007/s11277-013-1002-6},
journal = {Wireless Personal Communications},
keywords = {Algorithms,Cooperative localization; Direct paths; Indoor loc,Error statistics; Sensor networks; Sensor nodes;},
number = {1},
pages = {85--99},
title = {{A cooperative localization algorithm for uwb indoor sensor networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893683536{\&}doi=10.1007{\%}2Fs11277-013-1002-6{\&}partnerID=40{\&}md5=64a3d34c91bfd7e38cf3c9bf68cfd2bc},
volume = {72},
year = {2013}
}
@inproceedings{Walton201772,
abstract = {When rendering virtual objects in a mixed reality application, it is helpful to have access to an environment map that captures the appearance of the scene from the perspective of the virtual object. It is straightforward to render virtual objects into such maps, but capturing and correctly rendering the real components of the scene into the map is much more challenging. This information is often recovered from physical light probes, such as reflective spheres or fisheye cameras, placed at the location of the virtual object in the scene. For many application areas, however, real light probes would be intrusive or impractical. Ideally, all of the information necessary to produce detailed environment maps could be captured using a single device. We introduce a method using an RGBD camera and a small fisheye camera, contained in a single unit, to create environment maps at any location in an indoor scene. The method combines the output from both cameras to correct for their limited field of view and the displacement from the virtual object, producing complete environment maps suitable for rendering the virtual content in real time. Our method improves on previous probeless approaches by its ability to recover high-frequency environment maps. We demonstrate how this can be used to render virtual objects which shadow, reflect and refract their environment convincingly. {\textcopyright} 2017 IEEE.},
annote = {cited By 1},
author = {Walton, D R and Thomas, D and Steed, A and Sugimoto, A},
booktitle = {Proceedings of the 2017 IEEE International Symposium on Mixed and Augmented Reality, ISMAR 2017},
doi = {10.1109/ISMAR.2017.24},
keywords = {Application area; Environment maps; Field of view,Augmented reality; Cameras; Probes; Virtual realit,Rendering (computer graphics)},
pages = {72--81},
title = {{Synthesis of environment maps for mixed reality}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041656241{\&}doi=10.1109{\%}2FISMAR.2017.24{\&}partnerID=40{\&}md5=2fba729ffad55beccfe8e6ebbab58ddc},
year = {2017}
}
@inproceedings{Li2012,
abstract = {The use of magnetic field variations for positioning and navigation has been suggested by several researchers. In most of the applications, the magnetic field is used to determine the azimuth or heading. However, for indoor applications, accurate heading determination is difficult due to the presence of magnetic field anomalies. Here location fingerprinting methodology can take advantage of these anomalies. In fact, the more significant the local anomalies, the more unique the magnetic 'fingerprint'. In general, the more elements in each fingerprint, the better for positioning. Unfortunately, magnetic field intensity data only consists of three components. Since true north (or magnetic north) is generally unknown, even with help of the accelerometer to detect the direction of the gravity, only two components can be extracted, i.e. The horizontal intensity and the vertical intensity (or total intensity and inclination). Furthermore, moving objects containing ferromagnetic materials and electronic devices may affect the magnetic field. Tests were carried out to investigate the feasibility of using magnetic field alone for indoor positioning. Possible solutions are discussed. {\textcopyright} 2012 IEEE.},
annote = {cited By 114},
author = {Li, B and Gallagher, T and Dempster, A G and Rizos, C},
booktitle = {2012 International Conference on Indoor Positioning and Indoor Navigation, IPIN 2012 - Conference Proceedings},
doi = {10.1109/IPIN.2012.6418880},
keywords = {Electronic device; Fingerprinting; Indoor applicat,Magnetic fields,Navigation},
title = {{How feasible is the use of magnetic field alone for indoor positioning?}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874275423{\&}doi=10.1109{\%}2FIPIN.2012.6418880{\&}partnerID=40{\&}md5=0b0d0309f2c3d7304c62734f19834851},
year = {2012}
}
@inproceedings{Tesch2015556,
abstract = {Internet of Things (IoT) incorporates concepts from pervasive computing and enables iteration between people and objects. Location service is one of the primary services of IoT. However, existing techniques for indoor localization either have low accuracy or are too complex, requiring a high investment. This paper presents a technique of RFID indoor localization based on an analytical model of the Doppler Effect. From the Doppler frequency, due to the relative motion between the reader antenna and the tag, it is possible to estimate the spatial position of the reader antenna. Test results show the technique provides the location of the reader antenna with high accuracy and meets the requirements of low complexity and cost. {\textcopyright} 2015 IEEE.},
annote = {cited By 12},
author = {Tesch, D A and Berz, E L and Hessel, F P},
booktitle = {Proceedings - International Symposium on Quality Electronic Design, ISQED},
doi = {10.1109/ISQED.2015.7085487},
keywords = {Antennas; Doppler effect; Internet of things; Iter,Doppler frequency; Indoor localization; Internet,Indoor positioning systems},
pages = {556--560},
title = {{RFID indoor localization based on Doppler effect}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944322651{\&}doi=10.1109{\%}2FISQED.2015.7085487{\&}partnerID=40{\&}md5=75011183a2b0de63fcaf4de538d21151},
volume = {2015-April},
year = {2015}
}
@article{Chen2007575,
abstract = {The genetic algorithm is used to synthesize the radiation pattern of the directional circular arc array to minimize the bit error rate (BER) performance in indoor wireless communication system. The impulse responses of the indoor channel for any transmitter-receiver location are computed by shooting and bouncing ray/image techniques. By using the impulse response of multipath channel, the performance of the synthesized antenna pattern on BPSK (binary phase shift keying) system with phase and timing recovery circuits can be calculated. Based on the topography of the antenna and the BER formula, the synthesis problem can be reformulated into an optimization problem and solved by the genetic algorithm. The novelty of our approach is choosing BER as the object function instead of sidelobe level of the antenna pattern, i.e., BER performance is defined as a object function to optimize the excitation coefficient of array by the genetic algorithm. The strong point of the genetic algorithm is that it can find out the solution even if the performance index cannot be formulated by simple equations. Besides, the genetic algorithm will converge to global extreme instead of local extreme and achieves a good antenna pattern. Numerical results show that the synthesized antenna pattern is effective to combat the multipath fading and can increase the transmission rate of indoor millimeter wave system. {\textcopyright} 2006 Springer Science+Business Media, LLC.},
annote = {cited By 4},
author = {Chen, C.-H. and Chiu, C.-C. and Liu, C.-L.},
doi = {10.1007/s11277-006-9212-9},
journal = {Wireless Personal Communications},
keywords = {Binary phase shift keying; Bit error rate; Communi,Millimeter wave system; Radiation pattern; Timing,Wireless telecommunication systems},
number = {4},
pages = {575--586},
title = {{Novel directional radiation pattern by genetic algorithms in indoor wireless local loop}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547258528{\&}doi=10.1007{\%}2Fs11277-006-9212-9{\&}partnerID=40{\&}md5=748a87b16f777ee356f4e99f4dc6d95c},
volume = {42},
year = {2007}
}
@inproceedings{Piyathilaka20141427,
abstract = {Human context is the most natural explanation why objects are placed and arranged in a particular order in an indoor environment. Usually, humans arrange objects in order to support their intended activities in a given environment. However, most of the common approaches for robotic object search involve modelling object-object relationships. In this paper, we hypothesize such relationships are centered around humans and bring human context to object search by modelling human-objects relationships through affordance-map. It identifies locations in a 3D map which support a particular affordance using virtual human models. Therefore, our approach does not require to observe real humans in the scene. The affordance-map and object-human-robot relationship are then used to infer the object search strategy. We tested our algorithm using a mobile robot that actively searched for the object 'computer monitors' in an office environment with promising results. {\textcopyright} 2014 IEEE.},
annote = {cited By 4},
author = {Piyathilaka, L and Kodagoda, S},
booktitle = {2014 13th International Conference on Control Automation Robotics and Vision, ICARCV 2014},
doi = {10.1109/ICARCV.2014.7064525},
keywords = {Computer vision; Robotics; Robots,Human context; Human robots; Human-centric; Indoo,Virtual reality},
pages = {1427--1432},
title = {{Active visual object search using affordance-map in real world: A human-centric approach}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949925993{\&}doi=10.1109{\%}2FICARCV.2014.7064525{\&}partnerID=40{\&}md5=16f437a1f77e5d8be226f9921ae60bfd},
year = {2014}
}
@inproceedings{Konecny2018,
abstract = {The real-time location systems (RTLS) take recently important part in many location-aware systems especially in indoor objects localization tasks. In the health-care environment, bed tracking, patient monitoring or critical equipment tracking are important applications of such systems. The paper deals with currently developed RTLS based on the Infra-Red (IR) light. We develop the system primarily for University Hospital of Ostrava however the general structure of the system a hardware components can be used in other systems. In the article we introduce one part of the localization system - the Anchor. This paper also presents an energy assessment and testing of the power consumption of anchor performance. The result section brings major conclusions and possible directions for future work. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Konecny, J and Prauzek, M and Martinek, R and Michalek, L and Tomis, M},
booktitle = {2018 IEEE 20th International Conference on e-Health Networking, Applications and Services, Healthcom 2018},
doi = {10.1109/HealthCom.2018.8531110},
keywords = {Critical equipment; Energy assessment; General st,Hardware; Indoor positioning systems; Patient moni,Real time systems},
title = {{Real-time patient localization in urgent care: System design and hardware perspective}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058317003{\&}doi=10.1109{\%}2FHealthCom.2018.8531110{\&}partnerID=40{\&}md5=a099aed19744c06486ae6e8258e862dd},
year = {2018}
}
@inproceedings{Baba2016925,
abstract = {RFID is widely used for object tracking in indoor environments, e.g., airport baggage tracking. Analyzing RFID data offers insight into the underlying tracking systems as well as the associated business processes. However, the inherent uncertainty in RFID data, including noise (cross readings) and incompleteness (missing readings), pose challenges to high-level RFID data querying and analysis. In this paper, we address these challenges by proposing a learning-based data cleansing approach that, unlike existing approaches, requires no detailed prior knowledge about the spatiotemporal properties of the indoor space and the RFID reader deployment. Requiring only minimal information about RFID deployment, the approach learns relevant knowledge from raw RFID data and uses it to cleanse the data. In particular, we model raw RFID readings as time series that are sparse because the indoor space is only partly covered by a limited number of RFID readers. We propose the Indoor RFID Multi-variate Hidden Markov Model (IR-MHMM) to capture the uncertainties of indoor RFID data as well as the correlation of moving object locations and object RFID readings. We propose three state space design methods for IR-MHMM that enable the learning of parameters while contending with raw RFID data time series. We solely use raw uncleansed RFID data for the learning of model parameters, requiring no special labeled data or ground truth. The resulting IR-MHMM based RFID data cleansing approach is able to recover missing readings and reduce cross readings with high effectiveness and efficiency, as demonstrated by extensive experimental studies with both synthetic and real data. Given enough indoor RFID data for learning, the proposed approach achieves a data cleansing accuracy comparable to or even better than state-of-the-art techniques requiring very detailed prior knowledge, making our solution superior in terms of both effectiveness and employability. {\textcopyright} 2016 ACM.},
annote = {cited By 5},
author = {Baba, A I and Jaeger, M and Lu, H and Pedersen, T B and Ku, W.-S. and Xie, X},
booktitle = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
doi = {10.1145/2882903.2882907},
keywords = {Business Process; Effectiveness and efficiencies;,Hidden Markov models; Markov processes; Time serie,Radio frequency identification (RFID)},
pages = {925--936},
title = {{Learning-based cleansing for indoor RFID data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979655757{\&}doi=10.1145{\%}2F2882903.2882907{\&}partnerID=40{\&}md5=52396cd01cdf5e8dd2dad88e8377f3b0},
volume = {26-June-20},
year = {2016}
}
@article{Ye201248,
abstract = {Ultra Wide Band (UWB) wireless transmission has recently been the object of considerable attention in the field of next generation location aware wireless sensor networks (WSNs). This is due to its fine time resolution, energy efficiency and robustness to interference in harsh environments. This paper presents a thorough applied examination of prototype IEEE 802.15.4a impulse UWB transceiver technology to quantify the effect of line of sight (LOS) and non line of sight (NLOS) ranging in real indoor and outdoor environments. The results included draw on an extensive array of experiments that fully characterize the 802.15.4a UWB transceiver technology, its reliability and ranging capabilities for the first time. The goal of this work is to validate the technology as a dependable wireless communication mechanism for the subset of sensor network localization applications where reliability and precision positions are key concerns. Copyright {\textcopyright} 2012, IGI Global.},
annote = {cited By 6},
author = {Ye, T and Walsh, M and Haigh, P and Barton, J and Mathewson, A and O'Flynn, B and O'Mathuna, C},
doi = {10.4018/jaci.2012040104},
journal = {International Journal of Ambient Computing and Intelligence},
keywords = {802.15.4a; Experimental evaluation; Harsh environm,Energy efficiency; Reliability; Technology; Wirel,Radio communication},
number = {2},
pages = {48--63},
title = {{An experimental evaluation of IEEE 802.15.4a Ultra Wide Band technology for precision indoor ranging}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870264328{\&}doi=10.4018{\%}2Fjaci.2012040104{\&}partnerID=40{\&}md5=71536b8454dc98f25bf6793b410ca92b},
volume = {4},
year = {2012}
}
@article{Luoh2014443,
abstract = {Nowadays positioning system is no longer only for military purpose, while it has been widely applied to various livelihood purposes such as biological information, emergency rescue, public facilities and individual safety. While the most frequently used to identify the coordinates of users is global positioning system (GPS), however, it tends to be interfered by indoor buildings such that it cannot be effectively used in indoor environment. Recently, wireless sensor network has become a trendy research topic, the positioning service of indoor positioning system can be achieved by the measurements of received signal strength (RSS) or link quality indicator (LQI). In this paper, the average RSS is first adopted for reducing the noise interference of LQI, and then the object to be detected will be trained by radial basis function network (RBFN) with the capability of identifying the environment of location. ZigBee module will then be integrated to realize a set of convenient wireless indoor positioning system with low cost. In addition, multiple similar artificial neural networks within the same region will be adopted to further improve the positioning accuracy. Experiments shown that this study is capable of effective enhancement of existing IPS accuracy with the average error of indoor positioning at 2.8 meters 100 {\%} comparing with other approaches. {\textcopyright} 2013 Springer-Verlag Berlin Heidelberg.},
annote = {cited By 31},
author = {Luoh, L},
doi = {10.1007/s00500-013-1067-x},
journal = {Soft Computing},
keywords = {Biological information; Indoor positioning system,Global positioning system; Neural networks; Radial,Zigbee},
number = {3},
pages = {443--456},
title = {{ZigBee-based intelligent indoor positioning system soft computing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897580923{\&}doi=10.1007{\%}2Fs00500-013-1067-x{\&}partnerID=40{\&}md5=303bdb59b6f3071cdee769a3e050c19a},
volume = {18},
year = {2014}
}
@inproceedings{Vuckovic2011321,
abstract = {Indoor wireless localization has significant importance in wireless network technology and has wide deployment in a real-time indoor people and objects tracking. Location fingerprinting, which is based on received signal strength measurements, is a frequently used approach for indoor applications. In this paper, we examine the localization fingerprinting method through the enhanced well-known Weighted k-Nearest Neighbour (WkNN) method with MultiDimensional Scaling (MDS) through the post-processing step of transformation of signal-space and physical-space. The aim of this transformation step is to de-correlate and refine initially obtained location estimates. Impact of the variation of space-grid resolution on accuracy of the presented localization techniques is examined. Performances of the initial estimates obtained by the basic and enhanced WkNN localization methods are verified through the experiments with real environment data. {\textcopyright} 2011 IEEE.},
annote = {cited By 5},
author = {Vuckovic, M and Petrovi{\'{c}}, I and Vidovic, D and Kostovic, Z and Pletl, S and Kukolj, D},
booktitle = {2011 19th Telecommunications Forum, TELFOR 2011 - Proceedings of Papers},
doi = {10.1109/TELFOR.2011.6143554},
keywords = {Indoor applications; Indoor localization; Initial,Tracking (position)},
pages = {321--324},
title = {{Space grid resolution impact on accuracy of the indoor localization fingerprinting}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857465478{\&}doi=10.1109{\%}2FTELFOR.2011.6143554{\&}partnerID=40{\&}md5=1de5d5a1c224d81f570f11f7a329cf50},
year = {2011}
}
@inproceedings{Hong2016,
abstract = {We built a VR daylighting design system for architects to design an indoor daylighting experience. With this system, users can import 3d models or meshes, and interact with the architecture in space. In particular users can draw the lighting areas they want and receive system-generated window opennings, given the sunlight conditions of a specific time and location. This research proposes a reversed design paradigm empowered by virtual reality technology, which puts the design of spatial experience first rather than the design of physical objects. That is, window design is determined as a result of daylighting experience. {\textcopyright} Copyright is held by the owner/author(s). VR Meets PR 2016, December 05-08 2016.},
annote = {cited By 2},
author = {Hong, Y and Michalatos, P},
booktitle = {SA 2016 - SIGGRAPH ASIA 2016 Virtual Reality Meets Physical Reality: Modelling and Simulating Virtual Humans and Environments},
doi = {10.1145/2992138.2992140},
keywords = {Architectural design,Architecture; Daylighting; Interactive computer gr,Daylighting design; Design paradigm; Design tool;},
title = {{LumiSpace: A VR architectural daylighting design system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006931050{\&}doi=10.1145{\%}2F2992138.2992140{\&}partnerID=40{\&}md5=27cd93c7cb3133a8c05c595b00f45bae},
year = {2016}
}
@article{Li20181481,
abstract = {As people spend significant parts of daily lives indoors, it is useful and important to measure indoor densities and find the dense regions in many indoor scenarios like space management and security control. In this paper, we propose a data-driven approach that finds top-k indoor dense regions by using indoor positioning data. Such data is obtained by indoor positioning systems working at a relatively low frequency, and the reported locations in the data are discrete, from a preselected location set that does not continuously cover the entire indoor space. When a search is triggered, the object positioning information is already out-of-date and thus object locations are uncertain. To this end, we first integrate object location uncertainty into the definitions for counting objects in an indoor region and computing its density. Subsequently, we conduct a thorough analysis of the location uncertainty in the context of complex indoor topology, deriving upper and lower bounds of indoor region densities and introducing distance decaying effect into computing concrete indoor densities. Enabled by the uncertainty analysis outcomes, we design efficient search algorithms for solving the problem. Finally, we conduct extensive experimental studies on our proposals using synthetic and real data. The experimental results verify that the proposed search approach is efficient, scalable, and effective. The top-k indoor dense regions returned by our search are considerably consistent with ground truth, despite that the search uses neither historical data nor extra knowledge about objects. {\textcopyright} 1989-2012 IEEE.},
annote = {cited By 0},
author = {Li, H and Lu, H and Shou, L and Chen, G and Chen, K},
doi = {10.1109/TKDE.2018.2799215},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {Airport security; Airports; Indoor positioning sys,Algorithm design and analysis; Indoor positioning,Uncertainty analysis},
number = {8},
pages = {1481--1495},
title = {{In Search of Indoor Dense Regions: An Approach Using Indoor Positioning Data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041424201{\&}doi=10.1109{\%}2FTKDE.2018.2799215{\&}partnerID=40{\&}md5=f1102ff971b321e25346e073be28010f},
volume = {30},
year = {2018}
}
@inproceedings{Kapidis2018878,
abstract = {Egocentric vision is a technology that exists in a variety of fields such as life-logging, sports recording and robot navigation. Plenty of research work focuses on location detection and activity recognition, with applications in the area of Ambient Assisted Living. The basis of this work is the idea that locations can be characterized by the presence of specific objects. Our objective is the recognition of locations in egocentric videos that mainly consist of indoor house scenes. We perform an extensive comparison between Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) based classification methods that aim at finding the in-house location by classifying the detected objects which are extracted with a state-of-the-art object detector. We show that location classification is affected by the quality of the detected objects, i.e., the false detections among the correct ones in a series of frames, but this effect can be greatly limited by taking into account the temporal structure of the information by using LSTM. Finally, we argue about the potential for useful real-world applications. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Kapidis, G and Poppe, R W and {Van Dam}, E A and Veltkamp, R C and Noldus, L.P.J.J.},
booktitle = {2018 IEEE International Conference on Pervasive Computing and Communications Workshops, PerCom Workshops 2018},
doi = {10.1109/PERCOMW.2018.8480258},
keywords = {Activity recognition; Ambient assisted living; Cl,Classification (of information); Location; Long sh,Object detection},
pages = {878--883},
title = {{Where Am I? Comparing CNN and LSTM for Location Classification in Egocentric Videos}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056458809{\&}doi=10.1109{\%}2FPERCOMW.2018.8480258{\&}partnerID=40{\&}md5=bf2d83e5530b78f9b7ef78abf067f568},
year = {2018}
}
@inproceedings{Bagci2008887,
abstract = {Ubiquitous and pervasive computing envisions context-aware systems that gather real world information from many fixed and mobile microchips and sensors integrated in everyday objects. To provide valuable services, it is necessary to estimate the location of users or objects. Outdoor location tracking is achieved by Global Positioning System (GPS), but due to its poor indoor coverage, there is a need for alternative technologies in buildings. Since multiple wireless sensors may be situated in the environment, they can be used for location estimation and tracking. This paper presents LocSens, a cost-effective location tracking system based on sensor nodes with wireless connectivity. LocSens works with a minimum number of sensor nodes. It is established and tested in a real indoor scenario over multiple rooms. This paper describes results of several location estimation algorithms and experiences with tracking of moving objects. {\textcopyright} 2008 IEEE.},
annote = {cited By 5},
author = {Bagci, F and Kluge, F and Ungerer, T and Bagherzadeh, N},
booktitle = {Proceedings - International Conference on Computer Communications and Networks, ICCCN},
doi = {10.1109/ICCCN.2008.ECP.165},
keywords = {Alternative technologies; Context-aware; Effectiv,Computer networks; Doors; Global positioning syste,Wireless sensor networks},
pages = {887--891},
title = {{LocSens - An indoor location tracking system using wireless sensors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-57849141240{\&}doi=10.1109{\%}2FICCCN.2008.ECP.165{\&}partnerID=40{\&}md5=3eb766775340462c3b21573de32dd01e},
year = {2008}
}
@inproceedings{Yang2010335,
abstract = {The availability of indoor positioning renders it possible to deploy location-based services in indoor spaces. Many such services will benefit from the efficient support for k nearest neighbor (kNN) queries over large populations of indoor moving objects. However, existing kNN techniques fall short in indoor spaces because these differ from Euclidean and spatial network spaces and because of the limited capabilities of indoor positioning technologies. To contend with indoor settings, we propose the new concept of minimal indoor walking distance (MIWD) along with algorithms and data structures for distance computing and storage; and we differentiate the states of indoor moving objects based on a positioning device deployment graph, utilize these states in effective object indexing structures, and capture the uncertainty of object locations. On these foundations, we study the probabilistic threshold kNN (PTkNN) query. Given a query location q and a probability threshold T, this query returns all subsets of k objects that have probability larger than T of containing the kNN query result of q. We propose a combination of three techniques for processing this query. The first uses the MIWD metric to prune objects that are too far away. The second uses fast probability estimates to prune unqualified objects and candidate result subsets. The third uses efficient probability evaluation for computing the final result on the remaining candidate subsets. An empirical study using both synthetic and real data shows that the techniques are efficient. Copyright 2010 ACM.},
annote = {cited By 56},
author = {Yang, B and Lu, H and Jensen, C S},
booktitle = {Advances in Database Technology - EDBT 2010 - 13th International Conference on Extending Database Technology, Proceedings},
doi = {10.1145/1739041.1739083},
keywords = {Algorithms and data structures; Empirical studies;,Algorithms; Data structures; Database systems; Lo,Tracking (position)},
pages = {335--346},
title = {{Probabilistic threshold k nearest neighbor queries over moving objects in symbolic indoor space}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952253227{\&}doi=10.1145{\%}2F1739041.1739083{\&}partnerID=40{\&}md5=a7edb2f2ac1c50955c0d4e2fecbd6f93},
year = {2010}
}
@article{Lam2016262,
abstract = {Indoor positioning has attracted much research effort due to many potential applications such as human or object tracking and inventory management. Whilst there are a number of indoor positioning techniques and algorithms developed to improve positioning estimation, there is still no systematic way to characterise the estimation. In this paper, we propose a method comprising of three characteristics to characterise indoor positioning estimation. We conducted experiments on an active radio frequency identification (RFID)-based real-time location system in different environmental conditions. We used both a human and a robot to traverse two experimental areas and collected positioning results at different fixed points along the traversal path. Using this basic positioning data, we were able to characterise positioning estimation using three characterisations: position accuracy, centroid consistency and angular distribution. We demonstrate the use of these characteristics for examining different points in a travelling path and different measurements. {\textcopyright} 2016 Informa UK Limited, trading as Taylor {\&} Francis Group.},
annote = {cited By 0},
author = {Lam, L D M and Tang, A and Grundy, J},
doi = {10.1080/17489725.2016.1259893},
journal = {Journal of Location Based Services},
keywords = {Active radio frequency identifications; Environme,Angular distribution; Frequency estimation; Indoor,Radio frequency identification (RFID)},
number = {4},
pages = {262--284},
title = {{Characterising indoor positioning estimation using experimental data from an active RFID-based real-time location system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84997482172{\&}doi=10.1080{\%}2F17489725.2016.1259893{\&}partnerID=40{\&}md5=f759b4d52d5fa9867fd13f34bd5499f0},
volume = {10},
year = {2016}
}
@inproceedings{Kawaji2010105,
abstract = {In this paper, we present an image-based indoor positioning system for digital museum application using omniderectional images to which location information is embedded. By using robust image matching by PCA-SIFT, fast nearest neighbor search algorithm based Locaity Sensitive Hashing (LSH), and the confidence measure which takes into consideration of the location of the objects in the query image, our system can estimate users' locations with high accuracy and in a short time. We conducted some experiments of image matching and arguments about the results. {\textcopyright}2010 IEEE.},
annote = {cited By 8},
author = {Kawaji, H and Hatada, K and Yamasaki, T and Aizawa, K},
booktitle = {2010 16th International Conference on Virtual Systems and Multimedia, VSMM 2010},
doi = {10.1109/VSMM.2010.5665958},
keywords = {Cameras; Video cameras,Digital museums; Indoor localization; Locality sen,Image matching},
pages = {105--111},
title = {{An image-based indoor positioning for digital museum applications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651446948{\&}doi=10.1109{\%}2FVSMM.2010.5665958{\&}partnerID=40{\&}md5=6b11f69d69c2c00533a601be7f131e75},
year = {2010}
}
@inproceedings{Zhong20171093,
abstract = {The existing AR indoor registration technologies based on hardware often have the disadvantage of low registration accuracy. To solve the problem, a new indoor AR registration technology based on iBeacon is proposed in this paper. Firstly, the coordinates of the phone are calculated based on the data received by iBeacons. Secondly, the 3D directions of the phone are obtained based on the acceleration and gravity sensor integrated in the phone. The system could request the corresponding data of the object from the backend server according to the location information and 3D directions. Then, the superposition of virtual image and the target object in the real world is realized. The results show that the new indoor AR registration method proposed in this paper could realize accurate and real-time registration for target objects with high accuracy (error{\textless}65pixels) and real-time performance (time{\textless}0.5s), which will have a wide application in indoor AR registration in the future. {\textcopyright} 2017 IEEE.},
annote = {cited By 1},
author = {Zhong, X and Wang, W and Wang, Q},
booktitle = {2017 IEEE International Conference on Information and Automation, ICIA 2017},
doi = {10.1109/ICInfA.2017.8079065},
keywords = {3D directions; iBeacons; indoor; positioning; Real,Telephone sets},
pages = {1093--1098},
title = {{An indoor AR registration technique based on iBeacons}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039946047{\&}doi=10.1109{\%}2FICInfA.2017.8079065{\&}partnerID=40{\&}md5=731ac230c3cdc7d265f1d7009cc0ff37},
year = {2017}
}
@inproceedings{Choi2013394,
abstract = {In this paper, we propose a multiple 3D camera-based human tracking method which is robust to illumination changes and occlusions at indoor environments. To overcome the difficulties due to illumination change, several types of image features are used in a collaborative fashion, for which brightness intensity, hue, local binary pattern (LBP) and depth from 3D camera are considered. In addition, our method also exploits multiple camera views to resolve the occlusion between objects. Our algorithm first implements the background subtraction to extract moving objects from each camera view and then executes the human identification process to determine whether the human is previously confirmed. The proposed algorithm estimates the vertical axes of the humans detected in multiple calibrated camera views, which leads to generating the cross points of the detected human objects. Finally, the cross points (the location of the human objects) are fed into adaptive particle filter based on spatio-temporal information to track the human objects. The performance of the proposed algorithm is examined through experiments performed in varying indoor illumination and occlusion conditions. {\textcopyright} 2013 IEEE.},
annote = {cited By 0},
author = {Choi, J and Kim, C and Park, S.-K.},
booktitle = {Proceedings - IEEE International Workshop on Robot and Human Interactive Communication},
doi = {10.1109/ROMAN.2013.6628511},
keywords = {Adaptive particle filters; Background subtraction;,Algorithms; Cameras; Communication; Distributed c,Robots},
pages = {394--399},
title = {{Human tracking with multiple 3D cameras for perceptual sensor network}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889587379{\&}doi=10.1109{\%}2FROMAN.2013.6628511{\&}partnerID=40{\&}md5=82f454859f3da86cfac892b640b14e90},
year = {2013}
}
@inproceedings{Huwedi2006456,
abstract = {In this paper, we present an algorithm for feature based exploration of a prior unknown indoor environment. The mobile robot Odete equipped with two different types of sensors is used. Employing different sensor capabilities, 3D features are detected autonomously very quickly. The main contribution of the paper is to let the robot move to a new unexplored place, based on some prospect values of this place. One of these prospect values is the natural feature quality available at that place, whereas the second prospect value is the navigation cost to it. The vision-based feature extractor is demonstrated, showing how it is self motivated to search for an interesting region using a segmentation and detection process. The obtained region is classified into known objects, and the relative location information for the selected object is memorized. The mobile robot plans its motion such that it continuously builds up a geometrical model of the features, taking into consideration the cost of reaching a target point. The target point is chosen depending on the number of the features and their visibility that a robot can cover with its sensors upon reaching that location. The captured information from these sensors is transformed into different representations in order to achieve the task. {\textcopyright} 2006 IEEE.},
annote = {cited By 2},
author = {Huwedi, A and Steinhaus, P and Dillmann, R},
booktitle = {IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems},
doi = {10.1109/MFI.2006.265610},
keywords = {Algorithms,Autonomous agents; Feature extraction; Mobile robo,Autonomous feature-based exploration; Multi-senso},
pages = {456--461},
title = {{Autonomous feature-based exploration using multi-sensors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-40949122407{\&}doi=10.1109{\%}2FMFI.2006.265610{\&}partnerID=40{\&}md5=c0e2ec058f364fdfd1265b00f72c2e7c},
year = {2006}
}
@inproceedings{Bento200578,
abstract = {Location is an important dimension for context-awareness in ubiquitous devices. Nowadays different techniques are used alone or together to determine the position of a person or object. One aspect of the problem concerns to indoor location. Various authors propose the analysis of Radio Frequency (RF) footprints. In this paper we defend that case-based reasoning can make an important contribution for location from RF footprints. We apply an empirical dissimilarity metric for footprint retrieval and compare this approach with the results obtained with a neural network and C5.0 learning algorithms. The RF footprints are obtained from a Global System for Mobile Communications and General Packet Radio Service (GSM/GPRS) network. Signals from these networks are particularly complex when compared to the ones obtained from WiFi or Bluetooth networks. {\textcopyright} Springer-Verlag Berlin Heidelberg 2005.},
annote = {cited By 0},
author = {Bento, C and Peixoto, J and Veloso, M},
booktitle = {Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)},
keywords = {Bluetooth networks; Radio frequency,Global system for mobile communications; Ground pe,Problem solving},
pages = {78--90},
title = {{A case-based approach for indoor location}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-26944442031{\&}partnerID=40{\&}md5=6644359879c34fc3268311c507de3b29},
volume = {3620},
year = {2005}
}
@inproceedings{Emmanuel2008903,
abstract = {In this paper a novel way to control the amount of generated video surveillance data by controlling the spatial and temporal samplings of video is proposed. The samplings are controlled adaptively using the speed, distance and dimension of the object extracted dynamically from the surveillance video. We also present a method of estimating the actual 2D dimension, location and speed of moving objects especially from surveillance video of indoor environments such as indoor car parks, corridors of buildings, shopping malls etc. Experiments were conducted to study the generated data size reduction and the reduction is found to be substantial and also to find the accuracy of the estimated 2D dimension, location and speed of the moving object and the accuracy is found to be high. {\textcopyright} 2008 IEEE.},
annote = {cited By 0},
author = {Emmanuel, S and Zhang, P and Sugama, A},
booktitle = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
doi = {10.1109/ICSMC.2008.4811395},
keywords = {Car parks; D dimensions; Data size; Indoor environ,Control theory; Cybernetics; Monitoring; Parks; S,Security systems},
pages = {903--908},
title = {{Spatial and temporal sampling control for visual surveillance application}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-69949162053{\&}doi=10.1109{\%}2FICSMC.2008.4811395{\&}partnerID=40{\&}md5=a2f22eae30192b891b50a3e98cd031d2},
year = {2008}
}
@inproceedings{Ochmann2014,
abstract = {We present a new method for the hierarchical decomposition of 3D indoor scans and the subsequent generation of an according hierarchical graph-based building descriptor. The hierarchy consists of four basic levels with according entities, building - storey - room - object. All entities are represented as attributed nodes in a graph and are linked to the upper level entity they are located in. Additionally, nodes of the same level are linked depending on their spatial and topological relationship. The hierarchical description enables easy navigation in the formerly unstructured data, measurement takings, as well as carrying out retrieval tasks that incorporate geometric, topological, and also functional building properties describing e.g. the designated use of single rooms according to the objects it contains. In contrast to previous methods which either focus on the segmentation into rooms or on the recognition of indoor objects, our holistic approach incorporates a rather large spectrum of entities on different semantic levels that are inherent to 3D building representations. In our evaluation we show the feasibility of our method for extraction of hierarchical building descriptions for various tasks using synthetic as well as real world data. {\textcopyright} The Eurographics Association 2014.},
annote = {cited By 3},
author = {Ochmann, S and Vock, R and Wessel, R and Klein, R},
booktitle = {Eurographics Workshop on 3D Object Retrieval, EG 3DOR},
doi = {10.2312/3DOR.20141054},
keywords = {Building property; Hierarchical decompositions; H,Buildings,Extraction; Graphic methods; Semantics; Topology},
title = {{Towards the extraction of hierarchical building descriptions from 3D indoor scans}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018234625{\&}doi=10.2312{\%}2F3DOR.20141054{\&}partnerID=40{\&}md5=3813af6ce0fb93b09c3ecc5c419b0455},
year = {2014}
}
@inproceedings{Mata2011497,
abstract = {Indoor environments offer many possibilities for the development of navigation-aided systems and location-based services. This paper introduces an experimental setup that combines navigation facilities with augmented reality, and which is applied to two museums in the city of Mexico. The approach is based on a semantic model of a museum environment that reflects its organization and spatial structure. The experimental setup combines augmented reality, digital compass devices with smartphones. While several constraints reduce interaction capabilities among exhibitions and visitors, augmented reality offers the possibility of relaxing these constraints by combining real sceneries with digital representations. This enhances interactions between users and objects of interest pointed by the users, where additional multimedia information on the collections presented is available on demand. {\textcopyright} 2011 Authors.},
annote = {cited By 15},
author = {Mata, F and Claramunt, C and Juarez, A},
booktitle = {GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems},
doi = {10.1145/2093973.2094058},
keywords = {Augmented reality,Digital compass; Digital representations; Experime,Digital devices; Geographic information systems;},
pages = {497--500},
title = {{An experimental virtual museum based on augmented reality and navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84856508448{\&}doi=10.1145{\%}2F2093973.2094058{\&}partnerID=40{\&}md5=d682219ac8e0c5c00601a4c3dd546d77},
year = {2011}
}
@inproceedings{Brida2011203,
abstract = {The paper deals with performance evaluation of the indoor positioning solution based on utilization of IEEE 802.11 network and fingerprinting method. It is called WifiLOC and it is implemented as a mobile-assisted positioning system. The architecture of the system is presented. WifiLOC is based on the fingerprinting method, which utilizes signal strength information for position estimation. A lot of factors influence the propagation of radio signals in indoor environment. This fact also significantly impacts on properties of the positioning systems. In the paper, the impact of the positioning accuracy is presented various conditions such as moving objects in the observed area or the type of indoor environment, e.g. corridor, office and room, are taken into account. The influence of different conditions during the off-line and the on-line phase of fingerprinting method on the positioning accuracy is also investigated. {\textcopyright} 2011 IEEE.},
annote = {cited By 8},
author = {Brida, P and Benikovsky, J and MacHaj, J},
booktitle = {2011 34th International Conference on Telecommunications and Signal Processing, TSP 2011 - Proceedings},
doi = {10.1109/TSP.2011.6043743},
keywords = {Fingerprinting; Indoor positioning; Location-Based,Mobile computing; Navigation systems; Signal proc,Tracking (position)},
pages = {203--207},
title = {{Performance investigation of WifiLOC positioning system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80555139627{\&}doi=10.1109{\%}2FTSP.2011.6043743{\&}partnerID=40{\&}md5=5ecc7f53a58a24549050a0680fa4d987},
year = {2011}
}
@article{Dai2015371,
abstract = {The surveying technique of photogrammetry has been proven to be safe, efficient, and inexpensive to extracting spatial data (i.e. shape, size, position) of infrastructure from collected photos. These data are useful in many infrastructure and construction applications such as quality control and quantity take-off. However, photogrammetry has not been widely used in construction projects because much effort is still needed to convert the image data into a three-dimensional (3D) geometric model in the physical space. More specifically, it demands manually marking object vertices and edges and referencing them across photos. To alleviate this situation, this paper proposes a novel method to group and link line segments in order to automate the object vertices and edges marking process. In the proposed method, small, discontinuous line segments are first detected in an image, and classified into different sets based on the vanishing points they belong to. Within each set, a novel algorithm is created to link the line segments into long line segments. Next, the corner information is derived from the image by a classic corner detector, and utilized to assure the actual locations of endpoints of each obtained long line segment. By removing the remaining ungrouped or unlinked small line segments, the final result is a set of complete and accurate line edges readily to be used in the ensuing step of photogrammetric process. So far, the grouping and classification of line segments have been implemented. The test result from outdoor and indoor images indicates effectiveness and promise of the method in facilitating the automation and broad applications of photogrammetry in construction. {\textcopyright} 2014, Springer Science+Business Media Dordrecht.},
annote = {cited By 3},
author = {Dai, F and Zhu, Z},
doi = {10.1007/s10846-014-0119-5},
journal = {Journal of Intelligent and Robotic Systems: Theory and Applications},
keywords = {3D models; Construction engineering; Image-based,Algorithms; Data handling; Edge detection; Informa,Image segmentation},
number = {3-4},
pages = {371--384},
title = {{Line Segment Grouping and Linking: A Key Step Toward Automated Photogrammetry for Non-Contact Site Surveying}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940198739{\&}doi=10.1007{\%}2Fs10846-014-0119-5{\&}partnerID=40{\&}md5=f64a553581872e310af9e0a7453804ac},
volume = {79},
year = {2015}
}
@article{Ghadiok201241,
abstract = {This paper presents the design and development of autonomous attitude stabilization, navigation in unstructured, GPS-denied environments, aggressive landing on inclined surfaces, and aerial gripping using onboard sensors on a low-cost, custom-built quadrotor. The development of a multi-functional micro air vehicle (MAV) that utilizes inexpensive off-the-shelf components presents multiple challenges due to noise and sensor accuracy, and there are control challenges involved with achieving various capabilities beyond navigation. This paper addresses these issues by developing a complete system from the ground up, addressing the attitude stabilization problem using extensive filtering and an attitude estimation filter recently developed in the literature. Navigation in both indoor and outdoor environments is achieved using a visual Simultaneous Localization and Mapping (SLAM) algorithm that relies on an onboard monocular camera. The system utilizes nested controllers for attitude stabilization, vision-based navigation, and guidance, with the navigation controller implemented using a nonlinear controller based on the sigmoid function. The efficacy of the approach is demonstrated by maintaining a stable hover even in the presence of wind gusts and when manually hitting and pulling on the quadrotor. Precision landing on inclined surfaces is demonstrated as an example of an aggressive maneuver, and is performed using only onboard sensing. Aerial gripping is accomplished with the addition of a secondary camera, capable of detecting infrared light sources, which is used to estimate the 3D location of an object, while an under-actuated and passively compliant manipulator is designed for effective gripping under uncertainty. The quadrotor is therefore able to autonomously navigate inside and outside, in the presence of disturbances, and perform tasks such as aggressively landing on inclined surfaces and locating and grasping an object, using only inexpensive, onboard sensors. {\textcopyright} 2012 Springer Science+Business Media, LLC.},
annote = {cited By 29},
author = {Ghadiok, V and Goldin, J and Ren, W},
doi = {10.1007/s10514-012-9286-z},
journal = {Autonomous Robots},
keywords = {Attitude estimation; Attitude stabilization; Compl,Cameras; Controllers; Landing; Light sources; Mat,Global positioning system},
number = {1-2},
pages = {41--68},
title = {{On the design and development of attitude stabilization, vision-based navigation, and aerial gripping for a low-cost quadrotor}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862127692{\&}doi=10.1007{\%}2Fs10514-012-9286-z{\&}partnerID=40{\&}md5=f0dd1a97e563a954beca9a1b80af47e0},
volume = {33},
year = {2012}
}
@article{Petrushin2006229,
abstract = {With the rapid proliferation of video cameras in public places, the ability to identify and track people and other objects creates tremendous opportunities for business and security applications. This paper presents the Multiple Camera Indoor Surveillance project which is devoted to using multiple cameras, agent-based technology and knowledge-based techniques to identify and track people and summarize their activities. We also describe a people localization system, which identifies and localizes people in an indoor environment. The system uses low-level color features - a color histogram and average vertical color - for building people models and the Bayesian decision-making approach for people localization. The results of a pilot experiment that used 32 h of data (4 days  8 h) showed the average recall and precision values of 68 and 59{\%} respectively. Augmenting the system with domain knowledge, such as location of working places in cubicles, doors and passages, increased the average recall to 87{\%} and precision to 73{\%}. {\textcopyright} Springer-Verlag London Limited 2006.},
annote = {cited By 13},
author = {Petrushin, V A and Wei, G and Gershman, A V},
doi = {10.1007/s10115-006-0025-7},
journal = {Knowledge and Information Systems},
number = {2},
pages = {229--241},
title = {{Multiple-camera people localization in an indoor environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33747169857{\&}doi=10.1007{\%}2Fs10115-006-0025-7{\&}partnerID=40{\&}md5=312c53d3d988884539191af1079c8775},
volume = {10},
year = {2006}
}
@article{Chen2014,
abstract = {(Figure Presented). We present a novel solution to automatic semantic modeling of indoor scenes from a sparse set of low-quality RGB-D images. Such data presents challenges due to noise, low resolution, occlusion and missing depth information. We exploit the knowledge in a scene database containing 100s of indoor scenes with over 10,000 manually segmented and labeled mesh models of objects. In seconds, we output a visually plausible 3D scene, adapting these models and their parts to fit the input scans. Contextual relationships learned from the database are used to constrain reconstruction, ensuring semantic compatibility between both object models and parts. Small objects and objects with incomplete depth information which are difficult to recover reliably are processed with a two-stage approach. Major objects are recognized first, providing a known scene structure. 2D contour-based model retrieval is then used to recover smaller objects. Evaluations using our own data and two public datasets show that our approach can model typical real-world indoor scenes efficiently and robustly. Copyright {\textcopyright} ACM.},
annote = {cited By 55},
author = {Chen, K and Lai, Y.-K. and Wu, Y.-X. and Martin, R and Hu, S.-M.},
doi = {10.1145/2661229.2661239},
journal = {ACM Transactions on Graphics},
keywords = {3D scenes; Contextual information; Contextual rela,Semantics},
number = {6},
title = {{Automatic semantic modeling of indoor scenes from low-quality RGB-D data using contextual information}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84914703207{\&}doi=10.1145{\%}2F2661229.2661239{\&}partnerID=40{\&}md5=514503dc2766b27ab603d51c96f3cf67},
volume = {33},
year = {2014}
}
@article{Mndez-Polanco2009349,
abstract = {People detection and tracking is a key issue for social robot design and effective human robot interaction. This paper addresses the problem of detecting people with a mobile robot using a stereo camera. People detection using mobile robots is a difficult task because in real world scenarios it is common to find: unpredictable motion of people, dynamic environments, and different degrees of human body occlusion. Additionally, we cannot expect people to cooperate with the robot to perform its task. In our people detection method, first, an object segmentation method that uses the distance information provided by a stereo camera is used to separate people from the background. The segmentation method proposed in this work takes into account human body proportions to segment people and provides a first estimation of people location. After segmentation, an adaptive contour people model based on people distance to the robot is used to calculate a probability of detecting people. Finally, people are detected merging the probabilities of the contour people model and by evaluating evidence over time by applying a Bayesian scheme. We present experiments on detection of standing and sitting people, as well as people in frontal and side view with a mobile robot in real world scenarios. {\textcopyright} 2009 Springer-Verlag Berlin Heidelberg.},
annote = {cited By 5},
author = {M{\'{e}}ndez-Polanco, J A and Mu{\~{n}}oz-Mel{\'{e}}ndez, A and Morales, E F},
doi = {10.1007/978-3-642-05258-3_31},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Artificial intelligence; Cameras; Human computer,Bayesian; Distance information; Dynamic environmen,Machine design},
pages = {349--359},
title = {{People detection by a mobile robot using stereo vision in dynamic indoor environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70649088875{\&}doi=10.1007{\%}2F978-3-642-05258-3{\_}31{\&}partnerID=40{\&}md5=c994e35dbf922f6740a66df1c299077e},
volume = {5845 LNAI},
year = {2009}
}
@inproceedings{Khan2016158,
abstract = {Acoustic event Detection (AED) is concerned with recognition of sound which is produced by the human and the object that is handled by human or by nature. The Detection of acoustic events is an important task for our intelligent system which is supposed to recognize not only speech but also sounds of our indoor and outdoor environments that includes information retrieval, audio-based surveillance and monitoring systems. Currently, System for detection and classification of events from our daily monophonic sound is mature enough to extract features and detect isolated events nearly accurate but accuracy is very low for large dataset and for noisy and overlapped audio events. Mostly the real life sounds are polyphonic and events have some part of overlap which is harder to detect. In our work we will discuss the previous issues for detection and feature extraction of acoustic events. We use the DCASE dataset, published in an international IEEE AASP challenge for Acoustic Event Detection which includes the "office live" recordings which were prepared in an office environment. MFCC is a technique commonly used for features extraction of speech and Acoustic event. We propose to use the Gabor filterbank in addition to MFCCs coefficients to analyze the feature. For Classification we use the Decision tree algorithm that gives better classification and detection result. . Finally, we compare our proposed system with each system that was used for DCASE dataset and concluded that our technique gives best F-Score value in detection of events as compare to others. {\textcopyright} 2016 ACM.},
annote = {cited By 0},
author = {Khan, U Z and Shaukat, A and Akram, M U and Basit, M K and Hassan, A and Wahid, A},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3015166.3015186},
keywords = {Acoustic event detections; Decision-tree algorith,Audio acoustics; Audio systems; Classification (of,Feature extraction},
pages = {158--164},
title = {{Detection of acoustic events by using MFCC and spectro-temporal gabor filterbank features}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014853936{\&}doi=10.1145{\%}2F3015166.3015186{\&}partnerID=40{\&}md5=ea4047a1222ea0da395cd6db7ca574a9},
year = {2016}
}
@article{Swadzba2008734,
abstract = {In this paper, we propose a holistic classification scheme for different room types, like office or meeting room, based on 3D features. Such a categorization of scenes provides a rich source of information about potential objects, object locations, and activities typically found in them. Scene categorization is a challenging task. While outdoor scenes can be sufficiently characterized by color and texture features, indoor scenes consist of human-made structures that vary in terms of color and texture across different individual rooms of the same category. Nevertheless, humans tend to have an immediate impression in which room type they are. We suggest that such a decision could be based on the coarse spatial layout of a scene. Therefore, we present a system that categorizes different room types based on 3D sensor data extracted by a Time-of-Flight (ToF) camera. We extract planar structures combining region growing and RANSAC approaches. Then, feature vectors are defined on statistics over the relative sizes of the planar patches, the angles between pairs of (close) patches, and the ratios between sizes of pairs of patches to train classifiers. Experiments in a mobile robot scenario study the performance in classifying a room based on a single percept. {\textcopyright} 2008 Springer Berlin Heidelberg.},
annote = {cited By 7},
author = {Swadzba, A and Wachsmuth, S},
doi = {10.1007/978-3-540-89689-0_77},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {3d sensors; Challenging tasks; Classification sch,Pattern recognition,Surface plasmon resonance; Syntactics; Technical p},
pages = {734--744},
title = {{Categorizing perceptions of indoor rooms using 3D features}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-58349089716{\&}doi=10.1007{\%}2F978-3-540-89689-0{\_}77{\&}partnerID=40{\&}md5=eec23a12d71847ade27807da879f4eba},
volume = {5342 LNCS},
year = {2008}
}
@inproceedings{Kim2009,
abstract = {This paper reports preliminary work with an RFID based real time location system (RTLS) designed for location and guidance of people in welfare facilities like the sanatorium which has the both of indoor and out door environment. The system consists of a number of fixed RF readers and a number of active RFID tags carried by the target object, or senior people. We compare the performance of several RTLS schemes which use the received signal strength indication (RSSI) values emitted by the moving active RFID tags. Traditional trilateration, fingerprinting, and well-known LANDMARC approaches are evaluated and compared using the SystemC-based computer simulation. Results show a mean estimated error (MEE) performance of 3m with the 130 tags according to the position updated frequency in our simulation environment. {\textcopyright}2009 IEEE.},
annote = {cited By 2},
author = {Kim, T and Lee, S and Park, S.-C.},
booktitle = {2009 6th IEEE Consumer Communications and Networking Conference, CCNC 2009},
doi = {10.1109/CCNC.2009.4784821},
keywords = {Active RFID; Estimated errors; Positioning system;,Radio navigation},
title = {{Effect of collision on movement tracking using active RFID power measurement}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-63749131493{\&}doi=10.1109{\%}2FCCNC.2009.4784821{\&}partnerID=40{\&}md5=273befdb063091e810dcfa23f45afe83},
year = {2009}
}
@article{Shen20122182,
abstract = {Localization of objects is fast becoming a major aspect of wireless technologies, with applications in logistics, surveillance, and emergency response. Time-of-arrival (TOA) localization is ideally suited for high-precision localization of objects in particular in indoor environments, where GPS is not available. This paper considers the case where one transmitter and multiple, distributed, receivers are used to estimate the location of a passive (reflecting) object. It furthermore focuses on the situation when the transmitter and receivers can be synchronized, so that TOA (as opposed to time-difference-of-arrival (TDOA)) information can be used. We propose a novel, Two-Step estimation (TSE) algorithm for the localization of the object. We then derive the Cramer-Rao Lower Bound (CRLB) for TOA and show that it is an order of magnitude lower than the CRLB of TDOA in typical setups. The TSE algorithm achieves the CRLB when the TOA measurements are subject to small Gaussian-distributed errors, which is verified by analytical and simulation results. Moreover, practical measurement results show that the estimation error variance of TSE can be 33 dB lower than that of TDOA based algorithms. {\textcopyright} 2012 IEEE.},
annote = {cited By 162},
author = {Shen, J and Molisch, A F and Salmi, J},
doi = {10.1109/TWC.2012.040412.110697},
journal = {IEEE Transactions on Wireless Communications},
keywords = {Algorithms; Cramer-Rao bounds; Transmitters; Wire,Cramer-rao lower bound; CRLB; Emergency response;,Estimation},
number = {6},
pages = {2182--2192},
title = {{Accurate passive location estimation using TOA measurements}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862864307{\&}doi=10.1109{\%}2FTWC.2012.040412.110697{\&}partnerID=40{\&}md5=cef6159c8ce7c14bbafb74b42c2116a6},
volume = {11},
year = {2012}
}
@inproceedings{Zou2017237,
abstract = {Object differentiation plays a vital role in our daily life and such systems are widely deployed with RFID tags or bar codes attached on goods. In certain scenarios, however, attaching tags to objects may be impractical due to cost and protection issues. In this paper, we propose TagFree, a novel object differentiation scheme without attaching tags. Instead of relying on external tags, we exploit the inherent radiometric properties of different objects as their signatures. To improve the robustness and efficiency of TagFree, we empirically determine a spatial safe zone and harness successive cancellation to distinguish multiple objects simultaneously. We prototype TagFree on commercial WiFi infrastructure and evaluate its performance in various indoor scenarios. Experimental results demonstrate that TagFree achieves single object distinguishing accuracy of 96{\%} measured at the same location, and over 80{\%} within the safe zone range of up to 3m along a 7m link. TagFree can also differentiate up to 3 objects with acceptable accuracy. {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Zou, Y and Wang, Y and Ye, S and Wu, K and Ni, L M},
booktitle = {2017 IEEE International Conference on Pervasive Computing and Communications, PerCom 2017},
doi = {10.1109/PERCOM.2017.7917870},
keywords = {Bar codes; Network layers; Radiometry,Daily lives; Differentiation schemes; Multiple ob,Ubiquitous computing},
pages = {237--246},
title = {{TagFree: Passive object differentiation via physical layer radiometric signatures}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020030737{\&}doi=10.1109{\%}2FPERCOM.2017.7917870{\&}partnerID=40{\&}md5=62ee0f394ddf64074339aec71668c43d},
year = {2017}
}
@inproceedings{Funk2014,
abstract = {With head-mounted displays becoming more ubiquitous, the vision of extending human object search capabilities using a wearable system becomes feasible. Wearable cameras can recognize known objects and store their indoor location. But how can the location of objects be represented on a wearable device like Google Glass and how can the user be navigated towards the object? We implemented a prototype on a wearable computer with a head-mounted display and compared a last seen image representation against a map representation of the location. We found a significant interaction effect favoring the last seen image with harder hidden objects. Additionally, all objective and subjective measures generally favor the last seen image. Results suggest that a map representation is more helpful for gross navigation and an image representation is more supportive for fine navigation.},
annote = {cited By 8},
author = {Funk, M and Boldt, R and Pfleging, B and Pfeiffer, M and Henze, N and Schmidt, A},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/2582051.2582069},
keywords = {Augmented reality; Flow visualization; Wearable co,Head mounted displays; Image representations; Ind,Helmet mounted displays},
title = {{Representing indoor location of objects on wearable computers with head-mounted displays}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899878467{\&}doi=10.1145{\%}2F2582051.2582069{\&}partnerID=40{\&}md5=c58f519ad642aba3b69058a707e92990},
year = {2014}
}
@article{Afyouni2014128,
abstract = {Continuous location-dependent queries are key elements for the development of location-based and context-aware services. While most work on location-dependent query processing has been mainly oriented towards outdoor environments, this paper develops an approach for the continuous processing of location-dependent queries over indoor moving objects. A prototype for handling those queries has been developed as an extension for the open-source DBMS PostgreSQL. Several algorithms for the continuous processing of path searches and range queries applied to both static and moving objects are performed on top of a hierarchical and context-dependent data model. Experimental results have been conducted to report our findings. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
annote = {cited By 3},
author = {Afyouni, I and Ray, C and Ilarri, S and Claramunt, C},
doi = {10.1016/j.pmcj.2013.09.008},
journal = {Pervasive and Mobile Computing},
keywords = {Continuous processing; In-door navigations; Locat,Information services; Location; Query processing,Location based services},
pages = {128--150},
title = {{A PostgreSQL extension for continuous path and range queries in indoor mobile environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912150452{\&}doi=10.1016{\%}2Fj.pmcj.2013.09.008{\&}partnerID=40{\&}md5=28aac6ad54a514c10b00daf321ac0687},
volume = {15},
year = {2014}
}
@inproceedings{Xu20122002,
abstract = {In this demonstration, we introduce a system that is able to manage moving objects in all real world environments, e.g., road network, bus network and indoor. The complete trip of a person is managed by the system such as Walk, Car, Walk, and Indoor, where the precise locations of both outdoor and indoor movements are represented. Trajectories located in several environments are integrated into the same framework. The system supports the shortest path searching for start and end locations being in different environments, for example, from a room to a bus stop. A comprehensive and scalable set of moving objects is generated to simulate human movement in practice. Optimization methods are developed to efficiently answer novel queries regarding transportation modes and mobile environments. Most of these queries are not supported by existing methods because of the limitation of data representation. {\textcopyright} 2012 VLDB Endowment.},
annote = {cited By 5},
author = {Xu, J and G{\"{u}}ting, R H},
booktitle = {Proceedings of the VLDB Endowment},
doi = {10.14778/2367502.2367558},
keywords = {Data representations; Human movements; Mobile envi,Query processing},
number = {12},
pages = {2002--2005},
title = {{Manage and query generic moving objects in SECONDO}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873135382{\&}doi=10.14778{\%}2F2367502.2367558{\&}partnerID=40{\&}md5=dee766aaa5052e3b7f4e59d5d832afff},
volume = {5},
year = {2012}
}
@inproceedings{Liao2003723,
abstract = {Tracking the activity of people in indoor environments has gained considerable attention in the robotics community over the last years. Most of the existing approaches are based on sensors which allow to accurately determine the locations of people but do not provide means to distinguish between different persons. In this paper we propose a novel approach to tracking moving objects and their identity using noisy, sparse information collected by id-sensors such as infrared and ultrasound badge systems. The key idea of our approach is to use particle filters to estimate the locations of people on the Voronoi graph of the environment. By restricting particles to a graph, we make use of the inherent structure of indoor environments. The approach has two key advantages. First, it is by far more efficient and robust than unconstrained particle filters. Second, the Voronoi graph provides a natural discretization of human motion, which allows us to apply unsupervised learning techniques to derive typical motion patterns of the people in the environment. Experiments using a robot to collect ground-truth data indicate the superior performance of Voronoi tracking. Furthermore, we demonstrate that EM-based learning of behavior patterns increases the tracking performance and provides valuable information for high-level behavior recognition.},
annote = {cited By 81},
author = {Liao, L and Fox, D and Hightower, J and Kautz, H and Schulz, D},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
keywords = {Data reduction; Graph theory; Mobile robots; Moti,Laser range-finders; Particle filters,Robotics},
pages = {723--728},
title = {{Voronoi Tracking: Location Estimation Using Sparse and Noisy Sensor Data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0346780149{\&}partnerID=40{\&}md5=776f59f10dd9927f3c751a7cde332ce3},
volume = {1},
year = {2003}
}
@inproceedings{Alam2017333,
abstract = {In this paper we developed an image processing based indoor localization system with color detection technique of connected objects. By using color detection technique our system can pinpoint a user's location with very high accuracy for real-Time applications. We used our system to filter out an image for a specific color and extracted pixel co-ordinates for that image. User's location is then determined by comparing the matrix for those values against a pre-created matrix of training images. We successfully conducted experiments in indoor environments as well and they yielded very good results. After analyzing these results, we propose to integrate our localization system with indoor navigation systems which can be used for blind people where accuracy is the most important element. To further facilitate the navigation process we also developed an android based application. {\textcopyright} 2017 IEEE.},
annote = {cited By 2},
author = {Alam, M M and Arefin, S E and Alim, M A and Adib, S I and Rahman, M A},
booktitle = {ECCE 2017 - International Conference on Electrical, Computer and Communication Engineering},
doi = {10.1109/ECACE.2017.7912927},
keywords = {Color segmentation; Indoor localization; Indoor l,Color; Color image processing; Image processing; I,Indoor positioning systems},
pages = {333--338},
title = {{Indoor localization system for assisting visually impaired people}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019225753{\&}doi=10.1109{\%}2FECACE.2017.7912927{\&}partnerID=40{\&}md5=a2b52f403fc9ddb7823e1c678fa595a7},
year = {2017}
}
@article{Wang2011241,
abstract = {This paper presents a novel application called LOVINA for RFID computing that integrates RFID positioning technology and virtual reality. Using a museum as an example, we develop a 3D virtual navigation system that supports indoor RFID localisation. If a user is carrying a notebook or mobile device while walking through an exhibition room, the system can update the user's position accurately. This information can be used to guide users as they near particular historical objects; for example, the system can trigger special information that alerts users and helps them experience real and virtual historical relics, buildings, and incidents more completely. {\textcopyright} 2011 Inderscience Enterprises Ltd.},
annote = {cited By 2},
author = {Wang, C.-S.},
doi = {10.1504/IJAHUC.2011.043585},
journal = {International Journal of Ad Hoc and Ubiquitous Computing},
keywords = {Localisation; Location-aware; Positioning; Radio f,Mobile devices; Museums; Radio frequency identifi,Navigation systems},
number = {4},
pages = {241--248},
title = {{LOVINA: Location-aware virtual navigation system based on active RFID}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84255193266{\&}doi=10.1504{\%}2FIJAHUC.2011.043585{\&}partnerID=40{\&}md5=30c6a8a657607899a3e0518ef1984364},
volume = {8},
year = {2011}
}
@inproceedings{Datta20112507,
abstract = {Research done in two aspects of robot localization and mapping are presented. An online fast learning FLANN, capable of learning location specific spatio-temporally stable visual features is developed. A technique for building oriented place maps using vestibular sensory information that can store multiple pose information of objects is investigated. Unlike most localization and mapping techniques ours does not require any depth estimation and can also handle dynamically changing environments. The system is tested in indoor environments, ranging from very simple to extremely cluttered ones. Preliminary research results show good generalization and learning capabilities of the network and improved localization using multiple oriented place maps. {\textcopyright} 2011 IEEE.},
annote = {cited By 0},
author = {Datta, A and Yow, K.-C.},
booktitle = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
doi = {10.1109/ICSMC.2011.6084054},
keywords = {Changing environment; Depth Estimation; Fast learn,Cybernetics; E-learning; Mapping; Robot applicati,Neural networks},
pages = {2507--2514},
title = {{A fast learning neural network for oriented visual place map based robot navigation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-83755163960{\&}doi=10.1109{\%}2FICSMC.2011.6084054{\&}partnerID=40{\&}md5=7929fe48fc379ff2d5729274190c61ed},
year = {2011}
}
@article{Bahaaldin2016415,
abstract = {Localization of persons and objects has become a necessity in many industrial services. In indoor circumstances, radio frequency identification (RFID) has superior performance. However, radio signals within indoor environments are generally weak, and the tags have very restricted abilities. In addition, the multipath propagation, total cost, and signal interference increase with increasing number of reference tags over a certain limit. Therefore, to improve the performance of indoor positioning for real-time localization, a new active acquisition method for an active RFID system that works at 2.4GHz has been proposed; it is called the boundary virtual reference (BVIRE) algorithm. It depends on boundary virtual reference tags rather than increasing the number of real reference tags, which in turn reduces the total cost while maintaining the location accuracy. We have implemented a linear regression method to further enhance the positioning accuracy while eliminating the unnecessary tags from the estimation method using event filtering, in which only a few neighbouring reference tags are helpful in deciding the location of the object tag. The experimental results show that our BVIRE algorithm considerably reduces the error estimation compared with previous algorithms. The system has enhanced the positioning accuracy and lowered the total costs. In addition, the localization precision of the proposed approach has been significantly increased to approximately 90.25{\%} compared with PinPoint algorithm with no additional reference tags or radio frequency interference; this represents a significant improvement over other algorithms. {\textcopyright} 2016, Springer Science+Business Media New York.},
annote = {cited By 5},
author = {Baha aldin, N and Er{\c{c}}elebi, E and Ayka{\c{c}}, M},
doi = {10.1007/s10470-016-0789-y},
journal = {Analog Integrated Circuits and Signal Processing},
keywords = {Active RFID; Linear regression methods; Positioni,Algorithms; Communication channels (information th,Radio frequency identification (RFID)},
number = {3},
pages = {415--430},
title = {{Advanced boundary virtual reference algorithm for an indoor system using an active RFID interrogator and transponder}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976507487{\&}doi=10.1007{\%}2Fs10470-016-0789-y{\&}partnerID=40{\&}md5=c1d85d1cec4b2aa1cc6bb382f17aabd2},
volume = {88},
year = {2016}
}
@inproceedings{Bu2017,
abstract = {Currently, in the ROK, IoT holds the limelight and various types of IoT equipments that integrate the "Smart function" to existing electric or electronic equipments are being developed and introduced to the market. It takes many hours and much efforts to attach the smart equipments to each existing equipment to realize a complete IoT system so that this study is to make the central control device to recognize each product, provide relevant information to the product and command it to perform the movements corresponding the command, without additional smart equipments. Since interior structural changes of a household or a building are rare, relevant information can be provided to the user by tracking which object or structure he/she is being positioned in front of. However, the existing commercial positioning systems such as GPS and others often do not offer high-precision level and cannot be used indoors. The proposed system in this article attempts to localize the user's position by triangulation based on the signals emitted from widely installed beacons acting as the reference points. This concept does not use GPS satellite(s) but employ its basic principle. The system adopts the BLE and its exclusive equipments which allow a long-term operation of a beacon from approx. 1.8 to 28.7 months with the CR2045 battery due to their low power consumption rates. Thus, a location-based application service based on the BLE-utilized positioning system has been proposed in this study. In the design, smart phone's geomagnetic sensor and the acceleration sensor have been integrated within the BLE-based ranging system. The distance and direction of a beacon from one's own position will be indicated on the GUI map based on the measurements. In addition, a database for the initial values will be established so that there's no need to set up the initial value beforehand. The position of the relevant object can be estimated by aggregating the realtime measurements in the way of PIC control. This way, a rough estimation can be performed even with just one beacon. {\textcopyright} 2017 ACM.},
annote = {cited By 3},
author = {Bu, Y and Seo, K and Huh, J.-H.},
booktitle = {Proceedings of the 11th International Conference on Ubiquitous Information Management and Communication, IMCOM 2017},
doi = {10.1145/3022227.3022316},
keywords = {Acceleration sensors; Bluetooth low energies (BTL,Bluetooth; Geomagnetism; Global positioning system,Equipment},
title = {{A study of enhancement of ranging performance of beacons through improvement of the Smart phone's gyroscope: Focusing on the bluetooth low energy}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015207274{\&}doi=10.1145{\%}2F3022227.3022316{\&}partnerID=40{\&}md5=d44fac11eaf37608aeb66c60c41920a9},
year = {2017}
}
@inproceedings{Chen2011299,
abstract = {In this paper a novel method for tracking moving objects in wireless sensor network is presented. Firstly, the observed position is estimated by a moving object localization algorithm based on Received Signal Strength Indication (RSSI). Then, the estimated position is filtered by a Kalman filter in order to obtain a smoothed trajectory of moving objects movement. Simulation results show the effectiveness of presented algorithm in indoor environments. {\textcopyright} 2011 IEEE.},
annote = {cited By 3},
author = {Chen, Y and Ni, D and Zhang, L and Deng, C},
booktitle = {2011 IEEE 3rd International Conference on Communication Software and Networks, ICCSN 2011},
doi = {10.1109/ICCSN.2011.6014726},
keywords = {Algorithms; Communication; Kalman filters; Locati,Indoor environment; Mobile nodes; Moving object lo,Sensor nodes},
pages = {299--302},
title = {{Realizing mobile node tracking in wireless sensor network based on Kalman filter}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053139164{\&}doi=10.1109{\%}2FICCSN.2011.6014726{\&}partnerID=40{\&}md5=7012b8547efefab2c08537613e9cf7c8},
year = {2011}
}
@inproceedings{Satan20181,
abstract = {This paper presents an Android application that is capable for proximity based indoor localization using Bluetooth RSSI. Proximity based localization can be useful for finding well recognizable objects or areas within building. The goal of the system is to locate offices and people in office buildings. The presented algorithm estimates the distance between client and beacon, based on RSSI values and Log-Distance Path Loss Model. Application was tested in a three story building and experimental results demonstrate the applicability of the localization algorithm. The application estimated the position correctly in 88{\%} of the test cases. {\textcopyright} 2018 IEEE.},
annote = {cited By 2},
author = {Satan, A and Toth, Z},
booktitle = {2018 IEEE International Conference on Future IoT Technologies, Future IoT 2018},
doi = {10.1109/FIOT.2018.8325586},
keywords = {Android applications; Beacon; Bluetooth-based; In,Bluetooth; Internet of things; Office buildings,Indoor positioning systems},
pages = {1--6},
title = {{Development of bluetooth based indoor positioning application}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050213777{\&}doi=10.1109{\%}2FFIOT.2018.8325586{\&}partnerID=40{\&}md5=9baaa1a1f2ba38c40439ff23715e0edc},
volume = {2018-Janua},
year = {2018}
}
@article{Bahadori200783,
abstract = {Detecting, locating, and tracking people in a dynamic environment is important in many applications, ranging from security and environmental surveillance to assistance to people in domestic environments, to the analysis of human activities. To this end, several methods for tracking people have been developed in the field of Computer Vision using different settings, such as monocular cameras, stereo sensors, multiple cameras. In this article we describe a method for People Localization and Tracking (PLT) based on a calibrated fixed stereo vision sensor, its implementation and experimental results. The system analyzes three components of the stereo data (the left intensity image, the disparity image, and the 3-D world locations of measured points) to dynamically update a model of the background; extract foreground objects, such as people and rearranged furniture; track their positions in the world. The system is mostly suitable for indoor medium size environments. It can reliably detect and track people moving in an medium size area (a room or a corridor) in front of the sensor with high reliability and good precision. {\textcopyright} Springer Science+Business Media, LLC 2007.},
annote = {cited By 33},
author = {Bahadori, S and Iocchi, L and Leone, G R and Nardi, D and Scozzafava, L},
doi = {10.1007/s10489-006-0013-3},
journal = {Applied Intelligence},
keywords = {Background segmentation; Monocular cameras; Motio,Calibration; Cameras; Computer vision; Image segme,Tracking (position)},
number = {2},
pages = {83--97},
title = {{Real-time people localization and tracking through fixed stereo vision}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847740650{\&}doi=10.1007{\%}2Fs10489-006-0013-3{\&}partnerID=40{\&}md5=ad66f953373d0da6b0a057484fa55751},
volume = {26},
year = {2007}
}
@article{Chamberland-Tremblay2012226,
abstract = {Indoor location systems allow for the integration of more and more daily life objects into the smart home environment model. Consequently, managing the spatiotemporal data of things is becoming increasingly challenging. In this article, we propose a 3D geometrical approach to spatiotemporal object management and analysis based on the adaptation of the spatial database concept. We use the DOMUS apartment at Universit{\'{e}} de Sherbrooke as a reference environment for 3D modeling of smart homes. We present a sample of 3D spatial analysis functions implemented in the DBMS to illustrate the use of the geometric model in providing smart home indoor location-based services. {\textcopyright} 2012 Springer-Verlag.},
annote = {cited By 0},
author = {Chamberland-Tremblay, D and Giroux, S and Caron, C},
doi = {10.1007/978-3-642-30779-9_31},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {3-d modeling; 3D spatial analysis; Daily lives; Ge,Automation; Intelligent buildings; Location based,Three dimensional},
pages = {226--229},
title = {{A smart home 3D modeling approach for spatiotemporal analysis}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862205298{\&}doi=10.1007{\%}2F978-3-642-30779-9{\_}31{\&}partnerID=40{\&}md5=719a1a0b8278cf9933c29574627c1993},
volume = {7251 LNCS},
year = {2012}
}
@inproceedings{Sun20143165,
abstract = {Identifying objects based on language descriptions is an important capability for robots interacting with people in everyday environments. People naturally use attributes and names to refer to objects of interest. Due to the complexity of indoor environments and the fact that people use various ways to refer to objects, a robot frequently encounters new objects or object names. To deal with such situations, a robot must be able to continuously grow its object knowledge base. In this work we introduce a system that organizes objects and names in a semantic hierarchy. Similarity between name words is learned via a hierarchy embedded vector representation. The hierarchy enables reasoning about unknown objects and names. Novel objects are inserted automatically into the knowledge base, where the exact location in the hierarchy is determined by asking a user questions. The questions are informed by the current hierarchy and the appearance of the object. Experiments demonstrate that the learned representation captures the meaning of names and is helpful for object identification with new names. {\textcopyright} 2014 IEEE.},
annote = {cited By 5},
author = {Sun, Y and Bo, L and Fox, D},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2014.6907314},
pages = {3165--3172},
title = {{Learning to identify new objects}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929192418{\&}doi=10.1109{\%}2FICRA.2014.6907314{\&}partnerID=40{\&}md5=3224f5fec0c598da0d7644de7ae34495},
year = {2014}
}
@article{Hada2010280,
abstract = {This paper proposes an indoor positioning system for detecting the location of a moving object such as a person or a goods trolley in a wide indoor area. Conventional system requires synchronization between transmission and receiving unit. As a result, they include not only an ultrasonic part but also a radio part to maintain synchronization. We have developed a system that uses only ultrasonic waves, that is, an asynchronous system. The system configuration and sequence of operation are explained and the verification system which includes H8, PIC microprocessors and a PC for positioning calculation is described. It was confirmed that the proposed method is valid and the positioning error is within 100mm. {\textcopyright} 2010 Springer-Verlag Berlin Heidelberg.},
annote = {cited By 2},
author = {Hada, T and Sunaga, H and Akiyama, M and Ioroi, S and Tanaka, H},
doi = {10.1007/978-3-642-16917-5_31},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Artificial intelligence; Navigation; Sensors; Ult,Asynchronous system; Conventional systems; Indoor,Ultrasonics; Ambient intelligence},
pages = {280--284},
title = {{Investigation and demonstration of local positioning system using ultrasonic sensors for wide indoor areas}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649524392{\&}doi=10.1007{\%}2F978-3-642-16917-5{\_}31{\&}partnerID=40{\&}md5=511c9ede9c3de6365b3f39efde801265},
volume = {6439 LNCS},
year = {2010}
}
@article{Dey2014704,
abstract = {Handheld devices like smartphones and tablets have emerged as one of the most promising platforms for Augmented Reality (AR). The increased usage of these portable handheld devices has enabled handheld AR applications to reach the end-users; hence, it is timely and important to seriously consider the user experience of such applications. AR visualizations for occluded objects enable an observer to look through objects. AR visualizations have been predominantly evaluated using Head-Worn Displays (HWDs), handheld devices have rarely been used. However, unless we gain a better understanding of the perceptual and cognitive effects of handheld AR systems, effective interfaces for handheld devices cannot be designed. Similarly, human perception of AR systems in outdoor environments, which provide a higher degree of variation than indoor environments, has only been insufficiently explored. In this paper, we present insights acquired from five experiments we performed using handheld devices in outdoor locations. We provide design recommendations for handheld AR systems equipped with visualizations for occluded objects. Our key conclusions are the following: (1) Use of visualizations for occluded objects improves the depth perception of occluded objects akin to non-occluded objects. (2) To support different scenarios, handheld AR systems should provide multiple visualizations for occluded objects to complement each other. (3) Visual clutter in AR visualizations reduces the visibility of occluded objects and deteriorates depth judgment; depth judgment can be improved by providing clear visibility of the occluded objects. (4) Similar to virtual reality interfaces, both egocentric and exocentric distances are underestimated in handheld AR. (5) Depth perception will improve if handheld AR systems can dynamically adapt their geometric field of view (GFOV) to match the display field of view (DFOV). (6) Large handheld displays are hard to carry and use; however, they enable users to better grasp the depth of multiple graphical objects that are presented simultaneously. {\textcopyright} 2014 Elsevier Ltd.},
annote = {cited By 21},
author = {Dey, A and Sandor, C},
doi = {10.1016/j.ijhcs.2014.04.001},
journal = {International Journal of Human Computer Studies},
keywords = {Augmented reality; Cognitive systems; Depth percep,Design recommendations; Hand held device; Handhel,Visualization},
number = {10-11},
pages = {704--716},
title = {{Lessons learned: Evaluating visualizations for occluded objects in handheld augmented reality}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902682758{\&}doi=10.1016{\%}2Fj.ijhcs.2014.04.001{\&}partnerID=40{\&}md5=0e66136301f046e16ce7d1c09b7f44c9},
volume = {72},
year = {2014}
}
@article{Yuan2006569,
abstract = {Registration is one of the most difficult problems in augmented reality (AR) systems. In this paper, a simple registration method using natural features based on the projective reconstruction technique is proposed. This method consists of two steps: embedding and rendering. Embedding involves specifying four points to build the world coordinate system on which a virtual object will be superimposed. In rendering, the Kanade-Lucas-Tomasi (KLT) feature tracker is used to track the natural feature correspondences in the live video. The natural features that have been tracked are used to estimate the corresponding projective matrix in the image sequence. Next, the projective reconstruction technique is used to transfer the four specified points to compute the registration matrix for augmentation. This paper also proposes a robust method for estimating the projective matrix, where the natural features that have been tracked are normalized (translation and scaling) and used as the input data. The estimated projective matrix will be used as an initial estimate for a nonlinear optimization method that minimizes the actual residual errors based on the Levenberg-Marquardt (LM) minimization method, thus making the results more robust and stable. The proposed registration method has three major advantages: 1) It is simple, as no predefined fiducials or markers are used for registration for either indoor and outdoor AR applications. 2) It is robust, because it remains effective as long as at least six natural features are tracked during the entire augmentation, and the existence of the corresponding projective matrices in the live video is guaranteed. Meanwhile, the robust method to estimate the projective matrix can obtain stable results even when there are some outliers during the tracking process. 3) Virtual objects can still be superimposed on the specified areas, even if some parts of the areas are occluded during the entire process. Some indoor and outdoor experiments have been conducted to validate the performance of this proposed method. {\textcopyright} 2006 IEEE.},
annote = {cited By 46},
author = {Yuan, M L and Ong, S K and Nee, A Y C},
doi = {10.1109/TVCG.2006.79},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Algorithms; Artificial Intelligence; Cluster Anal,Automated; Photography; Signal Processing,Computer systems; Coordinate measuring machines;,Computer-Assisted; Imaging,Computer-Assisted; Pattern Recognition,Computer-Assisted; Subtraction Technique; User-Co,Natural feature tracking; Projective matrix; Proje,Three-Dimensional; Information Storage and Retrie,Virtual reality,algorithm; article; artificial intelligence; auto},
number = {4},
pages = {569--580},
title = {{Registration using natural features for augmented reality systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33744720750{\&}doi=10.1109{\%}2FTVCG.2006.79{\&}partnerID=40{\&}md5=c31bd5a13fff614702e1aed1df8a96b5},
volume = {12},
year = {2006}
}
@inproceedings{Senanayake20183241,
abstract = {Robots often have to deal with the challenges of operating in dynamic and sometimes unpredictable environments. Although an occupancy map of the environment is sufficient for navigation of a mobile robot or manipulation tasks with a robotic arm in static environments, robots operating in dynamic environments demand richer information to improve robustness, efficiency, and safety. For instance, in path planning, it is important to know the direction of motion of dynamic objects at various locations of the environment for safer navigation or human-robot interaction. In this paper, we introduce directional statistics into robotic mapping to model circular data. Primarily, in collateral to occupancy grid maps, we propose directional grid maps to represent the location-wide long-term angular motion of the environment. Being highly representative, this defines a probability measure-field over the longitude-latitude space rather than a scalar-field or a vector-field. Withal, we further demonstrate how the same theory can be used to model angular variations in the spatial domain, temporal domain, and spatiotemporal domain. We carried out a series of experiments to validate the proposed models using a variety of robots having different sensors such as RGB cameras and LiDARs on simulated and real-world settings in both indoor and outdoor environments. {\textcopyright} 2018 IEEE.},
annote = {cited By 0},
author = {Senanayake, R and Ramos, F},
booktitle = {IEEE International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2018.8594041},
keywords = {Angular uncertainty; Direction of motion; Directi,Human computer interaction; Human robot interactio,Robot programming},
pages = {3241--3248},
title = {{Directional Grid Maps: Modeling Multimodal Angular Uncertainty in Dynamic Environments}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062943331{\&}doi=10.1109{\%}2FIROS.2018.8594041{\&}partnerID=40{\&}md5=8756fa0d43e7278208ca55bd3b17694b},
year = {2018}
}
@inproceedings{Knierim2012,
abstract = {Searching for lost keys, wallets or mobile phones is a common nuisance. Compared to digital information, search support for physical objects is very limited. We propose Find My Stuff (FiMS) as a search engine for physical objects. We built a fully functional Arduino-based prototype. FiMS offers the users a simple search interface to locate tagged physical items in different indoor environments. A hierarchical search process ensures energy efficient and effective searches. Instead of a fixed search infrastructure, the localization system is based on SmartFurniture equipped with RFID readers and ZigBee modules. Search results provide intuitive search cues based on relative positioning to support users in the physical retrieval of their lost objects. The system requires no manual calibration and is robust against rearrangement of SmartFurniture. Safety mechanisms prevent abuse of the system and protect user privacy. Copyright 2012 ACM.},
annote = {cited By 2},
author = {Knierim, P and Nickels, J and Musiol, S and K{\"{o}}nings, B and Schaub, F and Wiedersheim, B and Weber, M},
booktitle = {Proceedings of the 11th International Conference on Mobile and Ubiquitous Multimedia, MUM 2012},
doi = {10.1145/2406367.2406433},
keywords = {Digital information; Energy efficient; Hierarchica,Energy efficiency; Global system for mobile commu,Search engines},
title = {{Find my stuff: A search engine for everyday objects}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871539000{\&}doi=10.1145{\%}2F2406367.2406433{\&}partnerID=40{\&}md5=9e3f52ba110df7c15e7b94cef0f7388e},
year = {2012}
}
@inproceedings{Zhou201742,
abstract = {The lack of digital oor plans is a huge obstacle to pervasive indoor location based services (LBS). Recent oor plan construction work crowdsources mobile sensing data from smartphone users for scalability. However, they incur long time (e.g., weeks or months) and tremendous efforts in data collection, and many rely on images thus suffering technical and privacy limitations. In this paper, we propose BatMapper, which explores a previously untapped sensing modality - acoustics - for fast, fine grained and low cost oor plan construction. We design sound signals suitable for heterogeneous microphones on commodity smartphones, and acoustic signal processing techniques to produce accurate distance measurements to nearby objects. We further develop robust probabilistic echo-object association, recursive outlier removal and probabilistic resampling algorithms to identify the correspondence between distances and objects, thus the geometry of corridors and rooms. We compensate minute hand sway movements to identify small surface recessions, thus detecting doors automatically. Experiments in real buildings show BatMapper achieves 1-2cm distance accuracy in ranges up around 4m; a 2  3 minute walk generates fine grained corridor shapes, detects doors at 92{\%} precision and 1  2m location error at 90-percentile; and tens of seconds of measurement gestures produce room geometry with errors {\textless} 0:3m at 80-percentile, at 1-2 orders of magnitude less data amounts and user efforts. {\textcopyright} 2017 ACM.},
annote = {cited By 9},
author = {Zhou, B and Elbadry, M and Gao, R and Ye, F},
booktitle = {MobiSys 2017 - Proceedings of the 15th Annual International Conference on Mobile Systems, Applications, and Services},
doi = {10.1145/3081333.3081363},
keywords = {Acoustic sensing; Construction works; Floorplans;,Floors; Signal processing; Smartphones,Location based services},
pages = {42--55},
title = {{BatMapper: Acoustic sensing based indoor floor plan construction using smartphones}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026197807{\&}doi=10.1145{\%}2F3081333.3081363{\&}partnerID=40{\&}md5=66208e94580b6a8f527bdf0fc296eeba},
year = {2017}
}
@inproceedings{Potgantwar2011,
abstract = {We have presented the issues and proposed system for design and architecture of our own innovative work about the Location Based System for Mobile Devices based on integration of RFID and wireless technology.Wireless technologies are capable of supporting mobility for users,and thus are popularly adopted to access the Internet today.As long as the position of a user is identified,location-based services,such as tour guide systems and mobile shopping, can be delivered to the user and improve the convenience in life.In indoor environment, the GPS signal cannot be received,and the positioning service requires the aid of indoor wireless technologies,such as wireless LAN,Bluetooth,Infrared and RFID. By integrating these heterogeneous wireless technologies, a hierarchical architecture for the indoor positioning service is proposed to enhance the positioning accuracy. The function of our system is based on strategically located passive RFID tags placed on objects around building which are identified using an RFID reader attached to a mobile device.The mobile device reads the RFID tag and through the wireless network, sends the request to the server.The server resolves the request and sends the desired location-based information back to the mobile device. We had addressed that we can go through the RFID technology for indoor which provides us better location accuracy because of no contact between the tag and the reader and the system requires no line of sight.In this paper we had also focused on the issues of RFID technologies i.e.Non-line-of-sight {\&} High inventory speeds. {\textcopyright} 2011 IEEE.},
annote = {cited By 5},
author = {Potgantwar, A D and Wadhai, V M},
booktitle = {Proceedings of 2011 International Conference on Process Automation, Control and Computing, PACC 2011},
doi = {10.1109/PACC.2011.5978985},
keywords = {Cryptography,GPS signals; Hierarchical architectures; Indoor en,Innovation; Mobile devices; Mobile phones; Networ},
title = {{Location based system for mobile devices with integration of RFID and wireless technology-issues and proposed system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052220853{\&}doi=10.1109{\%}2FPACC.2011.5978985{\&}partnerID=40{\&}md5=d645e36da1a0fc0cabe5fe2dd94c9a51},
year = {2011}
}
@article{Zhou20174115,
abstract = {In recent years, indoor positioning is becoming more and more important. Satellites can position only in the outdoor environment, which is unable to achieve precise positioning in the indoor environment. At present, the indoor positioning is mainly based on wireless signals, such as WiFi, RFID, Zigbee, Bluetooth etc. The cost and power consumption of using WiFi, RFID and Zigbee to realize the indoor positioning is very high and the deployment of WiFi, RFID and Zigbee is inconvenient. In this paper,indoor positioning is based on Bluetooth ibeacon, which is Bluetooth 4.0 standard. The power consumption and the cost of Bluetooth 4.0 is lower than others. In addition, Bluetooth has spread widely in the distance. This paper proposes a new indoor location method, which uses the method of learning to train the Bluetooth signal propagation model in the museum environment and uses the method of weighted least square and four-border positioning to estimate the location of the target object. The experimental result shows that the method is stable and good robustness. The positioning accuracy meets the requirements of the indoor positioning. {\textcopyright} 2017, Springer Science+Business Media New York.},
annote = {cited By 5},
author = {Zhou, C and Yuan, J and Liu, H and Qiu, J},
doi = {10.1007/s11277-017-4371-4},
journal = {Wireless Personal Communications},
keywords = {Bandpass filters; Bluetooth; Electric power utiliz,Indoor environment; Indoor positioning; Outdoor e,Indoor positioning systems},
number = {3},
pages = {4115--4130},
title = {{Bluetooth Indoor Positioning Based on RSSI and Kalman Filter}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025841739{\&}doi=10.1007{\%}2Fs11277-017-4371-4{\&}partnerID=40{\&}md5=33bea31d9a90dc5c450476adf92c8156},
volume = {96},
year = {2017}
}
@inproceedings{Kamruzzaman2017543,
abstract = {Automation of modern industrial plants require real-time tracking of object locations and sensing of local and ambient parameters for variety of applications such as counting and tracking of objects in assembly line, detection and positioning of failures of machines etc. Mostly, discrete Real Time Location System (RTLS) performs object tracking in existing industrial automation without its integration with the sensing and control network, which constrains application's responsiveness. In this paper, we propose an integrated solution of Wireless Positioning Sensor Network (WPSN) that is designed for accuracy, reliability, scalability and optimal network operation. The proposed WPSN is applicable for harsh indoor industrial environments for not only monitoring and control of plant operations but also for identification, localization and tracking of assets and inventory in industrial warehouses. The indoor industrial environment poses challenging conditions for radio signal propagation that adversely affects reliability of communication of sensing and location data. We approach reliability by incorporating redundancy and making our network reconfigurable through adaptive intelligent learning process. We employ adaptive clustering technique to address the need of scalable deployment for varied industrial scenarios. We include hybrid localization scheme to provide high precision positioning but with fallback reduced precision operation to deal with long-term channel impairment. The WPSN is connected with backend cloud infrastructure for low cost monitoring and control. {\textcopyright} 2017 IEEE.},
annote = {cited By 0},
author = {Kamruzzaman, S M and Jaseemuddin, M and Fernando, X and Moeini, P},
booktitle = {Proceedings - Conference on Local Computer Networks, LCN},
doi = {10.1109/LCN.2017.68},
keywords = {Automation; Computer networks; Discrete time contr,Indoor positioning; Industrial automation; Intell,Wireless sensor networks},
pages = {543--546},
title = {{Wireless Positioning Sensor Network Integrated with Cloud for Industrial Automation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040619536{\&}doi=10.1109{\%}2FLCN.2017.68{\&}partnerID=40{\&}md5=0262eb4c48381eabb279722e1efd977d},
volume = {2017-Octob},
year = {2017}
}
@article{Mineno2005431,
abstract = {Determining physical location of indoor objects is one of the key issues in ubiquitous computing. Although there are many proposals to provide physical location tracking, those have some restrictions such as a dependence on the type and size of objects and a trade-off between position accuracy and the number of sensing devices. In this paper we present a hierarchical approach to conquer these restrictions using mobile detectors. We describe a system called MobiTra that estimates the position of indoor any and all objects using mobile detectors' detection histories. The effect of position estimation is evaluated through prototype testbed and simulation. {\textcopyright} Springer-Verlag Berlin Heidelberg 2005.},
annote = {cited By 2},
author = {Mineno, H and Hida, K and Mizutani, M and Miyauchi, N and Kusunoki, K and Fukuda, A and Mizuno, T},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Computer simulation; Computer supported cooperativ,Mobile detectors; Position estimation; Tracking s,Tracking (position)},
pages = {431--437},
title = {{Position estimation for goods tracking system using mobile detectors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745302035{\&}partnerID=40{\&}md5=9320c57f1df430a3640b8e4aec959252},
volume = {3681 LNAI},
year = {2005}
}
@inproceedings{Ogawa20143700,
abstract = {In recent years, robots working in human living space with human-robot interactions are actively studied. To these robots, it is important to perform environmental cognition not only building environment map for autonomous motion of the robots but also estimating presences of human around the robots. In this study, by utilizing human state estimation function and SLAM based mapping technology, a concept and architecture of Human Motion Map by representing human behavior in the human living space as a hybrid map system are proposed. Beyond the conventional map which represents the existence of wall and objects, Human Motion Map represents not only the existence of humans in a particular location but also motion distributions. With recent improvements of the cloud computing technology, Human Motion Map can be accumulated as a kind of big data while measurements of robots are performed continuingly while it is moving around. In this paper, we propose a motion feature classification algorithm for clustering human motions geographically. Some experiment result of basic motion feature extraction, geographical clustering, and human motion behavior analyzing are provided for illustrating the validity of proposed algorithm. {\textcopyright} 2014 IEEE.},
annote = {cited By 3},
author = {Ogawa, Y and Wang, Z and Wada, T and Hirata, Y and Kosuge, K},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2014.6907395},
pages = {3700--3705},
title = {{Generating human motion transition map in indoor environment and analyzing human behavior by geographical clustering}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84929223284{\&}doi=10.1109{\%}2FICRA.2014.6907395{\&}partnerID=40{\&}md5=37f256717d11f4927766a276a6f09e6d},
year = {2014}
}
@article{Ahmed2017119,
abstract = {Finding the dense locations in large indoor spaces is very useful for many applications such as overloaded area detection, security control, crowd management, indoor navigation, and so on. Indoor tracking data can be enormous and are not immediately ready for finding dense locations. This paper presents two graph-based models for constrained and semi-constrained indoor movement, respectively, and then uses the models to map raw tracking records into mapping records that represent object entry and exit times in particular locations. Subsequently, an efficient indexing structure called Hierarchical Dense Location Time Index (HDLT-Index) is proposed for indexing the time intervals of the mapping table, along with index construction, query processing, and pruning techniques. The HDLT-Index supports very efficient aggregate point, interval, and duration queries as well as dense location queries. A comprehensive experimental study with both real and synthetic data shows that the proposed techniques are efficient and scalable and outperforms RDBMSs significantly. {\textcopyright} 2016, Springer Science+Business Media New York.},
annote = {cited By 2},
author = {Ahmed, T and Pedersen, T B and Lu, H},
doi = {10.1007/s10707-016-0276-8},
journal = {GeoInformatica},
keywords = {Aggregate queries; Duration query; Graph-based mo,Graphic methods; Indexing (of information); Locati,Indexing (materials working),graphical method; index method; mapping},
number = {1},
pages = {119--150},
title = {{Finding dense locations in symbolic indoor tracking data: modeling, indexing, and processing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994706942{\&}doi=10.1007{\%}2Fs10707-016-0276-8{\&}partnerID=40{\&}md5=27a9d348ad1b8c190de3059fd88f653b},
volume = {21},
year = {2017}
}
@article{Zhang2007279,
abstract = {This paper presents algorithms, simulations, and empirical results of a system that finds relative tag positions in 3D space using a new approach called "mobile infrastructure." Mobile infrastructure consists of one or more sensors in a fixed configuration on a mobile platform, and a set of tags affixed to objects or locations in the environment which the users want to localize. It is especially useful in cases where infrastructure is needed only temporarily, such as during installation, calibration, or maintenance. Mobile infrastructure can cover a much larger area than installed infrastructure with the same number of sensors, and is especially useful in cases where localization hardware costs are asymmetric, with expensive sensors and inexpensive tags. The data collected at various positions are combined by a simple "leapfrog" procedure, with constrained optimization to obtain better accuracy. Our system achieves about one foot (0.3 meter) accuracy with 90{\%} confidence in indoor environments. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
annote = {cited By 5},
author = {Zhang, Y and Partridge, K and Reich, J},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Computer hardware; Computer simulation; Constraine,Localization hardware costs; Localizing tags; Mob,Mobile telecommunication systems},
pages = {279--296},
title = {{Localizing tags using mobile infrastructure}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-38049092612{\&}partnerID=40{\&}md5=60bef4a1b42c037abeb02a6f544e971d},
volume = {4718 LNCS},
year = {2007}
}
@article{Guan2010283,
abstract = {In this paper, we present an algorithm to probabilistically estimate object shapes in a 3D dynamic scene using their silhouette information derived from multiple geometrically calibrated video camcorders. The scene is represented by a 3D volume. Every object in the scene is associated with a distinctive label to represent its existence at every voxel location. The label links together automatically-learned view-specific appearance models of the respective object, so as to avoid the photometric calibration of the cameras. Generative probabilistic sensor models can be derived by analyzing the dependencies between the sensor observations and object labels. Bayesian reasoning is then applied to achieve robust reconstruction against real-world environment challenges, such as lighting variations, changing background etc. Our main contribution is to explicitly model the visual occlusion process and show: (1) static objects (such as trees or lamp posts), as parts of the pre-learned background model, can be automatically recovered as a byproduct of the inference; (2) ambiguities due to inter-occlusion between multiple dynamic objects can be alleviated, and the final reconstruction quality is drastically improved. Several indoor and outdoor real-world datasets are evaluated to verify our framework. {\textcopyright} 2010 Springer Science+Business Media, LLC.},
annote = {cited By 15},
author = {Guan, L and Franco, J.-S. and Pollefeys, M},
doi = {10.1007/s11263-010-0341-y},
journal = {International Journal of Computer Vision},
keywords = {Bayesian inference; GraphicaL model; Multi-views;,Bayesian networks; Graphic methods; Inference eng,Three dimensional},
number = {3},
pages = {283--303},
title = {{Multi-view occlusion reasoning for probabilistic silhouette-based dynamic scene reconstruction}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78149232021{\&}doi=10.1007{\%}2Fs11263-010-0341-y{\&}partnerID=40{\&}md5=f4d74d419e9fa8a50cca853109bb8f61},
volume = {90},
year = {2010}
}
@article{Cadena2015582,
abstract = {The semantic mapping of the environment requires simultaneous segmentation and categorization of the acquired stream of sensory information. The existing methods typically consider the semantic mapping as the final goal and differ in the number and types of considered semantic categories. We envision semantic understanding of the environment as an on-going process and seek representations which can be refined and adapted depending on the task and robot's interaction with the environment. In this work we propose a novel and efficient method for semantic parsing, which can be adapted to the task at hand and enables localization of objects of interest in indoor environments. For basic mobility tasks we demonstrate how to obtain initial semantic segmentation of the scene into ground, structure, furniture and props categories which constitute the first level of hierarchy. Then, we propose a simple and efficient method for predicting locations of objects that based on their size afford a manipulation task. In our experiments we use the publicly available NYU V2 dataset and obtain better or comparable results than the state of the art at a fraction of the computational cost. We show the generalization of our approach on two more publicly available datasets. {\textcopyright} The Author(s) 2014.},
annote = {cited By 4},
author = {Cadena, C and Ko{\v{s}}eck{\'{a}}, J},
doi = {10.1177/0278364914549488},
journal = {International Journal of Robotics Research},
keywords = {Computational costs; Indoor environment; Manipula,Mapping; Object detection; Object recognition,Semantics},
number = {4-5},
pages = {582--597},
title = {{Semantic parsing for priming object detection in indoors RGB-D scenes}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928013196{\&}doi=10.1177{\%}2F0278364914549488{\&}partnerID=40{\&}md5=05dfa49d694d8591d37b6abd5226d92b},
volume = {34},
year = {2015}
}
@inproceedings{Liu2011380,
abstract = {We describe a novel two stage approach to object localization and tracking using a network of wireless cameras and a mobile robot. In the first stage, a robot travels through the camera network while updating its position in a global coordinate frame which it broadcasts to the cameras. The cameras use this information, along with image plane location of the robot, to compute a mapping from their image planes to the global coordinate frame. This is combined with an occupancy map generated by the robot during the mapping process to track the objects. We present results with a nine node indoor camera network to demonstrate that this approach is feasible and offers acceptable level of accuracy in terms of object locations. {\textcopyright} 2011 IEEE.},
annote = {cited By 1},
author = {Liu, J and Wark, T and Martin, S and Corke, P and D'Souza, M},
booktitle = {2011 IEEE International Conference on Pervasive Computing and Communications Workshops, PERCOM Workshops 2011},
doi = {10.1109/PERCOMW.2011.5766911},
keywords = {Camera network; Camera sensor; Distributed objects,Cameras; Object recognition; Robots; Ubiquitous c,Distributed computer systems},
pages = {380--383},
title = {{Distributed object tracking with robot and disjoint camera networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958044131{\&}doi=10.1109{\%}2FPERCOMW.2011.5766911{\&}partnerID=40{\&}md5=e06955320412df705ad6f7ec3dfc4bb6},
year = {2011}
}
@inproceedings{Jayakody2014490,
abstract = {While location-based services are already well established in outdoor scenarios, they are still not commonly available in indoor environments. Indoor location data are critical for emerging and future vision impaired indoor navigation applications. However, information for indoor environments is still very limited. When considering the indoor navigation for vision impaired, techniques to retrieve location information are narrowed and restricted. Therefore, it is very helpful if it contains semantic information about the spatial environment of the location, such as doors, walls, staircases. This paper presents a novel technique schema design used for an indoor map generation with the classification of real world objects and their locations. It will help to assist vision impaired individuals in an indoor navigation. Furthermore, this paper discusses the integration of input sensor data communication with K-SOAP protocol., Furthermore, the proposed schema design will facilitate real time map generation with a special cache integrated into the cloud database. {\textcopyright} 2014 IEEE.},
annote = {cited By 1},
author = {Jayakody, J.A.D.C.A. and Murray, I},
booktitle = {Proceedings of 2014 International Conference on Contemporary Computing and Informatics, IC3I 2014},
doi = {10.1109/IC3I.2014.7019791},
keywords = {Design; Location based services; Navigation; Seman,In-door navigations; Indoor environment; Location,Indoor positioning systems},
pages = {490--494},
title = {{Proposed novel schema design for map generation to assist vision impaired in an indoor navigation environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949923455{\&}doi=10.1109{\%}2FIC3I.2014.7019791{\&}partnerID=40{\&}md5=fe6e6affd96562694639ab9d324b2c97},
year = {2014}
}
@article{Ishiguro1992257,
abstract = {Omni-directional views of an indoor environment at different locations are integrated into a global map. A single camera swiveling about the vertical axis takes consecutive images and arranges them into a panoramic representation, which provides rich information around the observation point; a precise omni-directional view of the environment and coarse ranges to objects in it. Using the coarse map, the system autonomously plans consecutive observations at the intersections of lines connecting object points, where the directions of the imaging are estimated easily and precisely. From two panoramic views at the two planned locations, a modified binocular stereo method yields a more precise, but with direction-dependent uncertainties, local map. New observation points are selected to decrease the uncertainty, and another local map is yielded, which is then integrated into a more reliable global representation of the world with the adjacent local maps. {\textcopyright} 1992 IEEE},
annote = {cited By 185},
author = {Ishiguro, H and Yamamoto, M and Tsuji, S},
doi = {10.1109/34.121792},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Binocular Stereo,Cameras,Computer Vision},
number = {2},
pages = {257--262},
title = {{Omni-Directional Stereo}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026821791{\&}doi=10.1109{\%}2F34.121792{\&}partnerID=40{\&}md5=219f6b840c855c4950407c638333e990},
volume = {14},
year = {1992}
}
@article{Fernandes2014493,
abstract = {The task of moving from one place to another is a difficult challenge that involves obstacle avoidance, staying on street walks, finding doors, knowing the current location and keeping on track through the desired path. Nowadays, navigation systems are widely used to find the correct path, or the quickest, between two places. While assistive technology has contributed to the improvement of the quality of life of people with disabilities, people with visual impairment still face enormous limitations in terms of their mobility. In recent years, several approaches have been made to create systems that allow seamless tracking and navigation both in indoor and outdoor environments. However there is still an enormous lack of availability of information that can be used to assist the navigation of users with visual impairments as well as a lack of sufficient precision in terms of the estimation of the user's location. Blavigator is a navigation system designed to help users with visual impairments. In a known location, the use of object recognition algorithms can provide contextual feedback to the user and even serve as a validator to the positioning module and geographic information system of a navigation system for the visually impaired. This paper proposes a method where the use of computer vision algorithms validate the outputs of the positioning system of the Blavigator prototype. {\textcopyright} 2014 Springer International Publishing.},
annote = {cited By 5},
author = {Fernandes, H and Costa, P and Paredes, H and Filipe, V and Barroso, J},
doi = {10.1007/978-3-319-07446-7_48},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Assistive technology; blind; Computer vision algo,Computer vision; Geographic information systems; H,Location based services},
number = {PART 3},
pages = {493--500},
title = {{Integrating computer vision object recognition with location based services for the blind}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903473236{\&}doi=10.1007{\%}2F978-3-319-07446-7{\_}48{\&}partnerID=40{\&}md5=61f95ad398bae3d11dfad1700ce77ea3},
volume = {8515 LNCS},
year = {2014}
}
@inproceedings{Schwartz20121,
abstract = {Improving laser range data acquisition speed is important for many robotic applications such as mapping and localization. One approach to reducing acquisition time is to acquire laser range data through a dynamically small subset of measurement locations. The reconstruction can then be performed based on the concept of compressed sensing (CS), where a sparse signal representation allows for signal reconstruction at sub-Nyquist measurements. Motivated by this, a novel multi-scale saliency-guided CS-based algorithm is proposed for an efficient robotic laser range data acquisition for robotic vision. The proposed system samples the objects of interest through an optimized probability density function derived based on multi-scale saliency rather than the uniform random distribution used in traditional CS systems. Experimental results with laser range data from indoor and outdoor environments show that the proposed approach requires less than half the samples needed by existing CS-based approaches while maintaining the same reconstruction performance. In addition, the proposed method offers significant improvement in reconstruction SNR compared to current CS-based approaches. {\textcopyright} 2012 IEEE.},
annote = {cited By 5},
author = {Schwartz, S and Wong, A and Clausi, D A},
booktitle = {Proceedings of the 2012 9th Conference on Computer and Robot Vision, CRV 2012},
doi = {10.1109/CRV.2012.8},
keywords = {Compressed sensing; Data acquisition; Probability,Compressive sensing; Laser range measurements; Map,Computer vision},
pages = {1--8},
title = {{Multi-scale saliency-guided compressive sensing approach to efficient robotic laser range measurements}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878364989{\&}doi=10.1109{\%}2FCRV.2012.8{\&}partnerID=40{\&}md5=6760c3f66c59ef2258a845be55b88406},
year = {2012}
}
@article{Kim2013571,
abstract = {The widespread use of smart phones with GPS and orientation sensors opens up new possibilities for location-based annotations in outdoor environments. However, a completely different approach is required for indoors. In this study, we introduce IMAF, a novel indoor modeling and annotation framework on a mobile phone. The framework produces a 3D room model in situ with five selections from user without prior knowledge on actual geometry distance or additional apparatus. Using the framework, non-experts can easily capture room dimensions and annotate locations and objects within the room for linking virtual information to the real space represented by an approximated box. For registering 3D room model to the real space, an hybrid method of visual tracking and device sensors obtains accurate orientation tracking result and still achieves interactive frame-rates for real-time applications on a mobile phone. Once the created room model is registered to the real space, user-generated annotations can be attached and viewed in AR and VR modes. Finally, the framework supports object-based space to space registration for viewing and creating annotations from different views other than the view that generated the annotations. The performance of the proposed framework is demonstrated with achieved model accuracy, modeling time, stability of visual tracking and satisfaction of annotation. In the last section, we present two exemplar applications built on IMAF. {\textcopyright} 2012 Springer-Verlag London Limited.},
annote = {cited By 9},
author = {Kim, H and Reitmayr, G and Woo, W},
doi = {10.1007/s00779-012-0516-3},
journal = {Personal and Ubiquitous Computing},
keywords = {Cellular telephones; Mobile phones; Sensors; Thre,Interactive modeling; Orientation sensors; Orienta,Three dimensional},
number = {3},
pages = {571--582},
title = {{IMAF: In situ indoor modeling and annotation framework on mobile phones}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879689377{\&}doi=10.1007{\%}2Fs00779-012-0516-3{\&}partnerID=40{\&}md5=d7596d4a0eb0f9fb3d7ce0177d8ba08d},
volume = {17},
year = {2013}
}
@article{Wu2012147,
abstract = {The environment map plays an important role in robot service, so it should contain not only appearance information about the whole service environment, but also their profoundness. The key contribution of the paper is the presentation of a novel semantic map, namely, a holography map composed of robot, family persons, operable items, local environments, as well as locations and path sections for home service robot cognizing its surroundings and providing services. Inspired by the object-oriented approach, the holography map is divided into three hierarchies of item-room-home and in detail 13 classes of objects. The design and storage of the object-oriented holography map are described comprehensively, and construction of the map is introduced. The execution of robot service based on the object-oriented holography map is discussed briefly. Experiments on real service robot demonstrate that the object-oriented holography map is nearer to human thinking and applicable to indoor robot service tasks. {\textcopyright} 2012 Springer-Verlag.},
annote = {cited By 5},
author = {Wu, P and Kong, L and Gao, S},
doi = {10.1007/s11370-012-0109-z},
journal = {Intelligent Service Robotics},
keywords = {Environment cognition; Home robot; Home service ro,Holography,Mobile robots; Semantics},
number = {3},
pages = {147--157},
title = {{Holography map for home robot: An object-oriented approach}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862662227{\&}doi=10.1007{\%}2Fs11370-012-0109-z{\&}partnerID=40{\&}md5=5bf8c5f6e5485045059177382d89cfa2},
volume = {5},
year = {2012}
}
@inproceedings{Pittarello2006364,
abstract = {Access to real environments is often conditioned by a number of issues, including the skills of the user (i.e. affected by aging, physical and psychological deficiencies, etc.) and the complexity of the real environment itself. This work proposes an approach for helping users with different skills, including elderly people, to navigate through complex real scenes; such approach is based on the semantic description of the objects and zones that characterize the environment itself and takes advantage of an implementation architecture based on web standards for generating navigational support. A case study related to the creation of a guided tour through the indoor and outdoor locations of the city of Venice, accessible through a multimodal web browser, is presented. Copyright 2006 ACM.},
annote = {cited By 7},
author = {Pittarello, F and {De Faveri}, A},
booktitle = {Proceedings of the Workshop on Advanced Visual Interfaces},
doi = {10.1145/1133265.1133341},
keywords = {Computational complexity; Computer architecture;,Elderly people; Multimodality; Semantic 3D environ,User interfaces},
pages = {364--368},
title = {{Improving access of elderly people to real environments: A semantic based approach}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247161219{\&}doi=10.1145{\%}2F1133265.1133341{\&}partnerID=40{\&}md5=45176c98974103ede9cdc12d172ca0b1},
volume = {2006},
year = {2006}
}
@inproceedings{Sasagawa2016365,
abstract = {We propose a novel method for locating tagged items that uses a RFID reader, a smartphone, and unregistered RFID tags attached to a variety of items, furniture and places. As a user moves through a room to locate a target item, our system shows relative distances to the target item and images of items on the way to the target. At the same time, the system scans RFID tags nearby and captures images for scanned RFID-Tagged objects. This information is accumulated in a database and is accessible for future item location activities. Since all information was gathered during users' searching activities, the proposed system does not require users' effort for managing and registering tags. We asked 10 users to compare our method with the conventional method, which shows RSSI of the target item, of searching for the target item. The results suggest that our method is effective for location target RFID-Tagged items. {\textcopyright} 2016 ACM.},
annote = {cited By 4},
author = {Sasagawa, M and Ikematsu, K and Siio, I},
booktitle = {UbiComp 2016 Adjunct - Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
doi = {10.1145/2968219.2971366},
keywords = {Conventional methods; Mobile applications; Relati,Location; Radio frequency identification (RFID); U,Search engines},
pages = {365--368},
title = {{Simply tag and find: Finding indoor items by using detection history of RFID Tags}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991059216{\&}doi=10.1145{\%}2F2968219.2971366{\&}partnerID=40{\&}md5=45cb4a43cc3598a9bb38d9c9e50e2cb0},
year = {2016}
}
@article{Yoshida2011286,
abstract = {Thanks to the development of wireless communication and sensor technology, a smart object that is embedded sensors and/or communication equipment in objects that we use in daily lives is researched. Also the Internet of Things (IoT) is a networking technology by using the smart objects and attracts high attention. Furthermore, a smart home which consists of these technologies is expected to be spread widely. In the smart home, it is important to get the information of location/position accurately in order to provide services based on the information of person or object. One of the most popular methods for estimating the position of person or object, the Receive Signal Strength Indicator (RSSI) method is used for many systems. RSSI method uses a behavior that strength of a signal from beacon node is inversely proportional to distance. However, the location of the wireless nodes which receive a signal has to fix and be discovered in advance. Therefore if the nodes are moved from an original position, the person or object cannot be detected accurately. Accordingly, we propose a method that estimating the positions of moved nodes and updating the position information by adding node for the RSSI positioning method. Currently, we have performed preliminary implementation of the system. In the future we will finish the implementation of the methods designed in the paper and evaluate the methods in details. {\textcopyright} 2011 Springer-Verlag Berlin Heidelberg.},
annote = {cited By 1},
author = {Yoshida, T and Wang, J and Cheng, Z},
doi = {10.1007/978-3-642-25731-5_22},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Automation,Beacon nodes; Communication equipments; Daily live,Communication; Information systems; Intelligent b},
pages = {286--295},
title = {{A position correction method for RSSI based indoor-localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84455190068{\&}doi=10.1007{\%}2F978-3-642-25731-5{\_}22{\&}partnerID=40{\&}md5=9dd80215f58e606ec08adf1cacb60311},
volume = {7108 LNCS},
year = {2011}
}
@inproceedings{Zhuang20114042,
abstract = {Robust scene recognition serves as an essential task for robots to work within a complex dynamic environment. Considering vision device's limited adaptability in the dark environment, a 3D-laser-based scene recognition approach that extracts and matches SIFT features from Bearing Angle images is proposed, which makes it possible to make full use of both global metric information and local scale-invariant features. This approach can not only cope with irregular disturbances of dynamic objects, but also tackle obvious changes of observation location robustly in a semi-structured environment. An large-scale indoor environment with more than 30 offices is selected as the real-world scenes to test the performance of the proposed approach. {\textcopyright} 2011 IEEE.},
annote = {cited By 1},
author = {Zhuang, Y and Li, Y and Wang, W},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
doi = {10.1109/ICRA.2011.5979755},
keywords = {3D Laser scanning; Complex dynamics; Dynamic objec,Lasers,Robotics},
pages = {4042--4047},
title = {{Robust indoor scene recognition based on 3D laser scanning and bearing angle image}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871675976{\&}doi=10.1109{\%}2FICRA.2011.5979755{\&}partnerID=40{\&}md5=8d0634adc4acabea6da8f25cd3b2a18a},
year = {2011}
}
@article{Ropponen201157,
abstract = {In this study, an improved version of the low-frequency indoor location system, with a larger detection range and more durable antenna laminate, is presented. The basic system uses quad antennas, placed under the floor surface, to locate tags with 125-kHz radio signals. The improvements were achieved with a one-layer laminate construction and transmitter electronics that can feed larger currents to the antennas. The measured tag detection height was 2 m, which is adequate for location applications. The low-frequency signal was not affected by normal objects. The tag location reliability of 96.3{\%} was verified with a practical test. {\textcopyright} 2010 The Author(s).},
annote = {cited By 11},
author = {Ropponen, A and Rimminen, H and Sepponen, R},
doi = {10.1007/s11277-010-0189-z},
journal = {Wireless Personal Communications},
keywords = {Antennas,Basic systems; Detection range; Floor surface; Ind,Health care; Radio frequency identification (RFID},
number = {1},
pages = {57--71},
title = {{Robust system for indoor localisation and identification for the health care environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959187978{\&}doi=10.1007{\%}2Fs11277-010-0189-z{\&}partnerID=40{\&}md5=cde2fbefa393e9887c47bb6e9b29c0c1},
volume = {59},
year = {2011}
}
@article{Hernndez20141659,
abstract = {The evolution of wireless communications and pervasive computing is transforming current physical spaces into real smart environments. These emerging scenarios are expected to be composed by a potentially huge amount of heterogeneous smart objects which can be remotely accessed by users via their mobile devices anytime, anywhere. In this paper, we propose a distributed location-aware access control mechanism and its application in the smart building context. Our approach is based on an access control engine embedded into smart objects, which are responsible to make authorization decisions by considering both user location data and access credentials. User location data are estimated using a novel indoor localization system based on magnetic field data sent by user through her personal phone. This localization system implements a combination of soft computing techniques over the data collected by smartphones. Therefore, our location-aware access control mechanism does not require any intermediate entity, providing the benefits of a decentralized approach for smart environments. From the results obtained, we can consider our proposal as a promising approach to tackle the challenging security requirements of typical pervasive environments. {\textcopyright} 2014 Springer-Verlag Berlin Heidelberg.},
annote = {cited By 14},
author = {Hern{\'{a}}ndez, J L and Moreno, M V and Jara, A J and Skarmeta, A F},
doi = {10.1007/s00500-014-1278-9},
journal = {Soft Computing},
keywords = {Access control,Access control mechanism; Capability; Distributed,Intelligent buildings; Internet of things; Mobile},
number = {9},
pages = {1659--1674},
title = {{A soft computing based location-aware access control for smart buildings}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905732299{\&}doi=10.1007{\%}2Fs00500-014-1278-9{\&}partnerID=40{\&}md5=c721a0094fce328eaf9783dabcfdbf0d},
volume = {18},
year = {2014}
}
@inproceedings{Bishay1994775,
abstract = {In this paper a system that successfully detects stationary objects in indoor scenes is presented. The doors and ceiling lamps have been chosen to be detected in the initial phase of our system. The scene was divided into four different regions. The edges resulting from the walls/ceiling and the walls/floor intersections are the boundaries that separate the different regions. The use of the log-polar mapping transforms the problem of finding four edges of unknown orientations, that separated the different regions, into finding four horizontal edges. The log-polar map was performed such that it possesses the varying resolution property. The objects were detected using model-matching in the log-polar domain. The varying resolution property of the mapping simplified the model-matching problem. The detection (of edges and then objects) was very fast due to the small size of the log-polar image (6464) pixels.},
annote = {cited By 1},
author = {Bishay, M and {Peters II}, R A and Kawamura, K},
booktitle = {Proceedings - IEEE International Conference on Robotics and Automation},
keywords = {Computational methods; Image analysis; Image recon,Computer vision,Log polar mapping; Model matching problem; Object},
number = {pt 1},
pages = {775--780},
title = {{Object detection in indoor scenes using log-polar mapping}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0027928046{\&}partnerID=40{\&}md5=ef3686cc3897262b7f8cbb2e48af0848},
year = {1994}
}
@article{Daniyal2010235,
abstract = {We present a content-aware multi-camera selection technique that uses object- and frame-level features. First objects are detected using a color-based change detector. Next trajectory information for each object is generated using multi-frame graph matching. Finally, multiple features including size and location are used to generate an object score. At frame-level, we consider total activity, event score, number of objects and cumulative object score. These features are used to generate score information using a multivariate Gaussian distribution. The algorithm. The best view is selected using a Dynamic Bayesian Network (DBN), which utilizes camera network information. DBN employs previous view information to select the current view thus increasing resilience to frequent switching. The performance of the proposed approach is demonstrated on three multi-camera setups with semi-overlapping fields of view: a basketball game, an indoor airport surveillance scenario and a synthetic outdoor pedestrian dataset. We compare the proposed view selection approach with a maximum score based camera selection criterion and demonstrate a significant decrease in camera flickering. The performance of the proposed approach is also validated through subjective testing. {\textcopyright} 2009 Springer Science+Business Media, LLC.},
annote = {cited By 26},
author = {Daniyal, F and Taj, M and Cavallaro, A},
doi = {10.1007/s11042-009-0355-z},
journal = {Multimedia Tools and Applications},
keywords = {Airport security; Bayesian networks; Cameras; Inf,Airport surveillance; Camera network; Camera selec,Security systems},
number = {2-3},
pages = {235--258},
title = {{Content and task-based view selection from multiple video streams}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77049110311{\&}doi=10.1007{\%}2Fs11042-009-0355-z{\&}partnerID=40{\&}md5=07e45bcb86d351b107ba19c505331134},
volume = {46},
year = {2010}
}
@inproceedings{Li20171942,
abstract = {Spatial relationships between objects provide important information for text-based image retrieval. As users are more likely to describe a scene from a real world perspective, using 3D spatial relationships rather than 2D relationships that assume a particular viewing direction, one of the main challenges is to infer the 3D structure that bridges images with users' text descriptions. However, direct inference of 3D structure from images requires learning from large scale annotated data. Since interactions between objects can be reduced to a limited set of atomic spatial relations in 3D, we study the possibility of inferring 3D structure from a text description rather than an image, applying physical relation models to synthesize holistic 3D abstract object layouts satisfying the spatial constraints present in a textual description. We present a generic framework for retrieving images from a textual description of a scene by matching images with these generated abstract object layouts. Images are ranked by matching object detection outputs (bounding boxes) to 2D layout candidates (also represented by bounding boxes) which are obtained by projecting the 3D scenes with sampled camera directions. We validate our approach using public indoor scene datasets and show that our method outperforms baselines built upon object occurrence histograms and learned 2D pairwise relations. {\textcopyright} 2017 IEEE.},
annote = {cited By 2},
author = {Li, A and Sun, J and Ng, J.Y.-H. and Yu, R and Morariu, V I and Davis, L S},
booktitle = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
doi = {10.1109/CVPR.2017.210},
keywords = {Abstracting; Computer vision; Information retrieva,Camera direction; Generic frameworks; Spatial con,Image retrieval},
pages = {1942--1950},
title = {{Generating holistic 3D scene abstractions for text-based image retrieval}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044284703{\&}doi=10.1109{\%}2FCVPR.2017.210{\&}partnerID=40{\&}md5=23927793a398015550a5b87d7dc7f651},
volume = {2017-Janua},
year = {2017}
}
@article{Papapostolou2012861,
abstract = {Location awareness in an indoor environment and wireless access to Internet applications are major research areas towards the overwhelming success of wireless and mobile communications. However, the unpredictable indoor radio propagation and handover latency due to node mobility are the main challenging issues that need to be addressed. For tackling efficiently both problems of indoor localization and handover management, we propose combining key benefits of two outstanding wireless technologies, i.e. radio frequency identification (RFID) and a wireless local area network (WLAN) infrastructure. WLANs, such as IEEE 802.11 (WiFi), are now very common in many indoor environments for providing wireless communication among WiFi-enabled devices by accessing an Access Point (infrastructure mode) or through peer to peer connections (ad hoc mode). However, the small cell size of the Access Points (APs) in a WiFi-based network drives the need for frequent handovers leading to increased latency. RFID is an emerging technology consisting of two basic components, a tag and a reader, and its main purpose is the automatic identification of tagged objects by a reader. However, in the presence of multiple readers, RFID suffers from the so-called reader collision problem, mainly due to the inability for direct communication among them. In this paper, we propose a hybrid RFID and WLAN system; the RFID technology is employed for collecting information that is used for both localization and handover management within the WLAN, whereas the WLAN itself is utilized for controlling and coordinating the RFID reading process. In our system architecture, tag IDs of a RFID tag deployment are correlated with both location and topology information in order to determine the position and predict the next subnetwork of a Mobile Node (MN) with a reader attached to its mobile device. The role of the WLAN is to coordinate the readers when accessing the RFID channel for retrieving tags' IDs, hence compensating the persisting RFID collision problem among multiple readers. Numerical results based on extensive simulations validate the efficiency of the proposed hybrid system in providing accurate and time efficient localization and reducing the IP handover latency. {\textcopyright} Springer Science+Business Media, LLC 2012.},
annote = {cited By 8},
author = {Papapostolou, A and Chaouchi, H},
doi = {10.1007/s11276-012-0439-y},
journal = {Wireless Networks},
keywords = {Access points; Ad hoc mode; Automatic identificati,Automation; Hybrid systems; Internet protocols; M,Radio frequency identification (RFID)},
number = {7},
pages = {861--879},
title = {{Integrating RFID and WLAN for indoor positioning and IP movement detection}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869871121{\&}doi=10.1007{\%}2Fs11276-012-0439-y{\&}partnerID=40{\&}md5=002663549c8090240ebb2f1f352f86ed},
volume = {18},
year = {2012}
}
@inproceedings{Wirz2010,
abstract = {While it is challenging to obtain absolute location information of people and objects in indoor venues, obtaining proximity information is sufficient in various wearable computing applications. In this work, we characterize to which extent sound - a modality available in any mobile devices - may be used to infer proximity between these devices. We introduce a fingerprinting based approach and verify the existence of a relation between the distance of two devices and the similarity of the recorded ambient sound. While a quantitative distance estimation could only be achieved with an accuracy of 46 {\%}, we could infer a correct distance region with an accuracy of 80 {\%}. We further showed that an accurate estimation which of two devices is closer to a reference device is possible and that we could reliably infer if two devices are at the same location.},
annote = {cited By 12},
author = {Wirz, M and Roggen, D and Tr{\"{o}}ster, G},
booktitle = {Proceedings - International Symposium on Wearable Computers, ISWC},
doi = {10.1109/ISWC.2010.5665863},
keywords = {Accurate estimation; Distance estimation; Fuzzy pr,Equipment,Estimation; Mobile devices; Wearable computers},
title = {{A wearable, ambient sound-based approach for infrastructureless fuzzy proximity estimation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-78651401466{\&}doi=10.1109{\%}2FISWC.2010.5665863{\&}partnerID=40{\&}md5=9637e8e477901e44b4c09e63b3d84071},
year = {2010}
}
@inproceedings{Chiang20092099,
abstract = {In this paper, a software product line (SPL) architecture that explicitly captures common features of real-time object tracking systems using Cricket wireless sensors is presented. A software product line process is also presented including user requirements, architecture design, component development, and systems integration. The focus lies on the application of SPL to object location tracking, such as supply chains and transportation. Thus, this paper introduces three prototypes of the SPL member system including shop navigator systems, low/no visibility navigation systems (LVNS), and games for mazes where each one is created from the software product line architecture. The prototypes are experimented with and lessons are learned. {\textcopyright}2009 IEEE.},
annote = {cited By 0},
author = {Chiang, C.-C. and Marshall, B},
booktitle = {Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics},
doi = {10.1109/ICSMC.2009.5346267},
keywords = {Architecture; Computer software; Concurrent engin,Incremental development; Indoor positioning; Objec,Software prototyping},
pages = {2099--2104},
title = {{Applying software product line technology to prototyping of real-time object tracking}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-74849094109{\&}doi=10.1109{\%}2FICSMC.2009.5346267{\&}partnerID=40{\&}md5=73d8e492c24687af561beae308cfebf8},
year = {2009}
}
@inproceedings{Sato:2009:NVS:1578016.1578345,
address = {Washington, DC, USA},
author = {Sato, Yousuke and Hashimoto, Koji and Shibata, Yoshitaka},
booktitle = {Proceedings of the 2009 International Conference on Advanced Information Networking and Applications},
doi = {10.1109/AINA.2009.136},
isbn = {978-0-7695-3638-5},
keywords = {Surveillance System},
pages = {602--607},
publisher = {IEEE Computer Society},
series = {AINA '09},
title = {{A New Video Surveillance Video Tracking System Based on Omni-directional and Network Controlled Cameras}},
url = {https://doi.org/10.1109/AINA.2009.136},
year = {2009}
}
@inproceedings{Wallbaum:2006:IPU:1173689.1173761,
address = {Washington, DC, USA},
author = {Wallbaum, Michael and Spaniol, Otto},
booktitle = {Proceedings of the IEEE John Vincent Atanasoff 2006 International Symposium on Modern Computing},
doi = {10.1109/JVA.2006.28},
isbn = {0-7695-2643-8},
pages = {17--26},
publisher = {IEEE Computer Society},
series = {JVA '06},
title = {{Indoor Positioning UsingWireless Local Area Networks}},
url = {http://dx.doi.org/10.1109/JVA.2006.28},
year = {2006}
}
@article{Casas:2007:HID:1262537.1262571,
address = {Piscataway, NJ, USA},
author = {Casas, Roberto and Cuartielles, David and Marco, Alvaro and Gracia, Hector J and Falco, Jorge L},
doi = {10.1109/MPRV.2007.33},
issn = {1536-1268},
journal = {IEEE Pervasive Computing},
keywords = {Bluetooth,indoor location,sensor networks,system deployments,ubiquitous computing,ultrasound},
number = {2},
pages = {62--69},
publisher = {IEEE Educational Activities Department},
title = {{Hidden Issues in Deploying an Indoor Location System}},
url = {http://dx.doi.org/10.1109/MPRV.2007.33},
volume = {6},
year = {2007}
}
@inproceedings{Pushee:2012:CVC:2494766.2495216,
address = {Washington, DC, USA},
author = {Pushee, I and Morde, A and Silverstein, J and Ma, X and McAuliffe, S and Guler, S},
booktitle = {Proceedings of the 2012 IEEE Applied Imagery Pattern Recognition Workshop (AIPR 2012)},
doi = {10.1109/AIPR.2012.6528196},
isbn = {978-1-4673-4558-3},
pages = {1--8},
publisher = {IEEE Computer Society},
series = {AIPR '12},
title = {{Contextual Video Clip Classification}},
url = {http://dx.doi.org/10.1109/AIPR.2012.6528196},
year = {2012}
}
@inproceedings{Ahmed:2014:FDL:2678534.2678810,
address = {Washington, DC, USA},
author = {Ahmed, Tanvir and Pedersen, Torben Bach and Lu, Hua},
booktitle = {Proceedings of the 2014 IEEE 15th International Conference on Mobile Data Management - Volume 01},
doi = {10.1109/MDM.2014.29},
isbn = {978-1-4799-5705-7},
keywords = {Indoor tracking,RFID,aggregation,density,graph-based model,interval query,moving objects,temporal index},
pages = {189--194},
publisher = {IEEE Computer Society},
series = {MDM '14},
title = {{Finding Dense Locations in Indoor Tracking Data}},
url = {http://dx.doi.org/10.1109/MDM.2014.29},
year = {2014}
}
@inproceedings{Rashid:2014:DMD:2758202.2758293,
address = {Washington, DC, USA},
author = {Rashid, Maheen and Hebert, Martial},
booktitle = {Proceedings of the 2014 2Nd International Conference on 3D Vision - Volume 01},
doi = {10.1109/3DV.2014.32},
isbn = {978-1-4799-7000-1},
keywords = {3D Data,Computer Vision,Data Driven,Geometry Estimation,Scene Understanding},
pages = {139--146},
publisher = {IEEE Computer Society},
series = {3DV '14},
title = {{Detailed 3D Model Driven Single View Scene Understanding}},
url = {https://doi.org/10.1109/3DV.2014.32},
year = {2014}
}
@inproceedings{HaijiangXie:2015:ACB:2921565.2922146,
address = {Washington, DC, USA},
author = {Xie, Haijiang and Lin, Li and Jiang, Zhiping and Xi, Wei and Zhao, Kun and Ding, Meiyong and Zhao, Jizhong},
booktitle = {Proceedings of the 2015 IEEE 21st International Conference on Parallel and Distributed Systems (ICPADS)},
doi = {10.1109/ICPADS.2015.42},
isbn = {978-0-7695-5785-4},
pages = {274--281},
publisher = {IEEE Computer Society},
series = {ICPADS '15},
title = {{Accelerating Crowdsourcing Based Indoor Localization Using CSI}},
url = {http://dx.doi.org/10.1109/ICPADS.2015.42},
year = {2015}
}
@inproceedings{Zou:2005:THU:1099539.1100089,
address = {Washington, DC, USA},
author = {Zou, Xiaotao and Bhanu, Bir},
booktitle = {Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops - Volume 03},
doi = {10.1109/CVPR.2005.545},
isbn = {0-7695-2372-2-3},
pages = {4----},
publisher = {IEEE Computer Society},
series = {CVPR '05},
title = {{Tracking Humans Using Multi-modal Fusion}},
url = {https://doi.org/10.1109/CVPR.2005.545},
year = {2005}
}
@inproceedings{deAmorimSilva:2009:EEA:1688345.1688847,
address = {Piscataway, NJ, USA},
author = {{de Amorim Silva}, Rafael and {da S. Gon{\c{c}}alves}, Paulo Andr{\'{e}}},
booktitle = {Proceedings of the 2009 IEEE Conference on Wireless Communications {\&} Networking Conference},
isbn = {978-1-4244-2947-9},
pages = {2879--2884},
publisher = {IEEE Press},
series = {WCNC'09},
title = {{Enhancing the Efficiency of Active RFID-based Indoor Location Systems}},
url = {http://dl.acm.org/citation.cfm?id=1688345.1688847},
year = {2009}
}
@inproceedings{Wongphati:2009:BOF:1588302.1590234,
address = {Washington, DC, USA},
author = {Wongphati, Mahisorn and Niparnan, Nattee and Sudsang, Attawith},
booktitle = {Proceedings of the 2008 IEEE International Conference on Robotics and Biomimetics},
doi = {10.1109/ROBIO.2009.4913169},
isbn = {978-1-4244-2678-2},
pages = {1188--1193},
publisher = {IEEE Computer Society},
series = {ROBIO '09},
title = {{Bearing Only FastSLAM Using Vertical Line Information from an Omnidirectional Camera}},
url = {http://dx.doi.org/10.1109/ROBIO.2009.4913169},
year = {2009}
}
@inproceedings{Talukder:2007:STL:1548881.1549130,
address = {Washington, DC, USA},
author = {Talukder, Nilothpal and Ahamed, Sheikh I and Abid, Rezaul M},
booktitle = {Proceedings of the 2007 Fourth Annual International Conference on Mobile and Ubiquitous Systems: Networking{\&}Services (MobiQuitous)},
doi = {10.1109/MOBIQ.2007.4451037},
isbn = {978-1-4244-1024-8},
pages = {1--8},
publisher = {IEEE Computer Society},
series = {MOBIQUITOUS '07},
title = {{Smart Tracker: Light Weight Infrastructure-less Assets Tracking Solution for Ubiquitous Computing Environment}},
url = {https://doi.org/10.1109/MOBIQ.2007.4451037},
year = {2007}
}
@inproceedings{Radaelli:2013:ITM:2509997.2510031,
address = {Washington, DC, USA},
author = {Radaelli, Laura and Sabonis, Dovydas and Lu, Hua and Jensen, Christian S},
booktitle = {Proceedings of the 2013 IEEE 14th International Conference on Mobile Data Management - Volume 01},
doi = {10.1109/MDM.2013.29},
isbn = {978-0-7695-4973-6},
keywords = {frequent patterns,indoor moving objects,indoor space,trajectory mining},
pages = {197--206},
publisher = {IEEE Computer Society},
series = {MDM '13},
title = {{Identifying Typical Movements Among Indoor Objects -- Concepts and Empirical Study}},
url = {https://doi.org/10.1109/MDM.2013.29},
year = {2013}
}
@inproceedings{Kolodziej:2004:IPM:1018418.1019530,
address = {Washington, DC, USA},
author = {Kolodziej, Kris and Danado, Jose},
booktitle = {Proceedings of the Database and Expert Systems Applications, 15th International Workshop},
doi = {10.1109/DEXA.2004.83},
isbn = {0-7695-2195-9},
pages = {830--834},
publisher = {IEEE Computer Society},
series = {DEXA '04},
title = {{In-Building Positioning: Modeling Location for Indoor World}},
url = {https://doi.org/10.1109/DEXA.2004.83},
year = {2004}
}
@inproceedings{Xu:2011:IRM:2065228.2065270,
address = {Washington, DC, USA},
author = {Xu, Jianqiu and Guting, Ralf Hartmut},
booktitle = {Proceedings of the 2011 IEEE 12th International Conference on Mobile Data Management - Volume 01},
doi = {10.1109/MDM.2011.35},
isbn = {978-0-7695-4436-6},
pages = {329--332},
publisher = {IEEE Computer Society},
series = {MDM '11},
title = {{Infrastructures for Research on Multimodal Moving Objects}},
url = {https://doi.org/10.1109/MDM.2011.35},
year = {2011}
}
@article{Bagci:2009:OLN:1661393.1661395,
address = {Inderscience Publishers, Geneva, SWITZERLAND},
author = {Bagci, Faruk and Kluge, F and Ungerer, T and Bagherzadeh, N},
doi = {10.1504/IJSNET.2009.029392},
issn = {1748-1279},
journal = {Int. J. Sen. Netw.},
keywords = {WSNs,indoor location estimation,indoor location tracking,moving objects,pervasive computing,ubiquitous computing,wireless networks,wireless sensor networks},
number = {3/4},
pages = {157--166},
publisher = {Inderscience Publishers},
title = {{Optimisations for LocSens {\&}Ndash; an Indoor Location Tracking System Using Wireless Sensors}},
url = {http://dx.doi.org/10.1504/IJSNET.2009.029392},
volume = {6},
year = {2009}
}
@inproceedings{Iannizzotto:2005:BVI:1099539.1099930,
address = {Washington, DC, USA},
author = {Iannizzotto, G and Costanzo, C and Lanzafame, P and {La Rosa}, F},
booktitle = {Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Workshops - Volume 03},
doi = {10.1109/CVPR.2005.420},
isbn = {0-7695-2372-2-3},
pages = {29----},
publisher = {IEEE Computer Society},
series = {CVPR '05},
title = {{Badge3D for Visually Impaired}},
url = {https://doi.org/10.1109/CVPR.2005.420},
year = {2005}
}
@inproceedings{Barralet:2009:EAP:1701955.1702004,
address = {Piscataway, NJ, USA},
author = {Barralet, Mark and Huang, Xu and Sharma, Dharmendra},
booktitle = {Proceedings of the 11th International Conference on Advanced Communication Technology - Volume 1},
isbn = {978-8-9551-9138-7},
keywords = {RFID,RSSI,location,sensor networking,zigbee},
pages = {260--265},
publisher = {IEEE Press},
series = {ICACT'09},
title = {{Effects of Antenna Polarization on RSSI Based Location Identification}},
url = {http://dl.acm.org/citation.cfm?id=1701955.1702004},
year = {2009}
}
@inproceedings{Heidari:2007:NSM:2928264.2928776,
address = {Washington, DC, USA},
author = {Heidari, M and Pahlavan, K},
booktitle = {Proceedings of the 2007 IEEE Wireless Communications and Networking Conference},
doi = {10.1109/WCNC.2007.477},
isbn = {1-4244-0658-7},
pages = {2564--2569},
publisher = {IEEE Computer Society},
title = {{A New Statistical Model for the Behavior of Ranging Errors in TOA-Based Indoor Localization}},
url = {http://dx.doi.org/10.1109/WCNC.2007.477},
year = {2007}
}
@article{Bhaskar:2010:VFD:2322625.2324524,
address = {Piscataway, NJ, USA},
author = {Bhaskar, H and Mihaylova, L and Achim, A},
doi = {10.1109/TCSVT.2010.2051282},
issn = {1051-8215},
journal = {IEEE Trans. Cir. and Sys. for Video Technol.},
keywords = {Alpha-stable distribution,automatic object detection,background subtraction (BS),segmentation},
number = {8},
pages = {1133--1138},
publisher = {IEEE Press},
title = {{Video Foreground Detection Based on Symmetric Alpha-Stable Mixture Models}},
url = {https://doi.org/10.1109/TCSVT.2010.2051282},
volume = {20},
year = {2010}
}
@inproceedings{Christensen:2013:CQP:2509997.2510033,
address = {Washington, DC, USA},
author = {Christensen, Kenneth Fuglsang and Christiansen, Lasse Linnerup and Pedersen, Torben Bach and Pihl, Jeppe},
booktitle = {Proceedings of the 2013 IEEE 14th International Conference on Mobile Data Management - Volume 01},
doi = {10.1109/MDM.2013.31},
isbn = {978-0-7695-4973-6},
keywords = {Aggregate Queries,CQPF,Moving Objects,Object Flow,Prediction,Query Hierarchy,Selection Queries,Spatio-temporal Range Queries,Symbolic Space},
pages = {217--226},
publisher = {IEEE Computer Society},
series = {MDM '13},
title = {{Continuous Query Processing for Actual and Predicted Object Flow in Symbolic Space}},
url = {https://doi.org/10.1109/MDM.2013.31},
year = {2013}
}
@article{D,
author = {,  and , },
journal = {},
pages = {487--492},
title = {{No Title }},
url = {http://ir.obihiro.ac.jp/dspace/handle/10322/3933},
volume = {84},
year = {2013}
}
@inproceedings{D,
author = {{ }, },
pages = {14--15},
title = {{No Title     }},
year = {1382}
}
@article{Tesoriero:2010:SCI:1628324.1628579,
abstract = {Location awareness is a key issue to improve the development of autonomous entities that are embedded into ubiquitous computing environments. GPS seems to be the best solution to develop outdoor location systems, but the performance of these systems is not good enough to locate objects or humans within indoor environments, mainly if accuracy and precision are required. In this article we propose the use of a cheap and reliable technology as RFID to develop a passive RFID-based indoor location system that is able to accurately locate autonomous entities, such as robots and people, within a defined surface. This system is applied to solve the robot tracking problem. We include the evaluation of the proposal by comparing our system technology performance with other alternatives built on different technologies (Wi-Fi, Bluetooth, IrDA, ultrasound, etc.). We have also performed a location awareness proof concept test to analyze the viability of the approach. {\textcopyright} 2009 Elsevier Ltd. All rights reserved.},
address = {Tarrytown, NY, USA},
annote = {From Duplicate 1 (Improving location awareness in indoor spaces using RFID technology - Tesoriero, R; Tebar, R; Gallud, J A; Lozano, M D; Penichet, V M R)

cited By 74},
author = {Tesoriero, R and Tebar, R and Gallud, J A and Lozano, M D and Penichet, V M R},
doi = {10.1016/j.eswa.2009.05.062},
issn = {0957-4174},
journal = {Expert Syst. Appl.},
keywords = {,Autonomous systems,Cellular telephone systems,Indoor location systems,Locat,Location awareness,Passive RFID,Technology,Tracing,Ubiquitou,Wireless telecommunication systems},
number = {1},
pages = {894--898},
publisher = {Pergamon Press, Inc.},
title = {{Short Communication: Improving Location Awareness in Indoor Spaces Using RFID Technology}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349469685{\&}doi=10.1016{\%}2Fj.eswa.2009.05.062{\&}partnerID=40{\&}md5=5c6d8f990c053861d3a56c1882c5650b http://dx.doi.org/10.1016/j.eswa.2009.05.062},
volume = {37},
year = {2010}
}
@inproceedings{7006225,
abstract = {This paper investigates the deployment of WLAN for indoor localization. K-Nearest Neighbor algorithm is adapted to predict the location of a user in an indoor environment. The accuracy of K-Nearest Neighbor in predicting user's location in an indoor environment is evaluated. As resistance in indoor environment such as walls and movement of objects adversely affect the performance of the algorithm, emphasis is placed on RSS sample vector fluctuation correction. Two simulations were carried out, one adapting the fluctuation correction algorithm and one without fluctuation correction algorithm. The results of the investigation shows that deployment of fluctuation correction algorithm improves the prediction accuracy. The number of access points (APs) deployed in the investigated area also contribute to the prediction accuracy.},
annote = {From Duplicate 2 (WLAN environment for indoor localization - Burhan, M F B; Shiham, N S M; Balasubramaniam, N; Din, N M)

cited By 0},
author = {Burhan, M F B and Shiham, N S M and Balasubramaniam, N and Din, N M},
booktitle = {2014 4th International Conference on Engineering Technology and Technopreneuship (ICE2T)},
doi = {10.1109/ICE2T.2014.7006225},
keywords = {,Access point (APs),Correction algorithms,Forecasting,Indoor,Indoor positioning systems,Motion co,Wireless local area networks (WLAN),indoor radio,mobile computing,pattern classificati},
pages = {89--93},
title = {{WLAN environment for indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990964646{\&}doi=10.1109{\%}2FICE2T.2014.7006225{\&}partnerID=40{\&}md5=94b686a1cda280cc236c5b17c7de4bad},
volume = {2014-Augus},
year = {2014}
}
@inproceedings{7033735,
abstract = {In recent years the research on positioning and navigation systems for indoor environments has progressed rapidly. For this purpose many technologies based on e.g. UWB, WLAN, ultrasonic or infrared were utilized. However, these systems are restricted on line-of-sight (LOS) conditions due to disturbances, fading and multipath inside of buildings. Because magnetic fields are able to penetrate walls, building materials or other objects, a DC Magnetic signal based Indoor Local Positioning System (MILPS) was developed, which provides localisation in harsh indoor environments. Multiple electrical coils - representing reference stations - and tri-axial magnetometers as mobile stations are utilized. Capturing the magnetic field intensities of at least three different coils leads to the specific slope distances and finally to the observer's position. Because the current positioning algorithm is designed for stop-and-go applications originally, this contribution focuses on the sensor fusion of MILPS and an Inertial Measurement Unit (IMU) to face kinematic applications for wheeled platforms. The short time stable IMU-integrated data, which is influenced by sensor drifts and integration errors, is then supported by MILPS, which delivers positions in a low frequent update interval. To estimate a position in two dimensional environments - in the first step - an Iterative Kaiman Filter (IKF) is applied to eliminate linearization errors caused by inaccurate predictions. Therefore the dead reckoning trajectory is updated by using MILPS' distance observations. In this context first promising experiments with combinations of IMU and MILPS have been performed proving the capability of sensor integration. While acceleration and angular rate measurements lead to a state prediction (consisting of current position and velocity) external MILPS-observations are used for IMU-data support. The IKF estimates a current state in respect to both measurement systems' statistical information.},
annote = {From Duplicate 1 (Indoor localisation for wheeled platforms based on IMU and artificially generated magnetic field - Hellmers, H; Eichhorn, A; Norrdine, A; Blankenbach, J)

cited By 8},
author = {Hellmers, H and Eichhorn, A and Norrdine, A and Blankenbach, J},
booktitle = {2014 Ubiquitous Positioning Indoor Navigation and Location Based Service (UPINLBS)},
doi = {10.1109/UPINLBS.2014.7033735},
keywords = {,Angular rate measurements,DC magnetic field,Errors,Ind,Indoor positioning systems,Iterative methods,Location based services,indoor communication,indoor navigation,inertial na},
month = {nov},
pages = {255--264},
title = {{Indoor localisation for wheeled platforms based on IMU and artificially generated magnetic field}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924386000{\&}doi=10.1109{\%}2FUPINLBS.2014.7033735{\&}partnerID=40{\&}md5=7e31029bf3d5d9ebec9cde6e54341e56},
year = {2014}
}
@inproceedings{8273235,
abstract = {In this paper, the Deep Reinforcement Learning (DRL) is proposed to address a planning issue which is different from the traditional SLAM algorithm. It is an end-to-end trainable framework in which we do not need to build a map for the agent in advance. We apply a Q-CNN model whose policy is to combine the Convolutional Neural Network (CNN) and the Q functions. The raw images are used as inputs and outputs action directly. To achieve the task, we develop a simulation environment in Gazebo, which provides indoor 3D scenes with physics engine and high-quality pictures. In the environment, agent can be controlled conveniently and interacted with objects freely. Our experiment is to find the shortest trajectories from the initial location to the target. After iterative training, we have trained a set of parameters to approximate Q function well and made it have a better performance.},
annote = {From Duplicate 2 (A deep Q network for robotic planning from image - Han, J; Liu, H; Wang, B)

cited By 0},
author = {Han, J and Liu, H and Wang, B},
booktitle = {2017 2nd International Conference on Advanced Robotics and Mechatronics (ICARM)},
doi = {10.1109/ICARM.2017.8273235},
keywords = {,3D simulations,Convolutional Neural Networks (CN,Deep learning,Iterative methods,Neural networks,Robotics,learning (artificial intelligence),mobile robots,n},
pages = {626--631},
title = {{A deep Q network for robotic planning from image}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050721744{\&}doi=10.1109{\%}2FICARM.2017.8273235{\&}partnerID=40{\&}md5=1916be41ada72dba0fbb11e77cbbd2bf},
volume = {2018-Janua},
year = {2017}
}
@inproceedings{7846667,
abstract = {A large number of studies show that in complex indoor propagation environment, parameters of indoor positioning method for typical applications, such as localization performance of TOA, TDOA, AOA, RSSI method is often less than ideal. In order to reduce the influence of indoor environmental factors on the indoor wireless positioning, improve the positioning accuracy and expand the location area, the indoor wireless positioning method based on WiFi K-means is proposed. The improved distance formula is used to take into account the effect of attribute values, and the difference between different objects can be calculated more accurately. The AP in the position of each room is established by testing the signal strength of different signals. The experimental results show that the precision in location probability of 3 meters is more than 80{\%}, which relative than hard clustering algorithm, positioning accuracy is improved.},
annote = {From Duplicate 2 (WiFi indoor localization based on K-means - Zhong, Y; Wu, F; Zhang, J; Dong, B)

cited By 4},
author = {Zhong, Y and Wu, F and Zhang, J and Dong, B},
booktitle = {2016 International Conference on Audio, Language and Image Processing (ICALIP)},
doi = {10.1109/ICALIP.2016.7846667},
keywords = {,Clustering algorithms,Environmental factors,Hard clustering algorithms,Image processing,Indoor positioning systems,indoor navigation,loc,radionavigation,wireless LAN},
pages = {663--667},
title = {{WiFi indoor localization based on K-means}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016119072{\&}doi=10.1109{\%}2FICALIP.2016.7846667{\&}partnerID=40{\&}md5=84a0b4108662ca073f87dd69849b768a},
year = {2016}
}
@inproceedings{8645459,
abstract = {Visible light communications (VLC) is an emerging communication paradigm that can provide illumination, data communications, and localization services. In this study, a novel approach that uses VLC infrastructure and a photodetector is proposed to build a sparse map of an indoor area. VLC channel state information, which consists of the optical received signal strength and channel impulse response, is measured for wall/obstacle location estimation. The proposed algorithm uses the time-of-flight of the light to estimate the distance to the walls. The estimated wall locations are used as landmarks to build a sparse map of the indoor area. This technique can be used to estimate the distance to walls and objects in robotics applications. Furthermore, the proposed algorithm can be used to locate the agent and unknown LED locations using a simultaneous localization and mapping algorithm. Root mean square error of our wall localization algorithm is less than 10 cm when the VLC channel signal-to-noise ratio is 80 dB.},
annote = {From Duplicate 2 (Indoor Mapping Using the VLC Channel State Information - Vatansever, Z; Lian, J; Brandt-Pearce, M)

cited By 0},
author = {Vatansever, Z and Lian, J and Brandt-Pearce, M},
booktitle = {2018 52nd Asilomar Conference on Signals, Systems, and Computers},
doi = {10.1109/ACSSC.2018.8645459},
issn = {2576-2303},
keywords = {,Channel impulse response,Channel state information,Communication paradigm,Conformal mapping,Impulse response,Indoor positi,free-space optical communication,indoor communicat},
pages = {428--432},
title = {{Indoor Mapping Using the VLC Channel State Information}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062972044{\&}doi=10.1109{\%}2FACSSC.2018.8645459{\&}partnerID=40{\&}md5=49f22c3a0026747162144351ff2c70f0},
volume = {2018-Octob},
year = {2018}
}
@inproceedings{7033716,
abstract = {The last decade has seen an increase in the attention towards indoor space and its applications. Within this research topic, landmarks play an important role as these distinct objects exert important functions in the context of navigation and in the construction of a cognitive model of an environment. However, compared to outdoor research, little research has been conducted related to indoor landmarks and their specific characteristics with respect to their use and description. Therefore, the presented study aims to investigate when or where landmarks are mostly needed during a navigational task in a building and how they are verbally expressed. In order to examine these aspects, eleven test persons completed a route in a complex building. While navigating, they had to think out loud and their verbal descriptions were analyzed and compared. The results of this study show that landmarks were most needed on locations where a change of orientation took place. In addition, most referrals were made to objects near the observer. Furthermore, participants preferred to use common nouns to refer to a landmark and more detailing was given by specifying color and material. Finally, the results indicate that predominantly the same elements form the basis to identify an indoor landmark as an outdoor landmark namely visual, structural and semantic features.},
annote = {From Duplicate 2 (Thinking aloud in search of landmark characteristics in an indoor environment - Viaene, P; Vanclooster, A; Ooms, K; De Maeyer, P)

cited By 3},
author = {Viaene, P and Vanclooster, A and Ooms, K and {De Maeyer}, P},
booktitle = {2014 Ubiquitous Positioning Indoor Navigation and Location Based Service (UPINLBS)},
doi = {10.1109/UPINLBS.2014.7033716},
keywords = {,Cognitive model,Complex buildings,Indoor enviro,Location based services,Mobile devices,Navigation,Semantics,Telecommuni,cognitive radio,indoor environment,indoor navigati},
month = {nov},
pages = {103--110},
title = {{Thinking aloud in search of landmark characteristics in an indoor environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924358328{\&}doi=10.1109{\%}2FUPINLBS.2014.7033716{\&}partnerID=40{\&}md5=83b1a84f4481e22976e1056bd2819a61},
year = {2014}
}
@inproceedings{6967090,
abstract = {This paper discusses various factors of indoor localization system, and analyzes distance measurement based on RSSI. We propose a novel indoor localization algorithm, and give the prior probability and posterior probability of target location based on Bayes filtering theory. For dynamic target, we utilize Kalman filter to compensate distance measurement errors of dynamic target, solving the problems of localization and tracking of other target objects on the ground.},
annote = {From Duplicate 1 (The research and improvement of indoor localization algorithms based on RSSI - Chen, Z; Fan, H)

cited By 3},
author = {Chen, Z and Fan, H},
booktitle = {Proceedings of 2013 3rd International Conference on Computer Science and Network Technology},
doi = {10.1109/ICCSNT.2013.6967090},
keywords = {,Algorithms,Bayes filtering,Bayes methods,Bayes theory,Indoor localizatio,Kalman filters,Measurement errors,Target trackin,distance measurement,error compensat},
pages = {178--181},
title = {{The research and improvement of indoor localization algorithms based on RSSI}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919443074{\&}doi=10.1109{\%}2FICCSNT.2013.6967090{\&}partnerID=40{\&}md5=15e6380a60b4dce275a8ca7c33dbc319},
year = {2013}
}
@inproceedings{7843995,
abstract = {Map retrieval, the problem of similarity search over a large collection of 3D pointset maps previously built by mobile robots, is crucial for autonomous navigation in indoor and outdoor environments. Bag-of-words (BoW) methods constitute a popular approach to map retrieval; however, these methods have extremely limited descriptive ability because they ignore the spatial layout information of the local features. The main contribution of this paper is an extension of the bag-of-words map retrieval method to enable the use of spatial information from local features. Our strategy is to explicitly model a unique viewpoint of an input local map; the pose of the local feature is defined with respect to this unique viewpoint, and can be viewed as an additional invariant feature for discriminative map retrieval. Specifically, we wish to determine a unique viewpoint that is invariant to moving objects, clutter, occlusions, and actual viewpoints. Hence, we perform scene parsing to analyze the scene structure, and consider the "center" of the scene structure to be the unique viewpoint. Our scene parsing is based on a Manhattan world assumption that imposes a quasi-Manhattan world constraint to enable the robust detection of a scene structure that is invariant to clutter and moving objects. Experimental results using the publicly available University of Michigan North Campus Long-Term Vision and LIDAR Dataset (NCLT dataset [1]) validate the efficacy of the proposed approach.},
annote = {From Duplicate 1 (Map retrieval in 3D using view-dependent local map descriptor - Yoshiki, T; Kanji, T)

cited By 0},
author = {Yoshiki, T and Kanji, T},
booktitle = {2016 IEEE/SICE International Symposium on System Integration (SII)},
doi = {10.1109/SII.2016.7843995},
issn = {2474-2325},
keywords = {,Autonomous navigation,Clutter (information theory),Invariant features,Manhat,Mobile robots,Robots,feature extraction,image retrieval,mobile robots,p},
pages = {180--185},
title = {{Map retrieval in 3D using view-dependent local map descriptor}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015386954{\&}doi=10.1109{\%}2FSII.2016.7843995{\&}partnerID=40{\&}md5=f3cb22901c0194afb969a8d70ccfaa17},
year = {2016}
}
@inproceedings{8262565,
abstract = {The development of information technology and the concept of smart city began to grow. Information technology needed by the public that is looking for information position and location of destination in the building (indoor positionting). Indoor positioning using WiFi has limits on location placement. To overcome these shortcomings are used sensor beacon bluetooth low energy with the advantages of having low power consumption and relatively small dimensions that can be placed in various places that are difficult to reach by WiFi. Indoor Positioning System (IPS) is a system for knowing the position of objects or people in a room by using radio waves, magnetic fields, or other sensors obtained by mobile devices. The indoor positioning method is divided into deterministic and probabilistic. Deterministic can determine the position faster by using measurement techniques such as Trilateration and Triangulation. Trilateration is a method for determining location with known three location information and device distance to each access point. This research used Trilateration method with measurement technique based on RSSI value. Based on the results of the test, RSSI of the beacon is strongly affected by objects that have thickness and density. In line of sight conditions, Android devices are able to receive signals properly and determine the location of the device using trilateration with quite accurate.},
annote = {From Duplicate 2 (Development of mobile indoor positioning system application using android and bluetooth low energy with trilateration method - Noertjahyana, A; Wijayanto, I A; Andjarwirawan, J)

cited By 1},
author = {Noertjahyana, A and Wijayanto, I A and Andjarwirawan, J},
booktitle = {2017 International Conference on Soft Computing, Intelligent System and Information Technology (ICSIIT)},
doi = {10.1109/ICSIIT.2017.64},
keywords = {,Android,Android (operating system),Big data,Bluetooth,Bluetooth low energies (BTLE),I,Indoor po,Indoor positioning systems,indoor radio,mobile computing,wireless L},
pages = {185--189},
title = {{Development of Mobile Indoor Positioning System Application Using Android and Bluetooth Low Energy with Trilateration Method}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049304783{\&}doi=10.1109{\%}2FICSIIT.2017.64{\&}partnerID=40{\&}md5=bde4cc4ae3ac9b400d1f17020311c030},
volume = {2018-Janua},
year = {2017}
}
@inproceedings{8311629,
abstract = {During the last years, the market of embedded vision-based systems has been growing at an accelerated rate. Virtual and augmented reality has the potential to become one of the most innovative technologies for the next decade. One of the most important aspects of these technologies is related to the spatial location of objects or people in defined environments, for which there are several techniques. One of the most widely used is based on visual marker recognition. The main problems of these approaches are related to the accuracy, the changing environments, the processing time, the operating range/distance and the price. The popularization of these technologies produces a pull effect toward the companies developing the best technology at the lowest price. This paper proposes a marker design and an algorithm to detect the markers under different ambient conditions, with a long range to be executed on embedded systems with low computational requirements. The proposed method reduces the existing problems in the state-of-the-art related to the use of different environments and conditions such as different distances or different illumination. Moreover, the requisites of the method are minimal to reduce the cost of deployment.},
annote = {From Duplicate 1 (Short and long distance marker detection technique in outdoor and indoor environments for embedded systems - D{\'{i}}az, {\'{A}}; Pe{\~{n}}a, D; Villar, E)

cited By 0},
author = {D{\'{i}}az, {\'{A}} and Pe{\~{n}}a, D and Villar, E},
booktitle = {2017 32nd Conference on Design of Circuits and Integrated Systems (DCIS)},
doi = {10.1109/DCIS.2017.8311629},
keywords = {,Ambient conditions,Augmented reality,Changing environment,Computa,Embedded systems,Integrated control,Navigation,augmented reality,computer vision,embedded systems},
month = {nov},
pages = {1--6},
title = {{Short and long distance marker detection technique in outdoor and indoor environments for embedded systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050807592{\&}doi=10.1109{\%}2FDCIS.2017.8311629{\&}partnerID=40{\&}md5=0ef22ec5c55e019180c8aa2bcd10ad72},
volume = {2017-Novem},
year = {2017}
}
@inproceedings{7033729,
abstract = {Many of the indoor applications like navigation, indoor localization, object tracking require an indoor map. Indoor environments are dynamic in nature because of the objects present in it. To capture the essence of the indoor environment, it is essential to perform an object level mapping of an indoor space. This is because an object has the potential to alter the map of an indoor environment. Mapping a huge indoor environment could prove to be costly in terms of time with high infrastructure dependency. This compels us to find a simple solution in terms of cost, time and reliability to build an indoor map. The proposed solution should have minimal infrastructure dependence, so that it can be used in situations like disaster and rapid response scenarios, where the available infrastructure is minimal and time is of essence. We propose a Radio Frequency Identification(RFID) based approach which performs an object level mapping of the indoor environment using a portable RFID reader, RFID Ultra High Frequency(UHF) passive tags and inertial navigation sensors(INS). This approach identifies each object in the indoor environment using one or more passive tags. A novel algorithm has been developed which accurately maps the objects present in the indoor space. It is easily scalable to map huge indoor environments and can be applied without any intensive manual labor or expensive equipments. Our experiments show that this approach generates object level indoor maps with high accuracy.},
annote = {From Duplicate 1 (Object level mapping of an indoor environment using RFID - Malla, H; Purushothaman, P; Rajan, S V; Balasubramanian, V)

cited By 2},
author = {Malla, H and Purushothaman, P and Rajan, S V and Balasubramanian, V},
booktitle = {2014 Ubiquitous Positioning Indoor Navigation and Location Based Service (UPINLBS)},
doi = {10.1109/UPINLBS.2014.7033729},
keywords = {,Algorithms,Expensive equipments,Indoor,Indoor applications,Indoor positioning systems,Inertial navigation systems,Location,object level mapping,radiofrequency identification},
month = {nov},
pages = {203--212},
title = {{Object level mapping of an indoor environment using RFID}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924370431{\&}doi=10.1109{\%}2FUPINLBS.2014.7033729{\&}partnerID=40{\&}md5=13face667f58acff02f0aa8d14b5dc10},
year = {2014}
}
@inproceedings{7043402,
abstract = {Indoor positioning system (IPS) is becoming more and more important and necessary in our daily life. Based on the IPS, we may develop a variety of location based services (LBS) such as navigation and orientation in large commercial centers, tracking and monitoring objects, or locating the elderly and children. With the development of new advanced technologies, the hand-held devices such as smart-phones and tablets have been widely used. These devices are all equipped with common sensors such as accelerometer, magnetic field, gyro and sound sensors. Therefore, the development of sensors-based positioning system is becoming practical and easy to implement while GPS or Cell-ID works inaccurately in the indoor environment. In this paper, we propose a solution and develop an application to position user's location in an indoor environment by pedestrian dead reckoning (PDR) and orientation. The proposed system just uses some available sensors of smart-phones: accelerometer sensor, gyro sensor and gravity sensor for PDR which detects steps as well as to measure the length and the orientation of his/her steps and then computes his/her location.},
annote = {From Duplicate 1 (Smartphone-based pedestrian dead reckoning and orientation as an indoor positioning system - Do-Xuan, T; Tran-Quang, V; Bui-Xuan, T; Vu-Thanh, V)

cited By 10},
author = {Do-Xuan, T and Tran-Quang, V and Bui-Xuan, T and Vu-Thanh, V},
booktitle = {2014 International Conference on Advanced Technologies for Communications (ATC 2014)},
doi = {10.1109/ATC.2014.7043402},
issn = {2162-1020},
keywords = {,Accelerometer sensor,Accelerometers,Advanced technology,Gyroscopes,Hand h,Indoor positioning sys,Location based services,accelerometers,indoor navigation,pedestrians,smart},
pages = {303--308},
title = {{Smartphone-based pedestrian dead reckoning and orientation as an indoor positioning system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940507745{\&}doi=10.1109{\%}2FATC.2014.7043402{\&}partnerID=40{\&}md5=4f174bb01e2c32514d07855c53ee091e},
volume = {2015-Febru},
year = {2014}
}
@inproceedings{7894503,
abstract = {The procedure or activity of provoking blind's position and planning and following a route in an internal system. Source Localization is one of the forthright setbacks in incorporation sonar, countless spans, microphone arrays, radar, teleconferencing or videoconferencing mobile phone locale discovering exploration and globe positioning arrangements exact positioning of earthquake epicenters and subversive blasts, robots micro seismic events in mines sensor webs, tactile contact in novel profound human-computer interfaces talker dogging surveillance and sound basis tracking. Our objective is factual period elevated precision wideband sound basis outdoor localization. An extensive hypothesis is traditional for locating exactly to these sound. Conveying a localization prearrangement in suitable wide range of point of a localization zone frequently diminishes the echo degree and in an internal system it use microphone arrays to locate specific voice, remarkably for soaring objects. Additionally countless such sound basis signals are baseband signals. Moreover, indoor raised precision sound basis localization in district climates wants remarkably sensitive and elevated appearance.},
annote = {From Duplicate 2 (Proficient method for acoustic sound source location estimation using time difference of arrival - Srivastava, S; Saxena, U R)

cited By 0},
author = {Srivastava, S and Saxena, U R},
booktitle = {2016 International Conference System Modeling Advancement in Research Trends (SMART)},
doi = {10.1109/SYSMART.2016.7894503},
keywords = {,Acoustic generators,Base bands,Earthquakes,Global system fo,Indoor positioning systems,Microphones array,PHAT,Sound source,acoustic signal processing,indoor communication,mi},
month = {nov},
pages = {124--129},
title = {{Proficient method for acoustic sound source location estimation using time difference of arrival}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018289012{\&}doi=10.1109{\%}2FSYSMART.2016.7894503{\&}partnerID=40{\&}md5=5bc93c2a06d5d61f2a117bc0a1bb7b4f},
year = {2016}
}
@inproceedings{7006249,
abstract = {Indoor localization is vastly deployed for tracking the position and movement of objects and humans within an enclosed area. Poliferation of wireless technologies has further foster the deployment of indoor localization system in various field. This paper proposes RFID and ZigBee integrated environment for indoor localization system. K-Nearest Neighbor algorithm is adapted to predict the location of a user in an indoor environment. The accuracy of the indoor location sensing is investigated. Results of the RFID deployment in the research work is presented in this paper.},
annote = {From Duplicate 1 (RFID and ZigBee integrated environment for indoor localization - Keong, N Y; Chieh, K S; Burhan, M F; Balasubramaniam, N; Din, N M)

cited By 3},
author = {Keong, N Y and Chieh, K S and Burhan, M F and Balasubramaniam, N and Din, N M},
booktitle = {2014 4th International Conference on Engineering Technology and Technopreneuship (ICE2T)},
doi = {10.1109/ICE2T.2014.7006249},
keywords = {,Engineering research,Indoor environment,Indoor l,Indoor localization,Indoor positioning systems,Nearest neighbor search,Pat,indoor radio,object tracking,radio tracking,radiof},
pages = {213--217},
title = {{RFID and ZigBee integrated environment for indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991000978{\&}doi=10.1109{\%}2FICE2T.2014.7006249{\&}partnerID=40{\&}md5=e021e6d6d0bd7f3ca23e83dc2c2e779f},
volume = {2014-Augus},
year = {2014}
}
@inproceedings{8250971,
abstract = {An indoor positioning system (IPS) is a technology employed to locate objects and people within a building scenario using signal processing or other sensory information. Ultra Wide Band (UWB) is a versatile wireless technology that can be employed as an IPS and has shown very good performances. UWB can be used in many scenarios and its effectiveness in through wall detection along with its excellent resolution for person localization is one of the best applications of Impulse Radio (IR) UWB. The main objective of this work is to propose a concept for intelligent radar systems employing UWB augmented by machine learning approaches to not only localize but understand the location of a person or target within a building. Although suitably developed UWB is excellent for obtaining localizing data it does not automatically understand what that location effectively means or where it is thus further methods are required to create meaningful data for end user appreciation. Learning from the huge amount of UWB signal data through Multi Class Support Vector Machine (MC-SVM) architecture enables a truly evolving scheme to both localize targets and identify them in a useful way. Statistical analysis of the experimental results supports the proposed algorithm.},
annote = {From Duplicate 2 (UWB localization employing supervised learning method - Rana, S P; Dey, M; Siddiqui, H U; Tiberi, G; Ghavami, M; Dudley, S)

cited By 4},
author = {Rana, S P and Dey, M and Siddiqui, H U and Tiberi, G and Ghavami, M and Dudley, S},
booktitle = {2017 IEEE 17th International Conference on Ubiquitous Wireless Broadband (ICUWB)},
doi = {10.1109/ICUWB.2017.8250971},
keywords = {,Indoor positioning system (IPS),Indoor positioning systems,Localization,Ma,Principal component an,Ultra-wideband (UWB),indoor navigation,indoor radio,learning (artificia},
pages = {1--5},
title = {{UWB localization employing supervised learning method}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046007151{\&}doi=10.1109{\%}2FICUWB.2017.8250971{\&}partnerID=40{\&}md5=85367b5de07600b4c7fdf7db3300ef90},
volume = {2018-Janua},
year = {2017}
}
@inproceedings{4079271,
abstract = {This paper presents a new interaction metaphor we have termed "god-like interaction". This is a metaphor for improved communication of situational and navigational information between outdoor users, equipped with mobile augmented reality systems, and indoor users, equipped with tabletop projector display systems. Physical objects are captured by a series of cameras viewing a table surface indoors, the data is sent over a wireless network, and is then reconstructed at a real-world location for outdoor augmented reality users. Our novel god-like interaction metaphor allows users to communicate information using physical props as well as natural gestures. We have constructed a system that implements our god-like interaction metaphor as well as a series of novel applications to facilitate collaboration between indoor and outdoor users. We have extended a well-known video based rendering algorithm to make it suitable for use on outdoor wireless networks of limited bandwidth. This paper also describes the limitations and lessons learned during the design and construction of the hardware that supports this research.},
annote = {From Duplicate 2 (Implementation of god-like interaction techniques for supporting collaboration between outdoor AR and indoor tabletop users - Stafford, A; Piekarski, W; Thomas, B H)

cited By 43},
author = {Stafford, A and Piekarski, W and Thomas, B H},
booktitle = {2006 IEEE/ACM International Symposium on Mixed and Augmented Reality},
doi = {10.1109/ISMAR.2006.297809},
keywords = {,Architectural design,Argon,Augmented reality (AG),Communication systems,Design and construction,Wireless networks,augmented reality,mobile computing,user interfaces},
pages = {165--172},
title = {{Implementation of god-like interaction techniques for supporting collaboration between outdoor AR and indoor tabletop users}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-45149135433{\&}doi=10.1109{\%}2FISMAR.2006.297809{\&}partnerID=40{\&}md5=1884b6e3a4d20144ba6e3ea002baf573},
year = {2006}
}
@inproceedings{8336048,
abstract = {Exact real-time pupil tracking is an important step in a live eye gaze. Since pupil centre is a base point's reference, exact eye centre localization is essential for many applications, such as face recognition and eye gaze estimation. A new method proposed in this paper is to extract pupil eye features exactly within different intensity levels of eye images, mostly with localization of determined interest objects and where the human is looking. As application area, the eye localization in the frame of a video-sequence has been chosen with continuing in iris and pupil detection. This method is fast and has a high degree of accuracy to determine the eye gaze after the pupil is detected because it depends on the features in the human eye. The intensity increases in the centre of the eye, and these features are extracted using a multistage algorithm. Firstly, the feature-based algorithm detected the location of the face region and will be used to detect the pupil on the face. Secondly, use the pupil to determine where humans are looking. Proposed algorithm experiments results to the faces show that they are not only robust, but also relatively efficient. It has been tested on the Mackup database, which contains 500 images belonging to 108 females from the Asian region with different indoor illuminations. The image from a real-world indoor setting with lenses, and images from the Internet. The experiment results show 99{\%}. This ratio shows very good robustness and accuracy.},
annote = {From Duplicate 1 (Pupil detection algorithm based on feature extraction for eye gaze - Mohsin, H; Abdullah, S H)

cited By 0},
author = {Mohsin, H and Abdullah, S H},
booktitle = {2017 6th International Conference on Information and Communication Technology and Accessibility (ICTA)},
doi = {10.1109/ICTA.2017.8336048},
issn = {2379-4402},
keywords = {,Application area,Extraction,Eye gaze detection,Eye localiz,Face recognition,Feature extraction,Signal detection,face recognition,feature extraction,gaze tracking},
pages = {1--4},
title = {{Pupil detection algorithm based on feature extraction for eye gaze}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051021846{\&}doi=10.1109{\%}2FICTA.2017.8336048{\&}partnerID=40{\&}md5=89c0d3dc787c3a4a647dd7ef7b187c2f},
volume = {2017-Decem},
year = {2017}
}
@inproceedings{7006237,
abstract = {Indoor localization system has become popular and widely deployed in ftracking the position and movement of objects and humans within an enclosed structure. This work proposes development of indoor localization system using ZigBee. K-Nearest Neighbor algorithm is adapted to predict the location of a user in an indoor environment. The accuracy of the indoor location sensing is investigated. Emphasis is placed on RSS sample vector fluctuation correction to further increase the prediction accuracy.},
annote = {From Duplicate 1 (ZigBee environment for indoor localization - Chieh, K S; Keong, N Y; Burhan, M F; Balasubramaniam, N; Din, N M)

cited By 2},
author = {Chieh, K S and Keong, N Y and Burhan, M F and Balasubramaniam, N and Din, N M},
booktitle = {2014 4th International Conference on Engineering Technology and Technopreneuship (ICE2T)},
doi = {10.1109/ICE2T.2014.7006237},
keywords = {,Indoor environment,Indoor l,Indoor localization,Indoor positioning systems,Nearest neighbor search,Pattern recognition,ZigBee env,Zigb,Zigbee,indoor radio,regression analysis},
pages = {152--155},
title = {{ZigBee environment for indoor localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990922181{\&}doi=10.1109{\%}2FICE2T.2014.7006237{\&}partnerID=40{\&}md5=68edb8d1449e217e9f4c17987fd060af},
volume = {2014-Augus},
year = {2014}
}
@inproceedings{4079027,
abstract = {Summary form only given. The main ideas of pervasive/ubiquitous computing include 1) the fusion of cyberspace and physical space, 2) the distraction-free computing. Context awareness is the effort for computer systems to sense and leverage the rich context information in the dual space. It has been recognized as a promising approach to reach the goal of invisibility, which can provide attentive service for user. As a basic service in the computing environment, context-aware service is with four basic functions of collecting, storing, reasoning and querying. The reasoning and inosculating module are for formal reasoning module; the context base module provides the function of storing data and querying; the querying and subscribing module gives the non-processing interface for upper application to request context service; the raw data acquiring module acquires the raw data from the sensors and profile files. Not only can the computing framework provide context common service, but it has favorable expansibility and adaptability. And, location-aware computing is a representative research area of context-aware computing. For which we proposed 1) a multi-object-tracking, highly-precise indoor positioning system, Cicada, to acquire the objects' location in smart space, 2) an expeditious and active location-aware service model, which not only to provide rapid location-related query service to applications, but also to offer the active spatial event service. As a showcase, based on the framework of context-aware service, the smart camera man module which is one part of the smart classroom project was ameliorated and satisfying result is retrieved. Smart camera man module implements the function that switching to the most convenient camera view in terms of the shift of the vision focus of smart classroom, which embodies the distraction-free characteristic of smart space apparently},
annote = {From Duplicate 1 (Context awareness, the spirit of pervasive computing - Shi, Y)

cited By 3},
author = {Shi, Y},
booktitle = {2006 First International Symposium on Pervasive Computing and Applications},
doi = {10.1109/SPCA.2006.297456},
keywords = {,Contex,Context aware computing,Context awareness,Data acquisition,Mathematical models,Query proc,Ubiquitous computing,context awareness,pervasive c,ubiquitous computing},
pages = {6},
title = {{Context Awareness, the Spirit of Pervasive Computing}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-38649128782{\&}doi=10.1109{\%}2FSPCA.2006.297456{\&}partnerID=40{\&}md5=0086e63a7fe3a7b0a99e79abe3d7e1c3},
year = {2006}
}
@inproceedings{7899691,
abstract = {Reliable object discovery in realistic indoor scenes is a necessity for many computer vision and service robot applications. In these scenes, semantic segmentation methods have made huge advances in recent years. Such methods can provide useful prior information for object discovery by removing false positives and by delineating object boundaries. We propose a novel method that combines bottom-up object discovery and semantic priors for producing generic object candidates in RGB-D images. We use a deep learning method for semantic segmentation to classify colour and depth superpixels into meaningful categories. Separately for each category, we use saliency to estimate the location and scale of objects, and superpixels to find their precise boundaries. Finally, object candidates of all categories are combined and ranked. We evaluate our approach on the NYU Depth V2 dataset and show that we outperform other state-of-the-art object discovery methods in terms of recall.},
annote = {From Duplicate 2 (Semantic segmentation priors for object discovery - Garc{\'{i}}a, G M; Husain, F; Schulz, H; Frintrop, S; Torras, C; Behnke, S)

cited By 2},
author = {Garc{\'{i}}a, G M and Husain, F and Schulz, H and Frintrop, S and Torras, C and Behnke, S},
booktitle = {2016 23rd International Conference on Pattern Recognition (ICPR)},
doi = {10.1109/ICPR.2016.7899691},
keywords = {,Bottom up,Computer vision,False positive,Learning methods,Obje,Pattern recognition,Pixels,Robot applications,Seman,computer vision,image classification,image colour},
pages = {549--554},
title = {{Semantic segmentation priors for object discovery}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019162519{\&}doi=10.1109{\%}2FICPR.2016.7899691{\&}partnerID=40{\&}md5=697b160241dac66c6469a1f5d6f8c712},
year = {2016}
}
@inproceedings{8560835,
abstract = {This paper presents a multi-camera surveillance system that detects and tracks a moving object in indoor and outdoor environments. Since each camera has specific field of view (FOV), the problem is how to keep track of the object when it is out of the FOV of a camera. The system uses landmarks to coordinate the tracking tasks among the cameras. In this work we proposed and developed an algorithm to switch from one camera to another, according to the current location of the object of interest. The algorithm attempts to switch to the nearest camera which can observe the object of interest. Experimental test results showed that the system can coordinate the camera activities and track objects of interest as they move in the monitored area.},
annote = {From Duplicate 1 (Multi-camera Smart Surveillance System - Salman, B; Thanoon, M I; Zein-Sabatto, S; Yao, F)

cited By 0},
author = {Salman, B and Thanoon, M I and Zein-Sabatto, S and Yao, F},
booktitle = {2017 International Conference on Computational Science and Computational Intelligence (CSCI)},
doi = {10.1109/CSCI.2017.78},
keywords = {,Artificial intelligence,Cameras,Experimental test,Field of views,Landmark detec,Monitoring,Security systems,cameras,object detection,object tracking,video sig},
pages = {468--472},
title = {{Multi-camera Smart Surveillance System}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060567149{\&}doi=10.1109{\%}2FCSCI.2017.78{\&}partnerID=40{\&}md5=d26524a17f98a24961740afb5d969489},
year = {2017}
}
@inproceedings{7453783,
abstract = {A low cost vision guided robot was developed to perform indoor service operations. The robot uses a webcam to localize and track the object of interest and a SONAR is used in conjunction with the camera to estimate distance between the robot and the object. A 3 DOF robotic arm is mounted on the robot to manipulate the objects within its workspace. The robot is capable of operating at different lighting conditions. A Visual feedback loop is established between the object and the robot for continuous tracking. Path planning of the robot is done based on the mean of the object location from 5 frames to obtain smooth maneuver.},
annote = {From Duplicate 2 (Monocular vision based autonomous indoor mobile service robot - Emarose, S; Ranganathan, M D; Siranjeevi, M; Sugadev, M)

cited By 0},
author = {Emarose, S and Ranganathan, M D and Siranjeevi, M and Sugadev, M},
booktitle = {2015 Online International Conference on Green Engineering and Technologies (IC-GET)},
doi = {10.1109/GET.2015.7453783},
keywords = {,Artificial intelligence,Computer vision,Continuous tracking,First responders,Human dete,Integrated circuits,Lear,feedback,manipulators,mobile robots,object trackin},
month = {nov},
pages = {1--5},
title = {{Monocular vision based autonomous indoor mobile service robot}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966335487{\&}doi=10.1109{\%}2FGET.2015.7453783{\&}partnerID=40{\&}md5=2ee1bd307ba15198f24ce4f6580cb44c},
year = {2015}
}
@inproceedings{7873696,
abstract = {Locating physical objects is a highly relevant application addressed by numerous systems. Many of these systems have a drawback that, costly infrastructure must be installed before a significant physical area can be covered, i.e. before these systems may be used in practice. In this paper, a new architecture for indoor localization is built on the ubiquitous infrastructure using sensors for locating objects. Mobile nodes as well as static nodes equipped with sensors, naturally omnipresent in populated environments, are the main elements of this system. This paper describes, the design of object search system to be presented together with a set of simple heuristics which can be used for efficient object search. The proposed system can locate each of the physical items in our home, which may randomly change their location. The location of a mobile node is frequently changing and its co-ordinates will be calculated based on the static nodes near to it. The location updates are frequently broadcasted and therefore all nodes will get location updates of all other nodes and it is easy to find the missing items. This system can only be successfully deployed, if environment conditions such as the density of the participant and its mobility and system settings such as number of static sensors used, allows us to find an object rapidly and efficiently. We therefore demonstrate the practicability of our system and obtain suitable system parameters for its execution using simulations.},
annote = {From Duplicate 2 (A novel architecture for locating missing objects using location of things - Sruthi, S V; Ratheesh, T K)

cited By 0},
author = {Sruthi, S V and Ratheesh, T K},
booktitle = {2016 International Conference on Emerging Technological Trends (ICETT)},
doi = {10.1109/ICETT.2016.7873696},
keywords = {,Environment conditions,Indoor localization,Location,Nove,Surveying,Time difference of arrival,Triangulati,home automation,indoor navigation,mobile computing},
pages = {1--8},
title = {{A novel architecture for locating missing objects using location of things}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017194942{\&}doi=10.1109{\%}2FICETT.2016.7873696{\&}partnerID=40{\&}md5=158f490649202f402638418a42abaf39},
year = {2016}
}
@inproceedings{8397254,
abstract = {Scene recognition and Object detection have made momentous progress lately. While mobile robotics and drone analysis has already reached its growth apex, for robots, which can interact with humans and the indoor environment, having a sense of discerning indoor scenes or interiors of a building is an added benefit. Although, many approaches have been proposed to detect objects and locations such as Indoor Positioning System (IPS), feature based, content based recognition systems etc., indoor scene recognition is yet to gain ground. This is quite justified since, unlike outdoor scenes, indoor scenes lack distinctive local or global visual substance patterns. This paper proposes a new technique of achieving this goal by considering the data from the scene's RGB and Depth images. With advancement in machine learning methodologies such as neural networks, deep neural networks and Convolutional Neural Networks, the workable accuracy in scene recognition is no longer hypothetical. A Deep CNN framework is used with a transfer learning approach for indoor scene recognition implemented on Tensor Flow (python), using the RGB as well as point cloud data i.e., RGB-D images. With this proposed system of deep CNN model, accuracy is able to reach up to 94.4{\%} on the indoor dataset. Further a comparison of the proposed model performance with that of the digits' GoogLeNet and AlexNet framework is conducted. Also a training of the algorithm on the benchmark NYUv2 dataset and have achieved an accuracy of 75.9{\%} which beats the highest accuracy obtained on that model (64.5{\%}).},
annote = {From Duplicate 1 (Deep learning framework for scene based indoor location recognition - Hanni, A; Chickerur, S; Bidari, I)

cited By 0},
author = {Hanni, A and Chickerur, S and Bidari, I},
booktitle = {2017 International Conference on Technological Advancements in Power and Energy ( TAP Energy)},
doi = {10.1109/TAPENERGY.2017.8397254},
keywords = {,Content-based recognition,Convolutional neural n,Deep neural networks,Electric power transmission networks,Neural netwo,feedforward neural nets,image recognition,learning},
pages = {1--8},
title = {{Deep learning framework for scene based indoor location recognition}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050166565{\&}doi=10.1109{\%}2FTAPENERGY.2017.8397254{\&}partnerID=40{\&}md5=c40308e21e8b1c34110e3ddb3fc037af},
year = {2017}
}
@inproceedings{8615220,
abstract = {GPS and GLONASS are used worldwide to locate the devices using satellites but it cannot locate objects under the roof. Therefore different sensors are required to be deployed inside for indoor localization of the devices. Different techniques have been developed including angle of arrival technique, triangulation, trilateration, Artificial Neural Networks, KNN Classification techniques and Bayesian classification techniques. One of the most popular technique known as Naive Bayes Technique is mostly used for indoor localization of the objects and devices. Naive Bayes classifier assumes conditional independence between the attributes but in real world this is not the case. In order to overcome dependence and zero probability issue of Naive Bayes algorithm, different variants of Naive Bayes technique have been developed. In this paper we have done a comparative study of different Naive Bayes theorem based classification techniques and some other classification techniques for location estimation of device in indoor environment are done. The accuracy and efficiency of different techniques including SVM, SMO, Random Forest, Random Trees, Augmented Naive Bayes, Hidden Naive Bayes, Fine Grained Naive Bayes and Multinomial Naive Bayes technique are compared to find the best location estimation algorithm.},
annote = {From Duplicate 1 (Comparative study of classification techniques for indoor localization of mobile devices - Zia, K; Iram, H; Aziz-Ul-Haq, M; Zia, A)

cited By 0},
author = {Zia, K and Iram, H and Aziz-Ul-Haq, M and Zia, A},
booktitle = {2018 28th International Telecommunication Networks and Applications Conference (ITNAC)},
doi = {10.1109/ATNAC.2018.8615220},
issn = {2474-154X},
keywords = {,Bayes methods,Bayesian classification,Bayesian networks,Classification technique,Classifiers,Data mining,Decision trees,In,direction-of-arrival estimation,indo},
month = {nov},
pages = {1--5},
title = {{Comparative study of classification techniques for indoor localization of mobile devices}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062189258{\&}doi=10.1109{\%}2FATNAC.2018.8615220{\&}partnerID=40{\&}md5=46c091a64d7c4c5152e518ed7215ac6d},
year = {2018}
}
@inproceedings{8615781,
abstract = {The egocentric perspective is a recent perspective brought by new devices like the GoPro and Google Glass, which are becoming more available to the public. The hands are the most consistent objects in the egocentric perspective and they can represent more information about people and their activities, but the nature of the perspective and the ever changing shape of the hands makes them difficult to detect. Previous work has focused on indoor environments or controlled data since it brings simpler ways to approach it, but in this work we use data with changing background and variable illumination, which makes it more challenging. We use a Deformable Part Model based approach to generate hand proposals since it can handle the many gestures the hand can adopt and rivals other techniques on locating the hands while reducing the number of proposals. We also use the location where the hands appear and size in the image to reduce the number of detections. Finally, a CNN classifier is applied to remove the final false positives to generate the hand detections.},
annote = {From Duplicate 1 (Hand Detection using Deformable Part Models on an Egocentric Perspective - Cruz, S R; Chan, A B)

cited By 0},
author = {Cruz, S R and Chan, A B},
booktitle = {2018 Digital Image Computing: Techniques and Applications (DICTA)},
doi = {10.1109/DICTA.2018.8615781},
keywords = {,Computer programming,Computer science,Deformable part models,False positive,Hand dete,Palmprint recognition,convolutional neural nets,gesture recognition,imag},
pages = {1--7},
title = {{Hand Detection using Deformable Part Models on an Egocentric Perspective}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062225105{\&}doi=10.1109{\%}2FDICTA.2018.8615781{\&}partnerID=40{\&}md5=52217a9f4571c7a1664399b3b85849a1},
year = {2018}
}
@inproceedings{8644564,
abstract = {In engineering applications, related application of personnel location has become more and more popular. The global positioning system (GPS) is a classic system to locate people, vehicles and other objects. However the GPS signal cannot be received in closed space, so the localization can only be conducted through indoor positioning technologies. In this paper, we focus on the continuous positioning of people and vehicles in the tunnels. The ultra-wide-band (UWB) positioning technology is adopted, and we proposed a methods to remove the outliers to reduce the impact of NLOS transmissions. Moreover, we designed a continuous positioning algorithm based on prediction to increase the accuracy of positioning during the movement. Finally, an experimental platform was built, and the proposed scheme was evaluated. The experimental results show that the optimized algorithm can provide higher positioning accuracy and frequency than the traditional method.},
annote = {From Duplicate 2 (UWB-Based Real-Time Continuous Positioning System in NLOS Tunnel Environment - Ling, J; Wang, L; Ji, H; Xie, H; Ding, J; Dai, Q)

cited By 0},
author = {Ling, J and Wang, L and Ji, H and Xie, H and Ding, J and Dai, Q},
booktitle = {2018 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC)},
doi = {10.1109/CyberC.2018.00037},
keywords = {,Accuracy of positioning,Distributed computer systems,Engineering applications,Global Positioning System,Global positioning system,Ultra-wideband (UWB),tunnels,ultra wideband c},
pages = {142--1424},
title = {{UWB-Based Real-Time Continuous Positioning System in NLOS Tunnel Environment}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063137452{\&}doi=10.1109{\%}2FCyberC.2018.00037{\&}partnerID=40{\&}md5=3dcbb8577f1e336dd240fc87ffc052ce},
year = {2018}
}
@inproceedings{8275721,
abstract = {Indoor 3D object modeling is often used for object recognition, location and other robot manipulating task. In this paper, we put forward a common method to build 3D model of household object for robotic grasping. The point clouds including object from different viewpoints are captured from the Microsoft's Kinect v2 sensor. A pixel filtering approach is used to process depth image and morphology algorithm is implemented to filter noise points in the point clouds of object. FPFH descriptor is extracted from each point. Sample Consensus Initial Alignment and ICP algorithm is used to register two adjacent point cloud accurately. Based on a closed-loop optimization method, the cumulative error from continuous registration is reduced. We build some 3D models of indoor objects through the proposed approach. The experiment results shows that the method is convenient and can meet the accuracy requirements.},
annote = {From Duplicate 1 (A 3D Modeling Method of Indoor Objects Using Kinect Sensor - Shen, B; Yin, F; Chou, W)

cited By 0},
author = {Shen, B and Yin, F and Chou, W},
booktitle = {2017 10th International Symposium on Computational Intelligence and Design (ISCID)},
doi = {10.1109/ISCID.2017.12},
issn = {2473-3547},
keywords = {,3-d modeling,3D object modeling,Artificial intelligence,Closed loop opt,Object recognition,feature extraction,image filtering,image registrat},
pages = {64--68},
title = {{A 3D Modeling Method of Indoor Objects Using Kinect Sensor}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047007199{\&}doi=10.1109{\%}2FISCID.2017.12{\&}partnerID=40{\&}md5=3c4f30eec5361ba8d2ddc2489a5f3c32},
volume = {1},
year = {2017}
}
@inproceedings{8631602,
abstract = {In the period of wireless communication, Indoor positioning systems (IPSs) are getting enormous attention. These systems are construct to attain location information of individuals and objects inside a building. Now a day all the applicable wireless technologies used in this context are Wi-Fi and Bluetooth Low Energy (BLE) based. These advancements are additionally decided for their ease of use, low cost and integration into wireless devices. However, these techniques are having some positioning errors along with specified region. Here, we introduce another wireless technology named Light Fidelity (Li-Fi), the basic convention of this technology is the transfer of information using light illumination by light emitting diodes. This article primarily established a set of evaluation indexes for the performance of these three Wi-Fi, BLE and Li-Fi technologies in indoor positioning scenarios. We compare the predefined IPSs in term of performance and limitations. After then outline the tradeoffs among these systems from the perspective of all evaluation entities. We show experimentally that Li-Fi technology achieves a high efficiency but for accuracy, Wi-Fi is still better than Li-Fi and BLE technology.},
annote = {From Duplicate 1 (Performance Evaluation of Wi-Fi Bluetooth Low Energy Li-Fi Technology in Indoor Positioning - Afzal, M A; He, D; Zhu, Z; Yang, Y)

cited By 0},
author = {Afzal, M A and He, D and Zhu, Z and Yang, Y},
booktitle = {2018 IEEE 23rd International Conference on Digital Signal Processing (DSP)},
doi = {10.1109/ICDSP.2018.8631602},
issn = {2165-3577},
keywords = {,Access points,Bluetooth,Bluetooth low energies (BTLE),Digital signal processing,Direction of,IPS,Wi-Fi,free-space optical communication,indoor},
month = {nov},
pages = {1--5},
title = {{Performance Evaluation of Wi-Fi Bluetooth Low Energy amp; Li-Fi Technology in Indoor Positioning}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062798131{\&}doi=10.1109{\%}2FICDSP.2018.8631602{\&}partnerID=40{\&}md5=07a30569d3e066d83b7b51b047ce8cc8},
volume = {2018-Novem},
year = {2018}
}
@article{1561186,
abstract = {This paper proposes a dynamic conditional random field (DCRF) model for foreground object and moving shadow segmentation in indoor video scenes. Given an image sequence, temporal dependencies of consecutive segmentation fields and spatial dependencies within each segmentation field are unified by a dynamic probabilistic framework based on the conditional random field (CRF). An efficient approximate filtering algorithm is derived for the DCRF model to recursively estimate the segmentation field from the history of observed images. The foreground and shadow segmentation method integrates both intensity and gradient features. Moreover, models of background, shadow, and gradient information are updated adaptively for nonstationary background processes. Experimental results show that the proposed approach can accurately detect moving objects and their cast shadows even in monocular grayscale video sequences.},
annote = {From Duplicate 2 (A dynamic conditional random field model for foreground and shadow segmentation - Wang, Y; Loe, K.-F.; Wu, J.-K.)

cited By 136},
author = {Wang, Y and Loe, K.-F. and Wu, J.-K. and And},
doi = {10.1109/TPAMI.2006.25},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {,Algorithms,Artificial Intelligence,Automated,Biological,Colorimetry,Computer-Assisted,Conditional random fields (CRF),Dynamic condition,Feature extraction,Gradient methods,Image segmentation,Information Storage and Retrie,Information Storage and Retriev,Models,Nonlinear Dynamics,Pattern Recognit,Pattern Recognitio,Statistical,algorithm,article,artificial intelligence,auto,image segmentation,image sequences,video signal pr},
number = {2},
pages = {279--289},
title = {{A dynamic conditional random field model for foreground and shadow segmentation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33644850861{\&}doi=10.1109{\%}2FTPAMI.2006.25{\&}partnerID=40{\&}md5=2b2b1361ab0e41ea4142919f36ab0a07},
volume = {28},
year = {2006}
}
@inproceedings{8616693,
abstract = {Service robots aim to help humans in their daily tasks at home or office. To accomplish some of these tasks, robots must be able to navigate intelligently from one location to another in dynamic indoor environments. The indoor navigation is a challenging task as many moving and movable objects can be found in the way, blocking the robot's path. D*Lite is a path planning algorithm that replans more efficiently in case the environment changes. However, depending on how blocked the robot is, replanned paths can be much longer than the original or, in the worst case, the target location can not be reached anymore. Therefore, we introduce an adaptation to D*Lite which allows robots to ask for human assistance to move objects on its surrounding when its path is blocked. The algorithm also computes whether and how long the robot can wait for help. Experiments were carried out using simulation and a real robot.},
annote = {From Duplicate 1 (Indoor Navigation with Human Assistance for Service Robots Using DLite - Alves, R; Silva De Morais, J; Lopes, C R)

cited By 0},
author = {Alves, R and {Silva De Morais}, J and Lopes, C R},
booktitle = {2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
doi = {10.1109/SMC.2018.00696},
issn = {2577-1655},
keywords = {,Deuterium,Environment change,Human assistance,In-door nav,Indoor positioning systems,Mobile robo,Robot programming,indoor navigation,mobile robots,path planning,serv},
pages = {4106--4111},
title = {{Indoor Navigation with Human Assistance for Service Robots Using D*Lite}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062238740{\&}doi=10.1109{\%}2FSMC.2018.00696{\&}partnerID=40{\&}md5=f30fa804c116a17d403c42a3169f952a},
year = {2018}
}
@inproceedings{Shih:2006:IAI:1156426.1156926,
abstract = {The proliferation of mobile computing devices and wireless networks has fostered a growing interest in location sensing systems and services. In this paper we present an improvement approach of indoor location sensing using active RFID system. This is a location sensing system that uses radio frequency identification (RFID) technology for locating objects inside a building. The major advantage of this system is that it improves the overall precision of locating objects by utilizing array of reference tags and some mathematic algorithms. Based on our analysis, we demonstrate that the ability of using active RFID to estimate user location with a high degree of accuracy. Although RFID is not designed for indoor location sensing, this algorithm can be used for indoor location sensing, and added to make RFID technologies competitive in this new and growing market},
address = {Washington, DC, USA},
author = {Shih, Sung-Tsun and Hsieh, Kunta and Chen, Pei-Yuan and And},
booktitle = {Proceedings of the First International Conference on Innovative Computing, Information and Control - Volume 2},
doi = {10.1109/ICICIC.2006.234},
isbn = {0-7695-2616-0},
keywords = {,indoor radio,mobile computing,mobility management},
pages = {453--456},
publisher = {IEEE Computer Society},
series = {ICICIC '06},
title = {{An Improvement Approach of Indoor Location Sensing Using Active RFID}},
url = {http://dx.doi.org/10.1109/ICICIC.2006.234},
volume = {2},
year = {2006}
}
@inproceedings{7809935,
abstract = {"Room escape" is a kind of on-line puzzle game, in which players need to exploit their surrounding environment to discover clues for escaping from imprisonment. In recent years, a physical version of "room escape" becomes more and more popular, which transforms the playing paradigm from sitting in front of a computer and clicking the mouse into imprisoning people in a real locked room and having people to find clues by their bare hands. To enable a richer user experience while playing the room escape game in the real world, we proposed, in this work, a new type of playing mode by combining the real world environment with virtual world interactions. That is, a mobile application is developed by integrating both bluetooth-based indoor location and augmented reality (AR) techniques, in which people can play the room escape game with their mobile devices to interact with real world objects within virtual world actions.},
annote = {From Duplicate 2 (An Application of Using Bluetooth Indoor Positioning, Image Recognition and Augmented Reality - Tsai, C.-Y.; Hsu, K.-H.)

cited By 1},
author = {Tsai, C.-Y. and Hsu, K.-H.},
booktitle = {2016 IEEE 13th International Conference on e-Business Engineering (ICEBE)},
doi = {10.1109/ICEBE.2016.054},
keywords = {,Augmented reality,Bluetooth,Bluetooth-based,Electronic commerce,Indoor locations,Indoor positio,Indoor positioning systems,augmented reality,computer games,image r},
month = {nov},
pages = {276--281},
title = {{An Application of Using Bluetooth Indoor Positioning, Image Recognition and Augmented Reality}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013031479{\&}doi=10.1109{\%}2FICEBE.2016.054{\&}partnerID=40{\&}md5=d2b926745c3bdc9f5c343d63cb7ed151},
year = {2016}
}
@inproceedings{6311261,
abstract = {Smartphone is the best device to provide the location based service in a query-driven indoor location system, since the query of location based service from the user may appear any time or any where. This paper presents a query-driven indoor location system based on commercial available time of arrival (TOA) devices and Android smartphone. An energy-efficiency dynamic TDMA protocol is designed to localize the target according to the query command. The computing engine, an application for Android phones, is developed to send query command, run the localization algorithm and display the position of the targets. The system can responses the query in 495.72 ms and return the position of the mobile objects with the mean accuracy at 0.99 m. Life time of our protocol is compared with a typical TDMA protocol used in periodic location system. The result shows that our protocol has an improved life time in such a query-driven system.},
annote = {From Duplicate 1 (A query-driven indoor location system based on smartphone - Yu, Y; He, J; Wang, Q; Liu, F; Xu, C)

cited By 3},
author = {And and And and Yu, Y and He, J and Wang, Q and Liu, F and Xu, C},
booktitle = {2012 The First IEEE Workshop on Enabling Technologies for Smartphone and Internet of Things (ETSIoT)},
doi = {10.1109/ETSIoT.2012.6311261},
keywords = {,Computing engines,Indoor location system,Internet,Location based services,Robots,Signal encoding,Smartp,android,indoor radio,mobile handsets,protocols,time divisi},
pages = {25--29},
title = {{A query-driven indoor location system based on smartphone}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868656514{\&}doi=10.1109{\%}2FETSIoT.2012.6311261{\&}partnerID=40{\&}md5=b76ab1798411d814ccb290d5cb30fc52},
year = {2012}
}
@article{Deak:2012:RSA:2371829.2372111,
abstract = {In recent years the need for indoor localisation has increased. Earlier systems have been deployed in order to demonstrate that indoor localisation can be done. Many researchers are referring to location estimation as a crucial component in numerous applications. There is no standard in indoor localisation thus the selection of an existing system needs to be done based on the environment being tracked, the accuracy and the precision required. Modern localisation systems use various techniques such as Received Signal Strength Indicator (RSSI), Time of Arrival (TOA), Time Difference of Arrival (TDOA) and Angle of Arrival (AOA). This paper is a survey of various active and passive localisation techniques developed over the years. The majority of the localisation techniques are part of the active systems class due to the necessity of tags/electronic devices carried by the person being tracked or mounted on objects in order to estimate their position. The second class called passive localisation represents the estimation of a person's position without the need for a physical device i.e. tags or sensors. The assessment of the localisation systems is based on the wireless technology used, positioning algorithm, accuracy and precision, complexity, scalability and costs. In this paper we are comparing various systems presenting their advantages and disadvantages. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
address = {Amsterdam, The Netherlands, The Netherlands},
annote = {From Duplicate 2 (A survey of active and passive indoor localisation systems - Deak, G; Curran, K; Condell, J)

cited By 201},
author = {Deak, Gabriel and Curran, Kevin and Condell, Joan},
doi = {10.1016/j.comcom.2012.06.004},
issn = {0140-3664},
journal = {Comput. Commun.},
keywords = {,Accuracy and precision,Active systems,Angle of a,Estimation,Indoor active localisation,Indoor passive localisation,Location estimation techniques,Surveys,Wireless telecommunication systems},
number = {16},
pages = {1939--1954},
publisher = {Elsevier Science Publishers B. V.},
title = {{Review: A Survey of Active and Passive Indoor Localisation Systems}},
url = {http://dx.doi.org/10.1016/j.comcom.2012.06.004 https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866432123{\&}doi=10.1016{\%}2Fj.comcom.2012.06.004{\&}partnerID=40{\&}md5=a8298a953dc8994a8eb082de3f8d3a45},
volume = {35},
year = {2012}
}
@article{Jiang:2015:TSS:2738225.2738295,
abstract = {Although the object detection and recognition has received growing attention for decades, a robust fire and flame detection method is rarely explored. This paper presents an empirical study, towards a general and solid approach for fast detection of fire and flame in videos, with the applications in video surveillance and event retrieval. Our system consists of three cascaded steps: (1) candidate regions proposing by a background model, (2) fire region classifying with color-texture features and a dictionary of visual words, and (3) temporal verifying. The experimental evaluation and analysis are done for each step. We believe that it is a useful service to both academic research and real-world application. In addition, we release the software of the proposed system with the source code, as well as a public benchmark and data set, including 64 video clips covered both indoor and outdoor scenes under different conditions. We achieve an 82 {\%} Recall with 93 {\%} Precision on the data set, and greatly improve the performance by state-of-the-arts methods. {\textcopyright} 2014, Springer Science+Business Media New York.},
address = {Hingham, MA, USA},
annote = {From Duplicate 1 (Towards a solid solution of real-time fire and flame detection - Jiang, B; Lu, Y; Li, X; Lin, L)

cited By 8},
author = {Jiang, Bo and Lu, Yongyi and Li, Xiying and Lin, Liang},
doi = {10.1007/s11042-014-2106-z},
issn = {1380-7501},
journal = {Multimedia Tools Appl.},
keywords = {,Academic research,Color texture features,Empiri,Empirical study,Fire detection,Fires,Object detection,Object recognition,Region classification,Security systems,Video surveillance},
number = {3},
pages = {689--705},
publisher = {Kluwer Academic Publishers},
title = {{Towards a Solid Solution of Real-time Fire and Flame Detection}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84940265348{\&}doi=10.1007{\%}2Fs11042-014-2106-z{\&}partnerID=40{\&}md5=15b9582febfdf7cbfcace0db6bcd2e91 http://dx.doi.org/10.1007/s11042-014-2106-z},
volume = {74},
year = {2015}
}
@inproceedings{Ramachandran:2007:UFD:1304614.1306797,
address = {Washington, DC, USA},
author = {Ramachandran, Anil and Jagannathan, S and Sarangapani, Jagannathan},
booktitle = {Proceedings of the 32Nd IEEE Conference on Local Computer Networks},
doi = {10.1109/LCN.2007.163},
isbn = {0-7695-3000-1},
keywords = {,Frequency Diversity,Geo-location,Location Accuracy,Location Determination,Selection Combining,Spatial Diversity,WLAN Location Determination},
pages = {117--124},
publisher = {IEEE Computer Society},
series = {LCN '07},
title = {{Spatial Diversity in Signal Strength Based WLAN Location Determination Systems}},
url = {http://dx.doi.org/10.1109/LCN.2007.163 http://dx.doi.org/10.1109/LCN.2007.152},
year = {2007}
}
@inproceedings{8120589,
abstract = {This paper presents an alternative navigation tool that can be used in indoor environment. This is due to restrictions on GPS signals that cannot be detected in indoor locations. The work presented here shows the development of an interactive indoor localization system that uses live input video capture and can identify location markers to indicate its current location. In addition, augmented reality is also used to superimpose augmented reality objects above the location markers to indicate the direction to be taken by the user, which assists the user in navigating to the chosen destination. The developed system was implemented on a Raspberry Pi, an embedded computing platform, with a USB camera and display glasses for the live video capture and display devices respectively. It was tested in Universiti Teknologi PETRONAS' Information Resource Center, across multiple locations and different floors of the center.},
annote = {From Duplicate 1 (Augmented reality assisted localization for indoor navigation on embedded computing platform - Malek, M.F.B.A.; Sebastian, P; Drieberg, M)

cited By 1},
author = {{bin Abdul Malek}, M F and Sebastian, P and Drieberg, M and Malek, M.F.B.A. and Sebastian, P and Drieberg, M},
booktitle = {2017 IEEE International Conference on Signal and Image Processing Applications (ICSIPA)},
doi = {10.1109/ICSIPA.2017.8120589},
keywords = {,Augmented reality,Different floors,Display devices,Embedded computing,Embedded syste,Global,In-door nav,Indoor positioning systems,augmented reality,cameras,embedded systems},
pages = {111--116},
title = {{Augmented reality assisted localization for indoor navigation on embedded computing platform}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041383039{\&}doi=10.1109{\%}2FICSIPA.2017.8120589{\&}partnerID=40{\&}md5=fa6f2a2697343142e0e3a15970a75477},
year = {2017}
}
@inproceedings{7378593,
abstract = {Wi-Fi based indoor positioning, which is based on attenuation of Received Signal Strength Indicator (RSSI) is an emerging Location Based Service (LBS) technology. As positioning accuracy is sensitive to environmental factors, most of the existing algorithms based on experimental test perform badly without adaptation to dynamics of environment. In this paper, we propose an indoor positioning method by locating the representation of a cluster within similar environments. The K-Means algorithm is used to extract the similarities of the objects within the nearby area. To overcome the problem of parameter determination under the circumstances of lack of fingerprint and extra hardware, we proposed a Log-normal shadowing model (LNSM) with Artificial Neural Networks to estimate distance enabling the parameters to be dynamically adjusted according to the change of the environment. The experimental results of one day auto fair data demonstrate the performance of our method with a higher degree of accuracy than other methods.},
annote = {From Duplicate 2 (Self-adaptive Wi-Fi indoor positioning model - Chen, Y; Guo, D; Cui, W; Li, J)

cited By 1},
author = {Chen, Y and Guo, D and Cui, W and Li, J and And},
booktitle = {2015 23rd International Conference on Geoinformatics},
doi = {10.1109/GEOINFORMATICS.2015.7378593},
issn = {2161-024X},
keywords = {,Degree of accuracy,Environmental factors,Indoor,Indoor positioning systems,Location based services,Neural networks,RSSI,Telec,indoor radio,neural nets,telecommunication co},
pages = {1--6},
title = {{Self-adaptive Wi-Fi indoor positioning model}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962361536{\&}doi=10.1109{\%}2FGEOINFORMATICS.2015.7378593{\&}partnerID=40{\&}md5=7fa13e0b5ac352214bbc0abd5f35218a},
volume = {2016-Janua},
year = {2015}
}
@inproceedings{Son:2006:PSU:1169227.1169837,
abstract = {Location positioning of an object is essential technology for Location-Based Services (LBS). Most location positioning systems use specially designed equipment. Because distribution of this specialized equipment is costly, many studies have been conducted on location positioning using only wireless equipment under a wireless LAN infrastructure. A cooperative location positioning system (CLPS) that uses the RSSI (Received Signal Strength Indicator) between mobile equipment, including mobile equipment and access points, requires great concentration in their applications to increase accuracy. This study investigates the relationship between nodes by analyzing a WiPS (Wireless LAN based indoor Positioning System), a similar type of CLPS, and proposes a improved cooperative positioning system to increase performance. {\textcopyright} 2006 IEEE.},
address = {Washington, DC, USA},
annote = {From Duplicate 1 (Positioning system using dynamic location-convergence adjustment factor for wireless LAN infrastructures - Cheolsu, S; Namhyun, Y; Wonjung, K)

cited By 3},
author = {Son, Cheolsu and Yoo, Namhyun and Kim, Wonjung and Cheolsu, S and Namhyun, Y and Wonjung, K},
booktitle = {Proceedings of the Sixth IEEE International Conference on Computer and Information Technology},
doi = {10.1109/CIT.2006.148},
isbn = {0-7695-2687-X},
keywords = {,Indoor Positioning Systems,Location positioning,Mobile devices,Network architecture,Tracking (position),Wireless loc},
pages = {233----},
publisher = {IEEE Computer Society},
series = {CIT '06},
title = {{Positioning System Using Dynamic Location-convergence Adjustment Factor for Wireless LAN Infrastructures}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547348291{\&}doi=10.1109{\%}2FCIT.2006.148{\&}partnerID=40{\&}md5=53496bfb78f2fa54ff4c5c8769e51d1b http://dx.doi.org/10.1109/CIT.2006.148},
year = {2006}
}
@inproceedings{7925162,
abstract = {The RFID (Radio Frequency Identification) localization technology has become one of the most developed technologies owing to its low cost, full-fledged application and flexible deployment. However, current RFID localization system cannot achieve the task of precise and highly accurate object localization due to the limitations of localization algorithm. Traditionally, the localization algorithm cannot make the localization more accuracy. The demand to improve the localization precision is still growing dramatically. LANDMARC system is a typical case that uses virtual tag to improve the overall accuracy of locating moving objects. However, this overall accuracy is fluctuates due to the multipath effect and the various indoor environment. This research work attempts to improve localization precision by using the sensing information network coordination and the log-distance path loss model. From the results, this approach can deliver a localization precision.},
annote = {From Duplicate 1 (LANDMARC with improved k-nearest algorithm for RFID location system - Liu, X; Wen, M; Qin, G; Liu, R)

cited By 4},
author = {And and Liu, X and Wen, M and Qin, G and Liu, R},
booktitle = {2016 2nd IEEE International Conference on Computer and Communications (ICCC)},
doi = {10.1109/CompComm.2016.7925162},
keywords = {,Indoor environment,Information services,Landmarc,Local,Localization,Object recognition,Radio frequency identification (RFID),i,multipath channels,radiofrequency identification},
pages = {2569--2572},
title = {{LANDMARC with improved k-nearest algorithm for RFID location system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020202985{\&}doi=10.1109{\%}2FCompComm.2016.7925162{\&}partnerID=40{\&}md5=3d5a4a3747683bfa4a5cf39f16b4c0ed},
year = {2016}
}
@inproceedings{7844868,
abstract = {In this paper, we propose an indoor action detection system which can automatically keep the log of users' activities of daily life since each activity generally consists of a number of actions. The hardware setting here adopts top-view depth cameras which makes our system less privacy sensitive and less annoying to the users, too. We regard the series of images of an action as a set of key-poses in images of the interested user which are arranged in a certain temporal order and use the latent SVM framework to jointly learn the appearance of the key-poses and the temporal locations of the key-poses. In this work, two kinds of features are proposed. The first is the histogram of depth difference value which can encode the shape of the human poses. The second is the location-signified feature which can capture the spatial relations among the person, floor, and other static objects. Moreover, we find that some incorrect detection results of certain type of action are usually associated with another certain type of action. Therefore, we design an algorithm that tries to automatically discover the action pairs which are the most difficult to be differentiable, and suppress the incorrect detection outcomes. To validate our system, experiments have been conducted, and the experimental results have shown effectiveness and robustness of our proposed method.},
annote = {From Duplicate 2 (Privacy free indoor action detection system using top-view depth camera based on key-poses - Hsu, T.-W.; Yang, Y.-H.; Yeh, T.-H.; Liu, A.-S.; Fu, L.-C.; Zeng, Y.-C.)

cited By 2},
author = {Hsu, T.-W. and Yang, Y.-H. and Yeh, T.-H. and Liu, A.-S. and Fu, L.-C. and Zeng, Y.-C. and And and And},
booktitle = {2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
doi = {10.1109/SMC.2016.7844868},
keywords = {,Activities of Daily Life,Cameras,Cybernetics,Depth camera,Detection,cameras,image capture,object detection,pose estima},
pages = {4058--4063},
title = {{Privacy free indoor action detection system using top-view depth camera based on key-poses}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015782442{\&}doi=10.1109{\%}2FSMC.2016.7844868{\&}partnerID=40{\&}md5=b31560699c79e4650f62337b058e5177},
year = {2016}
}
@inproceedings{Sato2008313,
abstract = {In recent years, in the surveillance system which observes the behavior of human invasion to building or indoor, it is required not only to capture the high quality and wide area image, but also to automatically track to the specific suspicious person in real-time to reduce the number of the required surveillance cameras. While these installations have included a number of video streams, they have been also placed in contexts with limited personnel for monitoring. Using the suggested system, the location of the target motion objects in wide area with 360 degrees surround it can be detected and tracked by capturing high quality images in real-time. {\textcopyright} 2009 IEEE.},
annote = {From Duplicate 1 (A wide area surveillance video system by combination of omni-directional and network controlled cameras - Sato, Y; Hashimoto, K; Shibata, Y)

cited By 0

From Duplicate 2 (A new networked surveillance video system by combination of omni-directional and network controlled cameras - Sato, Y; Hashimoto, K; Shibata, Y)

cited By 5},
author = {Sato, Y and Hashimoto, K and Shibata, Y},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1109/CISIS.2009.192},
keywords = {,Cameras,Computer software,High quality,High quality images,High-quality,High-quality imaging,Information science,Information systems,International,Monitoring,Network-control,Security systems},
pages = {313--322},
title = {{A new networked surveillance video system by combination of omni-directional and network controlled cameras}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349754324{\&}doi=10.1109{\%}2FCISIS.2009.192{\&}partnerID=40{\&}md5=91cc725f0eac9933b4550682d6d3c27d https://www.scopus.com/inward/record.uri?eid=2-s2.0-52149108310{\&}doi=10.1007{\%}2F978-3-540-85693-1{\_}33{\&}partnerID=40{\&}md5=f230cb79c56c5b0a200b16cca478e5da},
volume = {5186 LNCS},
year = {2008}
}
@article{1316849,
abstract = {This paper presents an effective jump-diffusion method for segmenting a range image and its associated reflectance image in the Bayesian framework. The algorithm works on complex real-world scenes (indoor and outdoor), which consist of an unknown number of objects (or surfaces) of various sizes and types, such as planes, conics, smooth surfaces, and cluttered objects (like trees and bushes). Formulated in the Bayesian framework, the posterior probability is distributed over a solution space with a countable number of subspaces of varying dimensions. The algorithm simulates Markov chains with both reversible jumps and stochastic diffusions to traverse the solution space. The reversible jumps realize the moves between subspaces of different dimensions, such as switching surface models and changing the number of objects. The stochastic Langevin equation realizes diffusions within each subspace. To achieve effective computation, the algorithm precomputes some importance proposal probabilities over multiple scales through Hough transforms, edge detection, and data clustering. The latter are used by the Markov chains for fast mixing. The algorithm is tested on 100 1D simulated data sets for performance analysis on both accuracy and speed. Then, the algorithm is applied to three data sets of range images under the same parameter setting. The results are satisfactory in comparison with manual segmentations.},
annote = {From Duplicate 1 (Range image segmentation by an effective jump-diffusion method - Han, F; Tu, Z; Zhu, S.-C.)

cited By 55},
author = {And and Han, F and Tu, Z and Zhu, S.-C.},
doi = {10.1109/TPAMI.2004.70},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {,Algorithms,Artificial Intelligence,Automated,Bayesian formulation,Change point detection,Cluster Anal,Computer simulation,Computer-Assisted,Dat,Edge detection,G,Image segmentation,Imaging,Information Storage and Retrie,Information Storage and Retriev,Pattern Recognition,Photography,Reproducibility of Result,Reproducibility of Results,Statistical,Three-Dimensional,algorithm,article,artificial intelligence,auto,image segmentation,maximum likelihood estimation,p},
number = {9},
pages = {1138--1153},
title = {{Range image segmentation by an effective jump-diffusion method}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-4344570235{\&}doi=10.1109{\%}2FTPAMI.2004.70{\&}partnerID=40{\&}md5=1a4b00fa84b6829a3635ef73db7500c4},
volume = {26},
year = {2004}
}
@article{8573764,
abstract = {Doris, the social robot girl, is under development to be employed in museums and trade fairs as a tour guide. External sensorial information must be inputted so that Doris moves around each new location by using landmark identification points that can improve the real localization of the robot in combination with an extended Kalman filter. Doris is equipped with a semantic map that contains several information points such as the building structure, sites that the robot must pass, features (obstacles) of the built environment, and landmark locations. Three additional sensors were installed on Doris: a laser range finder LMS-200, an omnidirectional Mobotix C25 camera, and an RFID system Speedway Revolution 220 by Impinj. The use of these sensors implies the use of different types of landmarks: 35-cm-high circular landmarks, placed on the ground and covered with a reflective laser-detectable material; markers similar to QR codes placed at 250 cm above the ground level that the omnidirectional camera can identify; and RFID detectable dogbone antennas. One contribution is to prove a simple methodology of localization by using sensor fusion with a semantic map, without mapping the whole environment by creating a point cloud map and without using the SLAM technique. Additionally, another contribution for the research is to define a good methodology for a precise sensors calibration. The initial results showed that each sensor functions efficiently, when using only the laser and the camera, due to the low accuracy of the RFID system alone. The final results show the behavior of the robot localization in the presence of people and different objects when both sensors are working at the same time. Occlusions may affect the reflective landmarks or visual markers. Therefore, the sensor fusion is implemented to achieve better robustness in the location estimation.},
annote = {From Duplicate 2 (Sensor Fusion for Tour-Guide Robot Localization - Vasquez, B.P.E.A.; Gonzalez, R; Matia, F; De La Puente, P)

cited By 0},
author = {Vasquez, B.P.E.A. and Gonzalez, R and Matia, F and {De La Puente}, P and {Alvarado Vasquez}, B P E and Gonzalez, R and Matia, F and {De La Puente}, P},
doi = {10.1109/ACCESS.2018.2885648},
issn = {2169-3536},
journal = {IEEE Access},
keywords = {,Cameras,Extended Kalman filters,Indoor localization,Indoor positioni,Radio frequency identification (RFID),Radiofrequency identification,Rfid localizations,Sensor f,Sensor fusion,Simult},
pages = {78947--78964},
title = {{Sensor Fusion for Tour-Guide Robot Localization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058642958{\&}doi=10.1109{\%}2FACCESS.2018.2885648{\&}partnerID=40{\&}md5=e947d3cafe556d1a4cfd107b9245d720},
volume = {6},
year = {2018}
}
@inproceedings{7442367,
abstract = {In this paper, we present the design and implementation of toy car localization and navigation system, which enables toy cars and "passengers" to learn and exchange their fine-grained locations in an indoor environment with the help of the projected light based localization technique. The projected light consists of a sequence of gray code images which assigns each pixel in the projection area a unique gray code to distinguish their coordination. The light sensors installed on a toy cars and a potential "passenger" receive the light streams from the projected light, based on which their locations are inferred. The toy car then utilizes A* algorithm to plan a route based on its location, its orientation, the target's location and the map of "roads". The fast speed of projected light based localization technique enables the toy car to adjust its own orientation while "driving" and keep itself on "roads". The toy car system demonstrates that the localization technique and the client-server architecture can benefit similar applications that require fine-grained location information of multiple objects simultaneously.},
annote = {From Duplicate 2 (Smart Toy Car Localization and Navigation Using Projected Light - Fan, M; Liu, Q; Ma, S; Chiu, P)

cited By 0},
author = {Fan, M and Liu, Q and Ma, S and Chiu, P},
booktitle = {2015 IEEE International Symposium on Multimedia (ISM)},
doi = {10.1109/ISM.2015.113},
keywords = {,Client server computer systems,Gray codes,Indoor localization,Location,Multi-devices,Navigati,Projected lig,Vehicle locating systems,indoor navigation,optical sensors,smart},
pages = {399--402},
title = {{Smart Toy Car Localization and Navigation Using Projected Light}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969663954{\&}doi=10.1109{\%}2FISM.2015.113{\&}partnerID=40{\&}md5=5a4909097885ba54d12f78aefe64dd07},
year = {2015}
}
@inproceedings{4783693,
abstract = {Ubiquitous sensor networks have become one of the most popular areas for indoor location systems. This paper addresses the problem of tracking a moving object on-line, where location sensors provide position information about a moving object. All of these applications require the position of a device moving at human speeds to be tracked. This scheme presents a cheap and enhanced ranging technique using RSSI, which is achieved by considering the speed variance of the moving object. This proposed scheme applied the method of a sliding window which was used to track a mobile object on-line. The aim of the proposed system is to provide a low cost, simple technique based on RSSIs, provided by ZigBee modules. This paper considers the issues of user privacy, security, and accurate and robust indoor RF location. The analytical results of experimental data demonstrate the efficiency of the proposed RF-based indoor positioning.},
annote = {From Duplicate 2 (On-line ranging for mobile objects using ZIGBEE RSSI measurement - Sharly, J H; Choi, T.-Y.; Park, J.-H.; Kang, S.-H.; Yun, S.-J.; Park, J.-G.)

cited By 10},
author = {Sharly, J H and Choi, T.-Y. and Park, J.-H. J.-G. and Kang, S.-H. and Yun, S.-J. and Park, J.-H. J.-G. and Halder, S J and Choi, T.-Y. and Park, J.-H. J.-G. and Kang, S.-H. and Yun, S.-J. and Park, J.-H. J.-G.},
booktitle = {2008 Third International Conference on Pervasive Computing and Applications},
doi = {10.1109/ICPCA.2008.4783693},
keywords = {,Adaptive filtering,Adaptive filters,Analytical results,Application,Experimental datum,Indoor loc,Tracking (position),personal area networks,tracking,ubiquitous computi},
pages = {662--666},
title = {{On-Line Ranging for Mobile Objects Using ZIGBEE RSSI Measurement}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-64049100386{\&}doi=10.1109{\%}2FICPCA.2008.4783693{\&}partnerID=40{\&}md5=3fd14759e2f07c85866da88708e1b7c1},
volume = {2},
year = {2008}
}
@inproceedings{7139441,
abstract = {We present a novel method based on saliency and segmentation to generate generic object candidates from RGB-D data. Our method uses saliency as a cue to roughly estimate the location and extent of the objects present in the scene. Salient regions are used to glue together the segments obtained from over-segmenting the scene by either color or depth segmentation algorithms, or by a combination of both. We suggest a late-fusion approach that first extracts segments from color and depth independently before fusing them to exploit that the data is complementary. Furthermore, we investigate several mechanisms for ranking the object candidates. We evaluate on one publicly available dataset and on one challenging sequence with a high degree of clutter. The results show that we are able to retrieve most objects in real-world indoor scenes and clearly outperform other state-of-the art methods.},
annote = {From Duplicate 2 (Saliency-based object discovery on RGB-D data with a late-fusion approach - Garcia, G M; Potapova, E; Werner, T; Zillich, M; Vincze, M; Frintrop, S)

cited By 12},
author = {Garcia, G M and Potapova, E and Werner, T and Zillich, M and Vincze, M and Frintrop, S and Garc{\'{i}}a, G M and Potapova, E and Werner, T and Zillich, M and Vincze, M and Frintrop, S},
booktitle = {2015 IEEE International Conference on Robotics and Automation (ICRA)},
doi = {10.1109/ICRA.2015.7139441},
issn = {1050-4729},
keywords = {,Image segmentation,Late fusion,Real-world,Robotics,Salient regions,Segment,image colour analysis,image fusion,image segmentat},
number = {June},
pages = {1866--1873},
title = {{Saliency-based object discovery on RGB-D data with a late-fusion approach}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938233189{\&}doi=10.1109{\%}2FICRA.2015.7139441{\&}partnerID=40{\&}md5=2fe7faf592b9de82f6802100d247d6c4},
volume = {2015-June},
year = {2015}
}
@inproceedings{4686682,
abstract = {Scout Floor is a unique floor surface having a low cost sensor interface for a wide variety of applications. It is a floor surface that is an interactive information map from which data can be read or written. Scout Floor is an enabling technology that allows for indoor location of objects. The regular array of passive RFID sensors in the floor makes an x-y grid that allows a position map to be generated so an objectpsilas position and path is known. We have proved that HF and UHF RFID tags can be read through carpet tiles and have examined the effect of water on the carpet and the durability of the tags under the carpet. We have also formed partnership with companies that plan to use our embedded flooring system in their applications. With a maintenance partner we are working to verify that cleaning has been done as well as a record can be generated of a piece of equipment current and past position. It creates a platform that can be used for in-door robotics navigation, people and equipment location, safety in the home and industry, security, personal and handicap assistance, asset management, and entertainment.},
annote = {From Duplicate 2 (Embedded sensor scout flooring system by interface flor - Chung, H Z; Fezer, S F)

cited By 4},
author = {Chung, H Z and Fezer, S F and Zah, C H and Fezer, S F},
booktitle = {2008 IEEE International Conference on Technologies for Practical Robot Applications},
doi = {10.1109/TEPRA.2008.4686682},
issn = {2325-0526},
keywords = {,Applications,Asset management,Building materials,Effect of waters,Embedded sensors,Enabling tech,Floors,carpets,embedded systems,intelligent sensors,radio},
month = {nov},
pages = {106--110},
title = {{Embedded sensor Scout flooring system by Interface Flor}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-58049163979{\&}doi=10.1109{\%}2FTEPRA.2008.4686682{\&}partnerID=40{\&}md5=8b0d33b3f294f3fa715dfcde2c6b0583},
year = {2008}
}
@inproceedings{8491649,
abstract = {The main goal of this paper is to propose a technique that can transform a simple object into an autonomous object, which is an object that can move autonomously inside an indoor environment. In short, it consists of a location system, an embedded board and a human interface that should allow a vehicle to move through environments with as minimum human intervention as possible. The methodology explored in this work can be applied to different kinds of objects: for example, an industrial vehicle, a ground support vehicle or even an electric wheelchair. The algorithm proposed is simple and also efficient to complete the goal of controlling the trajectory because it relates external sensors inside the place with the concept of fuzzy clustering, aka the fuzzy c-means algorithm. This was used in order to control the displacement of the autonomous object.},
annote = {From Duplicate 1 (Trajectory tracking control based in fuzzy concepts - De Almeida, L H L; Aguiar, R)

cited By 0},
author = {{Lopes de Almeida}, L H and Aguiar, R and {De Almeida}, L H L and Aguiar, R},
booktitle = {2018 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)},
doi = {10.1109/FUZZ-IEEE.2018.8491649},
keywords = {,Clustering algorithms,Copying,Electric wheelchair,Fuzzy C-means algorithms,Fuzzy clustering,Fuzzy systems,Hu,Indoor p,control engineering computing,fuzzy set theory,han},
pages = {1--7},
title = {{Trajectory Tracking Control Based in Fuzzy Concepts}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060477257{\&}doi=10.1109{\%}2FFUZZ-IEEE.2018.8491649{\&}partnerID=40{\&}md5=ad3c2cf75fb172a7b6f7c0993712e3a8},
volume = {2018-July},
year = {2018}
}
@inproceedings{5354738,
abstract = {The real time requirement is an additional constraint on many intelligent applications in robotics, such as shape recognition and retrieval using a mobile robot platform. In this paper, we present a scalable approach for efficiently retrieving closed contour shapes. The contour of an object is represented by piecewise linear segments. A skip Tri-Gram is obtained by selecting three segments in the clockwise order while allowing a constant number of segments to be skipped in between. The main idea is to use skip Tri-Grams of the segments to implicitly encode the distant dependency of the shape. All skip Tri-Grams are used for efficiently retrieving closed contour shapes without pairwise matching feature points from two shapes. The retrieval is at least an order of magnitude faster than other state-of-the-art algorithms. We score 80{\%} in the Bullseye retrieval test on the whole MPEG 7 shape dataset. We further test the algorithm using a mobile robot platform in an indoor environment. 8 objects are used for testing from different viewing directions, and we achieve 82{\%} accuracy.},
annote = {From Duplicate 1 (Real-time shape retrieval for robotics using skip Tri-Grams - Li, Y; Bitsakos, K; Fermuller, C; Aloimonos, Y)

cited By 1},
author = {Yi, L and Bitsakos, K and Fermuller, C and Aloimonos, Y and Li, Y and Bitsakos, K and Fermuller, C and Aloimonos, Y},
booktitle = {2009 IEEE/RSJ International Conference on Intelligent Robots and Systems},
doi = {10.1109/IROS.2009.5354738},
issn = {2153-0858},
keywords = {,Bullseye,Closed contours,Data sets,Environmental testing,Feature poin,Intelligent robots,Mobile robots,Motion Picture,image retrieval,image segmentation,mobile robots,p},
pages = {4731--4738},
title = {{Real-time shape retrieval for robotics using skip Tri-Grams}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-76249110215{\&}doi=10.1109{\%}2FIROS.2009.5354738{\&}partnerID=40{\&}md5=cfe186c289a4943cbb5e5edd08e68acd},
year = {2009}
}
@article{Sertatil:2012:NAI:2169486.2170022,
abstract = {Nowadays outdoor location systems have been used extensively in all fields of human life from military applications to daily life. However, these systems cannot operate in indoor applications. Hence, this paper considers a novel indoor location system that aims to locate an object within an accuracy of about 2 cm using ordinary and inexpensive off-the-shelf devices and that was designed and tested in an office room to evaluate its performance. In order to compute the distance between the transducers (speakers) and object to be localized (microphone), time-of-arrival measurements of acoustic signals consisting of Binary Phase Shift Keying modulated Gold sequences are performed. This DS-CDMA scheme assures accurate distance measurements and provides immunity to noise and interference. Two methods have been proposed for location estimation. The first method takes the average of four location estimates obtained by trilateration technique. In the second method, only a single robust position estimate is obtained using three distances while the least reliable fourth distance measurement is not taken into account. The system's performance is evaluated at positions from two height levels using system parameters determined by preliminary experiments. The precision distributions in the work area and the precision versus accuracy plots depict the system performance. The proposed system provides location estimates of better than 2 cm accuracy with 99{\%} precision. {\textcopyright} 2011 Elsevier Inc. All rights reserved.},
address = {Orlando, FL, USA},
annote = {From Duplicate 1 (A novel acoustic indoor localization system employing CDMA - Sertatil, C; Altinkaya, M A; Raoof, K)

cited By 32},
author = {Sertat$\backslash$il, Cem and Alt$\backslash$inkaya, Mustafa A and Raoof, Kosai and Sertatil, C and Altinkaya, M A and Raoof, Kosai},
doi = {10.1016/j.dsp.2011.12.001},
issn = {1051-2004},
journal = {Digit. Signal Process.},
keywords = {,Acoustic fields,Acoustic localization,DS-CDMA,Distance measurement,Estimation,Indoor localizatio,Indoor localization,Military applic,Spread spectrum,Time of arrival},
number = {3},
pages = {506--517},
publisher = {Academic Press, Inc.},
title = {{A Novel Acoustic Indoor Localization System Employing CDMA}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858707959{\&}doi=10.1016{\%}2Fj.dsp.2011.12.001{\&}partnerID=40{\&}md5=5e15b22b895d610405146ef0760cd9ae http://dx.doi.org/10.1016/j.dsp.2011.12.001},
volume = {22},
year = {2012}
}
@inproceedings{4340304,
abstract = {Location-awareness is a crucial trait of the mobile computing applications. The RFID is not only a feasible, novel, and cost-effective candidate for the indoor location sensing but also considered as the bridge which can merge physical world with hyperspace. Our study focuses on a location-aware computing architecture which provides the scalable location-based services for tracking nearly all daily objects by utilizing the RFID tags. The paper presents a hierarchical structure to organize the position areas based on tracking zone of interest (TZOI). Because the context is vital for mobile computing and can enable the revolution in computing model, a method of managing the location-centric context record is brought forward. We further propose an approach to aware the object's intentions and requirements which are varying over location by tracing and matching these records. An original application experimenting on the baggage handling in the airport also demonstrates the location awareness, e.g., when the baggage has been automatically sorted and arrives the correct place, one SMS is delivered to the owner's mobile phone to remind him.},
annote = {From Duplicate 2 (A scalable RFID-based system for location-aware services - Ting, Z; Yuanxin, O; Chao, L; Zhang, X)

cited By 6},
author = {Ting, Z and Yuanxin, O and Chao, L and Zhang, X and Zhang, T and Ouyang, Y and Li, C and Xiong, Z},
booktitle = {2007 International Conference on Wireless Communications, Networking and Mobile Computing},
doi = {10.1109/WICOM.2007.529},
issn = {2161-9646},
keywords = {,Computer architecture,Electronic document identification systems,Indoor location sensing,Loca,Location awareness,Mathematical models,Mobile,mob,mobile computing,radiofrequency identification},
pages = {2117--2123},
title = {{A Scalable RFID-Based System for Location-Aware Services}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-38049047519{\&}doi=10.1109{\%}2FWICOM.2007.529{\&}partnerID=40{\&}md5=3c790910cb7c9453d3f5a4d4f40ed95f},
year = {2007}
}
@inproceedings{Halder:2008:ERU:1497308.1497374,
abstract = {The wireless sensor network is an emerging technology that may greatly facilitate human life by providing ubiquitous sensing, computing, and communication capability. To be context-aware, one of the central issues in sensor networks is location tracking. The accurate location of objects in indoor environments is a key aspect of many applications such as resource management or security. Ubiquitous indoor environments often contain substantial amounts of metal and other such reflective materials that affect the propagation of radio frequency signals in non-trivial ways, causing severe multi-path effects, dead-spots, noise, and interference. This scheme is presenting a cheap and enhanced ranging technique rather than other existing technique by making a fusion of RSSI and LQI that is particularly well suited to support context-aware computing. The aim of the proposed system is to provide a low cost, simple technique based on RSSI and LQI values, provided by the ZigBee module, which also without considering any needs to change the system according to specific indoor environments. This paper considers the issues of a user's privacy, security, and an accurate and robust indoor RF location. The analytical results demonstrate the efficiency of the proposed RF-based indoor location determination. {\textcopyright} 2008 ACM.},
address = {New York, NY, USA},
annote = {From Duplicate 1 (Enhanced ranging using adaptive filter of ZIGBEE RSSI and LQI measurement - Haider, S J; Choi, T.-Y.; Park, J.-H.; Kang, S.-H.; Park, S.-W.; Park, J.-G.)

cited By 14},
author = {Halder, Sharly Joana and Choi, Tae Young T.-Y. and Park, J.-H. Joon Goo J.-G. Jin Hyung and Kang, S.-H. Sung Hun and Park, Sin Woo S.-W. and Park, J.-H. Joon Goo J.-G. Jin Hyung and Haider, S J and Choi, Tae Young T.-Y. and Park, J.-H. Joon Goo J.-G. Jin Hyung and Kang, S.-H. Sung Hun and Park, Sin Woo S.-W. and Park, J.-H. Joon Goo J.-G. Jin Hyung},
booktitle = {Proceedings of the 10th International Conference on Information Integration and Web-based Applications {\&} Services},
doi = {10.1145/1497308.1497374},
isbn = {978-1-60558-349-5},
keywords = {,Accurate location,Adaptive filtering,Adaptive filters,Analytical results,Communicati,LQI,RSSI,Wireless sensor networks,ZigBee,adaptive filter,indoor locationing},
pages = {367--373},
publisher = {ACM},
series = {iiWAS '08},
title = {{Enhanced Ranging Using Adaptive Filter of ZIGBEE RSSI and LQI Measurement}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349084845{\&}doi=10.1145{\%}2F1497308.1497374{\&}partnerID=40{\&}md5=058615fcc22113277607ce0a317c6f96 http://doi.acm.org/10.1145/1497308.1497374},
year = {2008}
}
@inproceedings{4068313,
abstract = {In this work we show how to reduce the computational cost of using Bayesian networks for localization. We investigate a range of Monte Carlo sampling strategies, including Gibbs and Metropolis. We found that for our Gibbs samplers, most of the time is spent in slice sampling. Moreover, our results show that although uniform sampling over the entire domain suffers occasional rejections, it has a much lower overall computational cost than approaches that carefully avoid rejections. The key reason for this efficiency is the flatness of the full conditionals in our localization networks. Our sampling technique is also attractive because it does not require extensive tuning to achieve good performance, unlike the Metropolis samplers. We demonstrate that our whole domain sampling technique converges accurately with low latency. On commodity hardware our sampler localizes up to 10 points in less than half a second, which is over 10 times faster than a common general-purpose Bayesian sampler. Our sampler also scales well, localizing 51 objects with no location information in the training set in less than 6 seconds. Finally, we present an analytic model that describes the number of evaluations per variable using slice sampling. The model allows us to analytically determine how flat a distribution should be so that whole domain sampling is computationally more efficient when compared to other methods},
annote = {From Duplicate 1 (Reducing the computational cost of Bayesian indoor positioning systems - Kleisouris, K; Martin, R P)

cited By 6},
author = {Kleisounis, K and Martin, R P and Kleisouris, K and Martin, R P},
booktitle = {2006 3rd Annual IEEE Communications Society on Sensor and Ad Hoc Communications and Networks},
doi = {10.1109/SAHCN.2006.288512},
issn = {2155-5486},
keywords = {,Bayes methods,Bayesian indoor positioning systems,Bayesian networks,Computational,Computational complexity,Information analysis,M,cost reduction,indoor communication},
pages = {555--564},
title = {{Reducing the Computational Cost of Bayesian Indoor Positioning Systems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-44049094957{\&}doi=10.1109{\%}2FSAHCN.2006.288512{\&}partnerID=40{\&}md5=696b2cc7df7aa8bc88bb5c4fa6bf907f},
volume = {2},
year = {2006}
}
@inproceedings{Goncalo:2009:ILS:1607720.1608007,
abstract = {This paper describes a location system for persons and objects in an indoor environment, where wireless nodes can include sensors and provide unique identifiers. The system nodes, using ZigBee technology, can function as RFID tags, having each one a unique EPC identification number. Sensors can be associated with the wireless nodes Zigbee to create applications for home, health and traffic control. Location systems are analysed with emphasis on indoor location systems.The implemented location algorithm includes a propagation model based on the wall attenuation factor propagation model together with triangulation. A variety of tests were carried out in an indoor environment. Results demonstrate that the location system is viable, showing itself to be effective, flexible and easily adaptable to various locations. {\textcopyright} 2009 IEEE.},
address = {Washington, DC, USA},
annote = {From Duplicate 1 (Indoor location system using ZigBee technology - Gon{\c{c}}alo, G; Helena, S)

cited By 44},
author = {Goncalo, Gomes and Helena, Sarmento and Gon{\c{c}}alo, G and Helena, Sarmento},
booktitle = {Proceedings of the 2009 Third International Conference on Sensor Technologies and Applications},
doi = {10.1109/SENSORCOMM.2009.31},
isbn = {978-0-7695-3669-9},
keywords = {,Environmental testing,Identification number,Indoor,Indoor environment,Location,Propagation,Radio navigation,Sensors,Triangulation,WAF,ZigBee},
pages = {152--157},
publisher = {IEEE Computer Society},
series = {SENSORCOMM '09},
title = {{Indoor Location System Using ZigBee Technology}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449466620{\&}doi=10.1109{\%}2FSENSORCOMM.2009.31{\&}partnerID=40{\&}md5=30ca40305f6798194edfb712c68e2be9 https://doi.org/10.1109/SENSORCOMM.2009.31},
year = {2009}
}
@inproceedings{6835242,
abstract = {Nowadays ICT technology is infiltrated to all areas of human existence and the number of objects, animate or inanimate, actively acting within Internet services is rapidly growing. The reasons of object monitoring are permanently changing and evolving, following the development of public and non-public sectors. For example using of various tags, stuck on goods, are used for goods identification in stores and for security reasons for many years. Further, the assets identification using passive tags turns to active identification enabling automatic inventorying and permanent assets protection at the same time. Active identification provides also the remote monitoring of objects, moreover, when object's data are safely shared on Internet environment, a number of cloud services can be enabled to allow customers remote monitoring of objects. Based on such ICT environment, the architecture called Internet of Things is ready to come to daily life. The objects considered in such systems can be home appliances, medical devices, building assets, computers, mobile devices, cars, production components, manufacturing tools, building materials and, of course, people. Especially the bindings and relations among objects, for example an identified person having an expensive identified device and passing unauthorized zone is evaluated as a risk transaction resulting to a denied access. Beside the object identification the differentiation of static and moving objects brings a new important parameter to improve the IoT concept.},
annote = {From Duplicate 1 (System for simultaneous object identification {\&} sector indoor localization (OIDSIL) - Holy, R; Kalika, M; Kalikova, J; Havlik, J; Barak, P; Neburka, J)

cited By 0},
author = {Hol{\'{y}}, R and Kalika, M and Kalikov{\'{a}}, J and Havlik, J and Barak, P and Neburka, J and Holy, R and Kalika, M and Kalikova, J and Havlik, J and Barak, P and Neburka, J},
booktitle = {2014 International Conference on Intelligent Green Building and Smart Grid (IGBSG)},
doi = {10.1109/IGBSG.2014.6835242},
keywords = {,Biomedical equipment,Domestic appliances,Identif,Indoor localization,Information technology,Internet environment,Internet of Things,Object,indoor radio,o,object detection},
pages = {1--4},
title = {{System for simultaneous object identification amp; sector indoor localization (OIDSIL)}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903821747{\&}doi=10.1109{\%}2FIGBSG.2014.6835242{\&}partnerID=40{\&}md5=b24b0d61d688d8301ab14ac1c241847f},
year = {2014}
}
@inproceedings{JacquesJr.:2005:BSS:1114697.1115354,
abstract = {Tracking moving objects in video sequence is an important problem in computer vision, with applications several fields, such as video surveillance and target tracking. Most techniques reported in the literature use background subtraction techniques to obtain foreground objects, and apply shadow detection algorithms exploring spectral information of the images to retrieve only valid moving objects. In this paper, we propose a small improvement to an existing background model, and incorporate a novel technique for shadow detection in grayscale video sequences. The proposed algorithm works well for both indoor and outdoor sequences, and does not require the use of color cameras.},
address = {Washington, DC, USA},
author = {Jacques, J C S and Jung, Claudio Rosito and Musse, Soraia Raupp and {Jacques Jr.}, Julio Cezar Silveira and Jung, Claudio Rosito and Musse, Soraia Raupp},
booktitle = {Proceedings of the XVIII Brazilian Symposium on Computer Graphics and Image Processing},
doi = {10.1109/SIBGRAPI.2005.15},
isbn = {0-7695-2389-7},
issn = {1530-1834},
keywords = {,Compute,Gray-scale,Target tracking,Video sequences},
pages = {189----},
publisher = {IEEE Computer Society},
series = {SIBGRAPI '05},
title = {{Background Subtraction and Shadow Detection in Grayscale Video Sequences}},
url = {https://doi.org/10.1109/SIBGRAPI.2005.15},
year = {2005}
}
@inproceedings{8650371,
abstract = {This paper details a system that provides positioning, obstacle detection and avoidance, pathfinding, and energy monitoring suitable for indoor operation designed for the Crazyflie 2.0 drone. The positioning subsystem was achieved by a hybrid of Received Signal Strength Indicators and Dead Reckoning. Obstacle detection and avoidance used an IR sensor to detect objects in the drone's path, allowing the drone to look for alternate paths. Pathfinding used a modified Node Array A* algorithm implemented in a 3D model of the testing area within the Unity engine. Finally, energy monitoring used the drone's built-in Python library to log voltage values and were sent to the Unity system, which reroutes the drone upon detecting a low battery voltage. The system was able to provide a basic autonomous navigation system that prioritizes safety of the drone and its flying environment.},
annote = {From Duplicate 2 (Automated Indoor Drone Flight with Collision Prevention - Lagmay, J M S; Jed Leyba, L C; Santiago, A T; Tumabotabo, L B; Limjoco, W J R; Michael Tiglao, N C)

cited By 0},
author = {Lagmay, J M S and {Jed Leyba}, L C and Santiago, A T and Tumabotabo, L B and Limjoco, W J R and {Michael Tiglao}, N C and {Jed C. Leyba}, L and Santiago, A T and Tumabotabo, L B and Limjoco, W J R and {Michael C. Tiglao}, N},
booktitle = {TENCON 2018 - 2018 IEEE Region 10 Conference},
doi = {10.1109/TENCON.2018.8650371},
issn = {2159-3450},
keywords = {,3D modeling,Aircraft detection,Alternate path,Autonomous navigation systems,Ba,Drones,Navigation systems,Object de,aircraft control,autonomous aerial vehicles,mobile},
pages = {1762--1767},
title = {{Automated Indoor Drone Flight with Collision Prevention}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063236207{\&}doi=10.1109{\%}2FTENCON.2018.8650371{\&}partnerID=40{\&}md5=b9be8180ed7ef172857e3fda0f895ae2},
volume = {2018-Octob},
year = {2018}
}
@article{Will:2017:ARL:3163944.3164071,
abstract = {Social interaction between animals may influence disease transmission paths. Therefore, the usage of real-time location systems gains in importance for livestock farms and research institutes as this technology helps to simultaneously obtain positions of a large number of animals and to evaluate them automatically. Thus, the aim of the project was to specify the accuracy of the real-time location system under practical conditions with regard to a possible future application. In practice, ear tags have proven their worth because pigs manipulate and therefore destroy other objects applied to them in the long term. Therefore, a real-time location system was used providing the sending unit integrated in an ear tag. Ear tags were tested in a sows' gestation stall in static positions. Measuring took place for 5 min per static position, whereas data was transmitted once per second (1 Hz) which led to 300 data points per position. Metal pen equipment led to lost or noisy positions. On average, 9{\%} of data losses occurred and were inserted for the following data evaluation. A Haar wavelet was applied to reduce the noise. Filter settings were rated with the help of an error size consisting of the Euclidean error and an error for the variance of the filtered signal. An optimal filter setting could be achieved when only the 29 largest coefficients for the X axis and 20 largest coefficients for the Y axis were kept while all others were set to 0. Additionally, a t-test was performed to test whether an averaged number of coefficients over all ear tags and an optimal individual filtering of each single ear tag resulted in a significantly different filter result. P-values of the t-test were 0.15 (X coordinate) and 0.18 (Y coordinate) and therefore not significant. Thus, an averaged filter setting can be applied to all ear tags. The median accuracy of measured data described as Euclidean distance was 2.7 m before filtering and improved to 2.0 m after filtering. Considering the results of this system investigation, it shows that the system may be helpful for ensuing studies regarding e.g. animal behaviour, movement profiles, or social networks to uncover possible transmission paths for diseases. {\textcopyright} 2017 The Authors},
address = {Amsterdam, The Netherlands, The Netherlands},
annote = {From Duplicate 1 (Accuracy of a real-time location system in static positions under practical conditions: Prospects to track group-housed sows - Will, M K; B{\"{u}}ttner, K; Kaufholz, T; M{\"{u}}ller-Graf, C; Selhorst, T; Krieter, J)

cited By 1},
author = {Will, Maike K and Bttner, Kathrin and Kaufholz, Tobias and Mller-Graf, Christine and Selhorst, Thomas and Krieter, Joachim and B{\"{u}}ttner, K and Kaufholz, Tobias and M{\"{u}}ller-Graf, C and Selhorst, Thomas and Krieter, Joachim},
doi = {10.1016/j.compag.2017.09.020},
issn = {0168-1699},
journal = {Comput. Electron. Agric.},
keywords = {,Accuracy,Agriculture,Animalia,Animals,Data filtering,Disease transmission,Errors,Indoor sow tracking,Location,Median fil,R,Real time systems,Real-time location system,Suidae,Wavelet,accuracy assessment,data acquisition,disease tr},
number = {PA},
pages = {473--484},
publisher = {Elsevier Science Publishers B. V.},
title = {{Accuracy of a Real-time Location System in Static Positions Under Practical Conditions}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030331218{\&}doi=10.1016{\%}2Fj.compag.2017.09.020{\&}partnerID=40{\&}md5=1701e075062935b8ec4eb52cd6b4997b https://doi.org/10.1016/j.compag.2017.09.020},
volume = {142},
year = {2017}
}
@inproceedings{8633287,
abstract = {Indoor Positioning System (IPS) is a technology that provides precise and accurate location information in indoor environments. Since Global Positioning system (GPS) relies on line of sight communications with a satellite transceiver, it does not work within buildings. To overcome this challenge, IPS technology could use RF based communication and locate humans and objects indoors. The key advantage of RF based communication is its high coverage range and non-line of sight communications. Wi-Fi finger printing is an efficient RF based technique for IPS which utilizes signal strength of wireless LAN to identify different indoor locations. In this paper, we develop an experimental testbed to implement Wi-Fi fingerprinting based IPS. We analyse the performance of Wi-Fi fingerprinting based IPS for three different indoor scenarios. Results show that Wi-Fi finger printing based IPS accurately predicts user location when the multi-path fading is low and access points are closer to the user.},
annote = {From Duplicate 1 (Performance evaluation of Wi-Fi finger printing based indoor positioning system - Husnain Lodhi, N U; Malik, A; Zulfiqar, T; Javed, M A; Nafi, N S)

cited By 0},
author = {{u. Husnain Lodhi}, N and Malik, A and Zulfiqar, T and Javed, M A and Nafi, N S and {Husnain Lodhi}, N U and Malik, A and Zulfiqar, T and Javed, M A and Nafi, N S},
booktitle = {2018 IEEE Conference on Wireless Sensors (ICWiSe)},
doi = {10.1109/ICWISE.2018.8633287},
keywords = {,Experimental testbed,Global positioning system,Indoor positioning,Indoor positioning syst,Line of,Wireless local area networks (WLAN),indoor navigation,indoor radio,performance evaluat},
month = {nov},
pages = {56--61},
title = {{Performance Evaluation of Wi-Fi Finger Printing based Indoor Positioning System}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062827722{\&}doi=10.1109{\%}2FICWISE.2018.8633287{\&}partnerID=40{\&}md5=ad279e9e8fd6c89d9c91616f8e031647},
year = {2018}
}
@article{Ni:2004:LIL:1035678.1035686,
abstract = {Growing convergence among mobile computing devices and embedded technology sparks the development and deployment of "context-aware" applications, where location is the most essential context. In this paper we present LANDMARC, a location sensing prototype system that uses Radio Frequency Identification (RFID) technology for locating objects inside buildings. The major advantage of LANDMARC is that it improves the overall accuracy of locating objects by utilizing the concept of reference tags. Based on experimental analysis, we demonstrate that active RFID is a viable and cost-effective candidate for indoor location sensing. Although RFID is not designed for indoor location sensing, we point out three major features that should be added to make RFID technologies competitive in this new and growing market. {\textcopyright} 2003 IEEE.},
address = {Secaucus, NJ, USA},
annote = {From Duplicate 1 (LANDMARC: Indoor location sensing using active RFID - Lionel, M N; Liu, Y; Lau, Y C; Patil, A P)

cited By 1124

From Duplicate 2 (LANDMARC: Indoor location sensing using active RFID - Ni, L M; Liu, Y; Lau, Y C; Patil, A P)

cited By 720},
author = {Ni, Lionel M and Liu, Yunhao and Lau, Yiu Cho and Patil, Abhishek P and Lionel, M N and Liu, Yunhao and Lau, Yiu Cho and Patil, Abhishek P},
doi = {10.1023/B:WINE.0000044029.06344.dd},
issn = {1022-0038},
journal = {Wirel. Netw.},
keywords = {,Active RFID,Cellular telephone systems,Context-Aware,E,Embedded technology,Global positioning sys,Location,Location-aware computing,Mobile computing,RFID,Radio frequency identification (RFID),Sensing network,Signal,Ubiquitous,location-aware computing,sensing network,signal strength,wireless communication},
number = {6},
pages = {701--710},
publisher = {Springer-Verlag New York, Inc.},
title = {{LANDMARC: Indoor location sensing using active RFID}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-5544326540{\&}doi=10.1023{\%}2FB{\%}3AWINE.0000044029.06344.dd{\&}partnerID=40{\&}md5=e7c4c11df1649a5bd8ecd1069a005ce2 https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649697822{\&}partnerID=40{\&}md5=e1912949cf296898b76777ff31aa2836 http://dx.doi.org/10.1023/B:WINE.0000044029.06344.dd},
volume = {10},
year = {2004}
}
